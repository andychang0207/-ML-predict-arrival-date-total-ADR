{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\r09922110\\anaconda3\\envs\\ML\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime,time\n",
    "a = datetime.datetime.strptime('2015-07-01',\"%Y-%m-%d\")\n",
    "b = datetime.datetime.strptime('2015-07-02',\"%Y-%m-%d\")\n",
    "(b - a).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91531, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>stays_total_nights</th>\n",
       "      <th>booking_total_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.305161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>225.156681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>223.639203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>229.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>148.234941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>873.987482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.466305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>181.629107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>419.491216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>116.392941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342              2015   \n",
       "1          1    City Hotel            0        257              2015   \n",
       "2          2    City Hotel            0        257              2015   \n",
       "3          3    City Hotel            0        257              2015   \n",
       "4          4    City Hotel            0        257              2015   \n",
       "...      ...           ...          ...        ...               ...   \n",
       "91525  91525  Resort Hotel            0         72              2017   \n",
       "91527  91527  Resort Hotel            0         28              2017   \n",
       "91528  91528  Resort Hotel            0          2              2017   \n",
       "91529  91529  Resort Hotel            0         30              2017   \n",
       "91530  91530  Resort Hotel            0          1              2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number arrival_date_day_of_month  \\\n",
       "0                     07                        27                        01   \n",
       "1                     07                        27                        01   \n",
       "2                     07                        27                        01   \n",
       "3                     07                        27                        01   \n",
       "4                     07                        27                        01   \n",
       "...                  ...                       ...                       ...   \n",
       "91525                 03                        13                        31   \n",
       "91527                 03                        13                        31   \n",
       "91528                 03                        13                        31   \n",
       "91529                 03                        13                        31   \n",
       "91530                 03                        13                        31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  customer_type  \\\n",
       "0                            0                     0  ...      Transient   \n",
       "1                            0                     2  ...      Transient   \n",
       "2                            0                     2  ...      Transient   \n",
       "3                            0                     2  ...      Transient   \n",
       "4                            0                     2  ...      Transient   \n",
       "...                        ...                   ...  ...            ...   \n",
       "91525                        3                     7  ...       Contract   \n",
       "91527                        0                     2  ...      Transient   \n",
       "91528                        0                     1  ...      Transient   \n",
       "91529                        3                     7  ...      Transient   \n",
       "91530                        0                     1  ...      Transient   \n",
       "\n",
       "             adr  required_car_parking_spaces total_of_special_requests  \\\n",
       "0      -6.305161                            0                         0   \n",
       "1      75.052227                            0                         0   \n",
       "2      74.546401                            0                         0   \n",
       "3      76.376288                            0                         0   \n",
       "4      49.411647                            0                         0   \n",
       "...          ...                          ...                       ...   \n",
       "91525  79.453407                            0                         1   \n",
       "91527  -6.822102                            0                         0   \n",
       "91528  90.814554                            0                         2   \n",
       "91529  38.135565                            0                         1   \n",
       "91530  58.196470                            0                         1   \n",
       "\n",
       "      reservation_status reservation_status_date arrival_date  \\\n",
       "0              Check-Out              2015-07-01   2015-07-01   \n",
       "1              Check-Out              2015-07-03   2015-07-01   \n",
       "2              Check-Out              2015-07-03   2015-07-01   \n",
       "3              Check-Out              2015-07-03   2015-07-01   \n",
       "4              Check-Out              2015-07-03   2015-07-01   \n",
       "...                  ...                     ...          ...   \n",
       "91525          Check-Out              2017-04-10   2017-03-31   \n",
       "91527          Check-Out              2017-04-02   2017-03-31   \n",
       "91528          Check-Out              2017-04-01   2017-03-31   \n",
       "91529          Check-Out              2017-04-10   2017-03-31   \n",
       "91530          Check-Out              2017-04-01   2017-03-31   \n",
       "\n",
       "       date_difference  stays_total_nights  booking_total_revenue  \n",
       "0               1 days                   0              -6.305161  \n",
       "1               3 days                   2             225.156681  \n",
       "2               3 days                   2             223.639203  \n",
       "3               3 days                   2             229.128863  \n",
       "4               3 days                   2             148.234941  \n",
       "...                ...                 ...                    ...  \n",
       "91525          11 days                  10             873.987482  \n",
       "91527           3 days                   2             -20.466305  \n",
       "91528           2 days                   1             181.629107  \n",
       "91529          11 days                  10             419.491216  \n",
       "91530           2 days                   1             116.392941  \n",
       "\n",
       "[70457 rows x 37 columns]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meal, \n",
    "def preprocessing(train):\n",
    "    month_to_num ={'January':'01','February':'02','March':'03','April':'04','May':'05','June':'06','July':'07','August':'08','September':'09','October':'10','November':'11','December':'12'}\n",
    "    train_month_to_num = train.copy()\n",
    "    train_month_to_num.arrival_date_month = train_month_to_num.arrival_date_month.map(month_to_num)\n",
    "    train_month_to_num.arrival_date_day_of_month = train_month_to_num.arrival_date_day_of_month.astype('str')\n",
    "    day_to_str = {}\n",
    "    for i in range(1,32):\n",
    "        if i<10:\n",
    "            day_to_str[str(i)]='0'+str(i)\n",
    "        else:\n",
    "            day_to_str[str(i)]=str(i)\n",
    "    train_month_to_num.arrival_date_day_of_month = train_month_to_num.arrival_date_day_of_month.map(day_to_str)\n",
    "    train_groupby_date_count = train_month_to_num.groupby(['arrival_date_year','arrival_date_month','arrival_date_day_of_month']).count()\n",
    "    train_groupby_date_count.index = [train_groupby_date_count.index.map('{0[0]}-{0[1]}-{0[2]}'.format)]\n",
    "    train_groupby_date_count.index.names = ['arrival_date']\n",
    "    count_df = train_groupby_date_count['ID']\n",
    "    count_df.name = 'count'\n",
    "    train_groupby_date_sum = train_month_to_num.groupby(['arrival_date_year','arrival_date_month','arrival_date_day_of_month']).sum()\n",
    "    train_groupby_date_sum.index = [train_groupby_date_sum.index.map('{0[0]}-{0[1]}-{0[2]}'.format)]\n",
    "    train_groupby_date_sum.index.names = ['arrival_date']\n",
    "    train_groupby_date_sum = train_groupby_date_sum.join(count_df)\n",
    "    ret = train_groupby_date_sum.drop(['ID','lead_time','arrival_date_week_number','agent','company'],axis=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed1 = preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_processed1['is_not_canceled'] = train_processed1['count'] - train_processed1['is_canceled']\n",
    "arrival_date_per_adr = train_processed1['adr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time  arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342               2015   \n",
       "1          1    City Hotel            0        257               2015   \n",
       "2          2    City Hotel            0        257               2015   \n",
       "3          3    City Hotel            0        257               2015   \n",
       "4          4    City Hotel            0        257               2015   \n",
       "...      ...           ...          ...        ...                ...   \n",
       "91525  91525  Resort Hotel            0         72               2017   \n",
       "91527  91527  Resort Hotel            0         28               2017   \n",
       "91528  91528  Resort Hotel            0          2               2017   \n",
       "91529  91529  Resort Hotel            0         30               2017   \n",
       "91530  91530  Resort Hotel            0          1               2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                   July                        27                          1   \n",
       "1                   July                        27                          1   \n",
       "2                   July                        27                          1   \n",
       "3                   July                        27                          1   \n",
       "4                   July                        27                          1   \n",
       "...                  ...                       ...                        ...   \n",
       "91525              March                        13                         31   \n",
       "91527              March                        13                         31   \n",
       "91528              March                        13                         31   \n",
       "91529              March                        13                         31   \n",
       "91530              March                        13                         31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  deposit_type  \\\n",
       "0                            0                     0  ...    No Deposit   \n",
       "1                            0                     2  ...    No Deposit   \n",
       "2                            0                     2  ...    No Deposit   \n",
       "3                            0                     2  ...    No Deposit   \n",
       "4                            0                     2  ...    No Deposit   \n",
       "...                        ...                   ...  ...           ...   \n",
       "91525                        3                     7  ...    No Deposit   \n",
       "91527                        0                     2  ...    No Deposit   \n",
       "91528                        0                     1  ...    No Deposit   \n",
       "91529                        3                     7  ...    No Deposit   \n",
       "91530                        0                     1  ...    No Deposit   \n",
       "\n",
       "       agent  company days_in_waiting_list customer_type        adr  \\\n",
       "0        NaN      NaN                    0     Transient  -6.305161   \n",
       "1        6.0      NaN                    0     Transient  75.052227   \n",
       "2        6.0      NaN                    0     Transient  74.546401   \n",
       "3        6.0      NaN                    0     Transient  76.376288   \n",
       "4        6.0      NaN                    0     Transient  49.411647   \n",
       "...      ...      ...                  ...           ...        ...   \n",
       "91525   40.0      NaN                    0      Contract  79.453407   \n",
       "91527    NaN      NaN                    0     Transient  -6.822102   \n",
       "91528    NaN      NaN                    0     Transient  90.814554   \n",
       "91529  250.0      NaN                    0     Transient  38.135565   \n",
       "91530  250.0      NaN                    0     Transient  58.196470   \n",
       "\n",
       "      required_car_parking_spaces  total_of_special_requests  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "...                           ...                        ...   \n",
       "91525                           0                          1   \n",
       "91527                           0                          0   \n",
       "91528                           0                          2   \n",
       "91529                           0                          1   \n",
       "91530                           0                          1   \n",
       "\n",
       "       reservation_status  reservation_status_date  \n",
       "0               Check-Out               2015-07-01  \n",
       "1               Check-Out               2015-07-03  \n",
       "2               Check-Out               2015-07-03  \n",
       "3               Check-Out               2015-07-03  \n",
       "4               Check-Out               2015-07-03  \n",
       "...                   ...                      ...  \n",
       "91525           Check-Out               2017-04-10  \n",
       "91527           Check-Out               2017-04-02  \n",
       "91528           Check-Out               2017-04-01  \n",
       "91529           Check-Out               2017-04-10  \n",
       "91530           Check-Out               2017-04-01  \n",
       "\n",
       "[70457 rows x 33 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 丟掉 canceled 且 no deposit 的資料\n",
    "train.drop(train[(train['is_canceled']==1)&(train['deposit_type']=='No Deposit')].index,inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, hotel, is_canceled, lead_time, arrival_date_year, arrival_date_month, arrival_date_week_number, arrival_date_day_of_month, stays_in_weekend_nights, stays_in_week_nights, adults, children, babies, meal, country, market_segment, distribution_channel, is_repeated_guest, previous_cancellations, previous_bookings_not_canceled, reserved_room_type, assigned_room_type, booking_changes, deposit_type, agent, company, days_in_waiting_list, customer_type, adr, required_car_parking_spaces, total_of_special_requests, reservation_status, reservation_status_date]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#檢查有沒有丟乾淨\n",
    "train[(train.is_canceled==1) & (train.deposit_type==\"No deposit\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342              2015   \n",
       "1          1    City Hotel            0        257              2015   \n",
       "2          2    City Hotel            0        257              2015   \n",
       "3          3    City Hotel            0        257              2015   \n",
       "4          4    City Hotel            0        257              2015   \n",
       "...      ...           ...          ...        ...               ...   \n",
       "91525  91525  Resort Hotel            0         72              2017   \n",
       "91527  91527  Resort Hotel            0         28              2017   \n",
       "91528  91528  Resort Hotel            0          2              2017   \n",
       "91529  91529  Resort Hotel            0         30              2017   \n",
       "91530  91530  Resort Hotel            0          1              2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number arrival_date_day_of_month  \\\n",
       "0                     07                        27                        01   \n",
       "1                     07                        27                        01   \n",
       "2                     07                        27                        01   \n",
       "3                     07                        27                        01   \n",
       "4                     07                        27                        01   \n",
       "...                  ...                       ...                       ...   \n",
       "91525                 03                        13                        31   \n",
       "91527                 03                        13                        31   \n",
       "91528                 03                        13                        31   \n",
       "91529                 03                        13                        31   \n",
       "91530                 03                        13                        31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  agent  company  \\\n",
       "0                            0                     0  ...    NaN      NaN   \n",
       "1                            0                     2  ...    6.0      NaN   \n",
       "2                            0                     2  ...    6.0      NaN   \n",
       "3                            0                     2  ...    6.0      NaN   \n",
       "4                            0                     2  ...    6.0      NaN   \n",
       "...                        ...                   ...  ...    ...      ...   \n",
       "91525                        3                     7  ...   40.0      NaN   \n",
       "91527                        0                     2  ...    NaN      NaN   \n",
       "91528                        0                     1  ...    NaN      NaN   \n",
       "91529                        3                     7  ...  250.0      NaN   \n",
       "91530                        0                     1  ...  250.0      NaN   \n",
       "\n",
       "       days_in_waiting_list customer_type        adr  \\\n",
       "0                         0     Transient  -6.305161   \n",
       "1                         0     Transient  75.052227   \n",
       "2                         0     Transient  74.546401   \n",
       "3                         0     Transient  76.376288   \n",
       "4                         0     Transient  49.411647   \n",
       "...                     ...           ...        ...   \n",
       "91525                     0      Contract  79.453407   \n",
       "91527                     0     Transient  -6.822102   \n",
       "91528                     0     Transient  90.814554   \n",
       "91529                     0     Transient  38.135565   \n",
       "91530                     0     Transient  58.196470   \n",
       "\n",
       "      required_car_parking_spaces total_of_special_requests  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "...                           ...                       ...   \n",
       "91525                           0                         1   \n",
       "91527                           0                         0   \n",
       "91528                           0                         2   \n",
       "91529                           0                         1   \n",
       "91530                           0                         1   \n",
       "\n",
       "       reservation_status  reservation_status_date  arrival_date  \n",
       "0               Check-Out               2015-07-01    2015-07-01  \n",
       "1               Check-Out               2015-07-03    2015-07-01  \n",
       "2               Check-Out               2015-07-03    2015-07-01  \n",
       "3               Check-Out               2015-07-03    2015-07-01  \n",
       "4               Check-Out               2015-07-03    2015-07-01  \n",
       "...                   ...                      ...           ...  \n",
       "91525           Check-Out               2017-04-10    2017-03-31  \n",
       "91527           Check-Out               2017-04-02    2017-03-31  \n",
       "91528           Check-Out               2017-04-01    2017-03-31  \n",
       "91529           Check-Out               2017-04-10    2017-03-31  \n",
       "91530           Check-Out               2017-04-01    2017-03-31  \n",
       "\n",
       "[70457 rows x 34 columns]"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將arrival_date做出來\n",
    "day_to_str = {}\n",
    "for i in range(1,32):\n",
    "    if i<10:\n",
    "        day_to_str[str(i)]='0'+str(i)\n",
    "    else:\n",
    "        day_to_str[str(i)]=str(i)\n",
    "train['arrival_date_year'] = train['arrival_date_year'].astype(str)\n",
    "train['arrival_date_month'] = train['arrival_date_month'].map({'January':'01','February':'02','March':'03','April':'04','May':'05','June':'06','July':'07','August':'08','September':'09','October':'10','November':'11','December':'12'})\n",
    "train['arrival_date_day_of_month'] = train['arrival_date_day_of_month'].astype(str).map(day_to_str)\n",
    "train['arrival_date'] = train['arrival_date_year'] + '-' + train['arrival_date_month'] + '-' + train['arrival_date_day_of_month']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>stays_total_nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342              2015   \n",
       "1          1    City Hotel            0        257              2015   \n",
       "2          2    City Hotel            0        257              2015   \n",
       "3          3    City Hotel            0        257              2015   \n",
       "4          4    City Hotel            0        257              2015   \n",
       "...      ...           ...          ...        ...               ...   \n",
       "91525  91525  Resort Hotel            0         72              2017   \n",
       "91527  91527  Resort Hotel            0         28              2017   \n",
       "91528  91528  Resort Hotel            0          2              2017   \n",
       "91529  91529  Resort Hotel            0         30              2017   \n",
       "91530  91530  Resort Hotel            0          1              2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number arrival_date_day_of_month  \\\n",
       "0                     07                        27                        01   \n",
       "1                     07                        27                        01   \n",
       "2                     07                        27                        01   \n",
       "3                     07                        27                        01   \n",
       "4                     07                        27                        01   \n",
       "...                  ...                       ...                       ...   \n",
       "91525                 03                        13                        31   \n",
       "91527                 03                        13                        31   \n",
       "91528                 03                        13                        31   \n",
       "91529                 03                        13                        31   \n",
       "91530                 03                        13                        31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  \\\n",
       "0                            0                     0  ...   \n",
       "1                            0                     2  ...   \n",
       "2                            0                     2  ...   \n",
       "3                            0                     2  ...   \n",
       "4                            0                     2  ...   \n",
       "...                        ...                   ...  ...   \n",
       "91525                        3                     7  ...   \n",
       "91527                        0                     2  ...   \n",
       "91528                        0                     1  ...   \n",
       "91529                        3                     7  ...   \n",
       "91530                        0                     1  ...   \n",
       "\n",
       "       days_in_waiting_list  customer_type        adr  \\\n",
       "0                         0      Transient  -6.305161   \n",
       "1                         0      Transient  75.052227   \n",
       "2                         0      Transient  74.546401   \n",
       "3                         0      Transient  76.376288   \n",
       "4                         0      Transient  49.411647   \n",
       "...                     ...            ...        ...   \n",
       "91525                     0       Contract  79.453407   \n",
       "91527                     0      Transient  -6.822102   \n",
       "91528                     0      Transient  90.814554   \n",
       "91529                     0      Transient  38.135565   \n",
       "91530                     0      Transient  58.196470   \n",
       "\n",
       "      required_car_parking_spaces total_of_special_requests  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "...                           ...                       ...   \n",
       "91525                           0                         1   \n",
       "91527                           0                         0   \n",
       "91528                           0                         2   \n",
       "91529                           0                         1   \n",
       "91530                           0                         1   \n",
       "\n",
       "      reservation_status reservation_status_date  arrival_date  \\\n",
       "0              Check-Out              2015-07-01    2015-07-01   \n",
       "1              Check-Out              2015-07-03    2015-07-01   \n",
       "2              Check-Out              2015-07-03    2015-07-01   \n",
       "3              Check-Out              2015-07-03    2015-07-01   \n",
       "4              Check-Out              2015-07-03    2015-07-01   \n",
       "...                  ...                     ...           ...   \n",
       "91525          Check-Out              2017-04-10    2017-03-31   \n",
       "91527          Check-Out              2017-04-02    2017-03-31   \n",
       "91528          Check-Out              2017-04-01    2017-03-31   \n",
       "91529          Check-Out              2017-04-10    2017-03-31   \n",
       "91530          Check-Out              2017-04-01    2017-03-31   \n",
       "\n",
       "       date_difference  stays_total_nights  \n",
       "0               1 days                   0  \n",
       "1               3 days                   2  \n",
       "2               3 days                   2  \n",
       "3               3 days                   2  \n",
       "4               3 days                   2  \n",
       "...                ...                 ...  \n",
       "91525          11 days                  10  \n",
       "91527           3 days                   2  \n",
       "91528           2 days                   1  \n",
       "91529          11 days                  10  \n",
       "91530           2 days                   1  \n",
       "\n",
       "[70457 rows x 36 columns]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#算出total待的夜晚和待的天數\n",
    "train['date_difference'] = (pd.to_datetime(train['reservation_status_date']) - pd.to_datetime(train['arrival_date']) + datetime.timedelta(days=1))\n",
    "train['stays_total_nights'] = train['stays_in_week_nights'] + train['stays_in_weekend_nights']\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>stays_total_nights</th>\n",
       "      <th>booking_total_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.305161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>225.156681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>223.639203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>229.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2015</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>148.234941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>873.987482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.466305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>181.629107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>419.491216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>116.392941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time arrival_date_year  \\\n",
       "0          0  Resort Hotel            0        342              2015   \n",
       "1          1    City Hotel            0        257              2015   \n",
       "2          2    City Hotel            0        257              2015   \n",
       "3          3    City Hotel            0        257              2015   \n",
       "4          4    City Hotel            0        257              2015   \n",
       "...      ...           ...          ...        ...               ...   \n",
       "91525  91525  Resort Hotel            0         72              2017   \n",
       "91527  91527  Resort Hotel            0         28              2017   \n",
       "91528  91528  Resort Hotel            0          2              2017   \n",
       "91529  91529  Resort Hotel            0         30              2017   \n",
       "91530  91530  Resort Hotel            0          1              2017   \n",
       "\n",
       "      arrival_date_month  arrival_date_week_number arrival_date_day_of_month  \\\n",
       "0                     07                        27                        01   \n",
       "1                     07                        27                        01   \n",
       "2                     07                        27                        01   \n",
       "3                     07                        27                        01   \n",
       "4                     07                        27                        01   \n",
       "...                  ...                       ...                       ...   \n",
       "91525                 03                        13                        31   \n",
       "91527                 03                        13                        31   \n",
       "91528                 03                        13                        31   \n",
       "91529                 03                        13                        31   \n",
       "91530                 03                        13                        31   \n",
       "\n",
       "       stays_in_weekend_nights  stays_in_week_nights  ...  customer_type  \\\n",
       "0                            0                     0  ...      Transient   \n",
       "1                            0                     2  ...      Transient   \n",
       "2                            0                     2  ...      Transient   \n",
       "3                            0                     2  ...      Transient   \n",
       "4                            0                     2  ...      Transient   \n",
       "...                        ...                   ...  ...            ...   \n",
       "91525                        3                     7  ...       Contract   \n",
       "91527                        0                     2  ...      Transient   \n",
       "91528                        0                     1  ...      Transient   \n",
       "91529                        3                     7  ...      Transient   \n",
       "91530                        0                     1  ...      Transient   \n",
       "\n",
       "             adr  required_car_parking_spaces total_of_special_requests  \\\n",
       "0      -6.305161                            0                         0   \n",
       "1      75.052227                            0                         0   \n",
       "2      74.546401                            0                         0   \n",
       "3      76.376288                            0                         0   \n",
       "4      49.411647                            0                         0   \n",
       "...          ...                          ...                       ...   \n",
       "91525  79.453407                            0                         1   \n",
       "91527  -6.822102                            0                         0   \n",
       "91528  90.814554                            0                         2   \n",
       "91529  38.135565                            0                         1   \n",
       "91530  58.196470                            0                         1   \n",
       "\n",
       "      reservation_status reservation_status_date arrival_date  \\\n",
       "0              Check-Out              2015-07-01   2015-07-01   \n",
       "1              Check-Out              2015-07-03   2015-07-01   \n",
       "2              Check-Out              2015-07-03   2015-07-01   \n",
       "3              Check-Out              2015-07-03   2015-07-01   \n",
       "4              Check-Out              2015-07-03   2015-07-01   \n",
       "...                  ...                     ...          ...   \n",
       "91525          Check-Out              2017-04-10   2017-03-31   \n",
       "91527          Check-Out              2017-04-02   2017-03-31   \n",
       "91528          Check-Out              2017-04-01   2017-03-31   \n",
       "91529          Check-Out              2017-04-10   2017-03-31   \n",
       "91530          Check-Out              2017-04-01   2017-03-31   \n",
       "\n",
       "       date_difference  stays_total_nights  booking_total_revenue  \n",
       "0               1 days                   0              -6.305161  \n",
       "1               3 days                   2             225.156681  \n",
       "2               3 days                   2             223.639203  \n",
       "3               3 days                   2             229.128863  \n",
       "4               3 days                   2             148.234941  \n",
       "...                ...                 ...                    ...  \n",
       "91525          11 days                  10             873.987482  \n",
       "91527           3 days                   2             -20.466305  \n",
       "91528           2 days                   1             181.629107  \n",
       "91529          11 days                  10             419.491216  \n",
       "91530           2 days                   1             116.392941  \n",
       "\n",
       "[70457 rows x 37 columns]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#算出當日到房的所得，每筆訂單付的全額=adr*待的天數\n",
    "#若取消則只算adr\n",
    "# train['booking_total_revenue'] = ((train['date_difference'] / np.timedelta64(1, 'D')).astype(int))*train['adr']\n",
    "train['booking_total_revenue'] = np.where(train['is_canceled']==0,(train['stays_total_nights']+1)*train['adr'],train['adr'])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38296.46692395161"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = train['arrival_date']=='2017-03-27'\n",
    "train.loc[mask,'booking_total_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>...</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>stays_total_nights</th>\n",
       "      <th>booking_total_revenue</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>6406</td>\n",
       "      <td>0</td>\n",
       "      <td>19600</td>\n",
       "      <td>2781</td>\n",
       "      <td>38</td>\n",
       "      <td>276</td>\n",
       "      <td>186</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>6187.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7094.546385</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "      <td>27405.733006</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>6188</td>\n",
       "      <td>0</td>\n",
       "      <td>2518</td>\n",
       "      <td>972</td>\n",
       "      <td>55</td>\n",
       "      <td>150</td>\n",
       "      <td>71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3098.361671</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>205</td>\n",
       "      <td>19629.006947</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>8901</td>\n",
       "      <td>0</td>\n",
       "      <td>2419</td>\n",
       "      <td>999</td>\n",
       "      <td>37</td>\n",
       "      <td>123</td>\n",
       "      <td>74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3270.453785</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>160</td>\n",
       "      <td>16237.167949</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>20878</td>\n",
       "      <td>23</td>\n",
       "      <td>11415</td>\n",
       "      <td>1836</td>\n",
       "      <td>129</td>\n",
       "      <td>202</td>\n",
       "      <td>135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4493.307965</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>331</td>\n",
       "      <td>21973.962221</td>\n",
       "      <td>2015-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>14393</td>\n",
       "      <td>0</td>\n",
       "      <td>2789</td>\n",
       "      <td>1036</td>\n",
       "      <td>86</td>\n",
       "      <td>140</td>\n",
       "      <td>72</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3614.545744</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>226</td>\n",
       "      <td>23206.004222</td>\n",
       "      <td>2015-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>14437057</td>\n",
       "      <td>45</td>\n",
       "      <td>15621</td>\n",
       "      <td>2067</td>\n",
       "      <td>167</td>\n",
       "      <td>263</td>\n",
       "      <td>296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>29834.0</td>\n",
       "      <td>2361.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12079.085543</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>430</td>\n",
       "      <td>38296.466924</td>\n",
       "      <td>2017-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>6093282</td>\n",
       "      <td>0</td>\n",
       "      <td>3520</td>\n",
       "      <td>871</td>\n",
       "      <td>33</td>\n",
       "      <td>223</td>\n",
       "      <td>120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4502.192254</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>256</td>\n",
       "      <td>20687.369957</td>\n",
       "      <td>2017-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>11838144</td>\n",
       "      <td>0</td>\n",
       "      <td>5347</td>\n",
       "      <td>1690</td>\n",
       "      <td>31</td>\n",
       "      <td>333</td>\n",
       "      <td>215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>9054.0</td>\n",
       "      <td>3317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8865.047802</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>364</td>\n",
       "      <td>32867.303327</td>\n",
       "      <td>2017-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>12861613</td>\n",
       "      <td>17</td>\n",
       "      <td>18026</td>\n",
       "      <td>1833</td>\n",
       "      <td>80</td>\n",
       "      <td>398</td>\n",
       "      <td>246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6710.0</td>\n",
       "      <td>11059.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9264.471877</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>478</td>\n",
       "      <td>42359.769271</td>\n",
       "      <td>2017-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>15084126</td>\n",
       "      <td>35</td>\n",
       "      <td>10375</td>\n",
       "      <td>2145</td>\n",
       "      <td>114</td>\n",
       "      <td>357</td>\n",
       "      <td>310</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>3738.0</td>\n",
       "      <td>28</td>\n",
       "      <td>14554.743092</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>471</td>\n",
       "      <td>50616.846256</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  is_canceled  lead_time  arrival_date_week_number  \\\n",
       "arrival_date                                                               \n",
       "2015-07-01        6406            0      19600                      2781   \n",
       "2015-07-02        6188            0       2518                       972   \n",
       "2015-07-03        8901            0       2419                       999   \n",
       "2015-07-04       20878           23      11415                      1836   \n",
       "2015-07-05       14393            0       2789                      1036   \n",
       "...                ...          ...        ...                       ...   \n",
       "2017-03-27    14437057           45      15621                      2067   \n",
       "2017-03-28     6093282            0       3520                       871   \n",
       "2017-03-29    11838144            0       5347                      1690   \n",
       "2017-03-30    12861613           17      18026                      1833   \n",
       "2017-03-31    15084126           35      10375                      2145   \n",
       "\n",
       "              stays_in_weekend_nights  stays_in_week_nights  adults  children  \\\n",
       "arrival_date                                                                    \n",
       "2015-07-01                         38                   276     186       2.0   \n",
       "2015-07-02                         55                   150      71       2.0   \n",
       "2015-07-03                         37                   123      74       3.0   \n",
       "2015-07-04                        129                   202     135       5.0   \n",
       "2015-07-05                         86                   140      72       8.0   \n",
       "...                               ...                   ...     ...       ...   \n",
       "2017-03-27                        167                   263     296       0.0   \n",
       "2017-03-28                         33                   223     120       3.0   \n",
       "2017-03-29                         31                   333     215       7.0   \n",
       "2017-03-30                         80                   398     246       5.0   \n",
       "2017-03-31                        114                   357     310       9.0   \n",
       "\n",
       "              babies  is_repeated_guest  ...  booking_changes    agent  \\\n",
       "arrival_date                             ...                             \n",
       "2015-07-01         0                  1  ...               33   6187.0   \n",
       "2015-07-02         0                  0  ...                3   6143.0   \n",
       "2015-07-03         0                  0  ...                4   4557.0   \n",
       "2015-07-04         2                  0  ...                6   6229.0   \n",
       "2015-07-05         0                  0  ...               10   6357.0   \n",
       "...              ...                ...  ...              ...      ...   \n",
       "2017-03-27         0                  9  ...               28  29834.0   \n",
       "2017-03-28         1                  7  ...                7   5325.0   \n",
       "2017-03-29         2                 17  ...               28   9054.0   \n",
       "2017-03-30         3                  6  ...               32   6710.0   \n",
       "2017-03-31         0                  3  ...               23  12324.0   \n",
       "\n",
       "              company  days_in_waiting_list           adr  \\\n",
       "arrival_date                                                \n",
       "2015-07-01      584.0                     0   7094.546385   \n",
       "2015-07-02        0.0                     0   3098.361671   \n",
       "2015-07-03        0.0                     0   3270.453785   \n",
       "2015-07-04        0.0                     0   4493.307965   \n",
       "2015-07-05        0.0                     0   3614.545744   \n",
       "...               ...                   ...           ...   \n",
       "2017-03-27     2361.0                     0  12079.085543   \n",
       "2017-03-28     1508.0                     0   4502.192254   \n",
       "2017-03-29     3317.0                     0   8865.047802   \n",
       "2017-03-30    11059.0                     0   9264.471877   \n",
       "2017-03-31     3738.0                    28  14554.743092   \n",
       "\n",
       "              required_car_parking_spaces  total_of_special_requests  \\\n",
       "arrival_date                                                           \n",
       "2015-07-01                              4                         24   \n",
       "2015-07-02                              5                         26   \n",
       "2015-07-03                              7                         12   \n",
       "2015-07-04                              7                         31   \n",
       "2015-07-05                             13                         18   \n",
       "...                                   ...                        ...   \n",
       "2017-03-27                              8                        101   \n",
       "2017-03-28                              4                         46   \n",
       "2017-03-29                             13                         83   \n",
       "2017-03-30                              9                         88   \n",
       "2017-03-31                              8                        103   \n",
       "\n",
       "              stays_total_nights  booking_total_revenue  arrival_date  \n",
       "arrival_date                                                           \n",
       "2015-07-01                   314           27405.733006    2015-07-01  \n",
       "2015-07-02                   205           19629.006947    2015-07-02  \n",
       "2015-07-03                   160           16237.167949    2015-07-03  \n",
       "2015-07-04                   331           21973.962221    2015-07-04  \n",
       "2015-07-05                   226           23206.004222    2015-07-05  \n",
       "...                          ...                    ...           ...  \n",
       "2017-03-27                   430           38296.466924    2017-03-27  \n",
       "2017-03-28                   256           20687.369957    2017-03-28  \n",
       "2017-03-29                   364           32867.303327    2017-03-29  \n",
       "2017-03-30                   478           42359.769271    2017-03-30  \n",
       "2017-03-31                   471           50616.846256    2017-03-31  \n",
       "\n",
       "[640 rows x 22 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_booking_total_tmp = train.groupby('arrival_date').sum()\n",
    "train_booking_total_tmp['arrival_date'] = train_booking_total_tmp.index\n",
    "train_booking_total_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>booking_total_revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>27405.733006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>19629.006947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>16237.167949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>21973.962221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>23206.004222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>38296.466924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>20687.369957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>32867.303327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>42359.769271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>50616.846256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             arrival_date  booking_total_revenue\n",
       "arrival_date                                    \n",
       "2015-07-01     2015-07-01           27405.733006\n",
       "2015-07-02     2015-07-02           19629.006947\n",
       "2015-07-03     2015-07-03           16237.167949\n",
       "2015-07-04     2015-07-04           21973.962221\n",
       "2015-07-05     2015-07-05           23206.004222\n",
       "...                   ...                    ...\n",
       "2017-03-27     2017-03-27           38296.466924\n",
       "2017-03-28     2017-03-28           20687.369957\n",
       "2017-03-29     2017-03-29           32867.303327\n",
       "2017-03-30     2017-03-30           42359.769271\n",
       "2017-03-31     2017-03-31           50616.846256\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_booking_total = train_booking_total_tmp[['arrival_date','booking_total_revenue']]\n",
    "train_booking_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adr</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.305161</td>\n",
       "      <td>1 days</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.052227</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.546401</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.376288</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.411647</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>79.453407</td>\n",
       "      <td>11 days</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>-6.822102</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>90.814554</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>38.135565</td>\n",
       "      <td>11 days</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>58.196470</td>\n",
       "      <td>2 days</td>\n",
       "      <td>2017-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             adr date_difference arrival_date\n",
       "0      -6.305161          1 days   2015-07-01\n",
       "1      75.052227          3 days   2015-07-01\n",
       "2      74.546401          3 days   2015-07-01\n",
       "3      76.376288          3 days   2015-07-01\n",
       "4      49.411647          3 days   2015-07-01\n",
       "...          ...             ...          ...\n",
       "91525  79.453407         11 days   2017-03-31\n",
       "91527  -6.822102          3 days   2017-03-31\n",
       "91528  90.814554          2 days   2017-03-31\n",
       "91529  38.135565         11 days   2017-03-31\n",
       "91530  58.196470          2 days   2017-03-31\n",
       "\n",
       "[70457 rows x 3 columns]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#另一種處理\n",
    "tmp = train[['adr','date_difference','arrival_date']]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  adr\n",
       "0    2015-07-01    0\n",
       "1    2015-07-02    0\n",
       "2    2015-07-03    0\n",
       "3    2015-07-04    0\n",
       "4    2015-07-05    0\n",
       "..          ...  ...\n",
       "635  2017-03-27    0\n",
       "636  2017-03-28    0\n",
       "637  2017-03-29    0\n",
       "638  2017-03-30    0\n",
       "639  2017-03-31    0\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_date_revenue = pd.DataFrame(columns=['adr'])\n",
    "tmp_arrival_date = tmp['arrival_date'].unique()\n",
    "train_date_revenue.insert(loc=0,column='date',value=tmp_arrival_date)\n",
    "train_date_revenue.fillna(0,inplace=True)\n",
    "train_date_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#算出當日的所有adr累加\n",
    "for index,row in tmp.iterrows():\n",
    "    for i in range(0,row['date_difference'].days+1):\n",
    "        nowdate = datetime.datetime.strftime(datetime.datetime.strptime(row['arrival_date'],\"%Y-%m-%d\")+datetime.timedelta(days=i),\"%Y-%m-%d\")\n",
    "        train_date_revenue.loc[(train_date_revenue['date']==nowdate),'adr'] = train_date_revenue.loc[(train_date_revenue['date']==nowdate),'adr'] + row['adr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>7094.546385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>10192.908056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>13500.586137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>16303.776774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>14419.583193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>43723.097378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>34691.112094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>38303.408373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>43269.273847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>44546.902118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date           adr\n",
       "0    2015-07-01   7094.546385\n",
       "1    2015-07-02  10192.908056\n",
       "2    2015-07-03  13500.586137\n",
       "3    2015-07-04  16303.776774\n",
       "4    2015-07-05  14419.583193\n",
       "..          ...           ...\n",
       "635  2017-03-27  43723.097378\n",
       "636  2017-03-28  34691.112094\n",
       "637  2017-03-29  38303.408373\n",
       "638  2017-03-30  43269.273847\n",
       "639  2017-03-31  44546.902118\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_date_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>adr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>7094.546385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>3098.361671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>3270.453785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>4493.307965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>3614.545744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>12079.085543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>4502.192254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>8865.047802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>9264.471877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>14554.743092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             arrival_date           adr\n",
       "arrival_date                           \n",
       "2015-07-01     2015-07-01   7094.546385\n",
       "2015-07-02     2015-07-02   3098.361671\n",
       "2015-07-03     2015-07-03   3270.453785\n",
       "2015-07-04     2015-07-04   4493.307965\n",
       "2015-07-05     2015-07-05   3614.545744\n",
       "...                   ...           ...\n",
       "2017-03-27     2017-03-27  12079.085543\n",
       "2017-03-28     2017-03-28   4502.192254\n",
       "2017-03-29     2017-03-29   8865.047802\n",
       "2017-03-30     2017-03-30   9264.471877\n",
       "2017-03-31     2017-03-31  14554.743092\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第三種方法 ADR 直接依arrival_date加總\n",
    "train_adr_sum_tmp = train.groupby('arrival_date').sum()\n",
    "train_adr_sum_tmp['arrival_date'] = train_adr_sum_tmp.index\n",
    "train_adr_sum = train_adr_sum_tmp[['arrival_date','adr']]\n",
    "train_adr_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  label\n",
       "0     2015-07-01    2.0\n",
       "1     2015-07-02    1.0\n",
       "2     2015-07-03    1.0\n",
       "3     2015-07-04    1.0\n",
       "4     2015-07-05    1.0\n",
       "..           ...    ...\n",
       "635   2017-03-27    2.0\n",
       "636   2017-03-28    1.0\n",
       "637   2017-03-29    2.0\n",
       "638   2017-03-30    3.0\n",
       "639   2017-03-31    3.0\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_date_revenue.set_index('date').values\n",
    "y = train_label.set_index('arrival_date').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_booking_total.set_index('arrival_date').values\n",
    "y = train_label.set_index('arrival_date').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 3., 5., 4., 6., 9., 0., 8., 7.])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(y,(640,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 2)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_date_revenue.values\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27405.733006268274, 19629.006947370846, 16237.167948903701,\n",
       "       21973.96222127881, 23206.004221814608, 25080.799757586872,\n",
       "       13363.898673128657, 14632.752412159085, 12680.105792233302,\n",
       "       28113.028154933, 33818.69323242929, 27061.155129104227,\n",
       "       25108.60316807793, 18246.238507083464, 19589.78100207602,\n",
       "       29261.740004666928, 45955.88974213357, 45217.05673077108,\n",
       "       24682.388246026127, 44133.32374939691, 18478.154790038516,\n",
       "       17409.563134779863, 27086.50538786606, 35455.44919993568,\n",
       "       48614.01650299174, 28575.685489578864, 43976.74157101881,\n",
       "       12980.617772435568, 16723.792586845953, 26960.414627457256,\n",
       "       28105.733943920848, 64223.289338776216, 39917.773336390055,\n",
       "       48876.01198964029, 25996.02342480836, 27724.38865738425,\n",
       "       23678.007800068124, 35751.76311484895, 58425.54676285505,\n",
       "       48470.01400396884, 78429.32875461833, 38590.513745682096,\n",
       "       25994.42734278861, 33053.46718772895, 63908.358975592004,\n",
       "       69589.29614923435, 53626.77118961477, 66551.0423951582,\n",
       "       39671.46532085881, 27379.769123063375, 32111.175953412978,\n",
       "       42826.47651681306, 67065.18210283286, 49220.03579416572,\n",
       "       44404.123403366284, 28359.303275202976, 21637.117879448324,\n",
       "       21886.189374773392, 30780.144260195568, 48207.2654423954,\n",
       "       32064.221231978878, 35532.855116031766, 39132.540984819345,\n",
       "       23389.279144219356, 35907.2488091363, 52021.10219627282,\n",
       "       46595.95052881993, 62115.39359440654, 49463.72381615015,\n",
       "       28970.824109956127, 41220.092134921535, 30919.666020289853,\n",
       "       37807.33245176099, 38371.44669842171, 29068.919313155715,\n",
       "       41407.11344776556, 29628.271346599504, 34674.46870018522,\n",
       "       38765.61332925928, 59875.31075130213, 53696.537732026845,\n",
       "       44405.26446745927, 49999.670115112065, 31042.180987812873,\n",
       "       49290.199557386295, 45100.1527736775, 133266.1036601929,\n",
       "       58791.34051214296, 26333.28008946332, 29170.472382493106,\n",
       "       18524.64548824527, 38366.41668539828, 31942.254986135325,\n",
       "       51938.45107701742, 24434.491389879804, 48461.84371295302,\n",
       "       47769.97068657322, 37933.53075815333, 36837.99555745559,\n",
       "       18412.262340678615, 45944.45784765002, 36789.27785997344,\n",
       "       24078.778130416005, 47079.87462279158, 23420.671247830796,\n",
       "       14629.238447958585, 39463.03538962277, 54471.5427723958,\n",
       "       18597.561001583497, 40689.58622922872, 56553.86278050685,\n",
       "       30248.521234159605, 21143.622048403893, 22598.12618539089,\n",
       "       27261.38266530533, 29518.348308579436, 55293.32844572235,\n",
       "       22058.9556994577, 10241.37439663784, 38578.32720000803,\n",
       "       17403.119160907816, 15757.398339963609, 20184.871554642872,\n",
       "       14916.995993004855, 16529.602349949095, 10604.706269532815,\n",
       "       12577.29832326136, 13108.159514415423, 20977.18983216938,\n",
       "       20545.604899418326, 14504.55047472659, 12317.845806570973,\n",
       "       8045.4614364123845, 9698.313436430195, 9058.885612435959,\n",
       "       6857.846584308862, 8702.838118620619, 6118.95221839646,\n",
       "       9618.287040350879, 11175.484923151396, 33909.537923361044,\n",
       "       7448.646489093802, 27278.47822456964, 10239.278164332958,\n",
       "       11880.798097528714, 37112.481216249515, 10171.264208853972,\n",
       "       5904.01046669444, 7571.387111379314, 20443.701314941423,\n",
       "       7133.289201711629, 4524.199471311225, 8475.499140244949,\n",
       "       5374.3165268221965, 6881.663349699272, 12666.992087845618,\n",
       "       28116.059552039053, 85804.43985807251, 12224.76410439361,\n",
       "       3086.7565641537776, 17925.964214619667, 17202.556011659286,\n",
       "       6585.627908667795, 6072.951818108358, 7912.564045429671,\n",
       "       3396.168369442791, 5407.497517346588, 3336.0821104617366,\n",
       "       5526.528713473673, 7598.067002900067, 8371.24271631237,\n",
       "       13297.169818051505, 7319.133662711113, 7982.412922819334,\n",
       "       11998.907026009254, 18793.833755728352, 13486.348254831917,\n",
       "       10618.472140471937, 29807.812544224853, 34598.08739449839,\n",
       "       24501.29904571331, 32304.846585601485, 80012.52925568308,\n",
       "       34315.349338317836, 11113.52552882878, 44211.608250014964,\n",
       "       11459.786073202144, 17039.879677919038, 5398.239439118409,\n",
       "       7531.368491078115, 8035.078639956094, 10562.852864000672,\n",
       "       8135.743205620167, 12441.193335669634, 6838.098317294158,\n",
       "       7564.189692224845, 5752.143226472284, 11040.368789273341,\n",
       "       16162.691620592259, 10495.837061351242, 6766.878468920677,\n",
       "       9011.772157813595, 19621.424233640995, 8352.780393122945,\n",
       "       11426.439462648856, 13978.320266591136, 10453.94088557944,\n",
       "       9865.363440795034, 12935.882869639212, 2787.8374827037437,\n",
       "       15214.016933967425, 13077.67917422678, 14598.808711165564,\n",
       "       10456.721791230288, 8917.420177208438, 9939.135583345755,\n",
       "       7190.793193823724, 14694.177989621781, 16560.766874502573,\n",
       "       24076.743765172727, 47442.26596469794, 30883.680332289034,\n",
       "       20966.446386995973, 9708.667839675521, 13443.093960841028,\n",
       "       18270.318021678133, 37039.30752313241, 35298.508582553266,\n",
       "       29870.785134343783, 16777.334464621686, 12319.965250124182,\n",
       "       27512.11957493696, 18075.26741635267, 33661.30236273132,\n",
       "       23342.792643677665, 21581.375432236593, 24503.540079799026,\n",
       "       14103.374098871536, 16437.43533506566, 19406.26815731044,\n",
       "       30783.968390020193, 45033.74758582759, 24441.759074120433,\n",
       "       18694.79407602683, 20433.241229303007, 23312.790942225227,\n",
       "       22920.47602423755, 31506.678036708712, 28571.636166649605,\n",
       "       19265.657589956227, 35831.08098136685, 18541.058906675462,\n",
       "       28144.471341919932, 23550.707436636003, 30773.318320297913,\n",
       "       27472.53445908175, 29884.182824891173, 27507.030984376262,\n",
       "       19446.13752255041, 17079.93633262553, 31877.625250596142,\n",
       "       33329.015247961885, 45273.10269765141, 57084.88018383959,\n",
       "       37637.269367308145, 26020.51280997198, 28751.526644843616,\n",
       "       61471.81451036948, 50701.96758006173, 28265.049327019387,\n",
       "       26743.738696546796, 47006.96722078314, 25600.955870659876,\n",
       "       27013.43980180293, 41417.91671830468, 26359.26912250518,\n",
       "       26634.310097723723, 29139.533487547094, 45701.05837158982,\n",
       "       22594.28270715104, 40550.14142108975, 33008.69867176508,\n",
       "       37998.246022280066, 47839.37307518697, 32013.202883873615,\n",
       "       49243.009387217375, 28154.531545099257, 34782.65705744924,\n",
       "       29416.93483158963, 33816.28119365059, 42857.28691172707,\n",
       "       45456.691830448384, 50230.71014242335, 28366.68604050171,\n",
       "       37271.1201674318, 33126.87367049434, 47348.621190589336,\n",
       "       49376.41019691759, 38479.22695793994, 35494.86393259059,\n",
       "       35579.90641161052, 34340.11919880786, 54032.88375666405,\n",
       "       51598.414619330135, 50036.28919277941, 26278.094488308114,\n",
       "       61304.055577679734, 21933.167740802117, 30363.28084020737,\n",
       "       51749.63453319048, 31713.37092710381, 38362.46988036316,\n",
       "       42357.87235813963, 56111.20577878435, 31447.933718188724,\n",
       "       35539.149416190136, 40064.73752259169, 45822.037833452894,\n",
       "       33574.6437236197, 55054.934379924045, 45318.85561525502,\n",
       "       40650.53031135177, 28008.712790937683, 57014.32082545814,\n",
       "       37930.680583483365, 51772.759120246854, 44120.18519739429,\n",
       "       34790.951814244894, 38083.232798829355, 28031.923717520916,\n",
       "       63415.112825377946, 19411.19792393775, 22432.648920934116,\n",
       "       65238.28060552861, 53838.61804632674, 41594.95760023196,\n",
       "       37377.858990529894, 56052.33966723088, 45438.92074562444,\n",
       "       36600.161574876256, 28693.31430954615, 78504.89586980327,\n",
       "       31767.4599981594, 27689.368164177144, 46197.912014753005,\n",
       "       57198.386464355084, 36319.464746546175, 62571.23690107701,\n",
       "       39960.44724326339, 40563.44530492085, 59156.4861548236,\n",
       "       43134.319869875224, 69458.40129270934, 37913.171970928925,\n",
       "       47209.636843972614, 49297.70581958258, 36548.25107091925,\n",
       "       27659.506466144103, 21075.230744118962, 56896.97145199769,\n",
       "       30542.362138741726, 81139.2750757242, 47773.67695049016,\n",
       "       43246.31496830428, 26765.894506205117, 47905.452993888626,\n",
       "       45675.494593994124, 44038.57872470355, 53149.82850202298,\n",
       "       58386.43383116342, 50994.972299321686, 51039.70723839424,\n",
       "       41881.4710059229, 49048.94090046007, 55034.57681660339,\n",
       "       58333.07677716753, 63178.224608191085, 38253.980103932045,\n",
       "       51465.18105270083, 50115.06167803165, 53131.87125810459,\n",
       "       69590.00623424316, 67080.59062809846, 82069.1711466806,\n",
       "       42980.35434368098, 39853.5258915723, 67894.0148346114,\n",
       "       42078.37996817265, 84155.45818428928, 60381.11202206016,\n",
       "       73304.69511103602, 42498.19504956665, 46275.51791829435,\n",
       "       52492.09651583192, 49525.08361850303, 80312.71737902492,\n",
       "       61332.37558338031, 107601.45579515249, 57904.25357616556,\n",
       "       62347.37101380249, 71737.61967189373, 57925.2922426588,\n",
       "       72268.26369251343, 64179.531417818376, 103092.90154447546,\n",
       "       51492.49991783027, 48749.2388968662, 66442.72507043919,\n",
       "       68048.76728093001, 86249.12027013928, 73321.27395158568,\n",
       "       86177.55270494813, 73193.50268113599, 54799.22982974934,\n",
       "       65494.4118025962, 58773.000868382034, 89167.71789707836,\n",
       "       75197.39076487896, 95496.5115546677, 48923.381596848456,\n",
       "       48658.42742268177, 48180.49981755566, 62122.670500065804,\n",
       "       58843.76418208295, 79587.80600898011, 57426.63331931405,\n",
       "       36615.04296746049, 43198.96162797139, 61237.94333539607,\n",
       "       54030.29880292694, 57287.94230588625, 46896.42624421246,\n",
       "       75325.87239332336, 40733.752810932245, 30747.0126880713,\n",
       "       45969.792742177386, 53629.96881407655, 46229.43206670333,\n",
       "       58479.59548136063, 47679.10230318501, 53087.53855579736,\n",
       "       30889.683078144957, 62847.351445830056, 53582.84346751925,\n",
       "       42829.36292970642, 57362.08481048924, 64311.506286380914,\n",
       "       37561.683330992215, 41468.83080728653, 52805.77995188824,\n",
       "       37855.073338084054, 38072.09888847513, 60018.62498372196,\n",
       "       62616.68152794501, 35131.17567628774, 36771.18399289648,\n",
       "       35086.694092233665, 61785.73955893968, 32691.894223416297,\n",
       "       50431.05189112784, 52414.62533223812, 37122.01261624112,\n",
       "       39726.77910125559, 40485.54560114324, 48394.827334123285,\n",
       "       28537.083593002524, 43531.143824157545, 49381.11782292204,\n",
       "       32006.30247780173, 31865.360339463965, 40406.447526027456,\n",
       "       40663.78145725482, 31322.90330393346, 71596.54908053782,\n",
       "       47780.06516336036, 26261.641525673218, 27174.86502465635,\n",
       "       34980.27561445213, 45690.67215179166, 32992.16547192088,\n",
       "       55831.465405125964, 36030.53995899763, 39067.14649107839,\n",
       "       28578.82055198293, 28387.716644854703, 53394.50018887199,\n",
       "       50530.12187913677, 53018.50593055231, 39350.751633778455,\n",
       "       32490.59410353056, 32744.420512584627, 30810.99474381221,\n",
       "       38639.38128451881, 32498.630790835177, 53963.76521317145,\n",
       "       83934.30434347673, 20265.84314377474, 16842.4813031389,\n",
       "       33396.09867311114, 42840.55661965757, 32426.807125433537,\n",
       "       37230.55007657107, 38673.98934291352, 15186.278261248603,\n",
       "       24645.07627193131, 25543.160384873165, 37980.535898407645,\n",
       "       30687.737828939145, 20374.547538449417, 35588.39518242438,\n",
       "       11985.784240343553, 15611.092899080333, 20742.144759467083,\n",
       "       31727.562889357152, 21048.24281590979, 19435.156558263076,\n",
       "       19808.77433467565, 14373.80258606483, 12046.42128169824,\n",
       "       24577.534235851268, 28519.251713323767, 39314.569047253055,\n",
       "       20101.853843064353, 32230.80888500898, 13532.066909248642,\n",
       "       17731.56988146588, 44015.880115988264, 18028.133430375456,\n",
       "       18040.294814712328, 7132.350365308162, 11345.996764746966,\n",
       "       12073.573354164342, 12522.498724409632, 10303.038147130383,\n",
       "       15086.126769799292, 20918.529985726997, 19169.89258195681,\n",
       "       18083.72774268765, 15777.290364051052, 22029.22018873137,\n",
       "       28826.070560032906, 28194.02977523253, 35266.853832055465,\n",
       "       21431.483348697016, 26407.183782532895, 44692.22268002704,\n",
       "       43268.718063195745, 37739.29217302944, 84667.58688270811,\n",
       "       27437.07690341273, 28434.94620895318, 39800.27887747241,\n",
       "       24236.059015059294, 14742.224309866013, 15718.266620980256,\n",
       "       19847.842325692098, 21746.02855646995, 21187.09164370964,\n",
       "       15231.339084809752, 10636.163286355517, 10920.709257480235,\n",
       "       18163.165067118898, 15451.573763007116, 30717.30323705462,\n",
       "       23509.80919486572, 39550.71602287287, 10877.015933647563,\n",
       "       35449.64214832039, 27656.954146191678, 15099.281242842924,\n",
       "       19554.880717026077, 25172.856503636216, 26988.071122447418,\n",
       "       12918.483193404432, 27995.517885925045, 16972.8331168583,\n",
       "       24923.113782182434, 18853.902584363725, 17557.72523543149,\n",
       "       20741.036899186016, 11357.69233538126, 13727.024301684176,\n",
       "       29030.01035831995, 13900.42339132115, 30633.056512768297,\n",
       "       31822.827568534714, 22385.194229828394, 12714.154064666367,\n",
       "       15212.573499458904, 30028.010258330432, 30706.305277437885,\n",
       "       27016.496404760353, 52262.48687662665, 46028.57930068481,\n",
       "       22012.17355100725, 31562.414216868336, 26320.219743603073,\n",
       "       33342.93606319345, 29792.017780572693, 38988.590136760635,\n",
       "       37753.04588249809, 17459.761273719774, 28867.345428715584,\n",
       "       26822.993331477104, 25479.84605387376, 48260.4754170555,\n",
       "       52608.197369443056, 34632.37657573293, 15816.99358804495,\n",
       "       18385.462449415085, 47842.544030518606, 28453.317569217943,\n",
       "       20739.717492151543, 44372.653678446884, 37349.140149618455,\n",
       "       24891.015222612343, 19531.06173937602, 25578.385854400763,\n",
       "       39679.81163539535, 30096.74390581336, 32279.865084587585,\n",
       "       47453.93921008599, 26041.836354171617, 33423.800649309465,\n",
       "       35480.895298921256, 31460.8640693424, 30951.07353044662,\n",
       "       45905.39233858404, 43806.24863478775, 21385.494428046633,\n",
       "       20117.030354299783, 28395.290459958196, 36377.26054574096,\n",
       "       33178.81411922956, 40532.03995006479, 38296.46692395162,\n",
       "       20687.369957175702, 32867.303327441085, 42359.76927123394,\n",
       "       50616.84625597413], dtype=object)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ax.xaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(ax, title):\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=200))\n",
    "#     ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.set_xlabel('date', color='gray')\n",
    "    ax.set_ylabel('feature for train', color='gray')\n",
    "    ax.set_title(title, color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACkt0lEQVR4nOydd3wUZd7Av8/MtlQIvVfpvYMgimIBC/beu6ennt5ZXss63llPvbOdir0r9oYCCggqvfcOIZT0nm0z87x/zCZks5tkgYQAztfPfsw+O/PMs8vu/J5fF1JKbGxsbGxsakNp6AXY2NjY2BwZ2ALDxsbGxiYubIFhY2NjYxMXtsCwsbGxsYkLW2DY2NjY2MSFLTBsbGxsbOLC0dALsPnzoGnaO0CG1+t9sAGufTVwvdfrHRN+XgL093q9W+tg7v8Duni93us1TesEbAOcXq9Xr4O5OwBrgUZer9c42PlsbA4GW2DYHJZomjYb+MDr9b5RH/N7vd7kONZwQngN7WqZ6/E6Whaapm3HEmw/h+dOB2pdq43NocA2SdnYHASaptmbLps/DcLO9LapLzRNGwS8CXQDpgIS2Oz1eh/UNC0NeB8YgaXp/g7c7PV6MzRNewy4DwgBOvCO1+u9TdO054FzgUbAJuBOr9c7t5prNwXeBk4A1gPTgHGVTFIS6Ob1ejdrmjYReAZoDxQB/wFeAXIAN1AWnrY7cCPQF/ADZwF3Ae2AY7xe7+WVTFI3AY8AAnjG6/U+G77uO1Qyy1XWYjRNex+4DAgABvAoMIVKJi5N09oArwJjgDzgKa/X+3p4rkeA3uG1nQOkA1d5vd7FNf9L2djEh61h2NQLmqa5gK+xhEIT4DPgvEqHKFg39I5AB8AHvATg9XofAOYCt3m93mSv13tb+JxFwMDwfB8Bn2ma5qlmCS9j3ThbA9eGH9XxJnCT1+tNwRIGM71ebykwAdgdXkOy1+vdHT5+EvA50Bj4sJo5x2EJylOA+zRNG1/D9QHwer1XYN3kzwxf7+kYh30MZABtgPOBxzVNO6nS62cBn4TX9i3hz9TGpi6w1Wmb+mIk4AT+6/V6JfC5pml3lb/o9XpzgS/Kn4e1ilk1Tej1ej+o9PRZTdMeBHoAKyofp2maiiWc+oVv/Ks1TXsXGFvN1CGgt6ZpK7xebz6QX8t7m+f1er8O/+3TNC3WMVr42qs0TXsbuAT4uZZ5a0TTtPZYmsUZXq/XDyzXNO0N4Argl/Bhv3m93qnh498H7jyYa9rYVMYWGDb1RRtgV1hYlLOj/A9N0xKxTD+nAWnh4RRN09TqooE0TbsbuD48twRSgWYxDm2O9d3eGevaMTgPeBB4UtO0lcB9Xq93Xg3H76zhtVjH7AD6xXFObbQB8rxeb3GVuYdWer630t9lgEfTNEddRGzZ2NgmKZv6Yg/QVtM0UWmsQ6W/78bSDkZ4vd5U9u3+y4+PcK5pmnYccC9wIZDm9XobA4WVjq9MNpbvo301147A6/Uu8nq9k4AWWGa0KbHWUIl4HH9Vr11uzioFEiu91mo/5t4NNNE0LaXK3LviWI+NzUFjaxg29cU8rJv27ZqmvYxlWx/OPrNTCpbfokDTtCaAt8r5mUCXSs9TwvNlAw5N0+7D0jCi8Hq9hqZpXwKPaJp2LdAJuArYXvXYsK/lAuB7r9dbqGlaEZbDuXwNTTVNa+T1egv3470DPKRp2g1AZ+Aa4PLw+HLgbk3T/gW4iDYZVX3fld/XTk3T/gCe0DTt71hO+OsqzW1jU6/YGoZNveD1eoNYEU1XY/kELgK+rHTIf4EErEik+cBPVaZ4Hjhf07R8TdNewIpy+hHYiGWG8VOzaeg2rPyFvcA7WA726rgC2B4WFjcTvgF7vd71WE7mrZqmFYQjlOLlV2Azlm/hGa/XOz08/j6Wz2U7MB34tMp5TwAPhq/39xjzXoIlAHcDX1nL9M7Yj3XZ2BwwdlitjY2NjU1c2BqGjY2NjU1c2ALDxsbG5ihACHGHEGK1EGKNEOLO+riGLTBsbGxsjnCEEH2BG7ACSwYAZwghutX1dWyBYWNjY3Pk0wuYL6Usk1LqWEEX59T1Reyw2jDNmjWTnTp1auhl2NjYHAEsWbIkR0rZ/GDmOHVckszNi69i/ZKVgTVYkYHlTJZSTq70fDXwmBCiKVa4+kSgzmuI2QIjTKdOnVi82K7RZmNjUztCiJoqB8RFbp7BwmnV5pNGoLbe5JdSDq3udSnlOiHEU8AMoAQrdLvOs/ttk5SNjY1NAyABM87/4ppPyjellIOllGOxKhlvqus12xqGjY2NTQMgkYRk3TVRFEK0kFJmCSE6YCXNjqqzycPYAsPGxsamgYhXe4iTL8I+jBBwq5SytqrL+40tMGxsbGwaAInEqMNKG1LK4+pssmqwBYaNjY1NA2HGVfj48MF2eh+BmGVfYWYdh7m3J2bOGcjgkoZeko2NzX4iAQMZ1+NwwRYYRxjS/zMUecHMBEzQNyLzrkXq6Q29NBsbm/3ERMb1OFywBcYRhiz5H5H5OwAhZNnHDbEcGxubA0QCISnjehwu2D6MIw0zL8agDubeGOM2NjaHK/IwMzfFg61hHGm4xxEl50Uiwn1SgyzHxsbmAJFgxPk4XLAFxhGGSLkd1NYgkgAVSADnUPCc1tBLs7Gx2Q+sTO/4HocLtknqCEMoadDsRwjMBD0dnP3BNQIhREMvzcbGZr8QGBxZv1tbYByBCOGyNQobmyMcy+ltCwwbGxsbm1qw8jBsgWFjY2NjEwemrWHY2NjY2NSGrWHY2NjY2MSFRGAcYYGqtsCwsbGxaSBsk5SNjY2NTa1IBEGpNvQy9osjSx+ysbGxOUqwEveUuB7xIIT4mxBijRBitRDiYyGEp67XbAsMGxsbmwbCCCfv1faoDSFEW+B2YKiUsi9WGYiL63q9tknKxsbGpgGQUmDIOt2zO4AEIUQISAR21+XkYGsYNjY2Ng2GiYjrURtSyl3AM0A6sAcolFJOr+v12gLDxsbGpgGwnN6OuB5AMyHE4kqPGyvPJYRIAyYBnYE2QJIQ4vK6XrNtkrKxsbFpAMqd3nGSI6UcWsPr44FtUspsACHEl8CxwAcHtcgq1JuGIYR4SwiRJYRYXWns30KI9UKIlUKIr4QQjSu9dr8QYrMQYoMQ4tRK40OEEKvCr70gwmVZhRBuIcSn4fEFQohOlc65SgixKfy4qr7eo42Njc3BYEgR1yMO0oGRQojE8D3yJGBdXa+3Pk1S7wBVS6rOAPpKKfsDG4H7AYQQvbE8+n3C5/xPCFEeoPwKcCPQLfwon/M6IF9KeQzwH+Cp8FxNAC8wAhgOeMPqmo2Njc1hQ3mmdzyPWueScgHwObAUWIV1b59c12uuN4EhpZwD5FUZmy6l1MNP5wPtwn9PAj6RUgaklNuAzcBwIURrIFVKOU9KKYH3gLMrnfNu+O/PgZPCkvVUYIaUMk9KmY8lpOxa4DY2NocdplTiesSDlNIrpewppewrpbxCShmo6/U2pA/jWuDT8N9tsQRIORnhsVD476rj5efsBJBS6kKIQqBp5fEY50QQdhzdCNChQ4eDeCs2NjY2+4dVfPDIijtqkNUKIR4AdODD8qEYh8kaxg/0nMhBKSdLKYdKKYc2b9685kXb2NjY1CESQUiqcT0OFw65wAg7oc8ALgubmcDSAtpXOqwdVtJJBvvMVpXHI84RQjiARlgmsOrmsrGxsTlskBIMqcT1OFw4pCsRQpwG3AucJaUsq/TSt8DF4cinzljO7YVSyj1AsRBiZNg/cSXwTaVzyiOgzgdmhgXQNOAUIURa2Nl9SnjMxsbG5jAivqS9eBL3DhX15sMQQnwMnICVcJKBFbl0P+AGZoSjY+dLKW+WUq4RQkwB1mKZqm6VUhrhqW7BirhKAH4MPwDeBN4XQmzG0iwuBpBS5gkh/gksCh/3qJQywvluY2Nj09BIOKy0h3ioN4EhpbwkxvCbNRz/GPBYjPHFQN8Y437ggmrmegt4K+7F2tjY2DQAR5rT2870trGxsWkAJMJuoGRjY2NjUzsSCMkj6xZ8ZK3WxsbG5qghvl4XhxO2wLCxsbFpACTEncV9uGALDBsbG5sGwtYwbGxsbGxqRUphaxg2NjY2NrVjOb0Pn7If8WALDBsbG5sGoc57etc7tsCwsbGxaQAsp7ftw7CxsTkIgkY+QjhwKikNvRSbesbO9LaxsTkgSkM7WJp1FyXBrQA0SxjFwOZP4lRTG3hlNvVBXWZ6CyF6sK+/EEAX4GEp5X/r5AJhjizxZmNzlGJKnfl7rqY4uBFJCEmIHN88lmX/o6GXZlOPmChxPWpDSrlBSjlQSjkQGAKUAV/V9XptDcPG5jAgz78E3Syjcq8vSYhc30KCRgEutXGDrc2mfpASQma97NlPArZIKXfU9cS2wLCxOQwwzLKYKVxCCAzpP+Trsal/LJNU3AKjmRBicaXnk6WUk6s59mLg44NaXDXYAsPG5jCgScIwTIyo8QRHGzxqywZYkc2hYD8yvXOklENrO0gI4QLOwuo9VOfYPgwbm8MAp5LMwOZPowgPqkjCIZJwKo0Z3OI/hJuN2RxllIfVxvPYDyYAS6WUmfWxZlvDsLE5TGiVdCInJcwixzcPVXhIcXWnJLQVNZRIorNtQy/Pps6pl9Igl1BP5iiwBYaNzWGFU0mhVeLJbMj/D0sz70QRLkxCtEwcx4DmT6II+yd7NFGX/bqFEInAycBNdTZpFWyTlI3NYUa2bw47ij7GJIguSzBlgKyy2ewo+qihl2ZTh1hRUmpcj/jmk2VSyqZSysL6WrMtMGxsDjMyir/BkL6IMUP6ySiu87B6mwakPHGvjn0Y9Yqt39rYHGZUZ3YStjnqqKMuTVKHgnrTMIQQbwkhsoQQqyuNNRFCzBBCbAr/P63Sa/cLITYLITYIIU6tND5ECLEq/NoLIhwyIoRwCyE+DY8vEEJ0qnTOVeFrbBJCXFVf79HGpj5on3I+qvBEjKkigQ4plzTQimzqg3qKkqpX6tMk9Q5wWpWx+4BfpJTdgF/CzxFC9MZKNukTPud/Qohyw90rwI1At/CjfM7rgHwp5THAf4CnwnM1AbzACGA44K0smGxsDneaJgyne9odqOEQW0W4aZ9yPu1TzmnopdnUMaZU4nocLtSbjiulnFN51x9mEnBC+O93gdnAveHxT6SUAWCbEGIzMFwIsR1IlVLOAxBCvAecDfwYPueR8FyfAy+FtY9TgRlSyrzwOTOwhEy9hZrZ2NQ1nRtdQfuU8yjTd5KgtrYLEB6FSCnQDyNhEA+H2ijaUkq5B0BKuUcI0SI83haYX+m4jPBYKPx31fHyc3aG59KFEIVA08rjMc6xsTlicCiJpLp6NPQybOqRw8ncFA+Hixct1qcmaxg/0HMiLyrEjVjmLjp06FD7Km1sbGzqiCOxgdKh1ocyhRCtAcL/zwqPZwDtKx3XDtgdHm8XYzziHGGFjzQC8mqYKwop5WQp5VAp5dDmzZsfxNuysbGx2X9sp3fNfAuURy1dBXxTafzicORTZyzn9sKw+apYCDEy7J+4sso55XOdD8yUUkpgGnCKECIt7Ow+JTxmY2Njc9hg52FUQgjxMZaDu5kQIgMrculJYIoQ4jogHbgAQEq5RggxBVgL6MCtUsry0p23YEVcJWA5u38Mj78JvB92kOdhRVkhpcwTQvwTWBQ+7tFyB7iNzZGMIXV+y/6ZRXlzcCpujm9xGgMbj2joZdkcBEdaHkZ9RklVFzR+UjXHPwY8FmN8MdA3xrifsMCJ8dpbwFtxL9bG5gjg7W3Ps754JSEzCEDGjm1k+/dycqtJDbwymwNBStDrp4FSvXFkrdbG5k/KXl8G64v2CQuAoBlgeuZXEWM2RxZHmknKFhg2NkcAewO7UETsInRFoYJDuxibOsH2YdjY2NQLbRM6Ykg9alwgaORs0gArsqkL5GEkDOLB1jBsbI4AmrtbMTjtWFyKu2LMpbg4q80lOBR733ekYiLiehwu2N80G5sjhEs63EjPlH4szJuDW/FwXPNT6JbSp6GXZXOASFm3iXtCiMbAG1hBQhK4trysUl1hCwwbmyMERSgMaTKaIU1GN/RSbOoEgVG3UVLPAz9JKc8XQriAxLqcHOIQGJqmNQduADpVPt7r9V5b14uxsbGx+TNRVz4MIUQqMBa42ppXBoE6D5+LR8P4BpgL/AwYtRxrY2NTj2T6C/HpATokNUMRtgvySGY/a0k1E0IsrvR8spRycqXnXYBs4G0hxABgCXCHlLK0ThYbJh6Bkej1eu+ty4va2NjsHwXBMu5d9gFrCjNQhCDFkcDTgy6jT+P2tZ9sc3giLT9GnORIKYfW8LoDGAz8VUq5QAjxPFa/oYcObpGRxLNF+V7TtIl1eVEbG5v9w7tyCqsKdhI0dfxGiOxAEX9d/BZ+w07aO5KpwyipDCBDSrkg/PxzLAFSp8SjYdwB/J+maQGs/hQCkF6v1+7oYmNzCCjVAyzK3YwuzYhxKWFezibGtbQjpY5EZB06vaWUe4UQO4UQPaSUG7BKMK2tk8krUavA8Hq9KXV9URsbm/iR1dgtJKCbtlvxSGY/TFLx8Ffgw3CE1FbgmjqdnRoEhqZpPb1e73pN02KqNV6vd2ldL8bm8EQ3DUp0P6nOBNvReojZWZrLixt+RMboAWZiMqpZ9wZYlU1dUZeZ3lLK5UBNfo6DpiYN4y6sbnTPxnhNAifWy4psDis+3f4Hr22eQdDUSVTd3N3rDE5tM7Chl/WnYGdpLpf9/gJ+MxQxriDwqE6eGHgpyU5PA63O5mCR8sgrDVKtwPB6vTeG/z/u0C3H5nDi18y1vLxpGn7DumEFzTIeW/0VbRKb0K+x3dK2vnl766woYVHO4wMvYVTzI1O7kFKyrmgX6aU59EhtQ+fkFg29pAbjcCosGA9xZXprmtYX6A1UbGe8Xu979bUom8ODD7bNrRAW5QRMnc92zLMFRh1Rqgf4YddSNhTtpm+j9kxoOxCP6gJgQ1HMzsKYSDYXZ3Js8x6HbJ1bCnPJ9ZXRr1krEhzOA54nYIT425J3WV24EwWBIU1ObNkXb//z/5Tmzjr2YdQ78WR6e7E65/UGpgITgN8AW2Ac5ZTq/qgxiaQo5GuA1Rx95AdLuOKPlygK+vCbIWbsWckH2+fy7rG3kuzw0LdRBzYV7406zyFU2ic1PSRrLAoGuHbG56zOzcSpKBhS8vSYCZzRuecBzffx9t9ZVZBOwNxXeXd21lrG7F3Nya3719WyjwgkAvMobKB0PlaI1l6v13sNMABw13yKzdHAqa0H4lYid5Me1clptg+jTnh/6xzyA6UVZie/GSLTX8hnO6x6cVd3PR63iN7Nt/Q04rjmB3bD3l8emjeDFTl78Rs6xaEgZXqIv8+dyu6SogOab9qeFRHCAsBnBJm2e0VdLPeIQ8b5OFyIR2D4vF6vCeiapqUCWVhp6DZHORd3OpY+jdqRoLpIUF24FSdjmvX40+0E6wMpJb9mrSMkI8Nig6bO/JxNALROSOPz4+/i+Ba9SFTdpDg8nNt+OO8eeysOJXYzpbrmx+0bCFUJ3ZVIftqx8YDmS1Sj95oCQZLzT7gHDTu943kcLsTjw1isaVpj4HWs+iQlwML6XJTN4YFbdfLK8OtZU5jB9tJseqS2pltK64Ze1hGDlBITiVrFNq+bBvcs+4BdZXlR56gIOiY1r3je0tOIfw++ot7XWh0i5r1KoMR+oVYu7TwabeWeCGe+W3FwQYdRB7bAI53DSX2IgxoFhqZpAnjC6/UWAK9qmvYTkOr1elceisXZNDxCCPo2bk9fu2ZR3Oimwcsbp/FF+gICps7AtI481O882iVafofpe1ayJG8rZoy7hUt1cFnn4w71kqvlrM69+GbrOoKVtAwBTOh0YBFaJ7Xqx+6yfN7cMhNdmnhUJ3f3PONP+/06nLSHeKhRYHi9Xqlp2tfAkPDz7YdgTTZHIEFTZ1neNoQQDE7rfMhMJocjL2z4ka92LiIQ3kUvz9/B9fNf49sT7sGlOPhl7yp8RnS4rFOodEpqwUMrPuHU1gO5sONInA3cTe+RkePZW1bCwswMnIqCQPDc2Im0TDzwAhBXdBnLxZ2OpTDkI82VFKWB/VmQgGkeRQIjzHxN04Z5vd5FdXVRIcTfgOuxPrNVWCnsicCnWH03tgMXSinzw8ffD1yHVV79dinltPD4EOAdIAErgusOKaUUQrixoriGALnARVLK7XW1fptIVuan87cl72CGYwQdispLw66lR2qbBl7ZoUc3jQhhAZbN32+E+D1rPeNa9SXNlYyCiNIwdGmyrmgXANtLspmfs5EXh8VuO7OxaDdTdswnP1jCSa36cUrr/vUipJOcLt4/9UJ2lRSR5y+jR1pzXOrBX8epOGjm/pNXHZLA0aRhhBkH3KRp2g6glH3FBw/I8ymEaAvcDvSWUvqEEFOAi7HCdn+RUj4phLgPqzTvvUKI3uHX+wBtgJ+FEN2llAbwClY2+nwsgXEa8COWcMmXUh4jhLgYeAq46EDWa1Mzumlw99L3KK4cgmvA3Uve49sT7jnqY+tDpoFDKIiwTV+XJqEqUUAApjQpCJUBcGHHUUzfsyIqKa9y+Q+/GWJFwQ7WFe6iV6O2EcfNzVrPA8s/JmjqmEgW523ll72reGbwFRXrqGvaJqfSNtmuN1rXHGl5GPH8micAXbFKgZwJnBH+/8HgABKEEA4szWI3MAl4N/z6u8DZ4b8nAZ9IKQNSym3AZmC4EKI1kCqlnCet6mzvVTmnfK7PgZNEff2S9oPCYBn/XPUF43/5J2fMepL3t87BrFKB9EhjbeEudBldAK9Y97O1JKsBVnRomJWxlTGfvUb3d59l6Ccv89mmVYAVdhwrMMBEMrzpMQB0T23N4wMvoaWnEQqCVEdCTLOMQLCtymcopeSpNd/gN0MVGorPCLIobwtrCjPq+m3a1DdHWFxtPBrGv7xeb0SYhqZp7wMHFLohpdwlhHgGSAd8wHQp5XQhREsp5Z7wMXuEEOX1AtpiaRDlZITHQuG/q46Xn7MzPJcuhCgEmgI5ldcihLgRS0OhQ4f6zVyWUnLzwtfZUZqDLg2K8PH65l/IC5ZwR88jt92IS1ErTFGVMaVscPt7fbE2L4u/zPwan2FpErn+Mh6eN4NmnkTGte/KI/3P58YFr2NIA11a3Qyu63oibRObVMwxpkVPRjfvQdDUUYXCabMej0qINKWke2qk8AmYOjmB6BwIKSXri3b9aZ3HRyaHV8hsPMSjYUQU29c0TSXsBD8QhBBpWBpAZywTU5IQ4vKaTokxJmsYr+mcyAEpJ0sph0ophzZv3jzGKXXHsvzt7PHlR+zG/WaIz9PnE4jhAD1S6JHahiauZESlj1wVCu0Tm9AxqVkDrqz+eHftEgJVchN8hs4rq6zeNV1TWvHdCfdwb59J/LX7aXw0+g6u7npC1DxCCNyqE4eicmfPiXgqJUkmqE5GN+/OMSmtIs5xKw5SnAlRc6lCocNR+nkf1RwtGoamafcD/wckaJpWvqURWI3FJ1d3XhyMB7ZJKbMBhBBfAscCmUKI1mHtojVWgiBYmkPlbVM7LBNWRvjvquOVz8kIm70aAdFB74eQLH9hzHETSYnux60eeH2ehkQIwUvDruUfyz4gvdRS4Lomt+TpwTXtAY5ssn1lMbWqPP8+DSHR4WZCm0Fxz3lG2yG0S2zKp9v/oFj3c1qbgUyIkVEvhODW7qfw3LofKnwgLsVBh6RmDG1i59MeUUiQR0uUlNfrfQJ4QtO0J7xe7/11eM10YKQQIhHLJHUSsBjLoX4V8GT4/9+Ej/8W+EgI8RyWRtINWCilNIQQxUKIkcAC4ErgxUrnXAXMwyptMlNW14XmENG/cceojmkAjZ1JNHElN8CK6o62iU34aPTtZPoKEELQwtOooZdUr0zs1IN5e9Px6ZWSz1T1gHMTyhmY1omBaZ1qPe6sdsNo6k7hva1zKAyVcVKrvpzSegAbi/bQNaXlUWsKPDqpO4EhhNgOFGNFk+q19AA/IOLpuFeXwoJwg/LPgaWADizD0liSgSlCiOuwhMoF4ePXhCOp1oaPvzUcIQVwC/vCan8MPwDeBN4XQmzG0iwursv3cCC0SUzjko6j+XTHHwTMEA6hoioKD/c7r94iWw41LRMaN/QSDglnd+3Nd9vWsSgzA900cSoKHVPTuLnfiHq97oz0TTwy/xd2lRbRKjGZB4efyIntO3PPsg95f9tcHEJFEQKt/4Uc1+LQ1JqyOUjqfhs7TkqZU/thB4Zo4I33YcPQoUPl4sWL6/06qwrSmZW5hiTVzcS2g2idkFbv17Spe6SULMnaxarcTLo0asJxbTodcLmMeFievYeLf/wYv7EvZDfB4eCkHk1Ylr8loiaVW3Hy1di7aeaxw2DrCyHEkoPdwbs7t5OtvX+N69gd19xX6/XCGsbQ+hQYtu56iOnXuIPdS+IoQAjB0JbtGNqyXe0Hx0FBwEdRMEC75EZRgkdKyX+X/UbAqFLlVddZlLcpRvtWyczMNVzY8U9an+lIYf8S95oJISrvaCdLKav6kiUwXQghgddivH7Q1FZLSgFWer3evnV9YRsbG/DrIe6eO5UZ6ZtRhSDF5eaFE85kZCtrU7E8ew/XzviCvEBZzPNljHhBiSVkbA5/9uOfKScOjWa0lHJ3OCVhhhBivZRyzkEtsAo1htWGy5qv0DTN3hLb2NQD/1o4i593biZoGvgMnSxfKVdP/5zvt63j/t9/4oIfPqxWWHhUB50T2uAUkaU6BHBCqz4xz7E5zDBFfI84kFLuDv8/C/gKGF7Xy43HJNUaWKNp2kKsSCYAvF7vWXW9GBubPxNSSj7fvJqAEZnTETB0/jr7uxr9oQrQvXEzXhxxNvev+IhNRXtQFQVTSh7qey4t9yNSbXFmBj/t2EiK0825x/SlfcrRHeV2OCHqSBEUQiQBipSyOPz3KcCjlY/RNO3cmubwer1f1nadeASGFscxNjY2B4BuRodax3MPSXV5+PrMK1CE4M2RN7O9JIv8YCm9GrWt6AkeD08sms1765fh10M4FIVXVy9g8onnclzbTvG/CZsDo26T8loCX4UjLh3AR1LKn6ocU1NJJwkcvMDwer2/aprWEhgWHlro9XqP3iJBNjaHCCEEJ7bvwsydW2Pm6NTEhE49IpzjnZJb0Gk/r59eXMA765ZUaDgh0yRkmtzz24/8ceHNR0249+GLqLNqtVLKrVjts6sl3GL7oKi1NIimaRdiddi7ALgQWKBp2vkHe+E/M1JKFmdm8OzSuby7din5fl/tJ9kc9uSX+fhlwxaWZ+yp1em8NGs3zy6dS7+mreiQ0ogkh5MER+0KvwBaJSbz9yEH32RpSdaumEUPc/1l5AXs7+QhoQFKg2ia1lLTtDc1Tfsx/Ly3pmnXxXNuPCapB4Bh5VqFpmnNgZ+xqsDaHAAPzJvOV1vW4tdDuFUH/146hykTL6V3kxa1n2xzWPLx4hU8MeNXnKpVjLFNo1Tev+J8miQlRh376IJf+HjjCvy6jkt1oAKPjBpPourirrk/RHS3K+fYVh3o3KgJI1u155SO3XCrBx8R3zopJWaesSIEyc74zVo2B0HDFKt+B3gb694OsBGrF9GbtZ0YT/FBpYoJKjfO82xisCpnL19uXoNPDyEBv6FTEgpy3+9VzY02RwrpeQU8MWMOAd2gJBCkLBhie24+j0z9JerYTQU5fLRhBT5dR2I5uMsMnTfXLOGMLj25a9AYPJWEgQCGNG/DoyPH869RJ3Nml151IiwAhrdsT7vkRjiVfT/nBNXB1b0H19k1bGqgPA8jnkfd0szr9U4hLK68Xq+OVU6kVuL5Vvykado04OPw84uwmhXZHADz96ZjxLBXr8rZi5TSthsfgfy8YQuyyr+pbprM3Lg16th5e9JjWhg25Gfz/rql3NRvOL2btuDD9csp1YPsLC5kdV4WZ37/Pk3cCUw+6Rz6NG1ZJ+tWhGDKxEt5YvFspu3YSILDybW9h3JtnzovQWRTDXUVJbWflGqa1pSwsUvTtJFA7OqoVahWU9A0zQ3g9Xr/AbwG9Mdyqkz2er33HuyK/6y0SEzGFaOVpiIEzy37jTx/7Jh7m8MXt0ON2VnQGaOVaYvEZBzVdCF8fPFsPtm4krFtO/PaSefg03UySgoJGDo+PcSu0iIunzaFUAyT1YHSyO3hydGnsezS2/njwlu4vu+wei1xYlOFhilvfhdWgdaumqb9jtV8Lq4aJTVpGPOAwZqmvR9uoFRryJVN7ZzaoRv/WjgTnx6KMF8aUvLaqoVM2biKn86+hjRPdM8Dm8OT03p359+/zI0YczscnDcwOnnuxHZdcVRzQ/bpOi+umMclPQaQ7StlVc5ejCrO85BpMH/PTjvs1eaA8Xq9SzVNOx7ogWX13OD1euNqylOTwHBpmnYVcGyshI94kjxsovE4nPxn7BlcOf2zqLoAQdOgIODjvfXLuGPgsQ20Qpv9pWlSIq9efDZ//+pHiv0BTCk5uWdX7hkfHcnkVBRUVbH6RcYgP6xh+vRQlCYhQqAHTLKLS+r8Pdg0DA1hktI0zQP8BRiDpb/M1TTtVa/X66/t3JoExs3AZUBjohM+4krysInNd1vXVVsFP2AaLMnadUjXYxMfi9N38eSMX9mcnUfnpmncd/JYRnSyenuN7NSeOXfewK6CIholuEn1eGLO4Td0CgOxf5cCGBYuZrgse/e+FyQ4clSUoMAEvF/OZNvIAu4+cUxdvj2bQ40k7rIfdcx7WH0zyvsHXQK8T7ilRE3U1EDpN+A3TdMWe73eWsOtbGJTXgZ7a2EefZu1oneTFqQXF0SZGspxKSp968ipaVN3rM/M5vqPvsQXsirGrt2bxY0ff82HV19I39bWv5ciBO3Tai6r4VEdNHYnkBvDV5XkdKGNHG9dLy+7wnStFikoAVHRBjdoGLy/cBnHdu7AqM6xy7zppsmsjVtZtXsvXZo24bTe3fE47cinw46GcXr38Hq9lZP8ZmmatiKeE+PJ9LaFxQHi10NcNu1T1uVlA5bwOLF9V9q7GzNf7oyKlhNAotPJ1b0GH/rF2tTIW/OW4Ner1HzSdV7/fRHPn39G3PMIIXhw2Dj+749p+MLlylUE7VMa8e2ZV5Lq9rC3qJivFq0FF6CAWqZE9EwH8IV0vl+9IabACOo6l7/3GZuycikLhUh0Onn+1z/44vrLaJJo+8YOJxooSmqZpmkjvV7vfABN00YAv8dzor3lqEdeW72I1blZEX0Mftm0FTVXQBOsT1/BMjkoCpO69ubuQWNokXhkt2w92jCl5I+tO6KytyWQUVAU+6QYBAydN9Ys4qvNa2mZlEKi6sCpqpzZuReX9xyEJ5zpfc830yjI9SOag3RYYfhVDReKENVqDJ8vX8O6vdkEwyU/ykIhQsUG/5s7nwdPHRf3em0OAYdQYGiatip8RSdwpaZp6eHnHbE6mtaKLTDqke+3rYtqemPkm0hdwZnlwEyQmC4Tl6FyXf+h/OO4sRHH7ioooiQQ5JjmTVAVO1eyoXhv4TLyfNGlMpyqwohO7Xn4h5/5ef1mElxOrh05hEuHDoiZT3PDz1+yMDOjomtegsPJTX2Hc33fYRXH+IJBFu3IQEpwZjswkkxMt4nQI7UMp6IwqG1rSgJBkt37srI3ZObw+PTZhIzIvJCQafL+wuVsz83HO+FE2qc1PtiPxaYuOLQaRvyqcDXUKjA0TRNYzu8uXq/30XBvjFZer3fhwV78aCfF6Y4aE4b1oxcIVJ9A9SlIYHdBccUx+WU+/jLlW9bsyURVFBKcTl684AyGtG97qJZ+RJJVXMKeomKOad6UJFfdlbb4cNFyDDP6l+12OJi9aSvp+QXWDbrMx79/mUtOaRl3nBAZ5bYuL4tFlYQFWJFQr61awM39huNxODFMk+t++RIzrMkIKXCUWLkcDkUAAociMEyJISXeqb+gfz+D248fxXXHDkVKyV+mfBMlLABLiy2FRQt2cM6y93jzlvMZ0KVNnX1GNvuPkIfWJOX1endUfq5pWgsgdnRGNcSzbf0fMArLkw6Wd/3l/bnIn5Ub+w2PKignPEQlRiU4HYw9plPF83u++YmVu/YS0A3KgiFyS8u44aOvKA0GD8WyjzhChsHdX01l/Etvce2HX3Lss6/x0eK4fHhIKXn9j0WMevZV+j7+PNd++AU78wuqzB+74M/gdm3YU1Qc8bovpPP2/KWEqvS42F6UH1tLFIJsn+UAf27ZXObtTcdIMKParrodTmb+9TpuGj0ch6qgmyYlwSB+XefpX+Zy8ktv8dHiFeSWxkj8lODJBVcRqEEwSgxu/M9n/LF2e+0fkE39UocNlOJF07SzNE3bBGwDfgW2Az/Gc248AmOE1+u9FfADeL3efCx3nE0tnNaxO/cOOZ4UpxunotDMk4j31BNpkphAQtj+nOh00qNFc07v2xOAsmCIP7amx+iTIJizefuhfQNHCK//sZif12+pqOXk13WemjGHVbv31nruq78v5OU588kr8xEyTOZt28mFb32CP7RPE5jUvxduR2TWdoLTQa9WzWOaFHTToDQYmWjRp2lLQjF6XziEYGdOAXd89x3/W7kACehpBqZHUv6fcMDbl59Ly9Rkpq3fXBGpVZn0/EKenDEHPYZwUwOghPb5QQQQ0k2e+nRWrZ+PTf1SrmXU9qhj/gmMBDZ6vd7OwEnE6fSOR2CENE1T2Vd3pDkHWWNRCNFYCPG5EGK9EGKdEGKUEKKJEGKGEGJT+P9plY6/XwixWQixQQhxaqXxIUKIVeHXXhBhw7EQwi2E+DQ8vkAI0elg1nswXN17CMsv/SuLL76NhRffyqV9BjLt1mu4d/xYrhw+iCfOOoUPr74QV7iMRNWdZQWGyfdz1nC2921u/M9nLFiffgjfxeHN58tW4dcjb6JBw+DrlbX78d78Y0nEDdiUEr+uM2P95oqxvxw3gqEd2uJxOEh2u3CpKteOGso5A/rEDI9ulpREI0+kObJDSmPOP6YviQ4nYN20E1QHQ13t+cun3/Jd+vp9eZwK6M0Mgm10gq102vdIZUDb1tb6Ygidyu8ZAWoVDVYJEVOwZWQVVP/B2Bwa6rA0iBBCFUIsE0J8X8uhIa/XmwsomqYpXq93FjAwnmvE4/R+Aas/bAtN0x4DzgcejGfyGnge+ElKeb4QwgUkAv8H/CKlfFIIcR9wH3CvEKI3cDHQB2gD/CyE6C6lNIBXgBuB+VgFEU/DUq2uA/KllMcIIS4GnsIqmtggqIpCI/c+U2Gy28UlQ2P3OklyuRjcvg1L0nftuxlJkHt0Fu9OJ2SYpGcVsGrrHu487zhOGdqTtOQ/d6hkdb+nWlpSIKWkJBCIGg/pBjmlFd2IcTscvHXZeWzJziWjoIg+rVvQLDkJgAsH9eXzZasJFes4y0AIuHBY75jX+9eokxnbtjNfb1lDotPF+NZdufezaQR0A6kSIxQKhAJ3Dz6uYr2n9OpGen5hlIAsRwB9WrdkQ1Y2SKuUiOkMv1Dl82jVJKXmD8imfql77eEOYB2QWstxBZqmJQNzgA81TcsCYn+hqlCjhqFpmoJl57oHeALYA5zt9Xo/i2fyWAghUoGxhGuvSymDUsoCYBLwbviwd4Gzw39PAj6RUgaklNuAzcBwIURrIFVKOU9a8Y7vVTmnfK7PgZPKtY+GZENmDo9Nm80D381g3rb0apvsPHPOBDo1TSPR6STZ7SIppOIWaoStPKAbPP3pbCbc/zp3v/otvmBcpWCOSs4b0CfKZORyqJzdP/aNuxwhBP3atIoaV1WFUZ2i8xu6Nm/K8d06VwgLgAdOPYFTWnUhsUhBCYDww4c/LuHlb/Zp+Dklpbw5bzFPzfiVHRn5DHa35cxWPfGV6BV+DaVMROntAjirSy9O69SdRTsyOP7513n990XVCguAJkmJJLicnDugD3efNIYEpxPDDaYaKS/cTgd3nXd8jZ+PzSGgjjQMIUQ74HTgjTiuOgnwAX8DfgK2UHP71gpq1DC8Xq+padqzXq93FLA+ngnjoAuQDbwthBgALMGSjC2llHsApJR7hBDl3YTaYmkQ5WSEx0Lhv6uOl5+zMzyXLoQoBJoCOZUXIoS4EUtDoUOH2BmzdcWPazdy3zfTCBoGppT8sGY9lwwZwL0nj406tmVKMj/cfCXrM7MpDgRZtGIHb/4YHZQmgaBu8Pua7fx7ymwevvzken0Phys3jhnOxqwcZm/ehlNVCRkGd40bTf+20cKgKo+deTKXvjMF3TQI6AZuh8oFg/rSs1XzuK5dUOJjztItGJUd30GdD35ZyhUnDyWjqJAr3vuMkGEQDB8jgESXk2ZJ+wSPWqpgJkowwFGkoOgKQkCJO8Synbu54eOvYvouqpJbUsbeohKWpu/CoYYtyQL8zcBZAqofhAqPXzuBcf2Pies92tQfIn7jfjMhxOJKzydLKSdXev5frI19rWqj1+strfT03WoPjEE8JqnpmqadB3zp9XrrQoFyAIOBv0opFwghnscyP1VHLM1A1jBe0zmRA9YHPhlg6NCh9Rbgppsm3qm/ROwMfSGdDxcv54rhA2nTKFqDFELQq5UlM/1FQRLdTsoCsbWIoG4wdcE6Hrps/J+un4aUkuWbdtHWSOKybv0Y0KMNo7t1IsUTHdIci+4tmjHz9mv5ce1G8kp9jO7akf6VtI6Vu/eycHsGLVKSOKVnt6hkuc8XrY7Zj9uhKHw3fy1TNq+JcoBLoDQYImQUkeLxENINQqaJM1uNyLWQEn7bsoOF2zOI559VQIVjvbw/dwUKhFKtR5emabawOPLIkVLGbFQihDgDyJJSLhFCnFDdBJqmFRNbXxGA9Hq9tZmy4hIYdwFJgK5pmn9/Jq+GDCBDSrkg/PxzLIGRKYRoHdYuWgNZlY5vX+n8dsDu8Hi7GOOVz8kQQjiARkDeAa73oMksKiEQw4zgUBRW7tobU2BUZnSfTnRr24wNGdn4g7F3mUYVZ+iugiJe+W0ByzP20Ktlc245bgRdmjU58DdxmPL0p7P4dt5afMEQDlXhm7mr+c8tkxjRM36NMdXj4aLB/Sue55f5cCgKT874lR/WbCBkmLgcKk/NmMOUay+hbePUinDc/82bjzBk1A6lLBji1e//IDstFHv7AgQNkxbJSZzUvSszNmym2B+IER1nhQ3HsxGobceT6HSiKIJnzplQ61w2h4i62aaOBs4SQkzEyqtIFUJ8IKW8vPJBXq/3oJ1W8dSSqlPPmJRyrxBipxCih5RyA1ZI19rw4yrgyfD/vwmf8i3wkRDiOSyndzdgoZTSEEIUCyFGAguAK9lXffHb8BzzsJz0M2V1DoNDQJOkhJgOWFPKWovVgeU0n/y3C/h+/lp+WryRJZt2YlZKJHOoCqP7dKq4qWQWlXD26x9QGghiSMmWnDx+2biFz6+79KgSGtv35vH1H2sIhE01umGiGyaPvj+d7/913X5rW9tz87nzix/YnJOLKSVSUpFEpwdN/CEd7YdfaBlMYNqS9RQ2l6CAMxHL4V1lvjJ/yPJLRPdRqqBVajL/PGM8/zxjPP2feAE9ds5dtdWN48WlKpwzoDd3nTiaZHds7SuvzMeHi5azLGM3fVu35Irhg2heyV9jU8fUkdNbSnk/cD9AWMP4e1VhUVfEk+kdbWQHvF7vnIO47l+BD8MRUluBa7Ac8FOEENcB6YRL7Uop1wghpmAJFB24NRwhBXALVkPzBKzoqPLkkzeB94UQm7E0i4sPYq0HTYLTyeXDBvLR4uUVdmi3Q6V3qxb0aR1fZVqnQ+WcMf04Z0w/vpu/lsc/+gWHqmBKSZsmqTx02T7/xTsLluILhSqirEwpKQ2GuODNj3ng1BM4Z0Dvo8J0tXzr7pjd4bILSynxBUhJjD+JVTdNLn/vM3JKSqvd9JlSsmjxDly6QrDSUaFGYLosoaFWCWF1FltmoFjhJR6ng+uP3VcWpHuLZqzanRl1nFNVOLFbF2Zt2oZTVfCFQsRIPK8RRSgc07xp9cKitIwzX3ufIn+AoGGwaEcGny5dxTc3Xk6rVDuaqt5osG3sgRGPSeoflf72AMOxHNUnHuhFpZTLgVj2uJOqOf4x4LEY44uBvjHG/cRR2/1Q8o+TxtCucSrvLVyGP6RzRt+e3Dp2xAHNdebI3pwwoCsrtuwmLTmB3h1bRgiA5Tt3x8xOLgkGefSnmeSVlUXcqI5UWjdJjWnbdzpUEtz7l1u6cPtOyoKhGn+/wgARkISkEbnjF2AkWo/EbKvRUcVawpqHaKISqNIQaUKvbgztsK/cy0OnjeOK9z4jUKkqriKgVWoKe4tLMKWJXzdpmZJMfpk/ZrSUIqyyM1XzQyQwukvHat/bOwuWVggLsMxlZiDIq78t5JGJMX+WNnVBHQsMKeVsYHbdzrqPeExSEeFWmqa1B56urwUdrQghuHToAC4N518YpsnCHRmUBoIM79Su2oY7lSny+/l5wxZ8IZ1x3Tozpm/nqGP27C1g29K90Fxad48q+EI6r/y2kGtGDjniCxoO696eVk1SSM8qqMhw9rgcXDF+CA619ve2bW8eT348kxVbd+Nq5ERPrLlXthMFVQHDMBGAsyhSe0hwOujdvRnbNuVU+JoEkKyrOBMTyCyJ7JT3w5qN/O3EMbRMsaoTD2jbmu9vupI35i1mcfouklxOzuzbk0+XrmL17swKIZBZVEKS2400TYK6ad1zFFBNaOZI5JYTR/DMnN8JhSPyVEXhumOH0rFJ42rf25L03RXCohzdNFmcvounf57Dj2s3kuhycc2IwZw3sM9RoaE2NIL9ipI6LDiQarUZxNjV28TPzvwCLn/3M4oDQQTWD/PJs05hQp8e1Z6zPGMP1374RYVd/akZv/LgqeO4cHC/iOPeeG8urp0hlDQV01Gd0Ajh1/U6LdDXECiK4M27L+LFr39j1vLNJHlcXD5+MBeMjZ0UWZnCUj9XP/0JJb4AEgjkGQRc1OgsaN4kifzs4opDXGWgGGAmCwZ2a8P5A/tyZr+e/PfLuXw+ZwWqomAiGTe6O19uWLdvIhMcZeAwTV79cR73nTMOdzj6qkOTxjx6+viKQzdn5/LcrN8jNAYTKyHv2NS2LNmYgc8lESY4/FBCGc+8PwsTcCQrmNJkQr/u3DgqZoBNBb1aNWf5rj3opolaZtWdwoStoVy25eZXOOP/NW0WmcUl3Dp2ZK2fsU0tHOLig3VBPD6MF9mnOClYKeTxVXazicldX/5IVklphUMV4N5vpzGic4eYDW6klNz15dSo8Mx/TZvFyT2PIa3SOSvXZCBCkmYrdIrbK/haKlS127RMSSbR6azjd9UwNEry8OBl43nwsvG1H1yJnxatJ2QY++KwJbjyIZhGTKGR4HSQWVyKbAzu/PCgBEcQHpt0KhOG9ao49u7zj+fG00eSlV/MG4uX8MOajfsq0BrgybZ2lgLJj7+tY/WGPfz3lklMXbCOrXvzGN6jPRNH9MLtdFAWCsX006gSlm7YhWFIXFUsU1KG30KxiQJMm7eemQs3cv7Y/pwzph9zV23F5XBwytDuNG9kaTfXjhrC1yvX4isK4iqwzjecYKhApcgtX0jn9T8Wc8PoYRXlbBoCKSWbduVQVOanT6dWJLicZGQX8NoP81m9fS/d2zbjxtNH0rVNswZbY1wcbQIDqJwsogMfe73euApV2URTEgiwdm9WhLAAKxLqty3bOatfL35fs50Xv/6NPblF9O7YkqsmDIsoVVGOQyhMnr6AtRv3ENJNJh3bhzatGpOVXYyiQ6NtJijgb6ogVYFDUXCoCv864+Q/vUkhM78kKkTZ6QdPtqDrwFasycyyTDTSGhdBiZogCHigrIW1mwdwJqv07xZddj4lwU1WSQk/rNkYEVLtLC4XFhbBkMHOrALOf/Q9pJQEdYNfV27hk9nLee/eS2jTKDWcgBe5WXAKFVUhZrHBWIQMk89+XcGUX1eAEKhC8PK3v/Ofm89iRK+OtGmUypfXX8Y1z3xKPlbFW7Oau4NhmhT5/BEZ74eS/OIy/vLCl+zIsioAm6bkrvPG8vzXcynzhzClZGdWAb+t2c77915Cl9ZNG2SdcXEUCozGXq/3+coDmqbdUXXMJj4cihrT6iEQJDidLFi3g3+89l1FtdQF69NZuX03ZvMY36wCg69mriQYsmzP27/KY2CbVrjdDgIB6/xGWyWNSxWGTOxGq8apXDCoL52apkXP9SdjRK8OfDxrWUVIbjmGLklflU37tsnkqH5CGQFUUxBSDALlNZlU0MP3SqdD0DQpMeY1Vuzeu68QoGlpF2ogWoEJVmn96g/qbM/N5/T/vcve0hJMU6IKgdvpoLyz90uXnMX9L/0QUVW3NvSK0CpJ+RUffOcnpj1xI4oi6NCkMSlOV4XAUIPE1LZSPG6aVPOeDwXaBzPYsic3Qlg+8clMFEVUbMRMKQkEdV6fuoAnrpvYUEutlaPOJIWVz1BVOFwdY8wmDjxOByf26MqsjVsjnIwORXBc107c8t8vom4CekjSObkxO0oLKyJoVAkUmQQrfeH8QZ1lu/bwr79P5Jtvl7Frdz59e7XlhqvH0q7N0S0ksrKLePn1mSxevoNGqYlcefFIThvfL+o405Rsz8yjXbNUnA6FWMnz/oBOYUYZY3t3ZG7GNkKmgWqCEgDTTcVNNMHp4Ppjh1bbKrV940ZIJKrfMmOZilXTSanZt44EClMNCor2tX9VhaB1agp3nziGY7t0IMHp5J9Xn8bdr32LYZjV9uyojVJfkL35RbRpauUDnTCgK+/NWAJY63SUgZ6AVQgRqwbVo6ePj2kmOxQYpsnvq7dFNbSSSHQjcsyUks27IqoBRfHLsk189MtSygIhJo7oxcUnDMTpOISmtqNFYGiadglwKdBZ07RvK72UAuTW98KOZh4/8xT+/tWP/L51ByIcNvn8eafjcTrYm18cdXzIMOiZ2IS+HVoz9Y81iDJL8EhVEqqyO3WqKp5Gbl546pKoeY5W/P4QN935PgWFZZimpKQkwHMvzyAQNJg0cWDFcWt3ZHLXq99SXBbAMA1CsbLkwviCIRZv3Bnx+XryIJQMzkYOurRqwlUjBnNmuI9JLIZ2aEuzxERy04sQEowEyy+gBvdt3GMl5ZlOkFWCvAwpySgopHerFiSE/U+jenfkq0euZvqSjWzdk8vPSzZSWk35mOowpYzIV7nutOF8+MvSihuyq9CqP0WS4LzR/bh06AC6tWg4v4BAhM2pVUy6QkEKGSFIVEUwoGv1XQXfmb6IyT/MrzBN7sjMZ8H6dF667Zx6WXsU8uiKkvoDqzptM+DZSuPFwMr6XNTRSFGpnxJ/kNZNUkh2u3j14kkU+vyUBoIs3rmLF3+dT1piAt07NCOnsCRqB5XqdrNlYx6eMoWQYRI0YpsigrrBMW0Pc0dfHfPr7xvx+YMR2e+BgM67H/3OpIkDWZeeyXszFvPz0k0xW63GwqmqNE5KoKhsX/lzAXjKBGf264H3ylOizgkZBp/OXs4P89eR4HZy6YmD6JTcmFwsTUEq4Ix2RYEKTtR9Xfqq2bwrQlAWCpGZX0xuURld2zSlZVoKV4wfAsBDl43nvRlL+GT2cgpKfDROTiC/uAynQyUY0iuZpPahGyY3/edz7jhnDCN6dSQ9qwCHqmCEc0YE4AhAM3cCD084scF9X4oiOGlQN2Yt3xxhylNVQXKCh+KyAEHdwOlQSHC5uH5C7FynYEjn9R8WRPix/CGdpZsy2JiRTfd28RWfPGiOFg0j3P91B1Z7Vpv9wBcM8ems5fyyfBNpyYmUBYKs3mZ1f0twOzmub2fG9OvMuAHH8MB3M/ht6w584WgYlyFIcqgYVRyyPyxcD8gaTQ9OVWHi8J60TPtzZeZm5RRV+GwqU1BYxu+rt/GPyd8TCOn79dt0OhTuPHcs//f21Iibisuhcvn4wTHP+ftr37Fo/c4Kk+KGnVm06tK44nWHL7LzHVh/K5KITHAl3IlXLQVXieX7MF2Q1MrBsx/OZOGGnZjhSKibzhjJjadbP1FFUbj61GFcfeq+pMw9eUUs3bSL92csZmMM84wpJet3ZvG3V77lpb+ew5bdsY0HeSU+/CGdBFfDR9c9cOlJ5Jf4WL55Fw5VwelQefK6ifTs0JLXp85nzfa9DDqmLZeeOJhmjWI75vNLfDHbCyhCsG1v3iETGEedD0PTtJFYNZp6YbVmVYHSgyg+eFRjmCY3PPsZW/bkRjlUwdIAvl+wjl+Wbeb5Zr+T4Sy1bjAmOPMlSkDij9HQsKpjNAJT4iiTqNJk+h/rOfe4/vTtVHtp76OF/n3a4XI58PsjzTE9urXmiU9m7pdjGCDR7WTy386nd8dWPHfzWfzniznszC6gS6sm3H3BCTFDNTfvyokQFmCVOd+yJQepgqKHO9/FQK0SCCGwQm8VY59wUYMQ2OlnvtxZcZwEXv1+PskeN5eeZAkxXyDEoo07cTsdDOnWjtZNUjl9RCrz1m5n8+7cqOi8cvwhHe39GVx+0uBwQmfk9y3Z46rWV3OoSU5w8+od55GZX0xRWYDOrZpQ4gtwx/++ZsPObNSQZNvKveRszOPiScPo3TPaLNUkNRGHQ6kafIZhSnocKu0Cjh4NoxIvYdVi+gyrnMeVgF0buRrmr93B9sy8mMKiMr5giLLiYvSw2HXnx46gqQ0lKEnM1CsarZhFBrc+NoX7bzyF4/t3JcHd8DvCmvh15Rae+2IOe3KL6NQyjXsuGsfQ7u1rP7ES/fu0Y9SwLsxftJWyQAiRpOJQFK6+ajS3vPr1fs3ldqrcMHEkvTtaAndkr458+uAVtZ63PTMPJUaSpBIK5zJQ/b+trEic2IcaY39QnTXtuS9+5YSBXVm9bS/aBzMqHNIel4PX7jyfLq2bcsX4IcxctrlG4bkzu4DnvviVBLcL3TArNikel4Nbzjq2wc1RVWmZllKhTT/0zk+s3ZEJhSGceSamhNm/bmDevC30Gt2RVZlZlPgCDOjShgcuG0/nVk2467zjeXrKrAoNMsHlZNzArnRqdYgKdMbZHOlwIq7aEF6vdzOger1ew+v1vg2Mq99lHbls3p0bUQuoJsyAae34zNqFhdvpoFUMU5Mn17BCNiWEkgRlrR0UKzqPvj+DU+9/nfU7s2LMdniwZFMG9785lZ3h0h6bd+dy+8tf1xrZUhUhBN77zuKiK0fh7+Qm0MKJv5WTu97+Yb/mSXA5adO0EReM7V/7wWGklBSW+mneKLnafiWxbv7luJ0qfzt37EFFHZkSzva+w31vTsUXCFHqD1LqD5JXVMY/JlvtnXu0b8F//jIJZy0lUwIhA18gyKnDetC+eSP6dGzJP686jYuOH3jA66tvfMEQC9ano+sGnjwTEZa/Aih2m/y2eQeFpX4MU7Js8y6u+fenlPgCnD26Ly/ddg6nDOnO6D6deOjy8Tx61WmHbN0C63cbz+NwIR4No0zTNBewXNO0p7Ec4XbN4yr4AiGm/LqC7+avqb2ZdBhHCBKcLsr0EFH9OavQKi2ZN+6+kEse/5C8ojJMKRFSogStXgyGCoGmakVWtz+kQ0jn/jen8qX3qsNudwjw9k8Lo5LngrrBh78sjelUromyQIjXZy3a10/CiE9ol9OxRWOuPW04pwy1yrP8sGAd6Vn59O7YkjF9O8esu7V0UwYPvzuNrIKSatvtllP103eoCsO6t+eRK0/BFwzxxo/zCYTzaYQAl8NBSNfjrkobK4FPArtyCskqKKFF42RG9OxAr44tWbl1T61zdWqZhnblqfFdvAHIyC7g5W//YOXWPbRv0QgpJUoM5SnYSIkojyOBEl+Ah9+ZxkNXnMzgbu0Y3K1d9ImHiMNJGMRDPALjCixN5DasHrDtgfPqc1FHGiHD4JpnPmXb3ryoMFcIR5qolaJgwridDl656Gxm79jOB18vwghULzQMU9I0NYkvvFfx/rRF/Pr7RpqkJLB2506kBF/L2LHju3OLyC/20SS14RKtqiOroCRqzDQlmQWRocXb9+ZVOCLbNovsH5JdWMJHM5fxx5rtUU2k9odOrZpw5qg+5Jf4uPyJj8gvKcMf1BEC0pITeO3O8yt8F3NXbeXZz38lPavggK7ldjo477h+3HnuWFRFcNZDb1FQ6q94XUpIS/YQCBn4gyF8QZ0Et5MBnVozf0P6fl1LIiPyCq4+ZRj/99bUahtxgfVd+2TWciaN6ntYfm+yC0u47ImPKPUHMaVkT14RQoBQRbSJJ4ZCZUrJ3NVbOV97l08euJzmjZMPybpjcrQJDK/Xu0PTtASgtdfr1Q7Bmo445qzYyva9uVFx/aoiGDfwGC47aTCmKVm0YSczlmwkI6eQzq2acPf5xzOgcxv6dGhFB0cK//liDoGQHjMSKiOnECklP89dxxdvL0BVBIWiEKEIdDdIVUTVjCrH4zp0zspAUMfQDRITa2+ROrZ/F9KzCiIc+h6Xg+P7dwWsne59b/zA72u241AVdMNg4vBePBhuRbsnr4hLHvsQXyB4wIlrYN3Ah4X9Jq//MJ+sguKK8FspIa/Yx2VPfMTHD1xOdkEJ976+fxnWlXE5VGY8dSPJCdbnszEjm7wSX5RSWlgW4JXbz2PL7hz25BUzuFtbRvTswJJNu7j1xS8reohX58Qup1PLJqQl76s1dsKArtx57lj+9+3vlPqDuJ0OgroRpaHkF5fxr49+5rmbzzqg91kdSzZmMHnqfDLzSxjTpxPXTRwRsb54+OzXFQRCesR7lxISEpzIVBOKrZIuplughsCIUWPTMCXFvgBv/LSQ+y8+4E4NB8/RJjA0TTsTeAYrQqqzpmkDgUe9Xm/dfpOOYNZnZBGMkQRmmJKM7EJ+WrSeK08eyo2nj+TG0yOrfO7OLeK6Zz+lxBfENE0MU+JQlKhWnc0bJXH7S1+zYtomhGkV9SpHutVqhcVJA48h0VP/VWnLfEH+/fxPzP1jE6aUdD+mJQ/dcwZtW1efYX7VKcOYuWwzWQUl+AIhEtxOurRuytmjrWLIn/26gj/WbicQ0isysn9atJ4RvTpwypAevPnjQkr9gbhzK2KhCEHLtGQmha/5W4wsYrBMZZc89gHNGyUdsLAAq2bYii27GR0uTa+HS6VXxcqqtppmVWZo93bMfuYW/liznSKfn6c/nVVhyorFRcdHV+698PgBnH9cf0r9ARyKwn1vTmXu6m0Rx+imZO6qbUgp98ucKaXkp0Ub+GT2ckKGwdnH9uG84/pbtdIqhTgDTMktZNaKzXzhvXq/NjWbd+fGjBpslOTh2acv5NOvFjJ17WZ0IVEVAdIy21b9V9UNkyUbM+K+bp1Th/4JIYQHmAO4se7rn0spvXUz+z7icXo/gtU0qQDA6/UuBzrV9UKOZJqlVu/SWb8ziy/mruLif33ArpzCqNe9700ju6CUUn8QX9DaNRmmGWFG8LgcjOzVkSWr02PuSNxSifmDS/K4ePiK/fMFHChPPDeV3+ZtIqQbGIbJ+o17uf2ej2ssjpeS4ObTB6/Ae8Up3HTGKB6/biJv/+OiilLf381fG2U68QV1vpu3FoAVW3YflLAAaNE4iY/uv4yksFBtUYN5Iqgb7MotqvZ1IazPvHFyAkO6tYvpyPYFQxSW+gDr5upQFTwxchtSEtx0axs7vDPB7eSkwd0YP7g7E4f3inkMWD3jTxrcPWo8ZBg889ksTrlvMsfd9T82787BHaMchkNV9tv39fI3v/PPD2ewatse1qdn8d8v5/LQ2z8B8N8v50RED+qGSV6JjxlLNuzXNYZ2a1fxHSlHEYLBx7SlZ4cWZCtBTAdIAXotGljj5Pi7MtYLMs5H7QSAE6WUA7Aqip8Wbl9dp8QjMHSv1xt9p7OpYMKw6stDgPXDKAsEeeunhRHjJb4gSzdmRJkVnA6VET3a07VNU4b3bM9/bj7LCtWtxpHr8EmapibiqvSjdztVnrhu4iExR5WWBZi3YEtFEUSwboZlZUGWrajZ5u50qJw8pDs3nj6Ssf26RDiX3c7YfpnyUOFu7ZpF3ZQdimBM305RNxRVEVFKmCvc9rayBnb+8f0PPGJJQlDX8QdDFJSUVWsuWrF1D5t25XD6A29yzb8/pdjnRxECp6rgdqo0TU3khdvOiRmmW86unEImPfQWPy5aX+0xJpKzHnqLV7+fF+Hf+c/nc/jq9zUEQkbYB1AcFdnndqqcMXKfMNqRmc/1z05h6F/+y/F3/Y/JP8yPyKwHy5n84cylkdnTQZ2ZKzazK6cw5oYpENRZvJ+7/LNH96VlWnJFXojLoZKc4OLmM4/FME3mr0+P2khUFx22ZXcOC9ens3VPw1Q7EmZ8j9qQFuVOQWf4UecGr3juJqs1TbsUUDVN6wbcjlU2xCZMapKHEb06sGBd9TdHw5Ss3r43YuyR936K+S/qUBVOHdaT00fs+8G+//MSpFNgOAVqODIKAAGd2zfl2Qcu5v0Zi5mzcist01K45rRhDOwaXXa7PggE9NgxwcISJgfKJScOYkNGdsQNyONyVDRIun7CCH5duZVAWDNTFUGC28UDl47n9zXb+c8XczBNiUTSrlljtuyODNc1TclFJwwELAH37ymz+PK31ThUQVCv+bfmdjoIhHTcLgeqUAiEQhimJKSbhDDZsiev2nMXb9zJL8s2k1dcFrkeQ+JWVFwOlWa1OJuf/fxXisoCEUJJEdA0NZHC0gC6YWKG7fTvzVhMKKTz13OOwzBNvvp9VZQZy+1Urcgsw8A0JWP7deHu808ArAjAq//9CUVlfqSEYl+Ad6YvAogwsWbmF+NQFAJVkv5cqsr2zHyaN0omI4bQWJse3ce8JhI9Lj66/zK++WMNizftpFubZlxw/ACapiZVVPY1q/6yhMDlUKNMWYWlAe569VtMU9KzQwteuPXsCv/SoWA/TFLNhBCVW01MllJOjphLCBWrffYxwMtSygV1sshKxKNh/BXog6XyfAQUAnfW9UKOdB667OQaW54qQtCrQ4uK53lFZfy2envMYyWWc7Ko2McX3yzhnn9/xeaMHATga6GiJ4gKTbVXrzY8/c8LSElw85ezRvPJg1fw/K1nHzJhAZDWOJFWLRtFjeu6yeABHQ543pMHd+eaU4fhcTlIcDtJdDu549zjGNbDclB3ad2U9++9hPGDu9G5VRNOH9GL9++7hJ+XbuL9n5eQlpzA+WP78bV2DelZ+VHC2eVUrWQvYPqSjXz9xxqCulHhj4ra4EuJO1cneWcIR1aQxiGV68cNJdHj3C/TWHpWAQUlvpivBUIG2YWl/O+7mvdkSzZFa6amhO5tm+NQlYjX/EGdd2csZuueXMywUItGcNukY/n0wSuY9uSNPHXDGRXa6S/LLVNj5cv5gzof/LIkYoY2zRpF9RIHy5TXrW2ziO9/ZfbmRRfcrI1Ej4tLThzEszedxc1nHkvTsFlYUQQThveM0LbBMhdW9/ssC4Twh3TW7Mjkmc9m7/daDph4zVHWR5ojpRxa6TE5ajopDSnlQKAdMFwIUeedUWuqVvu+1+u9ArjB6/U+ADxQ1xc/mmjTNJUbTx/J2z8tJFglfl5VBB6Xk+sqFUIrKPWhWh1wIuYRAm4/ewy5OcX85a4PKFQNSlPZd/dSBYEWDhweJ389+zguiOHUBKuPxke/LKWwzM9pQ3ty3nH96q1ssxCCR+47izvv+wTDMJFhP8w9d5xGasr+RcBUnfeGiSO5fPwQsgtKaZWWjKuKqalL66Y8ef3pFc//+cEMfly03tJKTMnn3y7l9zkbo8wn5RSWWOGsX/2+OtJfIiVKmcTjUAm4rWgkT5FELZVWMlWRgVFkMOW9+ST3SyOHWFUFY1ObcNENk99WbavxmGapSRTH0N7W7cyO6TcyJVz970/55tFr6NGuOet3ZiEBtdTAVWSiCB2zUKdt00ZRprD8Yl/McPFSfzDCKZ7gcnLLmcfyynd/RGRPTzq2Ny0aJzOsR3vmrNoWVQWhaqj0wXLvRSdS7Avy++ptKEKQmuThiesm8NhHM0nPyq/WrxbSDWYs2cgjhzL/pB6ipKSUBUKI2cBpwOq6nLsmk9QQTdM6AtdqmvYeVYwOXq+3ep07DsLq02Jgl5TyDCFEE+BTLIf6duBCKWV++Nj7geuwCtzcLqWcFh4fArwDJABTgTuklFII4QbeA4ZglWK/SEq5/WDWGw83TBzB8f27MGflVnTDZG9+MRt2ZtG8URKNUxKYunAdZ43qQ+smqXRokYbLoeKrkh3scjiYOKIXj/zrG4pLA5S2dURtdT0uB/+6ZgJjw+GnVfnmj9U89em+kgcbM7KZs2oLL//13HpL4DumSwu+eP8WFizeRpk/yIghnUlrXDf5nQkuJx1aNK71uPwSHz8sWEdQNxAhSeJeHSEhMzsfs60DHJHvXTdMhvawkrbU8s9YShwlJu4CM9wZz8DtEsgUFXeJpErLBQzdoDS9GFwy4t9JEQKHqtRcA0zKaqPb0lJqNkndcuYoHn53WlRQQFUzV2VCus7kz35j79JMaAKeXB1HWNERSF55bRYb1u3m4XsjAyBH9OzAK4oSEbosBAzo0ibq+3TF+CF0b9uMz+asJGQYnDWqDycOtCoJTRjei8lTF6CXmBVhwQ5V4fQRPSMET3kS5IF+VxPcTp696UwKSnxWrkbAIBjUefWO83jso5+Zu2prtQmRhzLBtTzTu07mEqI5EAoLiwRgPPBU3cy+j5oExqvAT0AXLLtY5U9ShscPhjuAdUB5EcP7gF+klE8KIe4LP79XCNEbq5ZVH6AN8LMQoruU0gBeAW4E5mMJjNOAH7GES76U8hghxMVYH9xFB7neuOjernlEpcvHPvqZqQvW4wuGcKoK701fzAu3nUOyxxX15XQ5VP5xwQms2raH5authLxYRkPDlOzKiR2tEwzqPPXxTPyVblT+oM6KLbtZsyOzXosSut1Oxo6Ojso5VGTmF1ulvHUDd75R0QrVKuZn4GvpwOVSIZzfddd5x1eYMi4YO4Dlm3dh7PXjKpYRX3Y1KCFXJ9atPyBMRJYPd5JCoLFiNRrSYUzHdvQc1I7v568lp7A0SnCoEkv4xLg/uZ0Orp8Yuyx3OeMHd8cwTJ78ZBaFZf4aj61Ya1Bn2lcrMHSTpLBcifhRS8msuRs45aSt+EIhlu/ay+odezmmbXMmjujJ1AXr0cMRfC6HykOXnxwx/8YtmXz9/VKKSwKcPrYnx4/uEaGtJHlcfHj/pbz63Tx+WryeQNBAVQSvfj+fGUs28cR1E3n601n8vnY7qqJw+ohe/OPCE2qtkCulZFdOIR6XM6I6rRE0eOTRr9mxMxdFCBISXDz+8Llk5pfELJnjdKicMbJ3XJ9lXSEOMsqvEq2Bd8MbcQWYIqX8vq4mL0fUVtJA07RXvF7vLXV6USHaAe8CjwF3hTWMDcAJUso9QojWwGwpZY+wdoGU8onwudOwQn23A7OklD3D45eEz7+p/Bgp5TwhhAPYCzSXNbzZoUOHysWLF1f38gGxeVcOVzz1cZQKnprgJqDrEY5HIaBTqzT8AYOiMh9iiw+hS0raOJBOgeo3cRWaKCEJSSqP3XM2Ywd3JXtvIXnZRXTu3gqX28mDj3/F1PRtUTtXj1QY07E9vTu0ZPwJvWjX9hAVWDuE+AIhTrrnVfxBneT0UNTuTQoYNKYzx47qxqheHdi5LZfi0gDDBnWiSVoSL34xl8/fnl/trk9Vrc/UqKRm6B6Bwx9O8guPCaBR40S+/eg2wMrtuOf17/dpA1KSnCcxkPjSFCpHMLidKv936UmcOapPXO/5/96ayk+LosNSnaqCbkS6fhOCAseeYK1zqk6VopYKpiJRguAqMXEIwWXnjWBnaTGbd+fQrlljLhk3iCHdLQ3t19828NizPxAMGkgp8XicjBnZjYfuOSNq/p+XbsT77nR8wX3atVNVSPK4KPbty6txOVWO69uFf98YPUc5G3Zmcfdr31WUy+nfpTX/vvFMGiV5+Os/PmLN+l0R/15JSS4ym0trM1b5diAEXds05f17L40rslAIsURKObTWA2sgqVl72WvS3+I6dslbdx/09eqCeDK961RYhPkvcA9W975yWkop9wCEhUa5h6wtlgZRTkZ4LBT+u+p4+Tk7w3PpQohCoCmwf1XtDpLlW3fHHC/yRduepYTte/MRWH2JHY0EnlyJJ88gmCJIyDH33ciKDZ59eiozGqWwcsEWVKeK36VwzPDOrNqcCa0Vqwh9GGexgSM/xKKMLSz+YysffbaAe+6cwPgTqo/hP9Io8wXx+YLccc5xPP/VXKQaQlTJr3OqCqN7duLYbh247W8fEQjoFf6Way4bzeKfN8UUFkI3ceT7UEImSofGSLdAURRCukHAZaL692ky5Sjqvmdj+nbm8Wsn8sJXc8nenIdaaCANiQNIDJiEkpVwcyXJhSf3i1tYAAzq2pbZK7ZEmKaEgCHd2rFuZxaBogAiK4hqWDfgePrxlSVITCFxlJp48kwrwQx467sFyFQHRshg++pMFvy8gbEju3H/Tafyn//NiOhJ4veHmDtvI1u3Z9OlU2Q+yU+LNkQIC4CQYVJY6o8QcMGQwdxVWyuaQVUlENK56b+fU1Tqt/qMGJIVm3bxwFtTeeyqCazbsCdCWIDli3I5HBj5Adz51nsznUCqgxsmjDikVRHgyKslFVe12rpECHEGkCWlXFLrweFTYoxVo8xHbPKqe63yWm4UQiwWQizOzs6Ocznx0yotpWJXGg9S7iv1oCer6B5Q/ZKEbDPyiyXBn57Hsj82EQjq5KW6KE1xs2LDHkzDxJ1vWF5Oa0Lc4QqepikxDJNAUOfZF6cRjJGxXOYLMm/hFpavSq+wMx8qQiGDjVsyycqJP2omGNJ57JkfOOviF7n4mtf46r0F3Hf28fQb1jHqW6DrJtt25HCv9wvyC8osIeMPEQwaTH5nDjszYsTiGyaeXUU4SoKoAR25OQcjv4yUJDejRxxDQsukChNXORIoKvDx1ge/VYydMKAr5/bqQWIpyEo3MTUEnnyThFyTBEOhWdP9q2t0xsjetGycUpF34lQVEt0ubjl9FMeEEnFkBK2WsAaE/PEVZDTcAgQRlV9NB4QSBUbQIHG3bmm7pSZzZ27g2tveprgk2iwmhGDDpshQ8p0ZeSxetC2mszeW/0BRBCUxNlgA89ftwAiZJO7VSdyr48k2cO8IsmTRNvbmFMWsLSYQDG/TGk+eiWJazascQXDk6oTyDjwE/ICpu8S9Q0JDdEQZDZwlhJgIeIBUIcQHQKYQonUlk1S5kTEDq+BhOe2A3eHxdjHGK5+TETZJNQKinPTh0LTJYJmk6uj9VTCyV0eapiQRDBXVmPEMVCSLVYRDSonDX33Jc1Foqe56igvpVCMcrq5SiaIbBFMVRA35BNvTc+netWXF8z8WbEZ78jtrdywhKcnNf5+8mHZtqi/vUVf8Nm8Tjz87FSklumEwuH9HHvm/s0iopazJS5Nn8utvGwiFzXt79hbyyksz+fCN67lo8WsRyYQAU6evijmPlLF/l47iwL7SEgICbVORqkJmTjGZv21AT1ExWztx7t63YxaAYZh8OGU+E0/uVxFy/NnXS/DH6AxYcS2Hwmnj44+E3Lh5Lz//uo7xHTpg9HOyOTOXLq2bcNHxA3nokS/ZtCVrv/qrKIqw8hgCErPKncFwWjO5Cvb5hsDaIefll8a82QugfSXTp5SS/3v0S4wcP7R0RJhN3U4Vw5SYVTSClAQ3bZrGjqLSdRORGUAEIzU8Z47B/Q9/HruCsIRWrkQUqvx7S/jq26Wcfkr8pe3rAlvDqAUp5f1SynZSyk5YzuyZUsrLgW+Bq8KHXQV8E/77W+BiIYRbCNEZ6AYsDJuvioUQI4X1bb2yyjnlc50fvsYh/6dxqArv/OMiJg7vSaMkT7UZxC6HSqsmKUw6tg8epwOhS1wFce4GE5wxEgbAEZAkZhukloiYWa66btA0bZ+DsKQ0gPbkt/gDIcrKgpT5guTklvDIE99EnVvXZOUU8+hT31FaFqDMFyQYNFi6Ygf/e31W1LGFRT5+nr2W3+Ztwh8I8eOM1QSqRAqZUvLD9FVW2PJBogSNih+1nuRCqpHlsh3FBiIvtqFH102efv6niuc+X/X+g+7HtOT5Jy+haZP4NIwpXy3itn98xJQvF/HF10v4/oNFnNW7O3eeO5ayIj/pGfEFMQoB/3zwbL7/9HbOnzQEh0PBWWIiq3yllJD1IagBGSWEQiGT1i0b4XHvkzIul0qXTs3p02tft7s9ewvJzCpCCYInx7A2M1IiTDh7WG8evGw8bqeK26mSEM69efy6idVmvA/v1QFKjKj1CKCwMLqgo8Oh8Lj3HFav2xWzA0GZPx6DXR1jaxgHzJPAFCHEdUA6cAGAlHKNEGIKsBar5t6t4QgpgFvYF1b7Y/gB8CbwvhBiM5ZmcfGhehMA6zbs4e0PfydjVx79+7bnL5ePZkTrNjz+9gxKU0XFVkhgZYk/e9NZDDqmDXkFpSyYu4mi3b4Ku3EsHA6FpDaNCGWVEDDMasMzFUVwz52n8eOM1axek1Gx23a5HIwa1iXi5rRk2XaUKolNUkq27cihoLCMxo3qr8z17Lnro5LQgiGD6bPWcvdf98XEz5yzniefm4qiCgQCVRUVmkVlTMOK5NnfOlPlO+yIudwOZJnlQDfd0SHOAM4agpRWrclgzfrd9OnZhmFDOvHHgi0R1/C4HTz/1CX07N467nUWFft4/d05BIPWezcMiWHoPPfydMaO6U5+Qdm+MOFaEEKwZVs2Y4/tTlGxD9OUKCYkZRrobnAGAAmqbplHTYdA0aOFRutWjbjm8jF8+uVCSksDnHh8Ly49f0SE5lFY7KvQtJ0+iWOXDorVEve0QT0Y0Lc93Vs148U3Z5KxPZdO7ZrhrMFHn5Lgxu1UKz6Hfe8pdn8QIQQP/vPrmNUHHA6Fk8cdYp+ejK/sx+FEgwoMKeVsYHb471zgpGqOewwroqrq+GIgSoeXUvoJC5xDzZr1u/nb/Z9UOAD3ZBYyd95GgkEDEdRxhwTBRiqo0K5RKpPvv4iWaSmYpuTO+z6heGdJjWYEIeD8SUO47LzhPPX3T1m6eifVRd67XA4cqsrjD5/D5LfnMGPWWisT9pR+XHfFmKhjq8NRS8Lfxs17mb9oKx6Pk1HDu9KuTdp+VzitaooAK0S4nOISP08+NzVKm/B4HASDRuSNXgiOH92d4hI/n3+9BH81nfCq4nAoUTcfPcWNoygAhokS1DFMV0yhUR0h3WDRkm306dmGO285mY2bMikpDWCYJlLC2WcM2i9hAbBhUyZOhyNqraaEjF359O7ROm5hqaoKHreD/70+k59+XlMxrhjWw+lQads2jczMQmR2iFBiOFeCyA3N8pU7OeeMwbz23ytjXmflmgz+8dBnEX4xAWBaeRN9e7XF5w/yoPdL8gtK0XWT5Xnp/P3BKTz+8LkMHdQp5rwTTu7Hj9NXValjFlv4h0JGzA0GQFKim0vPrzmUua6pyzyMQ8XhpGEcsWzbkcPOjDy6dW3B6+/OiYgWMU2JzxdCmtauzFUqcZVarwdySip6Eq9cs5PMrOoroVbmq++X0bplYx5741o2b9jDjXd/EPMGYZomPbu1IsHj4o5bxnPHLeOrnbND+6aYVZyEDofC4AEdSU6qvrbO6+/OYcpXiypuXi+/PovGjRJ54O+nM3xI57jez5iR3fjfG7OjxqWU7N5TQJvWjVm2Ij2miUnXTZo1TaEk7HTVdYNbrx9H61aNuf7K42jfrgkvT55JcYm/1kaIwaCBw6GgVy6doQj8bVNxFPlR/Ho4FDN+geFyOWjc2NLOmjdL4eO3bmTB4q3k5pUyoF97OrZvGvdc5bRonoIeoxCloRs0SUsiMdHNP24/jaf++2O1N8hyFEWgKIIvv1sW83XVofDEw+dS5gvyl7s/QJTF9sEEgjofTJnPqOHRyaRSSh5/9gf8MUw+zZom8+9/XoCqKvw8Yx3FJf6Izz8Q0Hn1rdm88eLVMa976/XjyMsvZf6irUhTVmgW1WX2V0e/3m1xu2vO96gXDr2l/KCwBcZBEAoZPPDPr1i+Kh2HqhAKGVFmHbAcoDE33JW+LNk5JYg4bkRSWj+iV96cxWnj+3JMj9bceuOJvPz6zIgQQqdTZeLJ/WnTunGtc86as57Hn5sa8SNzqAoD+rbn4XvOrPa8XXvymfLV4qidbkFhGQ/+6yveevmauBzmHo8z+kYdfq/X//Ud7vvbBBKqKwgnYfSIrmTnltC9awvOmjiwIsNcCMGQAR3x+UNx/y6rrgEARaA3PrASJw6Hyolje0Y8Hz2y2wHNVU7H9k3p06tthJnR7XZwwpgeFabDk8f1ZkDfdngf/4a1G2K3ZHW7HDz20Dm8/PqsmKU/wLrZN0lLQggYNrgzi5duq9Zxn18QW9ctKQmQHSPyze1ycN0VYyrCbrdtz4kpVHbtKYg5b/lrLZunMmpYF35fsCXqdSEELqcapZlGrMPtYOKph9bZXY6tYfyJ+OybxSxflU4goFNuFVUUSzhUvkG5XCqmIaPsqoGgztW3vMXjD59Lv95to3b45cRSrxVVIX1XHt27tuS8s4bQr087PvtqMVu3Z9OsaTKTJg6Muduris8f5Mn//Bhh/gFwexw8/ej5NZqjlq/cWa0j39BNpk5fyY1XH1/rGpKT3KiKgh6jr3lpWZB/PfMDLzx1CQkJTnz+YMVnqyhWzso3U5cjpWTR0m2YJlxz+WgAli7fwSNPfVvrLrsyqiqiYvejjlEEnTo2Y/feAoxwVViX04GuG7Rv14Ss7GJKSv307N6af9x+cPW0quOJh8/ljffm8vPstaiKwhkTBnDFRZHtD1o0T6Vn91bVCoyTx/Vm2ODOlJVNi/m6AJo3SuTqm94gK68UpMQwZczvo9Opctyo2ILQ43HG/PdVVYXmzVIrnvfu2Zqp0534qgiNbpUi+SpTniwYChnVahRut4PmSR525hRVW4YlEND54psldGzX5NAmtB5mDu14sAXGQTD9lzUR5iewVGFVVVCEIKQbuN0OWjRL4cpLRvHcyzPwV9rtmqblVL7y5jc5blQ3jh/Tg19+XRfx5R/Qtx3rNu6Jtq2HDJo3TWblmgxWrs6gebMU7r7tFDye/VOrN2zaGzNXxDQtU1t1P1aApk2Sqo1g0Q2T4uL44trdbidnnzGIb35YFnP3GgoZfD9tJS88fSmPPvUdW7ZlhUMmRYRNPBDQ+eiz+Zw1cQCGKblf+6LGMNZYJCW6KSquudSGy+XgthtPZGC/9mzfmMmuzAKCWPW0yk1M+9upbn/xeJzcduOJ3HZjze1FTz91AN9MXR5TCO7YmcsjD32OahhRHelEQEc6VTIyC6nYAZWHfoe/n6qqIISlNTVJS+KcMwfxzAvTmP3behwOlbMmDuTKS47F6VQ5+4xBfP3Dsorfi6oqpDVOjKhmfPzoHnz8+UJ27sojENBRVQWnU+XW68dVHJOZVcSWbVm0a5vGMy9Oi/r9VcUIhMjZnAutky0JqIiYQSJLlu/gpjvf58M3bqjXAI+q2E7vPxFud/THJwQcO7wr7ds2YVt6DoMHdOSM0/qTmOCic8fm/OXuD6Ju/qGQwcw5ViOc8pu3oghSkt1o/zeJZ1+awcLFWyvUapdL5bhR3Xnh1V/4Y+EWgkGrL8Orb83itf9eSYvmqcRL40aJMSNKDN2gUS0/nKGDO5OY4KQsRrio06ly/Jj460rdfO0JNG2azGtvzo7yx5imJD+/jC++WUJRsY9jOrfgtPF9eGlydNitw6GyftNedqTn1KopxCJWAlplPG4nfXq1IdXp4MoTn6K02I+UkhatG/PPyddUHHcoi9jVxDFdWnDPHafxxHM/Rr5gmGycvpZNhkko0YVslrjvJiolwpTIypuBGO/HNE1aNk8lJ7eEnJxiLr/hDSuPJmzW++SLheTklnDPHadx0zXHk5zs5stvl+Lzhzh2eFf+etNJEX4pp1Plf89extTpq5i/aCtt2zTmvElDaNs6DSklz700nZ9+Xo3TqRIMGeg1FXbE+p04giZSN/DsKiLQLAnpqb6dcTCkM3X6Ki694NA5v22B8Sfi/ElDeebFaRF2V5fLwcXnDadv79j9KKya/NV/0ctvcqYpKSkNcNOd71NQUIbTpZKQ4CQYNAgEQ/z6+4YIe7vPHyIQ0Hlx8kz++cDZcb+HTh2a0aVTczZtyayYz+lUGdivPS2apdR4rkNVGDakMz/OiK6gnJToYsjAjrVev7jYz+R35zD3j40kJroYOrgTy1amVwhVpSyIqyTIgvmbMMKmkD17C1lfJYO4HH8gRKsWjVi7fne1dvmaqM7XkZrsoW+ftow9tjsnHteDq056msK8fSXNd23P4ZG/vMsr39wJWMlsy1amk5LsYfDAjjjqICekJhYu2cb3P63A5wtS6guyMyOP5s1SuO6KMYwc1hWnQ434PJx5PoQhCbSxEhEr30QVv47pqr0UvpTWjl9CzK90IKAzY+Yabr1hHEmJbq68+FiuvPjYaufbvnEvUz9dQHGRn7NP68fIE3tVCN5ZczcwbeYagiEjKhmzMooiSExw4fE4GTaoE7PnrEcC/pbJ4KpeWIAV9LBrd36t77vOkNhO7z8T40/oRcaufD7+YgECgaIKbr1hXLXComvnFiQmuqNstNVhGLIicioQ1CsiWiyhEiMqSkqWLN8BWJ3uXn3rV2bNWY/DoVSYB2LduP796AU8+9J05s7biBCCk47vVWNEVWWqey8JCdHVeKPWa0pu+8eHZOzOR9dN8gvKyMoqqjhXyS2DnFKMRCch0yTePNOunZsTCul88sXC2E7sKrhcDkIhvdrfrtvl4NknLqrIil+1aBvBGKbI3Tty2ZuRx4KV6bz02i+W/0dYZq4X/30prWM0maoL3vnwdz7+fGFU+HBRsR/tqe944O7TcTiUCIHhKAsRSnVHJSIC1k01ZEIcQq62252iKBQW+khKrLmL3fxZ63jyro8JBXVMUzL/l7WMObUvdz9hRcd//s3iWs1PYEWiffr2TQgh+OXXdcz+bQOhpgm1CguwzHyD49jk1CW20/tPhBCCay4fzaUXDCc7p5htO3LIyStly7YsunaO7i6mKIIntfP4+wNT8PmCNe6UYmGastZwwUYpCUgp+fsDU9i0NQu9JIAz38eU1T/y6ycLeeLlK2nTsVnEOSkpHh65/6z97kNgmpLCwujIGKdTZeyxtZujlq7YQWZ2UcRNPaSbhIr9OBUFR26ZVbLDUfuPvZzGjSwHc8/urRkxpHNF5IzQTdRCPyAxGifiTHBaLU2bJlNSEohy+lfmnDMHRZRQqb5ogCA7t4SXJs+M2An7/SGeeG4qLzx1SVzvYX8oLvbz4Wfzo8yc5QQCOm9/+DuXXTiCDz5dUCFUpAJGYuwqASQ4UPP9GO74P/fqcLsdtGxRs4lUSsmL3q8IVNp8+H1B5vy0ivOvHUuHY1qwZVt8td4SE/aVkunQrom1oUmuveWqx+OkW5cWHH+oy/PbAuPPh88f4p6HPyevoAzTsArtjBvbkzEjjsHnDzE0XD4boHvXlnz5wV9YuiKdp5//icLCsv0WHNXhdju44uJRbNqaxdYdOeilATx7iiuyxjO3ZPPX81/i1e/+RvNW0bvd/bW7f//TCtasj67I2yQtiSsvqd70UE5mVhGyGgGoB0I4wjWclKBefbnJSihC0CQtmbl/bOT9T+exbUeOdb8LGHh2F1V8DkqpTrMOjXn4xStBEdx85wfVzpngcdKnZ6TG2HtQR1RH5O5bKIJW7dLYtisv6h5rmpJVazLQdaPWJMj9ZcfO3JhJfJXJzi3m8otG0axpClO+WkRpWZCAIQn6Q0hXpANYCDimS0ucqmDNxthmv2oxrQ9YKAJVVVBVhfv+NgFVVdiyLZsPPp3H9vRcBg/owKUXWFngJaV+GiV6KIoRkqsI2LBqJ2mtUgnEmXy5bUcOjz/7A7dcP46PP19o+etr+OIcN6objRsnMrh/B8aO7l7n/z41YSfu/QlZsnwHT/33x6iku59mrGbWnPVIUxLSDbp1acmF5w5l1PCuJCd5GD6kM+++ei1ffLOEb35YTk5eyUGvZczIY5h4Sj9+X7AZVRE48/0RJUYEEPCH+Oa937n+nolxv79vflhGMGRw2vi+HD+6e4Vg+X7aypg3qmM6N68x2a+cPr3aVmsGkpXMIYpPRwR1pNtR/Y5XSpQCHxk7NvLwml2YCfuixVx5ZRGfg2mYZG3L48Gr3uDyeybgcCoEY9yPHKogKcnN2g27yS8sZc/eQoQQdGzfhKI0D6LET3kLvoRkN97/XcnqzXtjRo6pqhIzR+dgadO6ccyqw+UIAf16t0MIwYST+zHh5H7MmLWWp/4zFbUsYHWeq7LcTVszq/13ad40maISf5R5SC0O4Motw5HsIeRRSUlN4LGnL6ZHzzZs3LyX2/7+UUXQxtbt2Xz1/TKUsGBJ8DhRHQp6lY2TxPINPfPYt/tl6p8+cy0/z1oXl4sgY3c+f7l+XFz5SnVOOLigLhBCtMfqMtoKMIHJUsrn62TyStgCYz8JBHV+nr2Wpct3UFTsZ8WqndUmBVX+UW3cksm//v0DihAMGdSRB/9xBlJKCorKyCs4eGEBkLG7AIDePVpbSYSh6MJshm6ytZq4/Ixt2axYsJW0ZskMG9uDb6Yu5/V351aYMZatTGfpih3cdespQPUbflWNb5fWqUNTTh3fl+kz1+wLHAiEULfuQeQWYaQ1wpmcYu1caynH4czzWZVlAdMT+bVWA9GfA0BBbglvaN+gdImOvVcEqA6V4hI/H3++cN94RQ6CxJHixlloCeUyX4i1qzNo3i4t6mbqcjk45cTe1YYgHwxN0pI47aS+zJi1JiqE2OVy4HKq3HbDvrDU3LwSnn7+J0K6CSmecJleiVAELZun7nNiV0FRBE6nygN/P51nX5rOnszCClOiC3Dl+zElGMV+lGLw5/uY8vJMHnrxcia/MyfyNyIlhm5gCKsWmN8fwpPsIkFaQQvBJomYCQ7knmI+f3supS2SIEZEYk1UrU1WHdvTc7nz/k/45K2b6uXfp1bqTsPQgbullEuFECnAEiHEDCnl2jq7ArbA2C8CQZ2/3PUBGbvzY2akxoMpJUtXpHP3A1PYs7cAnz9IrHy9qsl/8eAMq9NpjZO45ooxvPPvH5GhQMTN0uFU6T88urvu28/9xNfv/Q7C2vV5kt3kpLmjmuL8OH0Vl10wkpYtUpl0+iC2v/JzhLPV43FyxmnxZ83edevJnDCmB599vYiF8zej/LEGgjpCSijxIdPK6HzCANb6agh3NSWO4gBCElVlFcB0qqjVOExNw2TCyG58//uGCJNc187NWbN+d3QxwvBzR1EAZ6F/n0khZPCfBz5H79Qk6hy3y0HXzi0IhMOf65q7bjuFHt1a8s3UFUgp6dWjFQKFNq0bMeHkfhF5BfMWbomUvRV9tCErJ7awABg5rAs3XDWWLp2a8/Kzl/P6O3P4bf4mkhLd9G7RmIW7VxKsFJ5t6CYLZq9DShk7oq2Kpmg29nD8af355feN+E0T595iMCQmtW8WAETIwFHgR2/kQcYR4VWOlJKiYh9r1++uNlilPqkrk1S4end5A7piIcQ6rEZytsBoKH6evfaghAUAUiJLAmzZuBfpqN5EUZOwcKgCKYnIV3C7HJxz5qCK5xefO5xPPp5HcH1WRR0rKSAkJePPHRwx3+Y1u/jm/T8iIn98IR09Kfrr4XSqbN2eTcsWqUw4uS+btmby/Y8rcDpVQrrJ5ReOYMTQ+Nu9CyEYMrAjQwZ25NGbJjNXNyLevJ5fhCM7G0fjxtWHyRpmxU5NSOvmIZ37HLahJgkoe4uJVQE4ZJis2rQXh8MyGY0a3pU7bjmJ8698tcYAA0dRIOrHHkxwoscwDxWX+Hntrdn8NGMV/3vu8jq3kyuK4MwJAzlzwsBaj3W7HYiqN2BZHsod+8YsBFwwaWhFCY9GqQn8/fZT+fvtViXhqZ8uYNGP0X1GynMsmqYlURxOhhQBPeYNPRQyaN29Jf4Fm6DMQPXrFf9WamkQPdVTreAQwX0+Kj01hilUShJ1SfPURHYFg1F5R4oQ+Py1t66tcySW9hwfzYQQlXtITw7384lCCNEJGAQsOKj1xeCQ98M4klm2Iv2ghYUrqxR3ZklkUlQVXE6V4UM643I5IjZiqqrQODWB0/p2svwTpqx4uEuDnFApwmP3nnwCpsTXLpVQYw96goNQYw/imKZs2xnZK2HR3I2EqtzoZMiI2bEspJu0b2eZcIQQ3HHzeD577xaeffwivvrwVq6oIc6+NpJMw7r5V2H3+l2MGtE1tslASpSgUaFZmA4lKqrKdKsEWqUgFRHVGc/XKplNu/IoLglQWORj9tz1fPTZQtJqSVqMZXs2leqL3vkDOukZefz6+8Ya561vRo84JjK4QQ8L2xoCHhwOlT7h3beUkp+/XsrtF7zErWe/wDfv/87Icb2iJLHT5WDcmQMRQnDRecMrxtWAgeLTo3ZEUkKXjs1xqIpVHbjyXAV+RMjqIhnrO+Cs5KNyFAf23YQNE2dWCQnbCxC7CslauwczhqZpmpL+fdpFjR8SZJwPyJFSDq30qE5YJANfAHdKKeOrZrof2AJjP+jYvgmu/VB3q6KWhVB9Vm8FUU0HPqdTpVPHZmj/N4m3/3cNt1x3Ajdfezz3/W0Czz1+IVPeuZnfflyJkldGQnoBnt1FJOwowJHrY/FvmyrmSUhwWTd8VUFPSyDYKgW9cQJSiKiY+JRUD05npDYhJCT5DTyVKnh63A6ODZcvr0zjRok0SfKwd3tOlONyf+g9sjueys5yRQGPmw59O3LzFccxIkb1W7UkiCt7XwKdkRCjNIoQmB6H1S3PoSCFwOV2oqS4UT3OiPIi/oDOZ18t5spLRsXM5Afr3yiheXSjI49uCfvq8PlDrF67q9rXDwWJiW6e/deFtGyRitvlwFnLBkhVFR576JwKU9pbz/7Ei498xabVu9i6YQ9vPzeNyU/+wCP/u4qURgk4XQ4cTpVhY7tz8/9ZhSsnjO9boZ2YTgVXTikiZEZseFLKQgwa2MHaJFXxvQkJnt3FuDNLGDP8mKhS/EpgnzbiKA6ilgYhZJCQUYijNGRp12GB4sosAcPEoQgSE1143E60/5vUMJVqCWvEcTzimksIJ5aw+FBK+WV9rNc2Se0HZ5w2gE+/XEwoZBxQgqYSbsQD4Mj3EWqWVKFmCyz7/8P3ncmoYV0RwspYvejc4RFzlBT5Km5wlvnF+tvvC/LE3z5i7MT+OJ0OevRrR99ebVi9dl/Gs6oImqQl0atHZP+FsRP68/ZzkQXo3B4nF144gpa92/Dlt0sJhnQmnNyPsyYOjDiutNjPo7e9z/oV6agOFVVVuPeZixh6XI+4PpOMbdn8/PVSgkGdUSf0pFnbJmSl5xBKTEZpmoYA1u3xc+OEZ1FUhdGjurKmsISCIp/1nnwhlEr/FsI0qS4Gt0//9nSc2IR+HZqjSMgL6bwzZR6hKsJbNwyOHX4M3CZ4+4PfyM0vIa1REr5ACIeqMPHkvkw6bQD3XjGZwvwyDN0AITjp1H7keRTmLdwasweHx+2kY4f9L2de1/Tu2YZP376JzKwi3nzye2asTkeKStneUiIkPHTfmYwc3rVig1FS5OPLt+dGaFEBf4jff15D5u58AoEQqkOghyQt2zXBHa5rJoTguivGoD31HUEpkaqCe1cRKAIRDp0+buIAVFXhoXvO5MFr34j6FxSAI2BQsHZPtHbiUJBBs6JNqzunrNoobCVokJBeSELLFP52/ySGDupIYi1JhfVJHUZJCazGceuklM/VyaQxsAXGfpDWOInJz1/J7fd+RHbO/kU2qcUBHCXBii+yszSEkKWE0hJQXCrHjenOLdeNo3mzFBbOXs/aZTto3b4px0/sT0KlXXdyagKt2zclI0YiUzCg8/NXSwGY/sVikpskMmRcDxYv3Y4E+vZqw4P3nBmVb5GalsST797Ac/d/RvqWLFxuJ2ddPoqLbxqHoiicdHz1nchefORr1i3bYVWEDav7/7r9Q9755R4a19JudO60VTx732fouoFpmEz9ZAHn3nI6OVv38PP0DRHmIytp0WDFb5vo3LM1bpeT3GAI1eWAslCFD0Mt/7tygTlTcuzgzjzx+IUR18/Ylcdbn/wRta5mTZJJTnZz6kl9OPWkPtWu/40f72bx3I1k7ymgz9DOdO7eCikla9btZuqMlUz7ZW1FvSNVVUhMdHHKuN41fiaHCiEErVo2YvjxPVnw20aKGnkqfGrCMDmuZ1tOOiFyrb9NXx3T5GboBpvX7o7QLn/8dCFDxnRjSNhMOnhgR6uysRAEWqfg3lWEopsVN/V5v6zl+Ye+JKVRIkqg+lLrGRszOeu6MXw9bWXFZ2t6nCjBSDNWTW5yAbRrmsLYQ52kV5XYBRsOlNHAFcAqIcTy8Nj/SSmn1tkVsAXGftOmdWNat2gUt8Bo06ox2VuycOSWRX2JHWUhkky4+8kLOO7Ufhi6wYPXv8X6lTvxlwXxJDh574XpvPD5bTSrVFbi709dwP3XvIm/LFht1rFhmBRml5AzfxsP3XkKTVqk0m9wp2qT87r1acsr395JwB/C4VTj6odtmia/TV+FUbX8hoB5P69lwoXDY5+IVW33hYe/jMjuDfhDfP7WbzRv3aja35FpSrastZIFXYDL7cBQlAity7OnmGCzREyniuLXSXM5eeiBSVFztWvbhEmnD+S7H1cQCIRwqGEN6c4J1X5OAX8IXTdISvagOlRGVGnrKYSgb++29O3dlpPH9eGdj34nM7OIoYM6cc3loxt0NxuL4ycO4LsP55G+JRufruNyO/A4HNx2X3QflC0xkjTBks1VTZF+X5BZ3y2vEBiJCS4evu9MtCe/RdVllK8q4A8x/cslUQmRVRGKoH/nFpz9ytU8/uxUNm3Owkx0QnEg7puv2+Pk8tviK31Tn1iJe3UjMaSUv7E/nb0OEFtgHAAlO/Pjyg0QAnr1aI0zvYBsWRr1ekKSi5vuP5PjTu0HwA+fLGDtsh0V0Up+X4hgUOft537iH09dVHFej37tefeXe7ll0n/JzazZr7U7PY//3P85pilJbZzI35+6kEGjjqn2ePd+lkePiaypfIbF3oy8mHWeVIdgT3pu3JcKBnRUh0rXXm3YsSkTwzBwmBJljyXQFUUgElxce8q/eeLt6+ncvVXE+bdeP47jRnVj+rSVBAv9nDKhf8x6Qv6yIM8//CW/TV+NlJIuPVpz7zMX07ZTs6hjyxnUvwOD+neo9vXDAZfLwbMf3szcn1axcuFW2nVpzinnDCE1XJmgMk2apcbshSGEiPr3VhQRoRnnZRWRtzmb688aSnZ+KTN2zSPgizbbRW0+quD3BXn6nk9RVZXRJ/eh/7g+7MopYtu8rRTnlhKqocQLQIvWjbnp/86IEvQNhl2t9uimrDRA5urdKM0Sw9nElUwfVXalLpeDi84dxkNfL48514lnDeLU84ZSWuLn9vNfYveO6BulaUiW/RHdSSylUQKTLj+WD176OaoQXlXKX8/LLuahG97mjEtHVjgkDwZFURgxrhcLZ69DD+375kspGXlizaaXxk2TY94c9JCBUBRkNUEBsfAkOLnh3okMGNGV3Kwipn4ynymv/4quW82NykoDUBrgn7e9z5vT/h6lPSycupK5H87H6VJZ9N0Keg3qiPbKlbgqOUKfe+Bz5s9aV7GT3rx2N/+44jXem3kfjhiO7vJmWPWR3V3XOF0OTjxrECeeNajG48afPZgpk2fjr1TO3ulSOXZ8H+bPWhchAJwuB6edPwywCgs+cdfHSNP69zAN84DKv4uw99o0wTR0Zv+wAkURuNwOTFMydkI/tq7fS1rTJBo1Teb3GasJ+q3vvqIKLrj+eC6+cRxzp6/i41dn0W9YZ/oM7tigpejrSsM4VNgCYz/ZvSMHaUo8WaWYLtUqAx00UB0Kw0/vz6aMPPZmFdKuTRq333wSPbq1YvCxxzD3p1UROzNPoqvCMfzXc19kT5VQ18o0bRG7zPikK0ez7I/NrF2+AyQR5p3qMAyTHz5ZwIr5W8jOLOSY3m249aFJtO/SIuo4f1mQxGR3jT+oOx89l4duepvtGzNRHQqmKfn7kxfSpHnNpdGTUxMYP2kQM79bHrFut8eJv2z/QpeDAZ0OXa31N22RSt+hXfj6/T/QSyLt2nnZxexJz40ovrj0j01M/WQhoaBesTtdu3Q7n06ezRV/PRkAX2mAeb+sjTC7SCkJ+EIsm7eZYWP3OfjLSgO89MjXzJ22CmlKhp/Qkzv+eS6NYuzYjzSat2rEY29ey38f/IKM7Tl4Epz0HtiRxXM3WsJCgNPpwO1x8JeHJtG1Vxu2bdzDv27/IGpzUJsGCmENfVBH2nVpzoblO8nYlh0R0QaWidIfFlQLZ6/n498eQHWobFydgQC2b86kVdsmnHX5KFq1a8LVJz9NwB8i4A/hcjno1K0lEy4czqiTesfUquqVuvVhHBJsgbGfrFq4jfL2ZErQQCmvpRQ0uO+eM0hM9kSdc90/JrJy4TZ8ZQECviBuj4uBI7sy/Pge7E7PrVFYuD1OLqvG3upyOXj8revYvHY3GduyWLFgC9O+WFJtQb9y9JDB9k2ZAKyYv5Wbz/wvr353Z4XQ+PKd3/jw5Z8J+EM0bprM7Y+cw/ATesacK6VxIv/99FbSt2RRVFBGt/9v77zDoyr2BvzO9lQSCC2B0EF6R0RRRLAgKiooKNi44lUR9V4L1rgq6FWvDSsq+Im9C9eCSlMRQZCO9JYASUgI6WXLfH+csyGb3U02ZEk2MO/znGfPzp4zZ3Z29vzOzK91Twp6Wev2Ry8jJ6uAP5b8XV5WXFjq1/M9ELYIC6PGDyK+Qu4Oi83k14pNSom5kvnkkgXrvJ6YQRNAixesKxcYgSLZSjQrsYrMuPMDNq7aXS5cVi3bykP/mMOsz6eGTVKlmpKdmceHry1m/cpdJLVN4F9PjWPNb9v46LUlrFl+zJQbCS6Xi/5ndcNR5mTv9nTuvvr1apeZ/GEwCKwRFsZPOZf/3PsxpSUOH2FRGafDxb6dmSz7br3miFrmxGw2cmhfNuP+cTavz1hAXk5h+dgoLXGwbWMae7an8/qMBaS8eh19hwRerg09oYslVVfUucAIFCRLCNEY+ARoC+wFrpJS5ujnPABMRkvTMk1KuVAv7w+8C0QA3wF3SimlEMKqX6M/kA1cLaXcG4r2WyPMGI0Gnz+B0Sh44KZ3MBgNXHLNYM4d3af8BtG0RSPm/HgPvy7cyOGDR+nWry29T2+PEIKMAznlAqgyEVFW7n7yCs0xqgo6dkukY7dEhl3ch54D2/PxG0tI3R1cOGjQntJm3PkBbyy4m6Xfrue9l38sX17Izshj5t0f8tKnt9OmU+B0rZ4nfH9kHMjhvZd+ZPNf+2jVrimT7hhBl16tMZqMbFm3v1Jbgmuz2WykU48k4ppEY7OZSdtzmFbtNFv/rn2SiYqxeRkFGE0GOnZL9InSa4uw+F2Xt1TwwWgUH0VS2wT26ULWg8vpol+FG0xWRi4bV+/xyiHucro5sCeLvdvTaVfJnLkhkJ9bzNQrXiY/t1j7LnuzWPPrdjAIvzdwt0uy7LsNrFyyFSGgLMgos5Xp0C0RATw7/RMfoRwIl8tNYX4xX7+3vHwZ1vP62K3vUVIhH3xFPMc89a+P+Oi3BzHWYcTahpZAqT4WWD1BsroCg4HbhRDdgOnAIillJ2CR/h79s/FAd+BC4DUhhOcXfR2YAnTStwv18slAjpSyI/AC8J9QNX7Dqt0BnpgE2zemsXXdfl5+9EvemLnAa9pti7Awckx/rrntPPoM7lAuTDp2TQwY9GzmO5MZWkVcJiklGQdyyK4QKXf4JX2Z/e2/iAwiB0BF9u/S8mR//s4yH2Wko8zJtx//4XPO0SMFfDHnF1574htWLNri9waSk5XP1CtnsfTb9WQcyGHNb9u5//q32LYhFbfbTV6OrzFAMDgcLrZuSGXFor/55K1lTL1iFr8u1MJTGAwGnp77D5I7NsNiNWG2GOnaO5lHZk3yqefCsQMxV3IEs0aYufTaM7zKkts39Tn32tvO81rGyM8t9pugymAUfsN3NwQWfv4nRQVlXmPe5XLjqsZBs6S4jOJi/zfoYNi3M5Ptmw6Qf7Q4qOPNZiPd+rUhbU+Wb+gTIDenEEc1uj6n01k+864TpJaiNZgtXKjzGUYVQbIuA4bph/0fsBS4Xy//WEpZCuwRQuwEBgkh9gKxUsoVAEKI94AxwPf6OY/pdX0OvCKEEDKYhdMqOJKZx+8/+4/lVfFmWVriZP77K1i1bBv3P3s1p1VIdF+ZmLhIJk07n3kv/ej1lDtiTD9O69064Hn7dmbwxB3vczg9F+mWJLSIpbiwlLycIpq2bERJUc1i43gEmL+nObdbkp2ey4ZfttCiXTOatU4gdXcmd49/HUeZk7JSJz99/Rfd+7Xl8Tev91L0fvvxSkqLHT7OXu+9/BMz3r6J1u2b+p0N+Xvq92mXHlrc5ZS4nG5eeuRLzhjeDZPZSFLbBN6YfxdZGbmYTEbimvj3CenYPYk77GN4/ckFuJxu3G43oycMZtTVx/I6b9uYyqpl23zOXfXLNq6aMqz8fXL7ppgtJoor9b3L5aZLr8C/ZTize9uh454l1GZ9vqwKfZzJbGDIyB4UFZSwdvlOEDBkZA/usI9h6f/WBRQM1UWwdTndxFQTEibkNLAZRr3qMCoFyWquCxOklIeEEJ41jiSg4uNtml7m0Pcrl3vOSdXrcgohcoEmQFal609Bm6GQnFy9+WPGwaOYLcZqTfc8pKce4YGb3ua9RdOJiQs8EMdPGUbvQe357tOVOEqdXDZpCF2rSBXpcrp44Ma3OZpdUD7eDu0/pgfJOHA0qPZV5IzzuiGE4KwLevLNvN+9vqPIzeX3t7/nz/d/wlHmZOgVgymwRVNUUFJ+/ZKiMjb/tZfVv2z30nfs3Z7ut788jofT7Jfz4OR3cFTKq1GdsPCHy+XmUGq2lwI/IYi0qOdd2o9zLupN5qGjxDeJ9jIHBVj/xy6/IU+2VlpOM5qMTP/vBOy3v1cebVhKyb+fGoetQia4hkT3fm34/afNQRlU1IR2XVqQuutwufNdTTAYjdz9xJXYIi243W5cLjd/LtvG3P/+wI9frQk8dqR/E2DQojh37ZNMs8S4GrenVjQseVF/AqNykKwqFIL+Pgjk+e/p/qo+O1agBfCaDTBgwIBqf7rkjs1qHCuppMjBi498wXXTzq9SB9C1TzJd+wRns79pzV5Kix21fjgRes6Hjt0SufOJKwGYcOtw1q3YyYG9WbilxJVfSOnhbKTLXR6Jdekny7F27eRz/ZKiMua+sJDnpn+K1Wbh0oln0GNAW82KpsINx2AQ5QKxS6/WJLbx1Q8cD84yV7Xe5YEwmY0kBgjbEZ8Qg9lqwlVp5hAV62vg0HdIR95bfD+//6wt0Z1xXrdqLcbCmfMu68dX/7eczIM5OMpc2pgxmzAZDTgczuNSaAPcfN8o3nrme/buSK/WSKMysfGR2CI1ASzdkocmz2HH5gPVzqoteqReR6nTS6gYDIIzzuvGnY9fUfMvUktETSw8woB6MRIPECQrQwjRUv+8JZCpl6cBFefzrYCDenkrP+Ve5wghTEAjILApUpBERduYNG2kl0I0GN/KFYu2MG3cq7wxc0FtmwBoOoVQ+HS2TG7Ccx/cwgsf30aMngs7MsrKy59P5bHXr+eW6aPp3a2Zj0+EdEucxaU+9QkB+3dlkJ9bTFZGLh+8uoitG1IxW0wY9LV9s8VIRJSV6+4cya8LNzLhrBkhERYAEuk3wm5tOev8HuU3Gw/WCDPj/nGO3+Nj46O4cNxALh5/eoMWFqDp3i4YO6D8pi51f9Wrbj6HW6ZfXD5uasqOzQd5+KVraNIstsZpw3OzCrT4XcCvCzexY1P1wsJkNhDTKILnP7yVwcO7EdMogjYdm/PgCxOYv+FJHnzhGqJifB8ATigSzewnmC1MqHOBUUWQrPnA9fr+9cA3FcrHCyGsQoh2aMrtVfryVb4QYrBe53WVzvHUNRZYXFv9hYeBZ3fR1vvLffWqH+1SatYiP3z2J3+v3VfrNvQc2L7GswtZVoZ0ubym44dSj/Dha4t9jhVC0GtQey66alBAxyL34WwvwelZgvHoFUDTVSz7dgOFBcW4XW4MBsFpvZN5/etpZO7P4rn7Pw3aAiYYjEYDi75ZG7L6PEREWXnho1vpc3oHzBZNH3LdHSO58sahIb9WuFFUWMr7s3728sovK3Xy0RuLadelJT0HtiM61obRZMBUTVgPD0aTgfiEaIwmI517JvkPrV7F30oCOzYfoKiwlL+W7/Axi65MRKSFUeMHM+uLO2h/WksemTWRT/94lDcW3MXQC3sFFQbnRCCQWvDFILZwoT6WpPwGyQKeBj4VQkwG9gPjAKSUm4UQn6JljnICt0spPetCt3LMrPZ7fQNNIM3TFeRH0KysQsK7zy/UlID6b+h58gpGSVta6mDVL9vo2jewfiIYrDYzj74yicenzkMI7SZdWqo5IjkdrvK2mC1GrU3STfGBbAwtmnsJOOmWrPltO4X5JQGfrgZe1Jc//rfGp9xQWsJ1tw/nx2/WcSQrn8TWTdi/K9Pvn1fq9xq3W7Jp2WZu7vE7ZRFRyJiYKvMw+MNoMmAwCB+dB2g3siOZIU8BAEBimwRmzpl8QuoOZ/btyMBkNvpEE3CUubh30uzyBwWzxURUjI2CvOJql21dTjeOMid3XfUqR48EsJKr4q/kdLiYfsPbuN2Stp2aY7aYqtQrzpwzuUrDk3oljIRBMNSHlVRVQbLOC3DODGCGn/LVQA8/5SXoAifU7Nh8wO9v7NYtlXIOFwR0MLJYTMRWofyuCX0Gd+Cj3x5i05o9mM0mOvVIYuWSrSyev5a1K3ZisZlwlLnoNag9cWY3P6Wm+4195XK6uXfSmzzw/AQfb2+Ai28ewex751Fa5L0EFdcslssnn8OVer7ozINHuXnUf6tss7u4BHfaIVzNEhAx2lJNTVfWLpt0JiPG9GPWY1+xdX2q1/q3LdJCv7M61bBGRVU0S4zzK5w9SKnNXksOHKK4pITIdq0xmEzV+tN88OoijtbQpFrqodARolwntm9nBlVJF5PZyOY1e5XACBHhH+gmzEjuGNhBLS+niHueHke7Li38fm40Gjh3dJ+QtcVqM9P/zM70GtSeiEgrzZPi2aB7GRcXluF0uNi0eg+ZqdkIa2C/jL3b07l34my/Hs1Gk5FnfnqEqEaR2KKsRETbiE2I4dHP7+HvlTtY+O4S5jz8ISvnr+KSawZjjTDrynTvoeXKzcO9Pw3RKBYRG4MQwnu243QiXVU/mVqsJgYM7Uy7zi24/9nxNIqPwhZpQRgEtggLA8/uQr8hSmCEkibNYjnz/B4Bvfel04lrXxqyoBCcLop27MWVdpCEWGNA/yKA3COFQVsISSlxHkzHnX3E5/5aVuokItpKn8Ed/J7rdLrID1cfmAaow1ChQWrIDXdfwJa/9vk1M3Q6XRzcn81rX9+Jo8zBE9M+YPWv25FuSdOWcTz00jUB/QFCweIFa32WDspKnaSlF2CItIEQSLcbKt+spaZIX/3LNoaM8M7/kJ9TQFF+Cc8ttZObmYswGCjKK+L+EY9TWlKGW1/btkZYsEZa+Pe709i6+SARkVYO7M1ixaItlOQVITM0M1pDXCNEpYB87rx83OmZYDBgbNEUERmpZdurhJTQa5CWda95Ujxzf7yXXxduJCs9lx4D2tFjQODw7Yrj556nxvJFp+a8++JCnxu2OzfP5ynZlV9E+tpdmNol+/0dDUaBMKDFbQiAlBJZWAQOB+68AigpQSQ09jsllS7JU3P/wVN3f8jynzd7WW5ZrebwiUzrB2UldZLTuUcrnpr7D7+fuV2yfDnqmfs+ZcPK3eVLJnlHC1m3YucJbZvBIPyqBCyNoklq3RikxJWqpQiVDieu9Eyce/fjOpSBs6SUwoISXE4XOZm5uJwuvpr1HVcn3kzK5c9w+4D7eW7ya7hdLp6a+DLFBSXlwgKgtLiM/JxCFr7xA5PvuQhjfh6rP/iZsozDGIsDLz1It1sTFlKCy4XrQDqug+l+ZxsGg7e/iS3SwsjL+zPh1uH0HNhOCYsThNFk5KopwzhnVG+vmaOUEkrL/C+rOJ3aw4kfGjeNpUmz2Cqv6c7Kxn0wHXdmFpRohhHu/EKfaxkMmu8QwC0PXkLTFo2IiLJijTBjsZoYdfWgWusMTxzS46xT/VYNQog5QohMIcSmE9liNcM4DvKPFmE0Clwu3x9y384M0vYcZtXSrV5P+6XFDj56fQljrjsrNDkn/DBiTH8Wfr7aJ/rrqKtOZ+hFPZly7gycJaXIwiLchzLKAzfJ0jKKthaw+/ctvHrjy5SVOjCZTThKy3BWWL/OSjvCg6NmYjL7HzbSLVm7eBP3jXiCLSu24dA9hIVBlA96d24uhoQmx2YZJaU+sbSknvK0Mm43RB+nGaei9tzy4Gh2/n2Q7IxcXEUlFO0/iMFqDZzs6lAGhiQ9fpbQ0rEOPq8bD754LT9/8xdvzFxQHn7cC5cTmZPre6MsLcWdnYOhSXx5RkV3qYNhI7UZROOmMbz9/b9Z89sOsjLz6DmgrV+9XNggCaUO413gFbQYeicMNcM4DqwR5oDWPRtW7WH/rky/ORKEQXjFfQo1nbonMWX6xVgjzERGWzFbTJx5fnfGTh5KYnIT+vbUdCvuQ+m+Uf7cks+fm09hbhGOEgfF+cVewsKDdMtyQeCPsuIy1i/d5HVMRcW0zMlFFhQi3W5tMxp817JLS6HM4WUCbLaYGHh25+N2zFPUnrjG0by54C4eeXkiHEqH4hLcR3MDHi+LinHt2Yc76wju7CM496XRJsFanitj4tSRRMXYEAJibYJEq5M+HWLo1zm+3G/Hp84jObh278Odnolr/wFc+9NY88MxU2qjycigYacx6qpB4S0sPIRIhyGl/IUQ+JpVh5phHAc9+rfFbDb69XK1WEy07dwioGlhQvOqp+K1ZdTVpzP80r6k7j5MQvNY4hNiKC0u5Yc5i9m7UfcBqeeQyu5DGcccN7SsOJjMRq8+c6UdwNC8GURHYTQaGH5pn5AkfVLUDoPBgFm6gh9DThcy52j52wM70wHN12fc5LMZe9NQ7GOfY/lXqzgC7N+wt/o6XS5NyQ6YLCYiYxvurDOcfCyCQQmM48BoMvLQSxN59Ja5XjNKi9XEqPGDSExuwtmjevHrDxvLI79aI8zccNf5XlncThS2CAudumthtUqKSpk6aDoZ+w5TUujrnX08VGf3HhSejtNfDUYDVBSyLjfug+nYom1Mn3cHZ14WOD+4om4xGATyOIMgJXX0tiBcv2wLy79adfxtMRkZfk0DdqAMXmAkCCFWV3g/Ww9tVKeoJanjZMDQzjz44jVERtuwRZgxW02ce0kfrr55GAB3P3kl0+yX03dIRwYP78qjsyZx2aQz67ydC+cuJn1vZsiEhTXSyqTHriImxEtD/qKTWiMstO6SyOCL+4f0Wora0WVQRyKij++pfsX81V7vF7z+w/E1QkCTxMY8/vV9NG3lPwZY2CMluNzBbZAlpRxQYatzYQFqhlErzjq/J4PP7UZ62hEaNY72iqtjMBgYfklfhl9SdZ7kE81fizZSWsNQ55Wx2MzYomw0bhnH5XeMok33Vqz8dg2bl/uG/A4V0fFRTHxkLKNvGVm3CW0U1WI0Gnl64cM8PPop8rLzkW6JlBK3W3OsS+zYgtRtB3H7cWBN3XbA670tsuq8LWabGemS5YEvASwRZq6+7zImPXpVw7eMU0tSpxYms7E801s40qZrK/78bm2tlpDKSrR8zXHNGvHy7W+XB347kUTGRHDlXaNP+HUUx0e7Hsm8v+c19m7aj8FkJPm0JE14SElc00Y8N/lVFs5d6nNei3beEZsvnjKSn9//1a9wMRgEkdER3DhzPLPvmacFvXS4uOCGc5n4yLiGLywgZAJDCPERWj6hBCFEGpAipXwnJJVXQAmMk5xLb7uA+a8txOnwDjxYU8qKHaxfurnKUNRGs1ETJrUNu24QnHa68tgOd4QQtOt5zMehUYJm0CGlpFP/Dvz8/q9emfmsERb++d/rverodkYXbpwxgbkPf6TNVNwSs9WELdJKn+E9mfLsJFq0bcb51w3j0O5MGreIIzouipMCScgMUKSUE0JSUTUogXGSk5DUhFl/zOSdBz7k75U7SOzYnC4DOvD1rO9rnMugurwF8c3iyDqQXZvmYrKYsEZYuPHJOhn/ihPAp8/N5337Z17CwhJhYeb3D9Hr7G4+x4+/bwwX3zyC3ev30bxtU1q09TWHNVvMJJ+W5FPesJHHInM2EJTAOAVo3SWJx768t/z9uiWb+Patn3EVhEYR7iE/J79W5wshuHjKCK6+b0zDVWSe4kgp+Wjml5RUClZpNBkpOBrY4z8mPprew7oH/PykROJRaDcYlJXUKUjPoV0xB/DWrg0t2gfOKFgZg5/cCdZIC2OmXqSERQPG6XBSlF/sU+5yOMncn+XnjFOcEIUGqSuUwDgFMZqMXjOOUGAwClq2DU75L4wCkx/LJ1uklZYdghc6ivDDbDHTukuiT7kwCHoODd8ggPWGEhiKhkCvc7qHVLH82Jf3sXZR9XHPDEYD54wbwtRXJmOJsGC2mvRIt1Ye+OBOjEZlQtvQ+ddbt2KLtmHWMzLaoqycO/4sOvRuW78NCztCF3ywrlA6jFOYJ/83nQmtbsFRWjuv7aTOLTjjkgEB4/9UpFO/doy+ZSSFuUW88MvjbFi2BbPVzNljBxPfPK5W7VCEB92HdGHOlhf58d0lHD2cxxmXDqTvcJ88ZwqJb0y3MEcJjFOYRk1ieWXl08yY8CIHd6WDlMS3jOPw/ppZOl15p+YvMWLSOSycu9iv17YlwkxihxaUlTh4ePRTGIwGHGVO/vncdVx624Uh+T6K8KFpqyZc+/DY+m5G+BNGs4dgUALjFKd9rza8s/kFcrPysERYsEVamdj2NjJTg1dQeoIGTnl2Ellp2az5aT1GPVpvn2HdkcCgi/qxbvFGfv/mT68gg2/eO4++5/WkdZeTzWRSoagO2eCspJTAUADHnK4AHvzoLqZf8CROh8NviHMvxLE4ULZIK49/cz/Zh3LIPZxHctckr9wZb/z7/3yi+LqdLpZ//Sfj71cCQ3GKIUE2MD8MpfRW+NB9SBfe2zmLm5+eRFSjyCqPNZlMnDlmoFdZk5bxtO/VxifRkr8cIQajAcsJSiilUIQ9bhncFiac1AJDCHGhEGKbEGKnEGJ6fbenIRHfPI4r7rqY6fOmYY20+D3GYDTwz+evp1VnXzNKf1x403AsEd51CYOBc64aUuv2KhQNEmUlFR4IIYzAq8BIIA34UwgxX0q5pX5b1rAYPLo/zy97nC9f/JacjKP0P78PkbE2IqJsDLywL7FNYoKua/JT13I0M5dfv1iJwWggQs910aRl/An8BgpFmCKlspIKIwYBO6WUuwGEEB8DlwFKYNSQzv07MH3etFrXY7GaeeD9O5k6q4CCnEKat22KwXBST3IViqoJo9lDMJzMAiMJSK3wPg04veIBQogpwBSA5OTkumvZKU5MfDQx8So3t+JURyJdJz5VQCg5mR/v/AXL9xLnUsrZngxWTZuGb04LhUJxEuIJb96AlN4n8wwjDWhd4X0r4GA9tUWhUCh8UWa1YcOfQCchRDshhAUYD8yv5zYpFAoFoE0wPEmjqtuCoS6sQk/aGYaU0imEmAosBIzAHCnl5npulkKhUGjI0CVQqiur0JNWYABIKb8DvqvvdigUCoU/Qqj0rhOr0JNaYNSENWvWZAkh9tV3OyqRAKisM8Gj+qtmqP6qGRX7q01VBwZDPjkLf5afJwR5uE0IsbrC+9lSytkV3ldrFRoKlMDQkVKGnZmUEGK1lHJAfbejoaD6q2ao/qoZoe4vKWUowzRXaxUaCk5mpbdCoVCcKtSJVagSGAqFQtHwqROrULUkFd7Mrv4QRQVUf9UM1V81I2z7q66sQoVsYLFMFAqFQlE/qCUphUKhUASFEhgKhUKhCAolMIJECNFaCLFECPG3EGKzEOJOvbyxEOInIcQO/TVeL2+iH18ghHilUl1LdRf+dfrWLMA1+wshNuqu/i8LIYRe3kYIsUgIsUGvq1WA861CiE/081cKIdrq5X2EECv077FBCHF1CLvKc+1Q9pdFCDFbCLFdCLFVCHFlgGsG6q9/6uXrhBC/CSG6BTj/X0KILXqfLBJCtKnw2fV6m3cIIa4PVT9Vun599NkMIUSqEKKgUrnfsePn/IDHCSGShRA/6t9nS6A6FA0IKaXagtiAlkA/fT8G2A50A54Bpuvl04H/6PtRwFnAP4FXKtW1FBgQxDVXAWeg2Vh/D1ykl38GXK/vDwfmBTj/NuANfX888Im+3xnopO8nAoeAuDDuLzvwpL5vABJq2F+xFY65FPghwPnnApH6/q0V+qsxsFt/jdf348N8jAXbZ4P16xYEM3aCHWMVxvlIfT/a07dqa7hbvTegoW7AN2hxW7YBLfWylsC2Ssfd4OfPvJRqBIZe19YK7ycAb+r7m4FW+r4A8gLUsRA4Q983oXmpCj/HrUcXIGHaX6lA1PH2V6XjJgDfB9HevsByf3UBbwITwnyMVdtnlY6vLDCCHTt+j0MTdL+d6D5SW91uaknqONCn1n2BlUBzKeUhAP3V7/KSH+bqSySPeJZOKpGE5ozjIU0vA+0G71liuByIEUI0CVBHqt42J5ALeB0nhBgEWIBdQba7xtSmv4QQcfruE0KIv4QQnwkhmvs5tKr+QghxuxBiF9rTejDpAyejzVI8dVcOu5Dkc0YIqaM+q4pqx041x3UGjgohvhRCrBVCPCu0AHmKBowSGDVECBENfAHcJaXMO85qrpVS9gSG6tskf5fyU+axgb4HOEcIsRY4BzgAOGtYB0KIlsA84EYpT0xg/hD0lwnNa3W5lLIfsAJ4zt+l/JSVf1cp5atSyg7A/cDD1bR5IjAAeDaYukNNHfZZlc3wU+bvOwc6zoQ2tu8BBgLt0WZCigaMEhg1QAhhRvsjfyCl/FIvztBvvJ4bcGZ19UgpD+iv+cCHwCAhhFEcU4I/jvYUW1GZXe7qL6U8KKW8QkrZF3hIL8vVFZjrhBDr9HPKwwUIIUxAI+CI/j4W+BZ4WEr5x/H1SNWEqL+ygSLgK/39Z0C/mvRXJT4GxujXr9xfCCFGoPXppVLKUr24zpJx1XGfVYXfsVODMZYGrJVS7tZnHl8D/artAEVYowRGkOjLRu8Af0spn6/w0XzAYzVzPdq6c1X1mIQQCfq+GRgNbJJSuqSUffTtUX3pIV8IMVi/9nWeuoUQCUIIz2/3ADAHQEr5kKcOP20bCyyWUkqhhQ74CnhPSvnZ8fVI1YSqv6SUElgADNOLzgO21LC/OlWo8mJgh163V38JIfqi6SculVJWvCkvBM4XQsTrFkrn62Uhpa77rJrm+B07wY4xtFAV8UIIT1DP4YQ41LaiHqhvJUpD2dCsUSSwAVinb6PQ1msXod2EFgGNK5yzF+1pqwDtiasbmmXLGr2ezcBLgDHANQcAm9D0C69wzDN/rH697cDbgDXA+Ta0p8udaBZE7fXyiYCjwvdYB/QJx/7Sy9sAv+h1LQKSa9hfL+l9vQ5YAnQPcP7PQEaF9s6v8NlNej/uRFvCC9sxVsM+e0Y/z62/PlbV2Al2jOmfjdSvvxF4F7DU9/9YbbXbVGgQhUKhUASFWpJSKBQKRVAogaFQKBSKoFACQ6FQKBRBoQSGQqFQKIJCCQyFQqFQBIUSGAoFYLfbH7Pb7fdU8fkYu93uN8qtQnGqoASGQhEcY9D8aBSKUxblh6E4ZbHb7Q+heYSnAofRHCpzgSloARl3osX56gP8T/8sl2OBH18FmqKF4bg5JSVlax02X6Goc9QMQ3FKYrfb+6Plb+gLXIEWIA/gy5SUlIEpKSm9gb+BySkpKb+jhcC4NyUlpU9KSsouYDZwR0pKSn+0AHuv1fmXUCjqGFN9N0ChqCeGAl+lpKQUAdjt9vl6eQ+73f4kEIeW9McnZpTdbo8GhgCf2e12T7H1RDdYoahvlMBQnMr4W499FxiTkpKy3m6338CxAH4VMQBHU1JS+pywlikUYYhaklKcqvwCXG632yPsdnsMcIleHgMcstvtZuDaCsfn65+RkpKSB+yx2+3jAOx2u7Db7b3rrukKRf2glN6KU5YKSu99aJFatwCFwH162UYgJiUl5Qa73X4m8BZQihYt2A28jpYy1Qx8nJKSUl2OCYWiQaMEhkKhUCiCQi1JKRQKhSIolMBQKBQKRVAogaFQKBSKoFACQ6FQKBRBoQSGQqFQKIJCCQyFQqFQBIUSGAqFQqEIiv8HvtlI1ZspjgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_booking_total.values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(x[:,0], x[:,1], c=y, cmap='viridis', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "# format the plot\n",
    "format_plot(ax, 'data distribution')\n",
    "# cb.set_ticks([]) \n",
    "cb.set_label('label', color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_date_revenue.values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(x[:,0], x[:,1], c=y, cmap='viridis', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "# format the plot\n",
    "format_plot(ax, 'data distribution')\n",
    "# cb.set_ticks([]) \n",
    "cb.set_label('label', color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_adr_sum.values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "fig, ax = plt.subplots()\n",
    "pts = ax.scatter(x[:,0], x[:,1], c=y, cmap='viridis', s=30)\n",
    "cb = fig.colorbar(pts, ax=ax)\n",
    "# format the plot\n",
    "format_plot(ax, 'data distribution')\n",
    "# cb.set_ticks([]) \n",
    "cb.set_label('label', color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 1)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c21ed41b38>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "?svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c21d5989b0>"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用每筆預約付的總金額拿來train\n",
    "x = train_booking_total.set_index('arrival_date').values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "y = np.reshape(y,(640,))\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "plt.scatter(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "?plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c21d5a5f28>]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train,y_train)\n",
    "plt.plot(x_test,y_predict,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1171875"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_func(transfer_label(y_predict),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 3., 3., 0., 1., 2., 3., 2., 1., 1., 2., 1., 2., 3., 3.,\n",
       "       2., 2., 2., 4., 2., 3., 0., 0., 1., 1., 2., 5., 3., 2., 0., 2., 3.,\n",
       "       3., 4., 1., 6., 0., 3., 2., 0., 3., 2., 2., 3., 2., 2., 2., 0., 3.,\n",
       "       2., 2., 2., 2., 2., 3., 2., 0., 2., 1., 0., 1., 2., 3., 1., 2., 1.,\n",
       "       2., 3., 1., 1., 2., 0., 2., 0., 2., 3., 1., 1., 0., 4., 5., 1., 4.,\n",
       "       0., 2., 4., 4., 1., 2., 3., 0., 1., 1., 2., 1., 2., 2., 4., 2., 2.,\n",
       "       0., 6., 2., 2., 0., 4., 2., 1., 3., 5., 2., 1., 1., 3., 3., 4., 2.,\n",
       "       3., 1., 2., 3., 6., 1., 1., 5., 5.])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_label(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 3., 2., 0., 1., 2., 3., 3., 1., 1., 2., 1., 3., 3., 4.,\n",
       "       2., 1., 2., 4., 2., 3., 0., 0., 1., 1., 2., 5., 3., 2., 0., 2., 3.,\n",
       "       3., 4., 1., 6., 0., 3., 2., 0., 3., 2., 1., 3., 1., 2., 2., 0., 3.,\n",
       "       2., 2., 2., 2., 0., 3., 2., 0., 1., 1., 0., 1., 2., 3., 1., 2., 1.,\n",
       "       2., 3., 1., 1., 3., 0., 2., 0., 2., 3., 1., 1., 0., 4., 5., 1., 4.,\n",
       "       1., 2., 4., 5., 1., 2., 3., 0., 1., 1., 2., 1., 2., 2., 4., 2., 2.,\n",
       "       0., 6., 2., 2., 0., 4., 2., 2., 3., 5., 2., 1., 1., 3., 3., 4., 2.,\n",
       "       3., 1., 2., 3., 6., 1., 2., 5., 5.])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c21dc1ea90>"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用每日的總adr拿來train\n",
    "x = train_date_revenue.set_index('date').values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "y = np.reshape(y,(640,))\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "plt.scatter(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015625"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_func(transfer_label(y_predict),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c21a2e6d30>]"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train,y_train)\n",
    "plt.plot(x_test,y_predict,color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c219526438>"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用adr groupby date拿來train\n",
    "x = train_adr_sum.set_index('arrival_date').values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "y = np.reshape(y,(640,))\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "plt.scatter(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640625"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_func(transfer_label(y_predict),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c2194c5a20>]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train,y_train)\n",
    "plt.plot(x_test,y_predict,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用每筆預約付的總金額拿來train\n",
    "x = train_booking_total.set_index('arrival_date').values\n",
    "y = train_label.set_index('arrival_date').values\n",
    "y = np.reshape(y,(640,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "err = []\n",
    "for train_index,test_index in kf.split(x):\n",
    "    clf = LinearRegression().fit(x[train_index],y[train_index])\n",
    "    y_predict = clf.predict(x[test_index])\n",
    "    err.append(err_func(transfer_label(y_predict),y[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.265625, 0.078125, 0.1953125, 0.1328125, 0.109375]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15625"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ecv\n",
    "sum(err)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - sum(err)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')\n",
    "x,y = preprocess(train,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('./test.csv')\n",
    "# test_nolabel = pd.read_csv('./test_nolabel.csv')\n",
    "# x_test,notuse_y = preprocess(test,train_label,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# # x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "# x_train = copy.deepcopy(x)\n",
    "# y_train = copy.deepcopy(y)\n",
    "# clf = LinearRegression().fit(x_train,y_train)\n",
    "# y_predict = clf.predict(x_test)\n",
    "# y_out = transfer_label(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date\n",
       "0     2017-04-01\n",
       "1     2017-04-02\n",
       "2     2017-04-03\n",
       "3     2017-04-04\n",
       "4     2017-04-05\n",
       "..           ...\n",
       "148   2017-08-27\n",
       "149   2017-08-28\n",
       "150   2017-08-29\n",
       "151   2017-08-30\n",
       "152   2017-08-31\n",
       "\n",
       "[153 rows x 1 columns]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nolabel = pd.read_csv('./test_nolabel.csv')\n",
    "test_nolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_arrival_date(x_data):\n",
    "    #將arrival_date做出來\n",
    "    day_to_str = {}\n",
    "    for i in range(1,32):\n",
    "        if i<10:\n",
    "            day_to_str[str(i)]='0'+str(i)\n",
    "        else:\n",
    "            day_to_str[str(i)]=str(i)\n",
    "    x_data['arrival_date_year'] = x_data['arrival_date_year'].astype(str)\n",
    "    x_data['arrival_date_month'] = x_data['arrival_date_month'].map({'January':'01','February':'02','March':'03','April':'04','May':'05','June':'06','July':'07','August':'08','September':'09','October':'10','November':'11','December':'12'})\n",
    "    x_data['arrival_date_day_of_month'] = x_data['arrival_date_day_of_month'].astype(str).map(day_to_str)\n",
    "    x_data['arrival_date'] = x_data['arrival_date_year'] + '-' + x_data['arrival_date_month'] + '-' + x_data['arrival_date_day_of_month']\n",
    "    # x_data.drop(['arrival_date_year','arrival_date_day_of_month'],axis=1,inplace=True)\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_func(y_pred,y_test):\n",
    "    summ = 0.0\n",
    "    for i in range(0,y_pred.shape[0]):\n",
    "        summ = summ + abs(y_pred[i]-y_test[i])\n",
    "    err = summ/y_pred.shape[0]\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_label(y_pred):\n",
    "    label = []\n",
    "    for x in y_pred:\n",
    "        temp = round(x)\n",
    "        if temp > 9:\n",
    "            temp = 9\n",
    "        elif temp < 0:\n",
    "            temp = 0\n",
    "        label.append(float(temp))\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x(x_data,is_train=True):\n",
    "    # 丟掉 canceled 且 no deposit 的資料\n",
    "    if(is_train):\n",
    "        x_data.drop(x_data[(x_data['is_canceled']==1)&(x_data['deposit_type']=='No Deposit')].index,inplace=True)\n",
    "    x_data = combine_arrival_date(x_data)\n",
    "    if(is_train):\n",
    "        x_data['date_difference'] = (pd.to_datetime(x_data['reservation_status_date']) - pd.to_datetime(x_data['arrival_date']) + datetime.timedelta(days=1))\n",
    "    x_data['stays_total_nights'] = x_data['stays_in_week_nights'] + x_data['stays_in_weekend_nights']\n",
    "    if(is_train):\n",
    "        x_data['booking_total_revenue'] = np.where(x_data['is_canceled']==0,(x_data['stays_total_nights']+1)*x_data['adr'],x_data['adr'])\n",
    "    else:\n",
    "        x_data['booking_total_revenue'] = (x_data['stays_total_nights']+1)*x_data['adr']\n",
    "    train_booking_total_tmp = x_data.groupby('arrival_date').sum()\n",
    "    train_booking_total_tmp['arrival_date'] = train_booking_total_tmp.index\n",
    "    train_booking_total = train_booking_total_tmp[['arrival_date','booking_total_revenue']]\n",
    "    x = train_booking_total.set_index('arrival_date').values\n",
    "#     y = y_data.set_index('arrival_date').values\n",
    "#     y = np.reshape(y,(640,))\n",
    "    return x,x_data\n",
    "def preprocess_y(y_data):\n",
    "    y = y_data.set_index('arrival_date').values\n",
    "    y = np.reshape(y,(640,))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先預測 booking total 或 adr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.decomposition import PCA\n",
    "import datetime,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def pre_adr_model(train,test):\n",
    "    x,booking_total = preprocess_x(train)\n",
    "    test = combine_arrival_date(test)\n",
    "    # 丟掉一些沒用到的 features\n",
    "    booking_total.drop(['country','company','is_canceled','reservation_status','reservation_status_date','date_difference','stays_total_nights'],axis=1,inplace=True)\n",
    "    test.drop(['country','company'],axis=1,inplace=True)\n",
    "    # children 補眾數(補 0)\n",
    "    booking_total['children'].fillna(0,inplace=True)\n",
    "    # agent 沒有的補 0\n",
    "    # booking_total['agent'].fillna(0,inplace=True)\n",
    "    # test['agent'].fillna(0,inplace=True)\n",
    "    booking_total.drop(['agent'],axis=1,inplace=True)\n",
    "    test.drop(['agent'],axis=1,inplace=True)\n",
    "\n",
    "    # datatype 轉成一樣\n",
    "    booking_total.hotel =booking_total.hotel.astype('category')\n",
    "    test.hotel = test.hotel.astype('category')\n",
    "    booking_total.children = booking_total[\"children\"].astype(int)\n",
    "    test.children = test[\"children\"].astype(int)\n",
    "    # meal 的 undefined 和 SC 是一樣的\n",
    "    booking_total['meal'].replace('Undefined','SC',inplace=True)\n",
    "    test['meal'].replace('Undefined','SC',inplace=True)\n",
    "    X_booking = pd.get_dummies(data=booking_total,columns=[\"hotel\",\"arrival_date_week_number\",\"arrival_date_year\",\"arrival_date_day_of_month\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "    \"distribution_channel\",\"reserved_room_type\",\"assigned_room_type\",\"deposit_type\",\"customer_type\"])\n",
    "    test = pd.get_dummies(data=test,columns=[\"hotel\",\"arrival_date_week_number\",\"arrival_date_year\",\"arrival_date_day_of_month\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "    \"distribution_channel\",\"reserved_room_type\",\"assigned_room_type\",\"deposit_type\",\"customer_type\"])\n",
    "    X_booking['assigned_room_type_P'] = 0\n",
    "    X_booking['reserved_room_type_P'] = 0\n",
    "    test['reserved_room_type_L'] = 0\n",
    "    test['arrival_date_month_01'] = 0\n",
    "    test['arrival_date_month_02'] = 0\n",
    "    test['arrival_date_month_03'] = 0\n",
    "    test['arrival_date_month_09'] = 0\n",
    "    test['arrival_date_month_10'] = 0\n",
    "    test['arrival_date_month_11'] = 0\n",
    "    test['arrival_date_month_12'] = 0\n",
    "    test['distribution_channel_Undefined'] = 0\n",
    "    X_booking_ret = copy.deepcopy(X_booking)\n",
    "    test_ret = copy.deepcopy(test)\n",
    "    X_booking.drop(['arrival_date','ID'],axis=1,inplace=True)\n",
    "    test.drop(['arrival_date','ID'],axis=1,inplace=True)\n",
    "    X = X_booking.drop(['booking_total_revenue','adr'],axis=1).values\n",
    "    test = test.values\n",
    "    Y = X_booking['adr']\n",
    "    return X,Y,test,X_booking_ret,test_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,test_X,X_booking_ret,test_ret = pre_adr_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_booking_ret.groupby('arrival_date').sum().drop(['ID','adr','booking_total_revenue'],axis=1).to_csv('train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ret.groupby('arrival_date').sum().drop(['ID'],axis=1).to_csv('test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>stays_total_nights</th>\n",
       "      <th>booking_total_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.305161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1 days</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.305161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.052227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>225.156681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>74.546401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>223.639203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>76.376288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>229.128863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>City Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>07</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>49.411647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>148.234941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91525</th>\n",
       "      <td>91525</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Contract</td>\n",
       "      <td>79.453407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>873.987482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91527</th>\n",
       "      <td>91527</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>-6.822102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>3 days</td>\n",
       "      <td>2</td>\n",
       "      <td>-20.466305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91528</th>\n",
       "      <td>91528</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>90.814554</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>181.629107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91529</th>\n",
       "      <td>91529</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>38.135565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>11 days</td>\n",
       "      <td>10</td>\n",
       "      <td>419.491216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>91530</td>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transient</td>\n",
       "      <td>58.196470</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2 days</td>\n",
       "      <td>1</td>\n",
       "      <td>116.392941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70457 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID         hotel  is_canceled  lead_time arrival_date_month  \\\n",
       "0          0  Resort Hotel            0        342                 07   \n",
       "1          1    City Hotel            0        257                 07   \n",
       "2          2    City Hotel            0        257                 07   \n",
       "3          3    City Hotel            0        257                 07   \n",
       "4          4    City Hotel            0        257                 07   \n",
       "...      ...           ...          ...        ...                ...   \n",
       "91525  91525  Resort Hotel            0         72                 03   \n",
       "91527  91527  Resort Hotel            0         28                 03   \n",
       "91528  91528  Resort Hotel            0          2                 03   \n",
       "91529  91529  Resort Hotel            0         30                 03   \n",
       "91530  91530  Resort Hotel            0          1                 03   \n",
       "\n",
       "       arrival_date_week_number  stays_in_weekend_nights  \\\n",
       "0                            27                        0   \n",
       "1                            27                        0   \n",
       "2                            27                        0   \n",
       "3                            27                        0   \n",
       "4                            27                        0   \n",
       "...                         ...                      ...   \n",
       "91525                        13                        3   \n",
       "91527                        13                        0   \n",
       "91528                        13                        0   \n",
       "91529                        13                        3   \n",
       "91530                        13                        0   \n",
       "\n",
       "       stays_in_week_nights  adults  children  ...  customer_type        adr  \\\n",
       "0                         0       2       0.0  ...      Transient  -6.305161   \n",
       "1                         2       1       0.0  ...      Transient  75.052227   \n",
       "2                         2       2       0.0  ...      Transient  74.546401   \n",
       "3                         2       2       0.0  ...      Transient  76.376288   \n",
       "4                         2       2       0.0  ...      Transient  49.411647   \n",
       "...                     ...     ...       ...  ...            ...        ...   \n",
       "91525                     7       2       0.0  ...       Contract  79.453407   \n",
       "91527                     2       2       0.0  ...      Transient  -6.822102   \n",
       "91528                     1       2       0.0  ...      Transient  90.814554   \n",
       "91529                     7       2       0.0  ...      Transient  38.135565   \n",
       "91530                     1       1       0.0  ...      Transient  58.196470   \n",
       "\n",
       "      required_car_parking_spaces total_of_special_requests  \\\n",
       "0                               0                         0   \n",
       "1                               0                         0   \n",
       "2                               0                         0   \n",
       "3                               0                         0   \n",
       "4                               0                         0   \n",
       "...                           ...                       ...   \n",
       "91525                           0                         1   \n",
       "91527                           0                         0   \n",
       "91528                           0                         2   \n",
       "91529                           0                         1   \n",
       "91530                           0                         1   \n",
       "\n",
       "      reservation_status  reservation_status_date  arrival_date  \\\n",
       "0              Check-Out               2015-07-01    2015-07-01   \n",
       "1              Check-Out               2015-07-03    2015-07-01   \n",
       "2              Check-Out               2015-07-03    2015-07-01   \n",
       "3              Check-Out               2015-07-03    2015-07-01   \n",
       "4              Check-Out               2015-07-03    2015-07-01   \n",
       "...                  ...                      ...           ...   \n",
       "91525          Check-Out               2017-04-10    2017-03-31   \n",
       "91527          Check-Out               2017-04-02    2017-03-31   \n",
       "91528          Check-Out               2017-04-01    2017-03-31   \n",
       "91529          Check-Out               2017-04-10    2017-03-31   \n",
       "91530          Check-Out               2017-04-01    2017-03-31   \n",
       "\n",
       "       date_difference stays_total_nights booking_total_revenue  \n",
       "0               1 days                  0             -6.305161  \n",
       "1               3 days                  2            225.156681  \n",
       "2               3 days                  2            223.639203  \n",
       "3               3 days                  2            229.128863  \n",
       "4               3 days                  2            148.234941  \n",
       "...                ...                ...                   ...  \n",
       "91525          11 days                 10            873.987482  \n",
       "91527           3 days                  2            -20.466305  \n",
       "91528           2 days                  1            181.629107  \n",
       "91529          11 days                 10            419.491216  \n",
       "91530           2 days                  1            116.392941  \n",
       "\n",
       "[70457 rows x 35 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,booking_total = preprocess_x(train)\n",
    "booking_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = combine_arrival_date(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_canceled\n",
      "adr\n",
      "reservation_status\n",
      "reservation_status_date\n",
      "date_difference\n",
      "stays_total_nights\n",
      "booking_total_revenue\n"
     ]
    }
   ],
   "source": [
    "# 看 train和 test 沒有共同有的 features\n",
    "for feature in booking_total.columns:\n",
    "    if feature not in test.columns:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                    0\n",
       "hotel                                 0\n",
       "lead_time                             0\n",
       "arrival_date_month                    0\n",
       "arrival_date_week_number              0\n",
       "stays_in_weekend_nights               0\n",
       "stays_in_week_nights                  0\n",
       "adults                                0\n",
       "children                              0\n",
       "babies                                0\n",
       "meal                                  0\n",
       "country                              20\n",
       "market_segment                        0\n",
       "distribution_channel                  0\n",
       "is_repeated_guest                     0\n",
       "previous_cancellations                0\n",
       "previous_bookings_not_canceled        0\n",
       "reserved_room_type                    0\n",
       "assigned_room_type                    0\n",
       "booking_changes                       0\n",
       "deposit_type                          0\n",
       "agent                              3123\n",
       "company                           26676\n",
       "days_in_waiting_list                  0\n",
       "customer_type                         0\n",
       "required_car_parking_spaces           0\n",
       "total_of_special_requests             0\n",
       "arrival_date                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看 nan 數量\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                0.000000\n",
       "hotel                             0.000000\n",
       "lead_time                         0.000000\n",
       "arrival_date_month                0.000000\n",
       "arrival_date_week_number          0.000000\n",
       "stays_in_weekend_nights           0.000000\n",
       "stays_in_week_nights              0.000000\n",
       "adults                            0.000000\n",
       "children                          0.000000\n",
       "babies                            0.000000\n",
       "meal                              0.000000\n",
       "country                           0.000718\n",
       "market_segment                    0.000000\n",
       "distribution_channel              0.000000\n",
       "is_repeated_guest                 0.000000\n",
       "previous_cancellations            0.000000\n",
       "previous_bookings_not_canceled    0.000000\n",
       "reserved_room_type                0.000000\n",
       "assigned_room_type                0.000000\n",
       "booking_changes                   0.000000\n",
       "deposit_type                      0.000000\n",
       "agent                             0.112100\n",
       "company                           0.957536\n",
       "days_in_waiting_list              0.000000\n",
       "customer_type                     0.000000\n",
       "required_car_parking_spaces       0.000000\n",
       "total_of_special_requests         0.000000\n",
       "arrival_date                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看 nan 占比\n",
    "test.apply(lambda x:sum(x.isnull()/len(x)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 觀察\n",
    "* country : 數量太多\n",
    "* agent : 有 miss\n",
    "* company : miss 太多，直接drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                0.000000\n",
       "hotel                             0.000000\n",
       "is_canceled                       0.000000\n",
       "lead_time                         0.000000\n",
       "arrival_date_month                0.000000\n",
       "arrival_date_week_number          0.000000\n",
       "stays_in_weekend_nights           0.000000\n",
       "stays_in_week_nights              0.000000\n",
       "adults                            0.000000\n",
       "children                          0.000000\n",
       "babies                            0.000000\n",
       "meal                              0.000000\n",
       "country                           0.006032\n",
       "market_segment                    0.000000\n",
       "distribution_channel              0.000000\n",
       "is_repeated_guest                 0.000000\n",
       "previous_cancellations            0.000000\n",
       "previous_bookings_not_canceled    0.000000\n",
       "reserved_room_type                0.000000\n",
       "assigned_room_type                0.000000\n",
       "booking_changes                   0.000000\n",
       "deposit_type                      0.000000\n",
       "agent                             0.164412\n",
       "company                           0.928424\n",
       "days_in_waiting_list              0.000000\n",
       "customer_type                     0.000000\n",
       "adr                               0.000000\n",
       "required_car_parking_spaces       0.000000\n",
       "total_of_special_requests         0.000000\n",
       "reservation_status                0.000000\n",
       "reservation_status_date           0.000000\n",
       "arrival_date                      0.000000\n",
       "date_difference                   0.000000\n",
       "stays_total_nights                0.000000\n",
       "booking_total_revenue             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booking_total.apply(lambda x:sum(x.isnull()/len(x)),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train 的 children 能用補的\n",
    "* 其他 drop 掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 丟掉一些沒用到的 features\n",
    "booking_total.drop(['country','company','is_canceled','reservation_status','reservation_status_date','date_difference','stays_total_nights'],axis=1,inplace=True)\n",
    "test.drop(['country','company'],axis=1,inplace=True)\n",
    "# children 補眾數\n",
    "booking_total['children'].fillna(booking_total['children'].mode()[0],inplace=True)\n",
    "# agent 沒有的補 0\n",
    "# booking_total['agent'].fillna(0,inplace=True)\n",
    "# test['agent'].fillna(0,inplace=True)\n",
    "booking_total.drop(['agent'],axis=1,inplace=True)\n",
    "test.drop(['agent'],axis=1,inplace=True)\n",
    "\n",
    "# datatype 轉成一樣\n",
    "booking_total.hotel =booking_total.hotel.astype('category')\n",
    "test.hotel = test.hotel.astype('category')\n",
    "booking_total.children = booking_total[\"children\"].astype(int)\n",
    "test.children = test[\"children\"].astype(int)\n",
    "# meal 的 undefined 和 SC 是一樣的\n",
    "booking_total['meal'].replace('Undefined','SC',inplace=True)\n",
    "test['meal'].replace('Undefined','SC',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                0.0\n",
       "hotel                             0.0\n",
       "lead_time                         0.0\n",
       "arrival_date_month                0.0\n",
       "arrival_date_week_number          0.0\n",
       "stays_in_weekend_nights           0.0\n",
       "stays_in_week_nights              0.0\n",
       "adults                            0.0\n",
       "children                          0.0\n",
       "babies                            0.0\n",
       "meal                              0.0\n",
       "market_segment                    0.0\n",
       "distribution_channel              0.0\n",
       "is_repeated_guest                 0.0\n",
       "previous_cancellations            0.0\n",
       "previous_bookings_not_canceled    0.0\n",
       "reserved_room_type                0.0\n",
       "assigned_room_type                0.0\n",
       "booking_changes                   0.0\n",
       "deposit_type                      0.0\n",
       "days_in_waiting_list              0.0\n",
       "customer_type                     0.0\n",
       "adr                               0.0\n",
       "required_car_parking_spaces       0.0\n",
       "total_of_special_requests         0.0\n",
       "arrival_date                      0.0\n",
       "booking_total_revenue             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#再看一次 miss占比\n",
    "booking_total.apply(lambda x:sum(x.isnull()/len(x)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_booking = pd.get_dummies(data=booking_total,columns=[\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "\"distribution_channel\",\"reserved_room_type\",\"assigned_room_type\",\"deposit_type\",\"customer_type\"])\n",
    "test = pd.get_dummies(data=test,columns=[\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "\"distribution_channel\",\"reserved_room_type\",\"assigned_room_type\",\"deposit_type\",\"customer_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_booking.drop(['arrival_date','ID'],axis=1,inplace=True)\n",
    "test.drop(['arrival_date','ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_room_type_I</th>\n",
       "      <th>assigned_room_type_K</th>\n",
       "      <th>assigned_room_type_P</th>\n",
       "      <th>deposit_type_No Deposit</th>\n",
       "      <th>deposit_type_Non Refund</th>\n",
       "      <th>deposit_type_Refundable</th>\n",
       "      <th>customer_type_Contract</th>\n",
       "      <th>customer_type_Group</th>\n",
       "      <th>customer_type_Transient</th>\n",
       "      <th>customer_type_Transient-Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27854</th>\n",
       "      <td>108</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27855</th>\n",
       "      <td>194</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27856</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27857</th>\n",
       "      <td>191</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27858</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27859 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lead_time  arrival_date_week_number  stays_in_weekend_nights  \\\n",
       "0             75                        13                        2   \n",
       "1            208                        13                        4   \n",
       "2             12                        13                        2   \n",
       "3             76                        13                        2   \n",
       "4              9                        13                        2   \n",
       "...          ...                       ...                      ...   \n",
       "27854        108                        35                        2   \n",
       "27855        194                        35                        2   \n",
       "27856         17                        35                        0   \n",
       "27857        191                        35                        2   \n",
       "27858          3                        35                        0   \n",
       "\n",
       "       stays_in_week_nights  adults  children  babies  is_repeated_guest  \\\n",
       "0                         5       2         0       0                  0   \n",
       "1                        10       2         0       0                  0   \n",
       "2                         5       2         0       0                  0   \n",
       "3                         5       3         0       0                  0   \n",
       "4                         4       2         2       0                  0   \n",
       "...                     ...     ...       ...     ...                ...   \n",
       "27854                     5       2         0       0                  0   \n",
       "27855                     5       2         1       0                  0   \n",
       "27856                     3       2         0       0                  0   \n",
       "27857                     5       2         0       0                  0   \n",
       "27858                     1       2         1       0                  1   \n",
       "\n",
       "       previous_cancellations  previous_bookings_not_canceled  ...  \\\n",
       "0                           0                               0  ...   \n",
       "1                           0                               0  ...   \n",
       "2                           0                               0  ...   \n",
       "3                           0                               0  ...   \n",
       "4                           0                               0  ...   \n",
       "...                       ...                             ...  ...   \n",
       "27854                       0                               0  ...   \n",
       "27855                       0                               0  ...   \n",
       "27856                       0                               0  ...   \n",
       "27857                       0                               0  ...   \n",
       "27858                       0                               1  ...   \n",
       "\n",
       "       assigned_room_type_I  assigned_room_type_K  assigned_room_type_P  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "27854                     0                     0                     0   \n",
       "27855                     0                     0                     0   \n",
       "27856                     0                     0                     0   \n",
       "27857                     0                     0                     0   \n",
       "27858                     0                     0                     0   \n",
       "\n",
       "       deposit_type_No Deposit  deposit_type_Non Refund  \\\n",
       "0                            1                        0   \n",
       "1                            1                        0   \n",
       "2                            1                        0   \n",
       "3                            1                        0   \n",
       "4                            1                        0   \n",
       "...                        ...                      ...   \n",
       "27854                        1                        0   \n",
       "27855                        1                        0   \n",
       "27856                        1                        0   \n",
       "27857                        1                        0   \n",
       "27858                        1                        0   \n",
       "\n",
       "       deposit_type_Refundable  customer_type_Contract  customer_type_Group  \\\n",
       "0                            0                       0                    0   \n",
       "1                            0                       0                    0   \n",
       "2                            0                       1                    0   \n",
       "3                            0                       0                    0   \n",
       "4                            0                       0                    0   \n",
       "...                        ...                     ...                  ...   \n",
       "27854                        0                       0                    0   \n",
       "27855                        0                       0                    0   \n",
       "27856                        0                       0                    0   \n",
       "27857                        0                       1                    0   \n",
       "27858                        0                       0                    0   \n",
       "\n",
       "       customer_type_Transient  customer_type_Transient-Party  \n",
       "0                            1                              0  \n",
       "1                            1                              0  \n",
       "2                            0                              0  \n",
       "3                            1                              0  \n",
       "4                            1                              0  \n",
       "...                        ...                            ...  \n",
       "27854                        1                              0  \n",
       "27855                        1                              0  \n",
       "27856                        1                              0  \n",
       "27857                        0                              0  \n",
       "27858                        1                              0  \n",
       "\n",
       "[27859 rows x 63 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adr',\n",
       " 'arrival_date_month_01',\n",
       " 'arrival_date_month_02',\n",
       " 'arrival_date_month_03',\n",
       " 'arrival_date_month_09',\n",
       " 'arrival_date_month_10',\n",
       " 'arrival_date_month_11',\n",
       " 'arrival_date_month_12',\n",
       " 'assigned_room_type_P',\n",
       " 'booking_total_revenue',\n",
       " 'distribution_channel_Undefined',\n",
       " 'reserved_room_type_L',\n",
       " 'reserved_room_type_P'}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = set(X_booking.columns)\n",
    "B = set(test.columns)\n",
    "A ^ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adr',\n",
       " 'arrival_date_month_01',\n",
       " 'arrival_date_month_02',\n",
       " 'arrival_date_month_03',\n",
       " 'arrival_date_month_09',\n",
       " 'arrival_date_month_10',\n",
       " 'arrival_date_month_11',\n",
       " 'arrival_date_month_12',\n",
       " 'booking_total_revenue',\n",
       " 'distribution_channel_Undefined',\n",
       " 'reserved_room_type_L'}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assigned_room_type_P', 'reserved_room_type_P'}"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B - A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_booking['assigned_room_type_P'] = 0\n",
    "X_booking['reserved_room_type_P'] = 0\n",
    "test['reserved_room_type_L'] = 0\n",
    "test['arrival_date_month_01'] = 0\n",
    "test['arrival_date_month_02'] = 0\n",
    "test['arrival_date_month_03'] = 0\n",
    "test['arrival_date_month_09'] = 0\n",
    "test['arrival_date_month_10'] = 0\n",
    "test['arrival_date_month_11'] = 0\n",
    "test['arrival_date_month_12'] = 0\n",
    "test['distribution_channel_Undefined'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adr', 'booking_total_revenue'}"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = set(X_booking.columns)\n",
    "B = set(test.columns)\n",
    "A ^ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_booking.drop(['booking_total_revenue','adr'],axis=1).values\n",
    "test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[342,  27,   0, ...,   0,   0,   0],\n",
       "       [257,  27,   0, ...,   0,   0,   0],\n",
       "       [257,  27,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  2,  13,   0, ...,   0,   0,   0],\n",
       "       [ 30,  13,   3, ...,   0,   0,   0],\n",
       "       [  1,  13,   0, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -6.305161\n",
       "1        75.052227\n",
       "2        74.546401\n",
       "3        76.376288\n",
       "4        49.411647\n",
       "           ...    \n",
       "91525    79.453407\n",
       "91527    -6.822102\n",
       "91528    90.814554\n",
       "91529    38.135565\n",
       "91530    58.196470\n",
       "Name: adr, Length: 70457, dtype: float64"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y = X_booking['booking_total_revenue']\n",
    "# Y\n",
    "Y = X_booking['adr']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70457, 72) (70457,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27859, 72)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error: 991.3508848502124\n",
      "r2 score: 0.5616839513644333\n",
      "adjusted r2 score: 0.5594328096637584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#切 validation set 希望每次都切一樣(random state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "clf = LinearRegression().fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "mse = np.mean((Y_val_predict - Y_test) ** 2)\n",
    "r_squared = clf.score(X_test, Y_test)\n",
    "adj_r_squared = r_squared - (1 - r_squared) * (X_test.shape[1] / (X_test.shape[0] - X_test.shape[1] - 1))\n",
    "print('mean square error:',mse)\n",
    "print('r2 score:',r_squared)\n",
    "print('adjusted r2 score:',adj_r_squared)\n",
    "# ******* predict adr、no agent ***********\n",
    "# mean square error: 991.3508848502124\n",
    "# r2 score: 0.5616839513644333\n",
    "# adjusted r2 score: 0.5594328096637584\n",
    "# ******* predict adr、with agent ***********\n",
    "# mean square error: 989.442687966173\n",
    "# r2 score: 0.5625276418589016\n",
    "# adjusted r2 score: 0.5602494650758869"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q: 真的有那麼準嗎?\n",
    "* Ans: 不小心把bookings total revenue 一起拿下去練了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error: 481.73404086850013\n",
      "r2 score: 0.7870060293347805\n",
      "adjusted r2 score: 0.786597124527616\n",
      "out of bag score: 0.662616586136143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "clf = RandomForestRegressor(oob_score=True).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "mse = np.mean((Y_val_predict - Y_test) ** 2)\n",
    "r_squared = clf.score(X_test, Y_test)\n",
    "adj_r_squared = r_squared - (1 - r_squared) * (X_test.shape[1] / (X_test.shape[0] - X_test.shape[1] - 1))\n",
    "print('mean square error:',mse)\n",
    "print('r2 score:',r_squared)\n",
    "print('adjusted r2 score:',adj_r_squared)\n",
    "print('out of bag score:',clf.oob_score_)\n",
    "# ******* predict adr、no agent ***********\n",
    "# mean square error: 478.88158210822274\n",
    "# r2 score: 0.7882672159356171\n",
    "# adjusted r2 score: 0.7871797802802468\n",
    "# out of bag score: 0.6700381618264833\n",
    "# ******* predict adr、with agent ***********\n",
    "# mean square error: 365.28636929916394\n",
    "# r2 score: 0.8384922226242489\n",
    "# adjusted r2 score: 0.8376511562989223\n",
    "# out of bag score: 0.6815365460892584\n",
    "# ******* predict adr、with agent，cut half features ***********\n",
    "# mean square error: 481.73404086850013\n",
    "# r2 score: 0.7870060293347805\n",
    "# adjusted r2 score: 0.786597124527616\n",
    "# out of bag score: 0.662616586136143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reserved_room_type_P              0.000000e+00\n",
       "assigned_room_type_P              0.000000e+00\n",
       "distribution_channel_Undefined    9.595639e-08\n",
       "reserved_room_type_L              8.358756e-06\n",
       "market_segment_Aviation           5.544686e-05\n",
       "                                      ...     \n",
       "deposit_type_Non Refund           5.093018e-02\n",
       "market_segment_Online TA          5.431613e-02\n",
       "arrival_date_month_08             7.006804e-02\n",
       "arrival_date_week_number          8.718516e-02\n",
       "lead_time                         1.378750e-01\n",
       "Length: 72, dtype: float64"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(data = clf.feature_importances_,index = X_booking.drop(['booking_total_revenue','adr'],axis=1).columns)\n",
    "feature_importances.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = feature_importances.sort_values()[:'reserved_room_type_G'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_booking.drop(todrop,axis=1,inplace=True)\n",
    "test.drop(todrop,axis=1,inplace=True)\n",
    "X = X_booking.drop(['booking_total_revenue','adr'],axis=1).values\n",
    "test = test.values\n",
    "Y = X_booking['adr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_booking.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.Series(data = clf.feature_importances_,index = X_booking.drop(['booking_total_revenue','adr'],axis=1).columns)\n",
    "plt.figure(figsize=(15, 8))\n",
    "feature_importances.sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error: 1785.4753165638558\n",
      "r2 score: 0.210569640222943\n",
      "adjusted r2 score: 0.2065152150924809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "rgr = AdaBoostRegressor(n_estimators=100).fit(X_train,Y_train)\n",
    "Y_val_predict = rgr.predict(X_test)\n",
    "mse = np.mean((Y_val_predict - Y_test) ** 2)\n",
    "r_squared = rgr.score(X_test, Y_test)\n",
    "adj_r_squared = r_squared - (1 - r_squared) * (X_test.shape[1] / (X_test.shape[0] - X_test.shape[1] - 1))\n",
    "print('mean square error:',mse)\n",
    "print('r2 score:',r_squared)\n",
    "print('adjusted r2 score:',adj_r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.utils import plot_model,to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_use,not_use2,not_use3,X_preprocess,test_preprocess = pre_adr_model(train,test)\n",
    "#X,Y,test,X_booking,test_booking = pre_adr_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X_preprocess.groupby('arrival_date').sum()\n",
    "test_X_tmp = test_preprocess.groupby('arrival_date').sum()\n",
    "#leadtime 先保留 (lead time 去掉)\n",
    "X_tmp.drop(['ID','agent','adr','booking_total_revenue'],axis=1,inplace=True)\n",
    "test_X_tmp.drop(['ID','agent'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_tmp.values\n",
    "test_X = test_X_tmp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train_label.drop(['arrival_date'],axis=1).values\n",
    "Y = np.reshape(Y,(Y.shape[0],))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 72)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 72)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 fold DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model():\n",
    "    KB.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=256,input_shape=(71,),activation='relu',kernel_initializer='normal'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    # model.add(Dense(units=1024,activation='relu',kernel_initializer='normal'))\n",
    "    # model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(units=256,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(units=64,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(units=1,activation='linear',kernel_initializer='normal'))\n",
    "    plot_model(model,to_file='./static/model.jpg',show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 14.5341 - soft_acc: 0.0000e+00best occur in epoch 0\n",
      "512/512 [==============================] - 0s 415us/sample - loss: 15.3588 - soft_acc: 0.0511 - val_loss: 8.1160 - val_soft_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.5024 - soft_acc: 0.1000best occur in epoch 1\n",
      "512/512 [==============================] - 0s 67us/sample - loss: 3.9810 - soft_acc: 0.1850 - val_loss: 2.7877 - val_soft_acc: 0.0150\n",
      "Epoch 3/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.8427 - soft_acc: 0.1500best occur in epoch 2\n",
      "512/512 [==============================] - 0s 67us/sample - loss: 2.1549 - soft_acc: 0.2539 - val_loss: 1.8033 - val_soft_acc: 0.0886\n",
      "Epoch 4/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.5753 - soft_acc: 0.2900best occur in epoch 3\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.5371 - soft_acc: 0.2722 - val_loss: 1.5307 - val_soft_acc: 0.2529\n",
      "Epoch 5/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3895 - soft_acc: 0.3100best occur in epoch 4\n",
      "512/512 [==============================] - 0s 68us/sample - loss: 1.1630 - soft_acc: 0.3917 - val_loss: 0.9589 - val_soft_acc: 0.4071\n",
      "Epoch 6/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.8438 - soft_acc: 0.4400best occur in epoch 5\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.7837 - soft_acc: 0.5011 - val_loss: 0.9106 - val_soft_acc: 0.3993\n",
      "Epoch 7/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.8218 - soft_acc: 0.4594 - val_loss: 2.1358 - val_soft_acc: 0.1686\n",
      "Epoch 8/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 1.3649 - soft_acc: 0.3750 - val_loss: 1.2351 - val_soft_acc: 0.2879\n",
      "Epoch 9/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 1.1453 - soft_acc: 0.3744 - val_loss: 0.9647 - val_soft_acc: 0.3436\n",
      "Epoch 10/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.8353 - soft_acc: 0.4156 - val_loss: 0.8447 - val_soft_acc: 0.4121\n",
      "Epoch 11/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.7227 - soft_acc: 0.4667 - val_loss: 0.8352 - val_soft_acc: 0.3657\n",
      "Epoch 12/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6433 - soft_acc: 0.5400best occur in epoch 11\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6157 - soft_acc: 0.5267 - val_loss: 0.7397 - val_soft_acc: 0.5336\n",
      "Epoch 13/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.6512 - soft_acc: 0.5083 - val_loss: 0.6877 - val_soft_acc: 0.4929\n",
      "Epoch 14/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6015 - soft_acc: 0.5239 - val_loss: 0.6113 - val_soft_acc: 0.5229\n",
      "Epoch 15/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5234 - soft_acc: 0.5767 - val_loss: 0.7398 - val_soft_acc: 0.4600\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.5598 - soft_acc: 0.5544 - val_loss: 1.0765 - val_soft_acc: 0.3186\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.7851 - soft_acc: 0.4783 - val_loss: 1.1159 - val_soft_acc: 0.3493\n",
      "Epoch 18/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.6235 - soft_acc: 0.5061 - val_loss: 0.7241 - val_soft_acc: 0.4493\n",
      "Epoch 19/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4716 - soft_acc: 0.5900best occur in epoch 18\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.4667 - soft_acc: 0.6517 - val_loss: 0.6206 - val_soft_acc: 0.4921\n",
      "Epoch 20/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4480 - soft_acc: 0.6506 - val_loss: 0.8531 - val_soft_acc: 0.4193\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.5210 - soft_acc: 0.5933 - val_loss: 0.8751 - val_soft_acc: 0.3964\n",
      "Epoch 22/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6311 - soft_acc: 0.4600best occur in epoch 21\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.5484 - soft_acc: 0.6250 - val_loss: 0.5964 - val_soft_acc: 0.5536\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4764 - soft_acc: 0.6428 - val_loss: 0.6684 - val_soft_acc: 0.4879\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.5553 - soft_acc: 0.6306 - val_loss: 0.8086 - val_soft_acc: 0.3836\n",
      "Epoch 25/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5444 - soft_acc: 0.5400best occur in epoch 24\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.5801 - soft_acc: 0.6078 - val_loss: 0.5691 - val_soft_acc: 0.5814\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4655 - soft_acc: 0.6750 - val_loss: 0.9921 - val_soft_acc: 0.3200\n",
      "Epoch 27/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.5877 - soft_acc: 0.6139 - val_loss: 1.2400 - val_soft_acc: 0.2471\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.8919 - soft_acc: 0.4483 - val_loss: 0.6070 - val_soft_acc: 0.4714\n",
      "Epoch 29/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.5735 - soft_acc: 0.6039 - val_loss: 0.7648 - val_soft_acc: 0.3807\n",
      "Epoch 30/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5855 - soft_acc: 0.6189 - val_loss: 0.5735 - val_soft_acc: 0.5121\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4950 - soft_acc: 0.6628 - val_loss: 0.6730 - val_soft_acc: 0.5207\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4676 - soft_acc: 0.6483 - val_loss: 0.7515 - val_soft_acc: 0.4243\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4589 - soft_acc: 0.6456 - val_loss: 0.6345 - val_soft_acc: 0.4971\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4889 - soft_acc: 0.6244 - val_loss: 0.6191 - val_soft_acc: 0.5121\n",
      "Epoch 35/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4477 - soft_acc: 0.6700best occur in epoch 34\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4196 - soft_acc: 0.6906 - val_loss: 0.5587 - val_soft_acc: 0.5279\n",
      "Epoch 36/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4154 - soft_acc: 0.6706 - val_loss: 0.7623 - val_soft_acc: 0.4986\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.5500 - soft_acc: 0.5900 - val_loss: 1.0265 - val_soft_acc: 0.3279\n",
      "Epoch 38/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.6805 - soft_acc: 0.5011 - val_loss: 0.5633 - val_soft_acc: 0.5529\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.4947 - soft_acc: 0.6239 - val_loss: 0.7799 - val_soft_acc: 0.4136\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5439 - soft_acc: 0.5739 - val_loss: 0.7636 - val_soft_acc: 0.3729\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.6222 - soft_acc: 0.5044 - val_loss: 0.6163 - val_soft_acc: 0.5714\n",
      "Epoch 42/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4432 - soft_acc: 0.6889 - val_loss: 0.6597 - val_soft_acc: 0.4979\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4156 - soft_acc: 0.6944 - val_loss: 0.6194 - val_soft_acc: 0.4871\n",
      "Epoch 44/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4423 - soft_acc: 0.6383 - val_loss: 0.5510 - val_soft_acc: 0.5607\n",
      "Epoch 45/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3529 - soft_acc: 0.7700best occur in epoch 44\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4307 - soft_acc: 0.6844 - val_loss: 0.6184 - val_soft_acc: 0.5771\n",
      "Epoch 46/1000\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.4590 - soft_acc: 0.6744 - val_loss: 0.5807 - val_soft_acc: 0.4786\n",
      "Epoch 47/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5022 - soft_acc: 0.6272 - val_loss: 0.6093 - val_soft_acc: 0.5429\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4333 - soft_acc: 0.6789 - val_loss: 0.5556 - val_soft_acc: 0.5450\n",
      "Epoch 49/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3713 - soft_acc: 0.7400best occur in epoch 48\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.4202 - soft_acc: 0.6667 - val_loss: 0.5825 - val_soft_acc: 0.5964\n",
      "Epoch 50/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4129 - soft_acc: 0.6800best occur in epoch 49\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.4116 - soft_acc: 0.7511 - val_loss: 0.5791 - val_soft_acc: 0.5557\n",
      "Epoch 51/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4139 - soft_acc: 0.6856 - val_loss: 0.7157 - val_soft_acc: 0.4364\n",
      "Epoch 52/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4410 - soft_acc: 0.7106 - val_loss: 0.7083 - val_soft_acc: 0.5079\n",
      "Epoch 53/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5556 - soft_acc: 0.5944 - val_loss: 0.6808 - val_soft_acc: 0.4979\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4372 - soft_acc: 0.6867 - val_loss: 0.6524 - val_soft_acc: 0.5664\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4546 - soft_acc: 0.6883 - val_loss: 0.7056 - val_soft_acc: 0.4571\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.5145 - soft_acc: 0.5956 - val_loss: 0.8660 - val_soft_acc: 0.3921\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4934 - soft_acc: 0.5983 - val_loss: 0.5719 - val_soft_acc: 0.5636\n",
      "Epoch 58/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3745 - soft_acc: 0.6928 - val_loss: 0.6393 - val_soft_acc: 0.5407\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4798 - soft_acc: 0.6483 - val_loss: 0.6746 - val_soft_acc: 0.5157\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4597 - soft_acc: 0.6878 - val_loss: 0.5464 - val_soft_acc: 0.4786\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3912 - soft_acc: 0.6850 - val_loss: 0.5782 - val_soft_acc: 0.5407\n",
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.3719 - soft_acc: 0.7122 - val_loss: 0.5719 - val_soft_acc: 0.5557\n",
      "Epoch 63/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4032 - soft_acc: 0.7200best occur in epoch 62\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3768 - soft_acc: 0.7611 - val_loss: 0.5945 - val_soft_acc: 0.5557\n",
      "Epoch 64/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3965 - soft_acc: 0.7406 - val_loss: 0.5920 - val_soft_acc: 0.5071\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3947 - soft_acc: 0.7100 - val_loss: 0.6208 - val_soft_acc: 0.5279\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3983 - soft_acc: 0.6894 - val_loss: 0.5544 - val_soft_acc: 0.5886\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3912 - soft_acc: 0.6694 - val_loss: 0.5526 - val_soft_acc: 0.5614\n",
      "Epoch 68/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3353 - soft_acc: 0.8200best occur in epoch 67\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3593 - soft_acc: 0.7550 - val_loss: 0.6349 - val_soft_acc: 0.5693\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4174 - soft_acc: 0.6944 - val_loss: 0.5518 - val_soft_acc: 0.5736\n",
      "Epoch 70/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3725 - soft_acc: 0.7539 - val_loss: 0.5717 - val_soft_acc: 0.5071\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3875 - soft_acc: 0.7261 - val_loss: 0.5459 - val_soft_acc: 0.5736\n",
      "Epoch 72/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3819 - soft_acc: 0.7356 - val_loss: 0.5528 - val_soft_acc: 0.5150\n",
      "Epoch 73/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3162 - soft_acc: 0.8300best occur in epoch 72\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3771 - soft_acc: 0.7744 - val_loss: 0.5936 - val_soft_acc: 0.5557\n",
      "Epoch 74/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3099 - soft_acc: 0.8000best occur in epoch 73\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3434 - soft_acc: 0.7428 - val_loss: 0.5561 - val_soft_acc: 0.6093\n",
      "Epoch 75/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3698 - soft_acc: 0.7639 - val_loss: 0.5951 - val_soft_acc: 0.5021\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3828 - soft_acc: 0.7328 - val_loss: 0.6039 - val_soft_acc: 0.4971\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3501 - soft_acc: 0.7422 - val_loss: 0.5909 - val_soft_acc: 0.5179\n",
      "Epoch 78/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3404 - soft_acc: 0.7800 - val_loss: 0.5541 - val_soft_acc: 0.5507\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3301 - soft_acc: 0.7694 - val_loss: 0.5536 - val_soft_acc: 0.5814\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3297 - soft_acc: 0.7778 - val_loss: 0.6396 - val_soft_acc: 0.5021\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3892 - soft_acc: 0.7389 - val_loss: 0.6614 - val_soft_acc: 0.4971\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4505 - soft_acc: 0.6611 - val_loss: 0.5789 - val_soft_acc: 0.5586\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3755 - soft_acc: 0.7172 - val_loss: 0.5512 - val_soft_acc: 0.5221\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3749 - soft_acc: 0.7156 - val_loss: 0.5659 - val_soft_acc: 0.5021\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3570 - soft_acc: 0.7467 - val_loss: 0.6868 - val_soft_acc: 0.4771\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4233 - soft_acc: 0.7133 - val_loss: 0.5455 - val_soft_acc: 0.5400\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3466 - soft_acc: 0.7756 - val_loss: 0.5968 - val_soft_acc: 0.5686\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3834 - soft_acc: 0.7372 - val_loss: 0.6125 - val_soft_acc: 0.6021\n",
      "Epoch 89/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3743 - soft_acc: 0.7261 - val_loss: 0.5475 - val_soft_acc: 0.5557\n",
      "Epoch 90/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3512 - soft_acc: 0.7739 - val_loss: 0.5833 - val_soft_acc: 0.4943\n",
      "Epoch 91/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4267 - soft_acc: 0.6400best occur in epoch 90\n",
      "512/512 [==============================] - 0s 75us/sample - loss: 0.3374 - soft_acc: 0.8133 - val_loss: 0.5388 - val_soft_acc: 0.5507\n",
      "Epoch 92/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3270 - soft_acc: 0.7961 - val_loss: 0.5520 - val_soft_acc: 0.5171\n",
      "Epoch 93/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3227 - soft_acc: 0.7800best occur in epoch 92\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3203 - soft_acc: 0.8433 - val_loss: 0.5493 - val_soft_acc: 0.5500\n",
      "Epoch 94/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3247 - soft_acc: 0.7478 - val_loss: 0.6181 - val_soft_acc: 0.5279\n",
      "Epoch 95/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3529 - soft_acc: 0.7594 - val_loss: 0.5395 - val_soft_acc: 0.5479\n",
      "Epoch 96/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3250 - soft_acc: 0.8128 - val_loss: 0.5468 - val_soft_acc: 0.5121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3150 - soft_acc: 0.7744 - val_loss: 0.5878 - val_soft_acc: 0.5586\n",
      "Epoch 98/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3347 - soft_acc: 0.7994 - val_loss: 0.5351 - val_soft_acc: 0.4843\n",
      "Epoch 99/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3104 - soft_acc: 0.8294 - val_loss: 0.5971 - val_soft_acc: 0.5300\n",
      "Epoch 100/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3358 - soft_acc: 0.8000best occur in epoch 99\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3343 - soft_acc: 0.7900 - val_loss: 0.5500 - val_soft_acc: 0.6271\n",
      "Epoch 101/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3303 - soft_acc: 0.7872 - val_loss: 0.5470 - val_soft_acc: 0.5500\n",
      "Epoch 102/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3447 - soft_acc: 0.8100 - val_loss: 0.5633 - val_soft_acc: 0.5607\n",
      "Epoch 103/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3345 - soft_acc: 0.8094 - val_loss: 0.5455 - val_soft_acc: 0.4614\n",
      "Epoch 104/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2921 - soft_acc: 0.8450 - val_loss: 0.5680 - val_soft_acc: 0.5150\n",
      "Epoch 105/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2893 - soft_acc: 0.8133 - val_loss: 0.5571 - val_soft_acc: 0.5100\n",
      "Epoch 106/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2921 - soft_acc: 0.8444 - val_loss: 0.6049 - val_soft_acc: 0.4971\n",
      "Epoch 107/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3232 - soft_acc: 0.8022 - val_loss: 0.5863 - val_soft_acc: 0.5307\n",
      "Epoch 108/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3294 - soft_acc: 0.7700 - val_loss: 0.5625 - val_soft_acc: 0.5121\n",
      "Epoch 109/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3136 - soft_acc: 0.8211 - val_loss: 0.5623 - val_soft_acc: 0.5636\n",
      "Epoch 110/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3106 - soft_acc: 0.7922 - val_loss: 0.5495 - val_soft_acc: 0.5736\n",
      "Epoch 111/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2848 - soft_acc: 0.8444 - val_loss: 0.5529 - val_soft_acc: 0.5200\n",
      "Epoch 112/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2761 - soft_acc: 0.8217 - val_loss: 0.5786 - val_soft_acc: 0.5021\n",
      "Epoch 113/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2952 - soft_acc: 0.7856 - val_loss: 0.5571 - val_soft_acc: 0.5150\n",
      "Epoch 114/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2774 - soft_acc: 0.8461 - val_loss: 0.5647 - val_soft_acc: 0.5486\n",
      "Epoch 115/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2819 - soft_acc: 0.8478 - val_loss: 0.6570 - val_soft_acc: 0.4336\n",
      "Epoch 116/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3109 - soft_acc: 0.7950 - val_loss: 0.5711 - val_soft_acc: 0.5100\n",
      "Epoch 117/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2854 - soft_acc: 0.8289 - val_loss: 0.5585 - val_soft_acc: 0.4893\n",
      "Epoch 118/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3066 - soft_acc: 0.7722 - val_loss: 0.5840 - val_soft_acc: 0.5336\n",
      "Epoch 119/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3958 - soft_acc: 0.6611 - val_loss: 0.6027 - val_soft_acc: 0.5250\n",
      "Epoch 120/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3778 - soft_acc: 0.7606 - val_loss: 0.6048 - val_soft_acc: 0.4436\n",
      "Epoch 121/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3409 - soft_acc: 0.7356 - val_loss: 0.6295 - val_soft_acc: 0.4714\n",
      "Epoch 122/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3187 - soft_acc: 0.8228 - val_loss: 0.6197 - val_soft_acc: 0.4743\n",
      "Epoch 123/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2833 - soft_acc: 0.8100best occur in epoch 122\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.2917 - soft_acc: 0.8583 - val_loss: 0.5629 - val_soft_acc: 0.6121\n",
      "Epoch 124/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3100 - soft_acc: 0.8033 - val_loss: 0.6269 - val_soft_acc: 0.4971\n",
      "Epoch 125/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3553 - soft_acc: 0.7689 - val_loss: 0.5718 - val_soft_acc: 0.4921\n",
      "Epoch 126/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2913 - soft_acc: 0.8050 - val_loss: 0.5792 - val_soft_acc: 0.5257\n",
      "Epoch 127/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2792 - soft_acc: 0.8478 - val_loss: 0.5669 - val_soft_acc: 0.5764\n",
      "Epoch 128/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2864 - soft_acc: 0.8633 - val_loss: 0.6125 - val_soft_acc: 0.5050\n",
      "Epoch 129/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3048 - soft_acc: 0.8411 - val_loss: 0.6311 - val_soft_acc: 0.5279\n",
      "Epoch 130/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3014 - soft_acc: 0.8100 - val_loss: 0.5627 - val_soft_acc: 0.5050\n",
      "Epoch 131/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2743 - soft_acc: 0.8600 - val_loss: 0.5614 - val_soft_acc: 0.5014\n",
      "Epoch 132/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2913 - soft_acc: 0.8550 - val_loss: 0.5566 - val_soft_acc: 0.5557\n",
      "Epoch 133/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2860 - soft_acc: 0.8272 - val_loss: 0.5659 - val_soft_acc: 0.4764\n",
      "Epoch 134/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2900 - soft_acc: 0.8394 - val_loss: 0.5839 - val_soft_acc: 0.4971\n",
      "Epoch 135/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2765 - soft_acc: 0.8583 - val_loss: 0.6446 - val_soft_acc: 0.4771\n",
      "Epoch 136/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3182 - soft_acc: 0.7894 - val_loss: 0.5716 - val_soft_acc: 0.5329\n",
      "Epoch 137/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2983 - soft_acc: 0.8172 - val_loss: 0.6091 - val_soft_acc: 0.5050\n",
      "Epoch 138/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3275 - soft_acc: 0.7750 - val_loss: 0.5629 - val_soft_acc: 0.5350\n",
      "Epoch 139/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2881 - soft_acc: 0.8289 - val_loss: 0.5532 - val_soft_acc: 0.5536\n",
      "Epoch 140/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2850 - soft_acc: 0.8256 - val_loss: 0.6905 - val_soft_acc: 0.4693\n",
      "Epoch 141/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3579 - soft_acc: 0.7867 - val_loss: 0.6196 - val_soft_acc: 0.4614\n",
      "Epoch 142/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3224 - soft_acc: 0.8072 - val_loss: 0.7250 - val_soft_acc: 0.4857\n",
      "Epoch 143/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3955 - soft_acc: 0.6911 - val_loss: 0.5653 - val_soft_acc: 0.4971\n",
      "Epoch 144/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3944 - soft_acc: 0.7094 - val_loss: 0.6203 - val_soft_acc: 0.5279\n",
      "Epoch 145/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4195 - soft_acc: 0.6522 - val_loss: 0.5499 - val_soft_acc: 0.5529\n",
      "Epoch 146/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3621 - soft_acc: 0.7589 - val_loss: 0.7687 - val_soft_acc: 0.3707\n",
      "Epoch 147/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3669 - soft_acc: 0.7589 - val_loss: 0.5513 - val_soft_acc: 0.5329\n",
      "Epoch 148/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3267 - soft_acc: 0.7750 - val_loss: 0.5635 - val_soft_acc: 0.5486\n",
      "Epoch 149/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2878 - soft_acc: 0.8428 - val_loss: 0.5493 - val_soft_acc: 0.5436\n",
      "Epoch 150/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2733 - soft_acc: 0.8111 - val_loss: 0.5601 - val_soft_acc: 0.5150\n",
      "Epoch 151/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2793 - soft_acc: 0.8200 - val_loss: 0.5619 - val_soft_acc: 0.6021\n",
      "Epoch 152/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3083 - soft_acc: 0.7517 - val_loss: 0.5620 - val_soft_acc: 0.5279\n",
      "Epoch 153/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2998 - soft_acc: 0.8261 - val_loss: 0.6658 - val_soft_acc: 0.4671\n",
      "Epoch 154/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3063 - soft_acc: 0.8006 - val_loss: 0.6791 - val_soft_acc: 0.5229\n",
      "Epoch 155/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3096 - soft_acc: 0.7933 - val_loss: 0.6023 - val_soft_acc: 0.5229\n",
      "Epoch 156/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3002 - soft_acc: 0.8000 - val_loss: 0.5546 - val_soft_acc: 0.5536\n",
      "Epoch 157/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2643 - soft_acc: 0.8711 - val_loss: 0.5488 - val_soft_acc: 0.5000\n",
      "Epoch 158/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2591 - soft_acc: 0.8711 - val_loss: 0.5616 - val_soft_acc: 0.5279\n",
      "Epoch 159/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2701 - soft_acc: 0.8594 - val_loss: 0.5514 - val_soft_acc: 0.5229\n",
      "Epoch 160/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2788 - soft_acc: 0.8356 - val_loss: 0.5584 - val_soft_acc: 0.5279\n",
      "Epoch 161/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2929 - soft_acc: 0.7994 - val_loss: 0.5781 - val_soft_acc: 0.5436\n",
      "Epoch 162/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3214 - soft_acc: 0.7678 - val_loss: 0.6991 - val_soft_acc: 0.4929\n",
      "Epoch 163/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3113 - soft_acc: 0.8417 - val_loss: 0.6938 - val_soft_acc: 0.4493\n",
      "Epoch 164/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3006 - soft_acc: 0.7744 - val_loss: 0.5669 - val_soft_acc: 0.5321\n",
      "Epoch 165/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2780 - soft_acc: 0.8417 - val_loss: 0.5599 - val_soft_acc: 0.5357\n",
      "Epoch 166/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2699 - soft_acc: 0.8578 - val_loss: 0.5703 - val_soft_acc: 0.5179\n",
      "Epoch 167/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2751 - soft_acc: 0.8472 - val_loss: 0.5794 - val_soft_acc: 0.4486\n",
      "Epoch 168/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3272 - soft_acc: 0.7956 - val_loss: 0.5937 - val_soft_acc: 0.6071\n",
      "Epoch 169/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2795 - soft_acc: 0.8389 - val_loss: 0.6910 - val_soft_acc: 0.5721\n",
      "Epoch 170/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2856 - soft_acc: 0.8233 - val_loss: 0.6440 - val_soft_acc: 0.4357\n",
      "Epoch 171/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2697 - soft_acc: 0.8322 - val_loss: 0.6561 - val_soft_acc: 0.4900\n",
      "Epoch 172/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3005 - soft_acc: 0.7861 - val_loss: 0.6244 - val_soft_acc: 0.5279\n",
      "Epoch 173/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3444 - soft_acc: 0.7578 - val_loss: 0.5551 - val_soft_acc: 0.5943\n",
      "Epoch 174/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2828 - soft_acc: 0.8256 - val_loss: 0.5698 - val_soft_acc: 0.4971\n",
      "Epoch 175/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2497 - soft_acc: 0.8778 - val_loss: 0.5619 - val_soft_acc: 0.5329\n",
      "Epoch 176/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2548 - soft_acc: 0.8422 - val_loss: 0.5989 - val_soft_acc: 0.4950\n",
      "Epoch 177/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2454 - soft_acc: 0.8867 - val_loss: 0.5934 - val_soft_acc: 0.5200\n",
      "Epoch 178/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2467 - soft_acc: 0.8711 - val_loss: 0.6409 - val_soft_acc: 0.5464\n",
      "Epoch 179/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2494 - soft_acc: 0.8850 - val_loss: 0.5539 - val_soft_acc: 0.5250\n",
      "Epoch 180/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2593 - soft_acc: 0.8211 - val_loss: 0.5551 - val_soft_acc: 0.5429\n",
      "Epoch 181/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2798 - soft_acc: 0.8583 - val_loss: 0.5530 - val_soft_acc: 0.4864\n",
      "Epoch 182/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2755 - soft_acc: 0.8311 - val_loss: 0.5866 - val_soft_acc: 0.4486\n",
      "Epoch 183/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2389 - soft_acc: 0.8739 - val_loss: 0.7192 - val_soft_acc: 0.4521\n",
      "Epoch 184/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3362 - soft_acc: 0.7806 - val_loss: 0.6082 - val_soft_acc: 0.5279\n",
      "Epoch 185/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2866 - soft_acc: 0.8017 - val_loss: 0.5998 - val_soft_acc: 0.4893\n",
      "Epoch 186/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2906 - soft_acc: 0.8033 - val_loss: 0.5905 - val_soft_acc: 0.5257\n",
      "Epoch 187/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2642 - soft_acc: 0.8439 - val_loss: 0.6024 - val_soft_acc: 0.5379\n",
      "Epoch 188/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3148 - soft_acc: 0.8228 - val_loss: 0.5606 - val_soft_acc: 0.4971\n",
      "Epoch 189/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2561 - soft_acc: 0.8467 - val_loss: 0.5684 - val_soft_acc: 0.5279\n",
      "Epoch 190/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2503 - soft_acc: 0.8594 - val_loss: 0.6494 - val_soft_acc: 0.5514\n",
      "Epoch 191/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2629 - soft_acc: 0.8633 - val_loss: 0.6209 - val_soft_acc: 0.5079\n",
      "Epoch 192/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2461 - soft_acc: 0.8794 - val_loss: 0.6674 - val_soft_acc: 0.5136\n",
      "Epoch 193/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2875 - soft_acc: 0.8361 - val_loss: 0.5845 - val_soft_acc: 0.5636\n",
      "Epoch 194/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2416 - soft_acc: 0.8967 - val_loss: 0.5980 - val_soft_acc: 0.4871\n",
      "Epoch 195/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2357 - soft_acc: 0.8739 - val_loss: 0.5868 - val_soft_acc: 0.4893\n",
      "Epoch 196/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2443 - soft_acc: 0.8678 - val_loss: 0.5740 - val_soft_acc: 0.4971\n",
      "Epoch 197/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2318 - soft_acc: 0.8756 - val_loss: 0.5767 - val_soft_acc: 0.5171\n",
      "Epoch 198/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2537 - soft_acc: 0.8733 - val_loss: 0.5686 - val_soft_acc: 0.5100\n",
      "Epoch 199/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2442 - soft_acc: 0.8761 - val_loss: 0.5985 - val_soft_acc: 0.4614\n",
      "Epoch 200/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2383 - soft_acc: 0.8772 - val_loss: 0.6068 - val_soft_acc: 0.5000\n",
      "Epoch 201/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2411 - soft_acc: 0.8622 - val_loss: 0.6450 - val_soft_acc: 0.4336\n",
      "Epoch 202/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2661 - soft_acc: 0.8283 - val_loss: 0.6745 - val_soft_acc: 0.4671\n",
      "Epoch 203/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2591 - soft_acc: 0.8644 - val_loss: 0.6211 - val_soft_acc: 0.4721\n",
      "Epoch 204/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2775 - soft_acc: 0.8356 - val_loss: 0.5619 - val_soft_acc: 0.5557\n",
      "Epoch 205/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3300 - soft_acc: 0.8067 - val_loss: 0.5814 - val_soft_acc: 0.5150\n",
      "Epoch 206/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2588 - soft_acc: 0.8506 - val_loss: 0.6060 - val_soft_acc: 0.4821\n",
      "Epoch 207/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2409 - soft_acc: 0.8744 - val_loss: 0.6408 - val_soft_acc: 0.5100\n",
      "Epoch 208/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2479 - soft_acc: 0.8417 - val_loss: 0.6005 - val_soft_acc: 0.4536\n",
      "Epoch 209/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2330 - soft_acc: 0.8439 - val_loss: 0.5715 - val_soft_acc: 0.5407\n",
      "Epoch 210/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3011 - soft_acc: 0.8517 - val_loss: 0.5827 - val_soft_acc: 0.5893\n",
      "Epoch 211/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2577 - soft_acc: 0.8800 - val_loss: 0.5688 - val_soft_acc: 0.5457\n",
      "Epoch 212/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2454 - soft_acc: 0.8794 - val_loss: 0.5656 - val_soft_acc: 0.5100\n",
      "Epoch 213/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2928 - soft_acc: 0.8244 - val_loss: 0.5597 - val_soft_acc: 0.5171\n",
      "Epoch 214/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2704 - soft_acc: 0.8078 - val_loss: 0.5878 - val_soft_acc: 0.5407\n",
      "Epoch 215/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2486 - soft_acc: 0.8967 - val_loss: 0.6512 - val_soft_acc: 0.4871\n",
      "Epoch 216/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2148 - soft_acc: 0.8922 - val_loss: 0.7820 - val_soft_acc: 0.4093\n",
      "Epoch 217/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3719 - soft_acc: 0.7072 - val_loss: 0.5723 - val_soft_acc: 0.5507\n",
      "Epoch 218/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3776 - soft_acc: 0.7283 - val_loss: 0.6221 - val_soft_acc: 0.4814\n",
      "Epoch 219/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3452 - soft_acc: 0.7200 - val_loss: 0.5962 - val_soft_acc: 0.5029\n",
      "Epoch 220/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2976 - soft_acc: 0.8000 - val_loss: 0.7982 - val_soft_acc: 0.3736\n",
      "Epoch 221/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3203 - soft_acc: 0.8139 - val_loss: 0.5960 - val_soft_acc: 0.4850\n",
      "Epoch 222/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2493 - soft_acc: 0.8539 - val_loss: 0.5627 - val_soft_acc: 0.5071\n",
      "Epoch 223/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2577 - soft_acc: 0.8767 - val_loss: 0.5890 - val_soft_acc: 0.5100\n",
      "Epoch 224/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2480 - soft_acc: 0.8606 - val_loss: 0.7013 - val_soft_acc: 0.4979\n",
      "Epoch 225/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2535 - soft_acc: 0.8589 - val_loss: 0.6258 - val_soft_acc: 0.5386\n",
      "Epoch 226/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2386 - soft_acc: 0.8544 - val_loss: 0.6906 - val_soft_acc: 0.5057\n",
      "Epoch 227/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2677 - soft_acc: 0.8633 - val_loss: 0.7530 - val_soft_acc: 0.4393\n",
      "Epoch 228/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2907 - soft_acc: 0.8139 - val_loss: 0.6872 - val_soft_acc: 0.4571\n",
      "Epoch 229/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2894 - soft_acc: 0.8272 - val_loss: 0.5771 - val_soft_acc: 0.5000\n",
      "Epoch 230/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2877 - soft_acc: 0.8244 - val_loss: 0.5803 - val_soft_acc: 0.4607\n",
      "Epoch 231/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2422 - soft_acc: 0.8711 - val_loss: 0.6391 - val_soft_acc: 0.5029\n",
      "Epoch 232/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2227 - soft_acc: 0.9050 - val_loss: 0.6446 - val_soft_acc: 0.4264\n",
      "Epoch 233/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2885 - soft_acc: 0.8428 - val_loss: 0.7969 - val_soft_acc: 0.4557\n",
      "Epoch 234/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2900 - soft_acc: 0.8344 - val_loss: 0.5875 - val_soft_acc: 0.4793\n",
      "Epoch 235/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2804 - soft_acc: 0.8444 - val_loss: 0.5998 - val_soft_acc: 0.4843\n",
      "Epoch 236/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2310 - soft_acc: 0.8961 - val_loss: 0.5849 - val_soft_acc: 0.5100\n",
      "Epoch 237/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2957 - soft_acc: 0.8106 - val_loss: 0.5943 - val_soft_acc: 0.5157\n",
      "Epoch 238/1000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3792 - soft_acc: 0.72 - 0s 46us/sample - loss: 0.2979 - soft_acc: 0.8206 - val_loss: 0.6508 - val_soft_acc: 0.4793\n",
      "Epoch 239/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2897 - soft_acc: 0.8311 - val_loss: 0.6441 - val_soft_acc: 0.5207\n",
      "Epoch 240/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2520 - soft_acc: 0.8878 - val_loss: 0.6881 - val_soft_acc: 0.4414\n",
      "Epoch 241/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2613 - soft_acc: 0.8867 - val_loss: 0.5711 - val_soft_acc: 0.5200\n",
      "Epoch 242/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2534 - soft_acc: 0.8744 - val_loss: 0.6377 - val_soft_acc: 0.5486\n",
      "Epoch 243/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2257 - soft_acc: 0.8756 - val_loss: 0.6168 - val_soft_acc: 0.5357\n",
      "Epoch 244/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2200 - soft_acc: 0.8922 - val_loss: 0.5903 - val_soft_acc: 0.5021\n",
      "Epoch 245/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2274 - soft_acc: 0.8789 - val_loss: 0.5812 - val_soft_acc: 0.4900\n",
      "Epoch 246/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2368 - soft_acc: 0.8944 - val_loss: 0.5705 - val_soft_acc: 0.4479\n",
      "Epoch 247/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2176 - soft_acc: 0.8922 - val_loss: 0.6566 - val_soft_acc: 0.5136\n",
      "Epoch 248/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2314 - soft_acc: 0.8628 - val_loss: 0.6140 - val_soft_acc: 0.5386\n",
      "Epoch 249/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2192 - soft_acc: 0.8839 - val_loss: 0.5951 - val_soft_acc: 0.4950\n",
      "Epoch 250/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2255 - soft_acc: 0.8944 - val_loss: 0.6142 - val_soft_acc: 0.5079\n",
      "Epoch 251/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2589 - soft_acc: 0.8572 - val_loss: 0.6022 - val_soft_acc: 0.5000\n",
      "Epoch 252/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2429 - soft_acc: 0.8517 - val_loss: 0.6219 - val_soft_acc: 0.4464\n",
      "Epoch 253/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2304 - soft_acc: 0.8672 - val_loss: 0.5778 - val_soft_acc: 0.5200\n",
      "Epoch 254/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2574 - soft_acc: 0.8567 - val_loss: 0.5741 - val_soft_acc: 0.5100\n",
      "Epoch 255/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2780 - soft_acc: 0.8511 - val_loss: 0.5862 - val_soft_acc: 0.4864\n",
      "Epoch 256/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2761 - soft_acc: 0.8494 - val_loss: 0.6281 - val_soft_acc: 0.4850\n",
      "Epoch 257/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2285 - soft_acc: 0.8828 - val_loss: 0.6923 - val_soft_acc: 0.4621\n",
      "Epoch 258/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2139 - soft_acc: 0.8994 - val_loss: 0.6309 - val_soft_acc: 0.4693\n",
      "Epoch 259/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2227 - soft_acc: 0.8789 - val_loss: 0.6312 - val_soft_acc: 0.5386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2447 - soft_acc: 0.8594 - val_loss: 0.6132 - val_soft_acc: 0.4357\n",
      "Epoch 261/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2483 - soft_acc: 0.8572 - val_loss: 0.6843 - val_soft_acc: 0.4621\n",
      "Epoch 262/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2648 - soft_acc: 0.8283 - val_loss: 0.6887 - val_soft_acc: 0.3907\n",
      "Epoch 263/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2472 - soft_acc: 0.8506 - val_loss: 0.6800 - val_soft_acc: 0.4314\n",
      "Epoch 264/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2241 - soft_acc: 0.8928 - val_loss: 0.6696 - val_soft_acc: 0.4464\n",
      "Epoch 265/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2297 - soft_acc: 0.8917 - val_loss: 0.6651 - val_soft_acc: 0.4621\n",
      "Epoch 266/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2015 - soft_acc: 0.9133 - val_loss: 0.6213 - val_soft_acc: 0.4564\n",
      "Epoch 267/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2193 - soft_acc: 0.8794 - val_loss: 0.6306 - val_soft_acc: 0.4157\n",
      "Epoch 268/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1991 - soft_acc: 0.8939 - val_loss: 0.6459 - val_soft_acc: 0.3979\n",
      "Epoch 269/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1977 - soft_acc: 0.9061 - val_loss: 0.6013 - val_soft_acc: 0.5229\n",
      "Epoch 270/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2064 - soft_acc: 0.9083 - val_loss: 0.6012 - val_soft_acc: 0.4921\n",
      "Epoch 271/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2019 - soft_acc: 0.9111 - val_loss: 0.5993 - val_soft_acc: 0.5279\n",
      "Epoch 272/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2023 - soft_acc: 0.8922 - val_loss: 0.6052 - val_soft_acc: 0.4821\n",
      "Epoch 273/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2096 - soft_acc: 0.8839 - val_loss: 0.5944 - val_soft_acc: 0.5429\n",
      "Epoch 274/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2398 - soft_acc: 0.8572 - val_loss: 0.6204 - val_soft_acc: 0.5029\n",
      "Epoch 275/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2495 - soft_acc: 0.8594 - val_loss: 0.5680 - val_soft_acc: 0.6071\n",
      "Epoch 276/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2882 - soft_acc: 0.8328 - val_loss: 0.5835 - val_soft_acc: 0.5464\n",
      "Epoch 277/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2517 - soft_acc: 0.8800 - val_loss: 0.6180 - val_soft_acc: 0.4871\n",
      "Epoch 278/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2282 - soft_acc: 0.8750 - val_loss: 0.6261 - val_soft_acc: 0.4693\n",
      "Epoch 279/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2078 - soft_acc: 0.9161 - val_loss: 0.6659 - val_soft_acc: 0.4693\n",
      "Epoch 280/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2587 - soft_acc: 0.8700best occur in epoch 279\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2170 - soft_acc: 0.8889 - val_loss: 0.5842 - val_soft_acc: 0.5893\n",
      "Epoch 281/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2612 - soft_acc: 0.8678 - val_loss: 0.5873 - val_soft_acc: 0.5329\n",
      "Epoch 282/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2639 - soft_acc: 0.8528 - val_loss: 0.7155 - val_soft_acc: 0.5064\n",
      "Epoch 283/1000\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.2417 - soft_acc: 0.8589 - val_loss: 0.6756 - val_soft_acc: 0.4393\n",
      "Epoch 284/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2105 - soft_acc: 0.9044 - val_loss: 0.7077 - val_soft_acc: 0.4393\n",
      "Epoch 285/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2049 - soft_acc: 0.9011 - val_loss: 0.6974 - val_soft_acc: 0.4086\n",
      "Epoch 286/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2445 - soft_acc: 0.8483 - val_loss: 0.7125 - val_soft_acc: 0.4471\n",
      "Epoch 287/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2442 - soft_acc: 0.8383 - val_loss: 0.6356 - val_soft_acc: 0.4464\n",
      "Epoch 288/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2174 - soft_acc: 0.9200 - val_loss: 0.6206 - val_soft_acc: 0.4593\n",
      "Epoch 289/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2028 - soft_acc: 0.8717 - val_loss: 0.6044 - val_soft_acc: 0.5564\n",
      "Epoch 290/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2146 - soft_acc: 0.8822 - val_loss: 0.6046 - val_soft_acc: 0.4536\n",
      "Epoch 291/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2391 - soft_acc: 0.8539 - val_loss: 0.6004 - val_soft_acc: 0.5100\n",
      "Epoch 292/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2922 - soft_acc: 0.8361 - val_loss: 0.5894 - val_soft_acc: 0.5379\n",
      "Epoch 293/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2822 - soft_acc: 0.8411 - val_loss: 0.6213 - val_soft_acc: 0.4264\n",
      "Epoch 294/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2682 - soft_acc: 0.8233 - val_loss: 0.6666 - val_soft_acc: 0.4521\n",
      "Epoch 295/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2541 - soft_acc: 0.8350 - val_loss: 0.7027 - val_soft_acc: 0.4164\n",
      "Epoch 296/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2226 - soft_acc: 0.8894 - val_loss: 0.7950 - val_soft_acc: 0.3507\n",
      "Epoch 297/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2533 - soft_acc: 0.8544 - val_loss: 0.6458 - val_soft_acc: 0.5057\n",
      "Epoch 298/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2079 - soft_acc: 0.9250 - val_loss: 0.6071 - val_soft_acc: 0.5129\n",
      "Epoch 299/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1992 - soft_acc: 0.9300 - val_loss: 0.5992 - val_soft_acc: 0.4871\n",
      "Epoch 300/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2683 - soft_acc: 0.8428 - val_loss: 0.6811 - val_soft_acc: 0.4243\n",
      "Epoch 301/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2359 - soft_acc: 0.8661 - val_loss: 0.6046 - val_soft_acc: 0.4693\n",
      "Epoch 302/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2272 - soft_acc: 0.8806 - val_loss: 0.7004 - val_soft_acc: 0.4393\n",
      "Epoch 303/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2366 - soft_acc: 0.8689 - val_loss: 0.7793 - val_soft_acc: 0.4300\n",
      "Epoch 304/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2490 - soft_acc: 0.8589 - val_loss: 0.6876 - val_soft_acc: 0.4136\n",
      "Epoch 305/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2032 - soft_acc: 0.9078 - val_loss: 0.6217 - val_soft_acc: 0.4693\n",
      "Epoch 306/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1999 - soft_acc: 0.9194 - val_loss: 0.6369 - val_soft_acc: 0.5336\n",
      "Epoch 307/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2269 - soft_acc: 0.8683 - val_loss: 0.6000 - val_soft_acc: 0.4643\n",
      "Epoch 308/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2231 - soft_acc: 0.8911 - val_loss: 0.5984 - val_soft_acc: 0.4614\n",
      "Epoch 309/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2440 - soft_acc: 0.8506 - val_loss: 0.6571 - val_soft_acc: 0.5286\n",
      "Epoch 310/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2269 - soft_acc: 0.8233 - val_loss: 0.6784 - val_soft_acc: 0.4136\n",
      "Epoch 311/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2083 - soft_acc: 0.8878 - val_loss: 0.7842 - val_soft_acc: 0.4479\n",
      "Epoch 312/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2409 - soft_acc: 0.8661 - val_loss: 0.7641 - val_soft_acc: 0.4064\n",
      "Epoch 313/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2922 - soft_acc: 0.7917 - val_loss: 0.6143 - val_soft_acc: 0.5029\n",
      "Epoch 314/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2839 - soft_acc: 0.8089 - val_loss: 0.5876 - val_soft_acc: 0.5407\n",
      "Epoch 315/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2371 - soft_acc: 0.8622 - val_loss: 0.6360 - val_soft_acc: 0.4979\n",
      "Epoch 316/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1903 - soft_acc: 0.9061 - val_loss: 0.6117 - val_soft_acc: 0.5029\n",
      "Epoch 317/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1915 - soft_acc: 0.8922 - val_loss: 0.6069 - val_soft_acc: 0.5207\n",
      "Epoch 318/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2195 - soft_acc: 0.8894 - val_loss: 0.6559 - val_soft_acc: 0.4543\n",
      "Epoch 319/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2138 - soft_acc: 0.9011 - val_loss: 0.6355 - val_soft_acc: 0.4979\n",
      "Epoch 320/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2142 - soft_acc: 0.8961 - val_loss: 0.7229 - val_soft_acc: 0.4114\n",
      "Epoch 321/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2291 - soft_acc: 0.8706 - val_loss: 0.7130 - val_soft_acc: 0.3550\n",
      "Epoch 322/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2249 - soft_acc: 0.9083 - val_loss: 0.6878 - val_soft_acc: 0.4650\n",
      "Epoch 323/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2299 - soft_acc: 0.8622 - val_loss: 0.7706 - val_soft_acc: 0.3864\n",
      "Epoch 324/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2867 - soft_acc: 0.8350 - val_loss: 0.5937 - val_soft_acc: 0.5814\n",
      "Epoch 325/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2335 - soft_acc: 0.8494 - val_loss: 0.6099 - val_soft_acc: 0.5050\n",
      "Epoch 326/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2163 - soft_acc: 0.8950 - val_loss: 0.6111 - val_soft_acc: 0.4364\n",
      "Epoch 327/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2040 - soft_acc: 0.8994 - val_loss: 0.6557 - val_soft_acc: 0.4907\n",
      "Epoch 328/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1951 - soft_acc: 0.9044 - val_loss: 0.6096 - val_soft_acc: 0.4693\n",
      "Epoch 329/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1887 - soft_acc: 0.9200 - val_loss: 0.6164 - val_soft_acc: 0.4614\n",
      "Epoch 330/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2126 - soft_acc: 0.9028 - val_loss: 0.6446 - val_soft_acc: 0.4714\n",
      "Epoch 331/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2033 - soft_acc: 0.9044 - val_loss: 0.6099 - val_soft_acc: 0.4721\n",
      "Epoch 332/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2073 - soft_acc: 0.8944 - val_loss: 0.6227 - val_soft_acc: 0.5000\n",
      "Epoch 333/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2054 - soft_acc: 0.9011 - val_loss: 0.5943 - val_soft_acc: 0.5686\n",
      "Epoch 334/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2332 - soft_acc: 0.8744 - val_loss: 0.6413 - val_soft_acc: 0.4393\n",
      "Epoch 335/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1885 - soft_acc: 0.9211 - val_loss: 0.7059 - val_soft_acc: 0.4271\n",
      "Epoch 336/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1914 - soft_acc: 0.9211 - val_loss: 0.7582 - val_soft_acc: 0.3886\n",
      "Epoch 337/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2227 - soft_acc: 0.8961 - val_loss: 0.7098 - val_soft_acc: 0.4957\n",
      "Epoch 338/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1945 - soft_acc: 0.9061 - val_loss: 0.6249 - val_soft_acc: 0.5000\n",
      "Epoch 339/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1989 - soft_acc: 0.9078 - val_loss: 0.7225 - val_soft_acc: 0.4964\n",
      "Epoch 340/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2027 - soft_acc: 0.8906 - val_loss: 0.6736 - val_soft_acc: 0.4314\n",
      "Epoch 341/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2029 - soft_acc: 0.9111 - val_loss: 0.6951 - val_soft_acc: 0.4064\n",
      "Epoch 342/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1984 - soft_acc: 0.9350 - val_loss: 0.6802 - val_soft_acc: 0.4136\n",
      "Epoch 343/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1857 - soft_acc: 0.8922 - val_loss: 0.6977 - val_soft_acc: 0.3650\n",
      "Epoch 344/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1849 - soft_acc: 0.9217 - val_loss: 0.7110 - val_soft_acc: 0.4321\n",
      "Epoch 345/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1946 - soft_acc: 0.8989 - val_loss: 0.6421 - val_soft_acc: 0.4593\n",
      "Epoch 346/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2137 - soft_acc: 0.8978 - val_loss: 0.5986 - val_soft_acc: 0.5129\n",
      "Epoch 347/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2407 - soft_acc: 0.8811 - val_loss: 0.6743 - val_soft_acc: 0.5064\n",
      "Epoch 348/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1817 - soft_acc: 0.9144 - val_loss: 0.6731 - val_soft_acc: 0.4800\n",
      "Epoch 349/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1723 - soft_acc: 0.9433 - val_loss: 0.6346 - val_soft_acc: 0.5029\n",
      "Epoch 350/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1778 - soft_acc: 0.9244 - val_loss: 0.6412 - val_soft_acc: 0.4800\n",
      "Epoch 351/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1853 - soft_acc: 0.9144 - val_loss: 0.6789 - val_soft_acc: 0.4621\n",
      "Epoch 352/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2013 - soft_acc: 0.9006 - val_loss: 0.6311 - val_soft_acc: 0.5057\n",
      "Epoch 353/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1903 - soft_acc: 0.9244 - val_loss: 0.6192 - val_soft_acc: 0.4079\n",
      "Epoch 354/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2099 - soft_acc: 0.9061 - val_loss: 0.6318 - val_soft_acc: 0.4900\n",
      "Epoch 355/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1739 - soft_acc: 0.9383 - val_loss: 0.6511 - val_soft_acc: 0.4550\n",
      "Epoch 356/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2017 - soft_acc: 0.9194 - val_loss: 0.6645 - val_soft_acc: 0.4086\n",
      "Epoch 357/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1899 - soft_acc: 0.9228 - val_loss: 0.7542 - val_soft_acc: 0.3679\n",
      "Epoch 358/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1982 - soft_acc: 0.8989 - val_loss: 0.6888 - val_soft_acc: 0.4829\n",
      "Epoch 359/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1912 - soft_acc: 0.9333 - val_loss: 0.7949 - val_soft_acc: 0.3914\n",
      "Epoch 360/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1879 - soft_acc: 0.9072 - val_loss: 0.6839 - val_soft_acc: 0.4164\n",
      "Epoch 361/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1894 - soft_acc: 0.9300 - val_loss: 0.6784 - val_soft_acc: 0.5036\n",
      "Epoch 362/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1843 - soft_acc: 0.9211 - val_loss: 0.6596 - val_soft_acc: 0.4414\n",
      "Epoch 363/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1963 - soft_acc: 0.9100 - val_loss: 0.6851 - val_soft_acc: 0.4136\n",
      "Epoch 364/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2212 - soft_acc: 0.9033 - val_loss: 0.8059 - val_soft_acc: 0.4171\n",
      "Epoch 365/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2414 - soft_acc: 0.8828 - val_loss: 0.7152 - val_soft_acc: 0.4757\n",
      "Epoch 366/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1974 - soft_acc: 0.9211 - val_loss: 0.6749 - val_soft_acc: 0.4414\n",
      "Epoch 367/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1621 - soft_acc: 0.9417 - val_loss: 0.7319 - val_soft_acc: 0.4164\n",
      "Epoch 368/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1937 - soft_acc: 0.9400 - val_loss: 0.7814 - val_soft_acc: 0.3986\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2376 - soft_acc: 0.8861 - val_loss: 0.7214 - val_soft_acc: 0.3400\n",
      "Epoch 370/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2006 - soft_acc: 0.9300 - val_loss: 0.6544 - val_soft_acc: 0.3979\n",
      "Epoch 371/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1911 - soft_acc: 0.9178 - val_loss: 0.6665 - val_soft_acc: 0.4721\n",
      "Epoch 372/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1720 - soft_acc: 0.9139 - val_loss: 0.7470 - val_soft_acc: 0.4271\n",
      "Epoch 373/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2094 - soft_acc: 0.9044 - val_loss: 0.6239 - val_soft_acc: 0.5000\n",
      "Epoch 374/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1987 - soft_acc: 0.9283 - val_loss: 0.6916 - val_soft_acc: 0.4629\n",
      "Epoch 375/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1766 - soft_acc: 0.9278 - val_loss: 0.6427 - val_soft_acc: 0.5286\n",
      "Epoch 376/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2091 - soft_acc: 0.9117 - val_loss: 0.6368 - val_soft_acc: 0.4800\n",
      "Epoch 377/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1929 - soft_acc: 0.8994 - val_loss: 0.7191 - val_soft_acc: 0.4321\n",
      "Epoch 378/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1821 - soft_acc: 0.9089 - val_loss: 0.7239 - val_soft_acc: 0.3857\n",
      "Epoch 379/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1811 - soft_acc: 0.9228 - val_loss: 0.7336 - val_soft_acc: 0.4243\n",
      "Epoch 380/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1788 - soft_acc: 0.9211 - val_loss: 0.6532 - val_soft_acc: 0.3879\n",
      "Epoch 381/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1772 - soft_acc: 0.9056 - val_loss: 0.7052 - val_soft_acc: 0.4264\n",
      "Epoch 382/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1894 - soft_acc: 0.9144 - val_loss: 0.6960 - val_soft_acc: 0.4093\n",
      "Epoch 383/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1960 - soft_acc: 0.9161 - val_loss: 0.7275 - val_soft_acc: 0.3757\n",
      "Epoch 384/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1931 - soft_acc: 0.9161 - val_loss: 0.8182 - val_soft_acc: 0.4193\n",
      "Epoch 385/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2315 - soft_acc: 0.8694 - val_loss: 0.8471 - val_soft_acc: 0.3764\n",
      "Epoch 386/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2616 - soft_acc: 0.8544 - val_loss: 0.6425 - val_soft_acc: 0.4186\n",
      "Epoch 387/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2376 - soft_acc: 0.8550 - val_loss: 0.6628 - val_soft_acc: 0.4386\n",
      "Epoch 388/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1931 - soft_acc: 0.9217 - val_loss: 0.6767 - val_soft_acc: 0.5057\n",
      "Epoch 389/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1982 - soft_acc: 0.9194 - val_loss: 0.6928 - val_soft_acc: 0.4600\n",
      "Epoch 390/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1744 - soft_acc: 0.9417 - val_loss: 0.7456 - val_soft_acc: 0.4214\n",
      "Epoch 391/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1957 - soft_acc: 0.9161 - val_loss: 0.7226 - val_soft_acc: 0.3936\n",
      "Epoch 392/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2042 - soft_acc: 0.8822 - val_loss: 0.7457 - val_soft_acc: 0.3500\n",
      "Epoch 393/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1889 - soft_acc: 0.9111 - val_loss: 0.6435 - val_soft_acc: 0.4364\n",
      "Epoch 394/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1806 - soft_acc: 0.9261 - val_loss: 0.6875 - val_soft_acc: 0.4650\n",
      "Epoch 395/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1710 - soft_acc: 0.9500 - val_loss: 0.6470 - val_soft_acc: 0.4979\n",
      "Epoch 396/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1716 - soft_acc: 0.9328 - val_loss: 0.7240 - val_soft_acc: 0.4164\n",
      "Epoch 397/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1638 - soft_acc: 0.9361 - val_loss: 0.7937 - val_soft_acc: 0.4243\n",
      "Epoch 398/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1837 - soft_acc: 0.9367 - val_loss: 0.8028 - val_soft_acc: 0.4221\n",
      "Epoch 399/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2261 - soft_acc: 0.8428 - val_loss: 0.7230 - val_soft_acc: 0.3807\n",
      "Epoch 400/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2280 - soft_acc: 0.9100 - val_loss: 0.6075 - val_soft_acc: 0.5071\n",
      "Epoch 401/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1999 - soft_acc: 0.9128 - val_loss: 0.6261 - val_soft_acc: 0.4921\n",
      "Epoch 402/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2080 - soft_acc: 0.9011 - val_loss: 0.6733 - val_soft_acc: 0.4264\n",
      "Epoch 403/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1747 - soft_acc: 0.9072 - val_loss: 0.7345 - val_soft_acc: 0.4421\n",
      "Epoch 404/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1839 - soft_acc: 0.9172 - val_loss: 0.7522 - val_soft_acc: 0.4550\n",
      "Epoch 405/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1736 - soft_acc: 0.9383 - val_loss: 0.6706 - val_soft_acc: 0.4721\n",
      "Epoch 406/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1798 - soft_acc: 0.9194 - val_loss: 0.6999 - val_soft_acc: 0.4193\n",
      "Epoch 407/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2097 - soft_acc: 0.8961 - val_loss: 0.6955 - val_soft_acc: 0.3957\n",
      "Epoch 408/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2180 - soft_acc: 0.8689 - val_loss: 0.7093 - val_soft_acc: 0.4550\n",
      "Epoch 409/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1852 - soft_acc: 0.9244 - val_loss: 0.6623 - val_soft_acc: 0.4750\n",
      "Epoch 410/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1604 - soft_acc: 0.9483 - val_loss: 0.6652 - val_soft_acc: 0.4700\n",
      "Epoch 411/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1651 - soft_acc: 0.9433 - val_loss: 0.7478 - val_soft_acc: 0.3914\n",
      "Epoch 412/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1776 - soft_acc: 0.9211 - val_loss: 0.7237 - val_soft_acc: 0.3986\n",
      "Epoch 413/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1747 - soft_acc: 0.9339 - val_loss: 0.7334 - val_soft_acc: 0.4193\n",
      "Epoch 414/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1772 - soft_acc: 0.9100 - val_loss: 0.6853 - val_soft_acc: 0.4471\n",
      "Epoch 415/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1594 - soft_acc: 0.9500 - val_loss: 0.7904 - val_soft_acc: 0.4093\n",
      "Epoch 416/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1947 - soft_acc: 0.9039 - val_loss: 0.7349 - val_soft_acc: 0.4293\n",
      "Epoch 417/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1764 - soft_acc: 0.9500 - val_loss: 0.7137 - val_soft_acc: 0.4114\n",
      "Epoch 418/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1596 - soft_acc: 0.9600 - val_loss: 0.6587 - val_soft_acc: 0.4343\n",
      "Epoch 419/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1775 - soft_acc: 0.9344 - val_loss: 0.6643 - val_soft_acc: 0.4743\n",
      "Epoch 420/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2006 - soft_acc: 0.9144 - val_loss: 0.6240 - val_soft_acc: 0.5079\n",
      "Epoch 421/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2066 - soft_acc: 0.8961 - val_loss: 0.6411 - val_soft_acc: 0.5357\n",
      "Epoch 422/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2116 - soft_acc: 0.8989 - val_loss: 0.6425 - val_soft_acc: 0.4314\n",
      "Epoch 423/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1969 - soft_acc: 0.8906 - val_loss: 0.7492 - val_soft_acc: 0.4421\n",
      "Epoch 424/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1858 - soft_acc: 0.9300 - val_loss: 0.7107 - val_soft_acc: 0.4550\n",
      "Epoch 425/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1977 - soft_acc: 0.9261 - val_loss: 0.7403 - val_soft_acc: 0.3986\n",
      "Epoch 426/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1725 - soft_acc: 0.9517 - val_loss: 0.6432 - val_soft_acc: 0.5029\n",
      "Epoch 427/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1656 - soft_acc: 0.9378 - val_loss: 0.6736 - val_soft_acc: 0.5007\n",
      "Epoch 428/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1703 - soft_acc: 0.9189 - val_loss: 0.7545 - val_soft_acc: 0.4321\n",
      "Epoch 429/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1823 - soft_acc: 0.9250 - val_loss: 0.6492 - val_soft_acc: 0.4114\n",
      "Epoch 430/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1915 - soft_acc: 0.9417 - val_loss: 0.7169 - val_soft_acc: 0.3729\n",
      "Epoch 431/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1824 - soft_acc: 0.9239 - val_loss: 0.6268 - val_soft_acc: 0.5229\n",
      "Epoch 432/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1900 - soft_acc: 0.9367 - val_loss: 0.6621 - val_soft_acc: 0.5157\n",
      "Epoch 433/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1705 - soft_acc: 0.9400 - val_loss: 0.7180 - val_soft_acc: 0.4036\n",
      "Epoch 434/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1749 - soft_acc: 0.9278 - val_loss: 0.7391 - val_soft_acc: 0.4086\n",
      "Epoch 435/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1820 - soft_acc: 0.9483 - val_loss: 0.7295 - val_soft_acc: 0.4086\n",
      "Epoch 436/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1565 - soft_acc: 0.9361 - val_loss: 0.7444 - val_soft_acc: 0.4479\n",
      "Epoch 437/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1688 - soft_acc: 0.9239 - val_loss: 0.6509 - val_soft_acc: 0.4821\n",
      "Epoch 438/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1895 - soft_acc: 0.9228 - val_loss: 0.6328 - val_soft_acc: 0.4236\n",
      "Epoch 439/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1654 - soft_acc: 0.9483 - val_loss: 0.7436 - val_soft_acc: 0.3600\n",
      "Epoch 440/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1549 - soft_acc: 0.9617 - val_loss: 0.8156 - val_soft_acc: 0.4350\n",
      "Epoch 441/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1923 - soft_acc: 0.9228 - val_loss: 0.7894 - val_soft_acc: 0.4221\n",
      "Epoch 442/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2402 - soft_acc: 0.8917 - val_loss: 0.7190 - val_soft_acc: 0.4650\n",
      "Epoch 443/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2062 - soft_acc: 0.9044 - val_loss: 0.6630 - val_soft_acc: 0.5593\n",
      "Epoch 444/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1986 - soft_acc: 0.9144 - val_loss: 0.6348 - val_soft_acc: 0.5536\n",
      "Epoch 445/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1838 - soft_acc: 0.9189 - val_loss: 0.7602 - val_soft_acc: 0.3886\n",
      "Epoch 446/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1821 - soft_acc: 0.9333 - val_loss: 0.6908 - val_soft_acc: 0.4500\n",
      "Epoch 447/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1654 - soft_acc: 0.9450 - val_loss: 0.7337 - val_soft_acc: 0.3986\n",
      "Epoch 448/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1448 - soft_acc: 0.9567 - val_loss: 0.6806 - val_soft_acc: 0.4729\n",
      "Epoch 449/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1560 - soft_acc: 0.9500 - val_loss: 0.6418 - val_soft_acc: 0.4614\n",
      "Epoch 450/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2045 - soft_acc: 0.9183 - val_loss: 0.6602 - val_soft_acc: 0.5000\n",
      "Epoch 451/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1815 - soft_acc: 0.9350 - val_loss: 0.6607 - val_soft_acc: 0.4650\n",
      "Epoch 452/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1784 - soft_acc: 0.9411 - val_loss: 0.6616 - val_soft_acc: 0.4136\n",
      "Epoch 453/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1705 - soft_acc: 0.9550 - val_loss: 0.6606 - val_soft_acc: 0.4443\n",
      "Epoch 454/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1642 - soft_acc: 0.9483 - val_loss: 0.7032 - val_soft_acc: 0.4779\n",
      "Epoch 455/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1648 - soft_acc: 0.9650 - val_loss: 0.6588 - val_soft_acc: 0.4236\n",
      "Epoch 456/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1675 - soft_acc: 0.9483 - val_loss: 0.7350 - val_soft_acc: 0.4143\n",
      "Epoch 457/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1575 - soft_acc: 0.9500 - val_loss: 0.6636 - val_soft_acc: 0.5186\n",
      "Epoch 458/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1736 - soft_acc: 0.9383 - val_loss: 0.7507 - val_soft_acc: 0.3807\n",
      "Epoch 459/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1597 - soft_acc: 0.9617 - val_loss: 0.7316 - val_soft_acc: 0.3629\n",
      "Epoch 460/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1900 - soft_acc: 0.9444 - val_loss: 0.8622 - val_soft_acc: 0.3836\n",
      "Epoch 461/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2418 - soft_acc: 0.8756 - val_loss: 0.7290 - val_soft_acc: 0.4093\n",
      "Epoch 462/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1661 - soft_acc: 0.9150 - val_loss: 0.7956 - val_soft_acc: 0.3707\n",
      "Epoch 463/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2316 - soft_acc: 0.8461 - val_loss: 0.6417 - val_soft_acc: 0.4079\n",
      "Epoch 464/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1979 - soft_acc: 0.8800 - val_loss: 0.6363 - val_soft_acc: 0.5357\n",
      "Epoch 465/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2064 - soft_acc: 0.9150 - val_loss: 0.6435 - val_soft_acc: 0.4586\n",
      "Epoch 466/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2239 - soft_acc: 0.8756 - val_loss: 0.6492 - val_soft_acc: 0.4950\n",
      "Epoch 467/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2675 - soft_acc: 0.8578 - val_loss: 0.6375 - val_soft_acc: 0.5307\n",
      "Epoch 468/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2133 - soft_acc: 0.9011 - val_loss: 0.6936 - val_soft_acc: 0.4293\n",
      "Epoch 469/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1647 - soft_acc: 0.9550 - val_loss: 0.6706 - val_soft_acc: 0.4286\n",
      "Epoch 470/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1613 - soft_acc: 0.9344 - val_loss: 0.6744 - val_soft_acc: 0.4593\n",
      "Epoch 471/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1633 - soft_acc: 0.9517 - val_loss: 0.6704 - val_soft_acc: 0.3986\n",
      "Epoch 472/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1745 - soft_acc: 0.9033 - val_loss: 0.7090 - val_soft_acc: 0.4450\n",
      "Epoch 473/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1497 - soft_acc: 0.9617 - val_loss: 0.7617 - val_soft_acc: 0.4607\n",
      "Epoch 474/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1600 - soft_acc: 0.9494 - val_loss: 0.8086 - val_soft_acc: 0.4429\n",
      "Epoch 475/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1813 - soft_acc: 0.9294 - val_loss: 0.7084 - val_soft_acc: 0.4164\n",
      "Epoch 476/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1637 - soft_acc: 0.9500 - val_loss: 0.7296 - val_soft_acc: 0.4471\n",
      "Epoch 477/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1613 - soft_acc: 0.9461 - val_loss: 0.6917 - val_soft_acc: 0.4679\n",
      "Epoch 478/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1591 - soft_acc: 0.9600 - val_loss: 0.6972 - val_soft_acc: 0.3807\n",
      "Epoch 479/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1739 - soft_acc: 0.9206 - val_loss: 0.6617 - val_soft_acc: 0.4800\n",
      "Epoch 480/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1718 - soft_acc: 0.9450 - val_loss: 0.6830 - val_soft_acc: 0.4650\n",
      "Epoch 481/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1481 - soft_acc: 0.9650 - val_loss: 0.7772 - val_soft_acc: 0.4450\n",
      "Epoch 482/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2195 - soft_acc: 0.8994 - val_loss: 0.7919 - val_soft_acc: 0.4014\n",
      "Epoch 483/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2203 - soft_acc: 0.9067 - val_loss: 0.6623 - val_soft_acc: 0.5157\n",
      "Epoch 484/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1641 - soft_acc: 0.9450 - val_loss: 0.6689 - val_soft_acc: 0.4114\n",
      "Epoch 485/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1587 - soft_acc: 0.9461 - val_loss: 0.6808 - val_soft_acc: 0.4550\n",
      "Epoch 486/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1526 - soft_acc: 0.9500 - val_loss: 0.7028 - val_soft_acc: 0.4164\n",
      "Epoch 487/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1617 - soft_acc: 0.9278 - val_loss: 0.6766 - val_soft_acc: 0.4264\n",
      "Epoch 488/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1634 - soft_acc: 0.9433 - val_loss: 0.6611 - val_soft_acc: 0.5000\n",
      "Epoch 489/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1798 - soft_acc: 0.9467 - val_loss: 0.7045 - val_soft_acc: 0.4550\n",
      "Epoch 490/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1504 - soft_acc: 0.9633 - val_loss: 0.6930 - val_soft_acc: 0.4314\n",
      "Epoch 491/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1433 - soft_acc: 0.9633 - val_loss: 0.7195 - val_soft_acc: 0.4143\n",
      "Epoch 492/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1400 - soft_acc: 0.9617 - val_loss: 0.7463 - val_soft_acc: 0.4293\n",
      "Epoch 493/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1804 - soft_acc: 0.9567 - val_loss: 0.8212 - val_soft_acc: 0.3864\n",
      "Epoch 494/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2026 - soft_acc: 0.9250 - val_loss: 0.7427 - val_soft_acc: 0.4064\n",
      "Epoch 495/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1641 - soft_acc: 0.9294 - val_loss: 0.8134 - val_soft_acc: 0.3450\n",
      "Epoch 496/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1863 - soft_acc: 0.9039 - val_loss: 0.7777 - val_soft_acc: 0.3914\n",
      "Epoch 497/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1375 - soft_acc: 0.9633 - val_loss: 0.7594 - val_soft_acc: 0.3986\n",
      "Epoch 498/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1495 - soft_acc: 0.9550 - val_loss: 0.7044 - val_soft_acc: 0.4829\n",
      "Epoch 499/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1581 - soft_acc: 0.9600 - val_loss: 0.6727 - val_soft_acc: 0.4621\n",
      "Epoch 500/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1593 - soft_acc: 0.9322 - val_loss: 0.7185 - val_soft_acc: 0.4193\n",
      "Epoch 501/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1532 - soft_acc: 0.9306 - val_loss: 0.7144 - val_soft_acc: 0.4321\n",
      "Epoch 502/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1515 - soft_acc: 0.9600 - val_loss: 0.6909 - val_soft_acc: 0.4571\n",
      "Epoch 503/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1589 - soft_acc: 0.9483 - val_loss: 0.6992 - val_soft_acc: 0.4550\n",
      "Epoch 504/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1575 - soft_acc: 0.9500best occur in epoch 503\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.1617 - soft_acc: 0.9567 - val_loss: 0.6385 - val_soft_acc: 0.5464\n",
      "Epoch 505/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1515 - soft_acc: 0.9583 - val_loss: 0.7419 - val_soft_acc: 0.4371\n",
      "Epoch 506/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1660 - soft_acc: 0.9500 - val_loss: 0.6905 - val_soft_acc: 0.5014\n",
      "Epoch 507/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1659 - soft_acc: 0.9550 - val_loss: 0.7823 - val_soft_acc: 0.3836\n",
      "Epoch 508/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1481 - soft_acc: 0.9428 - val_loss: 0.7227 - val_soft_acc: 0.4164\n",
      "Epoch 509/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1413 - soft_acc: 0.9683 - val_loss: 0.7619 - val_soft_acc: 0.3321\n",
      "Epoch 510/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1494 - soft_acc: 0.9478 - val_loss: 0.6856 - val_soft_acc: 0.4700\n",
      "Epoch 511/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1700 - soft_acc: 0.9467 - val_loss: 0.6843 - val_soft_acc: 0.4829\n",
      "Epoch 512/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1381 - soft_acc: 0.9733 - val_loss: 0.6786 - val_soft_acc: 0.4214\n",
      "Epoch 513/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.1335 - soft_acc: 0.9633 - val_loss: 0.8017 - val_soft_acc: 0.4679\n",
      "Epoch 514/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1590 - soft_acc: 0.9467 - val_loss: 0.7921 - val_soft_acc: 0.4500\n",
      "Epoch 515/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1851 - soft_acc: 0.9333 - val_loss: 0.7440 - val_soft_acc: 0.4036\n",
      "Epoch 516/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1519 - soft_acc: 0.9550 - val_loss: 0.6970 - val_soft_acc: 0.4243\n",
      "Epoch 517/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1407 - soft_acc: 0.9717 - val_loss: 0.6863 - val_soft_acc: 0.4500\n",
      "Epoch 518/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1447 - soft_acc: 0.9550 - val_loss: 0.7290 - val_soft_acc: 0.4064\n",
      "Epoch 519/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1300 - soft_acc: 0.9578 - val_loss: 0.6810 - val_soft_acc: 0.5086\n",
      "Epoch 520/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1313 - soft_acc: 0.9528 - val_loss: 0.6991 - val_soft_acc: 0.4650\n",
      "Epoch 521/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1410 - soft_acc: 0.9667 - val_loss: 0.7374 - val_soft_acc: 0.4243\n",
      "Epoch 522/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1349 - soft_acc: 0.9633 - val_loss: 0.6867 - val_soft_acc: 0.4421\n",
      "Epoch 523/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1371 - soft_acc: 0.9633 - val_loss: 0.7769 - val_soft_acc: 0.4393\n",
      "Epoch 524/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1530 - soft_acc: 0.9550 - val_loss: 0.7184 - val_soft_acc: 0.3779\n",
      "Epoch 525/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1293 - soft_acc: 0.9594 - val_loss: 0.7213 - val_soft_acc: 0.4221\n",
      "Epoch 526/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1516 - soft_acc: 0.9289 - val_loss: 0.7846 - val_soft_acc: 0.3907\n",
      "Epoch 527/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1779 - soft_acc: 0.9106 - val_loss: 0.6492 - val_soft_acc: 0.4671\n",
      "Epoch 528/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1641 - soft_acc: 0.9600 - val_loss: 0.6903 - val_soft_acc: 0.4186\n",
      "Epoch 529/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1755 - soft_acc: 0.9433 - val_loss: 0.6658 - val_soft_acc: 0.4464\n",
      "Epoch 530/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1629 - soft_acc: 0.9067 - val_loss: 0.6888 - val_soft_acc: 0.4143\n",
      "Epoch 531/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1536 - soft_acc: 0.9339 - val_loss: 0.7576 - val_soft_acc: 0.4243\n",
      "Epoch 532/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1747 - soft_acc: 0.9194 - val_loss: 0.7746 - val_soft_acc: 0.3757\n",
      "Epoch 533/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1802 - soft_acc: 0.9328 - val_loss: 0.8127 - val_soft_acc: 0.3529\n",
      "Epoch 534/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2206 - soft_acc: 0.8817 - val_loss: 0.7703 - val_soft_acc: 0.3193\n",
      "Epoch 535/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2069 - soft_acc: 0.8661 - val_loss: 0.7145 - val_soft_acc: 0.4600\n",
      "Epoch 536/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2096 - soft_acc: 0.8578 - val_loss: 0.6464 - val_soft_acc: 0.4871\n",
      "Epoch 537/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1936 - soft_acc: 0.9194 - val_loss: 0.7694 - val_soft_acc: 0.4014\n",
      "Epoch 538/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1826 - soft_acc: 0.9228 - val_loss: 0.7500 - val_soft_acc: 0.4657\n",
      "Epoch 539/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2091 - soft_acc: 0.9217 - val_loss: 0.6357 - val_soft_acc: 0.5279\n",
      "Epoch 540/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1824 - soft_acc: 0.9467 - val_loss: 0.7060 - val_soft_acc: 0.4471\n",
      "Epoch 541/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1478 - soft_acc: 0.9700 - val_loss: 0.6778 - val_soft_acc: 0.4343\n",
      "Epoch 542/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1374 - soft_acc: 0.9422 - val_loss: 0.7073 - val_soft_acc: 0.4650\n",
      "Epoch 543/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1657 - soft_acc: 0.9428 - val_loss: 0.7110 - val_soft_acc: 0.4857\n",
      "Epoch 544/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1486 - soft_acc: 0.9500 - val_loss: 0.7030 - val_soft_acc: 0.4371\n",
      "Epoch 545/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1278 - soft_acc: 0.9650 - val_loss: 0.7302 - val_soft_acc: 0.4914\n",
      "Epoch 546/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1244 - soft_acc: 0.9683 - val_loss: 0.7205 - val_soft_acc: 0.4143\n",
      "Epoch 547/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1253 - soft_acc: 0.9717 - val_loss: 0.7034 - val_soft_acc: 0.4421\n",
      "Epoch 548/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1296 - soft_acc: 0.9733 - val_loss: 0.7127 - val_soft_acc: 0.3857\n",
      "Epoch 549/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1276 - soft_acc: 0.9717 - val_loss: 0.7375 - val_soft_acc: 0.3757\n",
      "Epoch 550/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1455 - soft_acc: 0.9617 - val_loss: 0.7599 - val_soft_acc: 0.4064\n",
      "Epoch 551/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1407 - soft_acc: 0.9356 - val_loss: 0.7365 - val_soft_acc: 0.3907\n",
      "Epoch 552/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1408 - soft_acc: 0.9478 - val_loss: 0.7030 - val_soft_acc: 0.4243\n",
      "Epoch 553/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1824 - soft_acc: 0.9228 - val_loss: 0.7249 - val_soft_acc: 0.4500\n",
      "Epoch 554/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1643 - soft_acc: 0.9444 - val_loss: 0.7001 - val_soft_acc: 0.4057\n",
      "Epoch 555/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1478 - soft_acc: 0.9361 - val_loss: 0.7607 - val_soft_acc: 0.3786\n",
      "Epoch 556/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1575 - soft_acc: 0.9239 - val_loss: 0.7794 - val_soft_acc: 0.4557\n",
      "Epoch 557/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1521 - soft_acc: 0.9200 - val_loss: 0.7247 - val_soft_acc: 0.4193\n",
      "Epoch 558/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1474 - soft_acc: 0.9567 - val_loss: 0.7569 - val_soft_acc: 0.4450\n",
      "Epoch 559/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1303 - soft_acc: 0.9750 - val_loss: 0.8096 - val_soft_acc: 0.4121\n",
      "Epoch 560/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1601 - soft_acc: 0.9533 - val_loss: 0.7980 - val_soft_acc: 0.4400\n",
      "Epoch 561/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1775 - soft_acc: 0.9500 - val_loss: 0.9156 - val_soft_acc: 0.3179\n",
      "Epoch 562/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2843 - soft_acc: 0.7856 - val_loss: 0.6742 - val_soft_acc: 0.4214\n",
      "Epoch 563/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2738 - soft_acc: 0.8078 - val_loss: 0.6582 - val_soft_acc: 0.4950\n",
      "Epoch 564/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2561 - soft_acc: 0.8650 - val_loss: 0.8214 - val_soft_acc: 0.3479\n",
      "Epoch 565/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1924 - soft_acc: 0.9400 - val_loss: 0.7563 - val_soft_acc: 0.4964\n",
      "Epoch 566/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1920 - soft_acc: 0.9433 - val_loss: 0.8145 - val_soft_acc: 0.3836\n",
      "Epoch 567/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1970 - soft_acc: 0.9078 - val_loss: 0.6896 - val_soft_acc: 0.4471\n",
      "Epoch 568/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1784 - soft_acc: 0.9467 - val_loss: 0.6712 - val_soft_acc: 0.4850\n",
      "Epoch 569/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1628 - soft_acc: 0.9567 - val_loss: 0.6733 - val_soft_acc: 0.4571\n",
      "Epoch 570/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1533 - soft_acc: 0.9250 - val_loss: 0.7331 - val_soft_acc: 0.4243\n",
      "Epoch 571/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1411 - soft_acc: 0.9683 - val_loss: 0.7383 - val_soft_acc: 0.4064\n",
      "Epoch 572/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1333 - soft_acc: 0.9683 - val_loss: 0.7336 - val_soft_acc: 0.4186\n",
      "Epoch 573/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1262 - soft_acc: 0.9700 - val_loss: 0.8227 - val_soft_acc: 0.4043\n",
      "Epoch 574/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1635 - soft_acc: 0.9411 - val_loss: 0.8372 - val_soft_acc: 0.3736\n",
      "Epoch 575/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1877 - soft_acc: 0.9333 - val_loss: 0.8144 - val_soft_acc: 0.4221\n",
      "Epoch 576/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2159 - soft_acc: 0.8700 - val_loss: 0.7274 - val_soft_acc: 0.3886\n",
      "Epoch 577/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1831 - soft_acc: 0.9161 - val_loss: 0.7004 - val_soft_acc: 0.4186\n",
      "Epoch 578/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1644 - soft_acc: 0.9328 - val_loss: 0.7016 - val_soft_acc: 0.4036\n",
      "Epoch 579/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1389 - soft_acc: 0.9250 - val_loss: 0.7018 - val_soft_acc: 0.3629\n",
      "Epoch 580/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1429 - soft_acc: 0.9650 - val_loss: 0.7337 - val_soft_acc: 0.3807\n",
      "Epoch 581/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1389 - soft_acc: 0.9700 - val_loss: 0.7844 - val_soft_acc: 0.3600\n",
      "Epoch 582/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1605 - soft_acc: 0.9550 - val_loss: 0.6939 - val_soft_acc: 0.3986\n",
      "Epoch 583/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1617 - soft_acc: 0.9344 - val_loss: 0.7804 - val_soft_acc: 0.4143\n",
      "Epoch 584/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1777 - soft_acc: 0.9417 - val_loss: 0.8059 - val_soft_acc: 0.3886\n",
      "Epoch 585/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2554 - soft_acc: 0.8544 - val_loss: 0.6830 - val_soft_acc: 0.4414\n",
      "Epoch 586/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1996 - soft_acc: 0.9250 - val_loss: 0.6727 - val_soft_acc: 0.3950\n",
      "Epoch 587/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1602 - soft_acc: 0.9550 - val_loss: 0.7155 - val_soft_acc: 0.3986\n",
      "Epoch 588/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1391 - soft_acc: 0.9750 - val_loss: 0.6964 - val_soft_acc: 0.4136\n",
      "Epoch 589/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1391 - soft_acc: 0.9667 - val_loss: 0.7660 - val_soft_acc: 0.3936\n",
      "Epoch 590/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1358 - soft_acc: 0.9700 - val_loss: 0.7783 - val_soft_acc: 0.4321\n",
      "Epoch 591/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1233 - soft_acc: 0.9456 - val_loss: 0.7189 - val_soft_acc: 0.3907\n",
      "Epoch 592/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1156 - soft_acc: 0.9717 - val_loss: 0.7501 - val_soft_acc: 0.4629\n",
      "Epoch 593/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1198 - soft_acc: 0.9750 - val_loss: 0.7477 - val_soft_acc: 0.4657\n",
      "Epoch 594/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1133 - soft_acc: 0.9644 - val_loss: 0.6998 - val_soft_acc: 0.4829\n",
      "Epoch 595/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1315 - soft_acc: 0.9667 - val_loss: 0.6721 - val_soft_acc: 0.4564\n",
      "Epoch 596/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1601 - soft_acc: 0.9517 - val_loss: 0.7085 - val_soft_acc: 0.5007\n",
      "Epoch 597/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1389 - soft_acc: 0.9733 - val_loss: 0.6788 - val_soft_acc: 0.4621\n",
      "Epoch 598/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1331 - soft_acc: 0.9317 - val_loss: 0.7074 - val_soft_acc: 0.4214\n",
      "Epoch 599/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1491 - soft_acc: 0.9600 - val_loss: 0.6777 - val_soft_acc: 0.4393\n",
      "Epoch 600/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1507 - soft_acc: 0.9389 - val_loss: 0.6899 - val_soft_acc: 0.4900\n",
      "Epoch 601/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1413 - soft_acc: 0.9717 - val_loss: 0.6623 - val_soft_acc: 0.4821\n",
      "Epoch 602/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1369 - soft_acc: 0.9544 - val_loss: 0.7185 - val_soft_acc: 0.4650\n",
      "Epoch 603/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1372 - soft_acc: 0.9600 - val_loss: 0.8013 - val_soft_acc: 0.4121\n",
      "Epoch 604/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1770 - soft_acc: 0.9467 - val_loss: 0.7403 - val_soft_acc: 0.3807\n",
      "Epoch 605/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1553 - soft_acc: 0.9428 - val_loss: 0.6910 - val_soft_acc: 0.4800\n",
      "Epoch 606/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1253 - soft_acc: 0.9750 - val_loss: 0.7243 - val_soft_acc: 0.4264\n",
      "Epoch 607/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1285 - soft_acc: 0.9333 - val_loss: 0.7568 - val_soft_acc: 0.4093\n",
      "Epoch 608/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1461 - soft_acc: 0.9406 - val_loss: 0.7686 - val_soft_acc: 0.3707\n",
      "Epoch 609/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1676 - soft_acc: 0.9517 - val_loss: 0.6906 - val_soft_acc: 0.4750\n",
      "Epoch 610/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1310 - soft_acc: 0.9783 - val_loss: 0.6978 - val_soft_acc: 0.4550\n",
      "Epoch 611/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1221 - soft_acc: 0.9800 - val_loss: 0.6944 - val_soft_acc: 0.4750\n",
      "Epoch 612/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1351 - soft_acc: 0.9667 - val_loss: 0.7251 - val_soft_acc: 0.4571\n",
      "Epoch 613/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1403 - soft_acc: 0.9683 - val_loss: 0.6745 - val_soft_acc: 0.4750\n",
      "Epoch 614/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1497 - soft_acc: 0.9478 - val_loss: 0.7177 - val_soft_acc: 0.4750\n",
      "Epoch 615/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1705 - soft_acc: 0.9278 - val_loss: 0.6508 - val_soft_acc: 0.4693\n",
      "Epoch 616/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1727 - soft_acc: 0.9294 - val_loss: 0.6643 - val_soft_acc: 0.4721\n",
      "Epoch 617/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1927 - soft_acc: 0.9350 - val_loss: 0.6820 - val_soft_acc: 0.3850\n",
      "Epoch 618/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1819 - soft_acc: 0.9006 - val_loss: 0.7679 - val_soft_acc: 0.3686\n",
      "Epoch 619/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1653 - soft_acc: 0.9433 - val_loss: 0.8218 - val_soft_acc: 0.4171\n",
      "Epoch 620/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1770 - soft_acc: 0.9328 - val_loss: 0.7720 - val_soft_acc: 0.4143\n",
      "Epoch 621/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1799 - soft_acc: 0.9567 - val_loss: 0.7082 - val_soft_acc: 0.4036\n",
      "Epoch 622/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1343 - soft_acc: 0.9561 - val_loss: 0.7807 - val_soft_acc: 0.3450\n",
      "Epoch 623/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1501 - soft_acc: 0.9517 - val_loss: 0.7109 - val_soft_acc: 0.4471\n",
      "Epoch 624/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1473 - soft_acc: 0.9533 - val_loss: 0.7499 - val_soft_acc: 0.4064\n",
      "Epoch 625/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1772 - soft_acc: 0.9450 - val_loss: 0.7137 - val_soft_acc: 0.4293\n",
      "Epoch 626/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1595 - soft_acc: 0.9433 - val_loss: 0.7423 - val_soft_acc: 0.4579\n",
      "Epoch 627/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1469 - soft_acc: 0.9717 - val_loss: 0.7419 - val_soft_acc: 0.4036\n",
      "Epoch 628/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1453 - soft_acc: 0.9422 - val_loss: 0.7754 - val_soft_acc: 0.4300\n",
      "Epoch 629/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1506 - soft_acc: 0.9667 - val_loss: 0.7099 - val_soft_acc: 0.4464\n",
      "Epoch 630/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1264 - soft_acc: 0.9733 - val_loss: 0.7610 - val_soft_acc: 0.4271\n",
      "Epoch 631/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1388 - soft_acc: 0.9717 - val_loss: 0.7611 - val_soft_acc: 0.4193\n",
      "Epoch 632/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1594 - soft_acc: 0.9633 - val_loss: 0.8017 - val_soft_acc: 0.4093\n",
      "Epoch 633/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1390 - soft_acc: 0.9650 - val_loss: 0.6789 - val_soft_acc: 0.4257\n",
      "Epoch 634/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1595 - soft_acc: 0.9289 - val_loss: 0.7174 - val_soft_acc: 0.4679\n",
      "Epoch 635/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1542 - soft_acc: 0.9500 - val_loss: 0.6602 - val_soft_acc: 0.5000\n",
      "Epoch 636/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1928 - soft_acc: 0.9211 - val_loss: 0.7299 - val_soft_acc: 0.4271\n",
      "Epoch 637/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2283 - soft_acc: 0.8278 - val_loss: 0.7186 - val_soft_acc: 0.4471\n",
      "Epoch 638/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2177 - soft_acc: 0.8894 - val_loss: 0.8014 - val_soft_acc: 0.4271\n",
      "Epoch 639/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2035 - soft_acc: 0.9050 - val_loss: 0.6989 - val_soft_acc: 0.4443\n",
      "Epoch 640/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2049 - soft_acc: 0.9267 - val_loss: 0.6574 - val_soft_acc: 0.4364\n",
      "Epoch 641/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1570 - soft_acc: 0.9633 - val_loss: 0.7334 - val_soft_acc: 0.3500\n",
      "Epoch 642/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1524 - soft_acc: 0.9683 - val_loss: 0.6924 - val_soft_acc: 0.3957\n",
      "Epoch 643/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1265 - soft_acc: 0.9733 - val_loss: 0.7434 - val_soft_acc: 0.3964\n",
      "Epoch 644/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1257 - soft_acc: 0.9489 - val_loss: 0.7365 - val_soft_acc: 0.4529\n",
      "Epoch 645/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1223 - soft_acc: 0.9667 - val_loss: 0.7675 - val_soft_acc: 0.3836\n",
      "Epoch 646/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1274 - soft_acc: 0.9628 - val_loss: 0.7972 - val_soft_acc: 0.3964\n",
      "Epoch 647/1000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.1581 - soft_acc: 0.95 - 0s 42us/sample - loss: 0.1360 - soft_acc: 0.9511 - val_loss: 0.8205 - val_soft_acc: 0.3707\n",
      "Epoch 648/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1549 - soft_acc: 0.9683 - val_loss: 0.7697 - val_soft_acc: 0.3786\n",
      "Epoch 649/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1318 - soft_acc: 0.9439 - val_loss: 0.7232 - val_soft_acc: 0.3729\n",
      "Epoch 650/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1224 - soft_acc: 0.9767 - val_loss: 0.7425 - val_soft_acc: 0.4350\n",
      "Epoch 651/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1374 - soft_acc: 0.9733 - val_loss: 0.8107 - val_soft_acc: 0.4121\n",
      "Epoch 652/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1442 - soft_acc: 0.9650 - val_loss: 0.7217 - val_soft_acc: 0.4343\n",
      "Epoch 653/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1289 - soft_acc: 0.9650 - val_loss: 0.7509 - val_soft_acc: 0.5264\n",
      "Epoch 654/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1201 - soft_acc: 0.9767 - val_loss: 0.7437 - val_soft_acc: 0.4500\n",
      "Epoch 655/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1256 - soft_acc: 0.9700 - val_loss: 0.7471 - val_soft_acc: 0.4679\n",
      "Epoch 656/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1082 - soft_acc: 0.9800 - val_loss: 0.6927 - val_soft_acc: 0.4879\n",
      "Epoch 657/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1935 - soft_acc: 0.9350 - val_loss: 0.7111 - val_soft_acc: 0.4493\n",
      "Epoch 658/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1571 - soft_acc: 0.9394 - val_loss: 0.7363 - val_soft_acc: 0.4243\n",
      "Epoch 659/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1205 - soft_acc: 0.9750 - val_loss: 0.7105 - val_soft_acc: 0.4064\n",
      "Epoch 660/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1329 - soft_acc: 0.9650 - val_loss: 0.7473 - val_soft_acc: 0.3857\n",
      "Epoch 661/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1238 - soft_acc: 0.9561 - val_loss: 0.7740 - val_soft_acc: 0.4400\n",
      "Epoch 662/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1292 - soft_acc: 0.9661 - val_loss: 0.7490 - val_soft_acc: 0.4886\n",
      "Epoch 663/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1063 - soft_acc: 0.9800 - val_loss: 0.7376 - val_soft_acc: 0.4807\n",
      "Epoch 664/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1062 - soft_acc: 0.9817 - val_loss: 0.7205 - val_soft_acc: 0.3957\n",
      "Epoch 665/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1008 - soft_acc: 0.9800 - val_loss: 0.7669 - val_soft_acc: 0.4629\n",
      "Epoch 666/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1261 - soft_acc: 0.9628 - val_loss: 0.7657 - val_soft_acc: 0.4371\n",
      "Epoch 667/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1344 - soft_acc: 0.9478 - val_loss: 0.7440 - val_soft_acc: 0.3736\n",
      "Epoch 668/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1307 - soft_acc: 0.9611 - val_loss: 0.7950 - val_soft_acc: 0.4836\n",
      "Epoch 669/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1526 - soft_acc: 0.9800best occur in epoch 668\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1481 - soft_acc: 0.9667 - val_loss: 0.7006 - val_soft_acc: 0.5364\n",
      "Epoch 670/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1417 - soft_acc: 0.9367 - val_loss: 0.7210 - val_soft_acc: 0.4671\n",
      "Epoch 671/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1469 - soft_acc: 0.9717 - val_loss: 0.6690 - val_soft_acc: 0.4771\n",
      "Epoch 672/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1836 - soft_acc: 0.9250 - val_loss: 0.7232 - val_soft_acc: 0.4393\n",
      "Epoch 673/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1561 - soft_acc: 0.9650 - val_loss: 0.6924 - val_soft_acc: 0.4900\n",
      "Epoch 674/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1319 - soft_acc: 0.9750 - val_loss: 0.6994 - val_soft_acc: 0.4800\n",
      "Epoch 675/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1807 - soft_acc: 0.9294 - val_loss: 0.6809 - val_soft_acc: 0.5029\n",
      "Epoch 676/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1736 - soft_acc: 0.9383 - val_loss: 0.7393 - val_soft_acc: 0.4314\n",
      "Epoch 677/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1323 - soft_acc: 0.9633 - val_loss: 0.6996 - val_soft_acc: 0.3879\n",
      "Epoch 678/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1489 - soft_acc: 0.9600 - val_loss: 0.7282 - val_soft_acc: 0.4007\n",
      "Epoch 679/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1297 - soft_acc: 0.9700 - val_loss: 0.7212 - val_soft_acc: 0.4957\n",
      "Epoch 680/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1116 - soft_acc: 0.9833 - val_loss: 0.7147 - val_soft_acc: 0.5029\n",
      "Epoch 681/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1167 - soft_acc: 0.9700 - val_loss: 0.7741 - val_soft_acc: 0.4171\n",
      "Epoch 682/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1372 - soft_acc: 0.9767 - val_loss: 0.7370 - val_soft_acc: 0.4857\n",
      "Epoch 683/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.0984 - soft_acc: 0.9900best occur in epoch 682\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.1079 - soft_acc: 0.9783 - val_loss: 0.7305 - val_soft_acc: 0.5314\n",
      "Epoch 684/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1071 - soft_acc: 0.9783 - val_loss: 0.7469 - val_soft_acc: 0.5057\n",
      "Epoch 685/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1058 - soft_acc: 0.9800 - val_loss: 0.7556 - val_soft_acc: 0.3936\n",
      "Epoch 686/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1055 - soft_acc: 0.9711 - val_loss: 0.7637 - val_soft_acc: 0.4421\n",
      "Epoch 687/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1255 - soft_acc: 0.9733 - val_loss: 0.7470 - val_soft_acc: 0.4807\n",
      "Epoch 688/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1268 - soft_acc: 0.9544 - val_loss: 0.7940 - val_soft_acc: 0.3707\n",
      "Epoch 689/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1323 - soft_acc: 0.9750 - val_loss: 0.7875 - val_soft_acc: 0.3864\n",
      "Epoch 690/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1310 - soft_acc: 0.9644 - val_loss: 0.7332 - val_soft_acc: 0.5107\n",
      "Epoch 691/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1125 - soft_acc: 0.9783 - val_loss: 0.7037 - val_soft_acc: 0.4929\n",
      "Epoch 692/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1029 - soft_acc: 0.9817 - val_loss: 0.7399 - val_soft_acc: 0.4979\n",
      "Epoch 693/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1126 - soft_acc: 0.9750 - val_loss: 0.7439 - val_soft_acc: 0.4471\n",
      "Epoch 694/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1380 - soft_acc: 0.9800 - val_loss: 0.7875 - val_soft_acc: 0.3500\n",
      "Epoch 695/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1311 - soft_acc: 0.9700 - val_loss: 0.7504 - val_soft_acc: 0.4421\n",
      "Epoch 696/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1284 - soft_acc: 0.9750 - val_loss: 0.7988 - val_soft_acc: 0.4014\n",
      "Epoch 697/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2003 - soft_acc: 0.9211 - val_loss: 0.7285 - val_soft_acc: 0.4271\n",
      "Epoch 698/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1554 - soft_acc: 0.9444 - val_loss: 0.7566 - val_soft_acc: 0.4471\n",
      "Epoch 699/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1762 - soft_acc: 0.9122 - val_loss: 0.7339 - val_soft_acc: 0.4986\n",
      "Epoch 700/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1376 - soft_acc: 0.9650 - val_loss: 0.7112 - val_soft_acc: 0.4543\n",
      "Epoch 701/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1369 - soft_acc: 0.9700 - val_loss: 0.7027 - val_soft_acc: 0.5007\n",
      "Epoch 702/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1483 - soft_acc: 0.9578 - val_loss: 0.7255 - val_soft_acc: 0.4314\n",
      "Epoch 703/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1258 - soft_acc: 0.9733 - val_loss: 0.8219 - val_soft_acc: 0.4300\n",
      "Epoch 704/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1772 - soft_acc: 0.9378 - val_loss: 0.7482 - val_soft_acc: 0.3886\n",
      "Epoch 705/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1385 - soft_acc: 0.9617 - val_loss: 0.7070 - val_soft_acc: 0.4771\n",
      "Epoch 706/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1628 - soft_acc: 0.9444 - val_loss: 0.7005 - val_soft_acc: 0.4214\n",
      "Epoch 707/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1817 - soft_acc: 0.9500 - val_loss: 0.6799 - val_soft_acc: 0.4443\n",
      "Epoch 708/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1290 - soft_acc: 0.9611 - val_loss: 0.7480 - val_soft_acc: 0.4471\n",
      "Epoch 709/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1330 - soft_acc: 0.9667 - val_loss: 0.8278 - val_soft_acc: 0.3707\n",
      "Epoch 710/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2066 - soft_acc: 0.9022 - val_loss: 0.6738 - val_soft_acc: 0.4929\n",
      "Epoch 711/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1715 - soft_acc: 0.9467 - val_loss: 0.6865 - val_soft_acc: 0.5207\n",
      "Epoch 712/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1802 - soft_acc: 0.9400best occur in epoch 711\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1767 - soft_acc: 0.9500 - val_loss: 0.6887 - val_soft_acc: 0.6071\n",
      "Epoch 713/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1284 - soft_acc: 0.9767 - val_loss: 0.7375 - val_soft_acc: 0.4421\n",
      "Epoch 714/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1303 - soft_acc: 0.9594 - val_loss: 0.6864 - val_soft_acc: 0.4643\n",
      "Epoch 715/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1401 - soft_acc: 0.9767 - val_loss: 0.7039 - val_soft_acc: 0.4521\n",
      "Epoch 716/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1330 - soft_acc: 0.9611 - val_loss: 0.7156 - val_soft_acc: 0.4443\n",
      "Epoch 717/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1133 - soft_acc: 0.9783 - val_loss: 0.7020 - val_soft_acc: 0.4414\n",
      "Epoch 718/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1389 - soft_acc: 0.9750 - val_loss: 0.7143 - val_soft_acc: 0.4779\n",
      "Epoch 719/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1721 - soft_acc: 0.9311 - val_loss: 0.7647 - val_soft_acc: 0.3879\n",
      "Epoch 720/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1349 - soft_acc: 0.9717 - val_loss: 0.7506 - val_soft_acc: 0.3864\n",
      "Epoch 721/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1390 - soft_acc: 0.9428 - val_loss: 0.7845 - val_soft_acc: 0.4471\n",
      "Epoch 722/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1393 - soft_acc: 0.9683 - val_loss: 0.7083 - val_soft_acc: 0.4771\n",
      "Epoch 723/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1188 - soft_acc: 0.9661 - val_loss: 0.7614 - val_soft_acc: 0.4879\n",
      "Epoch 724/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1191 - soft_acc: 0.9644 - val_loss: 0.7231 - val_soft_acc: 0.3957\n",
      "Epoch 725/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1223 - soft_acc: 0.9783 - val_loss: 0.7169 - val_soft_acc: 0.4371\n",
      "Epoch 726/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1132 - soft_acc: 0.9833 - val_loss: 0.7101 - val_soft_acc: 0.4314\n",
      "Epoch 727/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1540 - soft_acc: 0.9561 - val_loss: 0.7158 - val_soft_acc: 0.4571\n",
      "Epoch 728/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1405 - soft_acc: 0.9683 - val_loss: 0.6922 - val_soft_acc: 0.4743\n",
      "Epoch 729/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1384 - soft_acc: 0.9600 - val_loss: 0.6888 - val_soft_acc: 0.4743\n",
      "Epoch 730/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1231 - soft_acc: 0.9783 - val_loss: 0.7159 - val_soft_acc: 0.4671\n",
      "Epoch 731/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1135 - soft_acc: 0.9661 - val_loss: 0.7399 - val_soft_acc: 0.4671\n",
      "Epoch 732/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1308 - soft_acc: 0.9472 - val_loss: 0.7491 - val_soft_acc: 0.3857\n",
      "Epoch 733/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1134 - soft_acc: 0.9661 - val_loss: 0.6903 - val_soft_acc: 0.4386\n",
      "Epoch 734/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1100 - soft_acc: 0.9850 - val_loss: 0.7607 - val_soft_acc: 0.4393\n",
      "Epoch 735/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1003 - soft_acc: 0.9589 - val_loss: 0.7376 - val_soft_acc: 0.4314\n",
      "Epoch 736/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1066 - soft_acc: 0.9850 - val_loss: 0.7195 - val_soft_acc: 0.4679\n",
      "Epoch 737/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1226 - soft_acc: 0.9783 - val_loss: 0.7227 - val_soft_acc: 0.4343\n",
      "Epoch 738/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1158 - soft_acc: 0.9783 - val_loss: 0.6994 - val_soft_acc: 0.4236\n",
      "Epoch 739/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1349 - soft_acc: 0.9700 - val_loss: 0.7059 - val_soft_acc: 0.4443\n",
      "Epoch 740/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1230 - soft_acc: 0.9733 - val_loss: 0.6947 - val_soft_acc: 0.4721\n",
      "Epoch 741/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1050 - soft_acc: 0.9783 - val_loss: 0.7260 - val_soft_acc: 0.4600\n",
      "Epoch 742/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1012 - soft_acc: 0.9728 - val_loss: 0.6996 - val_soft_acc: 0.4493\n",
      "Epoch 743/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1181 - soft_acc: 0.9783 - val_loss: 0.7536 - val_soft_acc: 0.4443\n",
      "Epoch 744/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1098 - soft_acc: 0.9800 - val_loss: 0.7034 - val_soft_acc: 0.4236\n",
      "Epoch 745/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1091 - soft_acc: 0.9694 - val_loss: 0.7844 - val_soft_acc: 0.4164\n",
      "Epoch 746/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1285 - soft_acc: 0.9750 - val_loss: 0.7583 - val_soft_acc: 0.3829\n",
      "Epoch 747/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1217 - soft_acc: 0.9578 - val_loss: 0.7679 - val_soft_acc: 0.4343\n",
      "Epoch 748/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1349 - soft_acc: 0.9633 - val_loss: 0.7909 - val_soft_acc: 0.4293\n",
      "Epoch 749/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1669 - soft_acc: 0.9467 - val_loss: 0.7397 - val_soft_acc: 0.4393\n",
      "Epoch 750/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1156 - soft_acc: 0.9750 - val_loss: 0.7416 - val_soft_acc: 0.4314\n",
      "Epoch 751/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1097 - soft_acc: 0.9406 - val_loss: 0.7571 - val_soft_acc: 0.4700\n",
      "Epoch 752/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1243 - soft_acc: 0.9683 - val_loss: 0.7158 - val_soft_acc: 0.4829\n",
      "Epoch 753/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1241 - soft_acc: 0.9733 - val_loss: 0.7754 - val_soft_acc: 0.4064\n",
      "Epoch 754/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1087 - soft_acc: 0.9833 - val_loss: 0.7785 - val_soft_acc: 0.4321\n",
      "Epoch 755/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1197 - soft_acc: 0.9850 - val_loss: 0.8489 - val_soft_acc: 0.4093\n",
      "Epoch 756/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1999 - soft_acc: 0.9317 - val_loss: 0.7868 - val_soft_acc: 0.4243\n",
      "Epoch 757/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1953 - soft_acc: 0.9211 - val_loss: 0.6737 - val_soft_acc: 0.4593\n",
      "Epoch 758/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1839 - soft_acc: 0.9317 - val_loss: 0.7321 - val_soft_acc: 0.4293\n",
      "Epoch 759/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1329 - soft_acc: 0.9661 - val_loss: 0.7231 - val_soft_acc: 0.4443\n",
      "Epoch 760/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1421 - soft_acc: 0.9567 - val_loss: 0.7470 - val_soft_acc: 0.4057\n",
      "Epoch 761/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1136 - soft_acc: 0.9817 - val_loss: 0.6948 - val_soft_acc: 0.4979\n",
      "Epoch 762/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1187 - soft_acc: 0.9767 - val_loss: 0.6753 - val_soft_acc: 0.5050\n",
      "Epoch 763/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1087 - soft_acc: 0.9817 - val_loss: 0.7686 - val_soft_acc: 0.4521\n",
      "Epoch 764/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1200 - soft_acc: 0.9733 - val_loss: 0.7394 - val_soft_acc: 0.4414\n",
      "Epoch 765/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1077 - soft_acc: 0.9783 - val_loss: 0.7209 - val_soft_acc: 0.5157\n",
      "Epoch 766/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1175 - soft_acc: 0.9700 - val_loss: 0.7301 - val_soft_acc: 0.4521\n",
      "Epoch 767/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1635 - soft_acc: 0.9517 - val_loss: 0.6988 - val_soft_acc: 0.4286\n",
      "Epoch 768/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1559 - soft_acc: 0.9550 - val_loss: 0.6914 - val_soft_acc: 0.3979\n",
      "Epoch 769/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1531 - soft_acc: 0.9617 - val_loss: 0.7522 - val_soft_acc: 0.4550\n",
      "Epoch 770/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1137 - soft_acc: 0.9817 - val_loss: 0.7548 - val_soft_acc: 0.4800\n",
      "Epoch 771/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1079 - soft_acc: 0.9694 - val_loss: 0.7266 - val_soft_acc: 0.4879\n",
      "Epoch 772/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1242 - soft_acc: 0.9767 - val_loss: 0.7261 - val_soft_acc: 0.4471\n",
      "Epoch 773/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1048 - soft_acc: 0.9833 - val_loss: 0.7567 - val_soft_acc: 0.4264\n",
      "Epoch 774/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1063 - soft_acc: 0.9767 - val_loss: 0.7223 - val_soft_acc: 0.4107\n",
      "Epoch 775/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1145 - soft_acc: 0.9817 - val_loss: 0.7395 - val_soft_acc: 0.4621\n",
      "Epoch 776/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1117 - soft_acc: 0.9833 - val_loss: 0.6974 - val_soft_acc: 0.5007\n",
      "Epoch 777/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1231 - soft_acc: 0.9700 - val_loss: 0.7001 - val_soft_acc: 0.4721\n",
      "Epoch 778/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1298 - soft_acc: 0.9561 - val_loss: 0.7129 - val_soft_acc: 0.4007\n",
      "Epoch 779/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1135 - soft_acc: 0.9800 - val_loss: 0.7130 - val_soft_acc: 0.5514\n",
      "Epoch 780/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0987 - soft_acc: 0.9850 - val_loss: 0.7059 - val_soft_acc: 0.4771\n",
      "Epoch 781/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1021 - soft_acc: 0.9833 - val_loss: 0.7390 - val_soft_acc: 0.4850\n",
      "Epoch 782/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.0969 - soft_acc: 0.9867 - val_loss: 0.7623 - val_soft_acc: 0.5086\n",
      "Epoch 783/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1068 - soft_acc: 0.9628 - val_loss: 0.7218 - val_soft_acc: 0.4821\n",
      "Epoch 784/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.0925 - soft_acc: 0.9850 - val_loss: 0.7143 - val_soft_acc: 0.4514\n",
      "Epoch 785/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.0866 - soft_acc: 0.9833 - val_loss: 0.7508 - val_soft_acc: 0.4957\n",
      "Epoch 786/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.0939 - soft_acc: 0.9850 - val_loss: 0.7617 - val_soft_acc: 0.4314\n",
      "Epoch 787/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1039 - soft_acc: 0.9800 - val_loss: 0.7498 - val_soft_acc: 0.4286\n",
      "Epoch 788/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1051 - soft_acc: 0.9800 - val_loss: 0.6994 - val_soft_acc: 0.4800\n",
      "Epoch 789/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1059 - soft_acc: 0.9817 - val_loss: 0.7263 - val_soft_acc: 0.4543\n",
      "Epoch 790/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1115 - soft_acc: 0.9783 - val_loss: 0.7276 - val_soft_acc: 0.4621\n",
      "Epoch 791/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0971 - soft_acc: 0.9728 - val_loss: 0.7607 - val_soft_acc: 0.4621\n",
      "Epoch 792/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1172 - soft_acc: 0.9850 - val_loss: 0.7128 - val_soft_acc: 0.4057\n",
      "Epoch 793/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1043 - soft_acc: 0.9817 - val_loss: 0.7649 - val_soft_acc: 0.4550\n",
      "Epoch 794/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1089 - soft_acc: 0.9750 - val_loss: 0.6989 - val_soft_acc: 0.4950\n",
      "Epoch 795/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.0948 - soft_acc: 0.9850 - val_loss: 0.7205 - val_soft_acc: 0.5543\n",
      "Epoch 796/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.0904 - soft_acc: 0.9850 - val_loss: 0.7529 - val_soft_acc: 0.4621\n",
      "Epoch 797/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.0948 - soft_acc: 0.9850 - val_loss: 0.7312 - val_soft_acc: 0.4521\n",
      "Epoch 798/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1067 - soft_acc: 0.9817 - val_loss: 0.7063 - val_soft_acc: 0.4721\n",
      "Epoch 799/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1046 - soft_acc: 0.9833 - val_loss: 0.8121 - val_soft_acc: 0.4479\n",
      "Epoch 800/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1655 - soft_acc: 0.9450 - val_loss: 0.7570 - val_soft_acc: 0.3957\n",
      "Epoch 801/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1201 - soft_acc: 0.9750 - val_loss: 0.7447 - val_soft_acc: 0.4750\n",
      "Epoch 802/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1031 - soft_acc: 0.9833 - val_loss: 0.7411 - val_soft_acc: 0.4621\n",
      "Epoch 803/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1180 - soft_acc: 0.9800 - val_loss: 0.7334 - val_soft_acc: 0.4621\n",
      "Epoch 804/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1030 - soft_acc: 0.9783 - val_loss: 0.7108 - val_soft_acc: 0.4850\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0931 - soft_acc: 0.9506 - val_loss: 0.7267 - val_soft_acc: 0.4721\n",
      "Epoch 806/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1063 - soft_acc: 0.9850 - val_loss: 0.6954 - val_soft_acc: 0.4207\n",
      "Epoch 807/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1037 - soft_acc: 0.9867 - val_loss: 0.6987 - val_soft_acc: 0.4700\n",
      "Epoch 808/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1078 - soft_acc: 0.9867 - val_loss: 0.7124 - val_soft_acc: 0.4593\n",
      "Epoch 809/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1017 - soft_acc: 0.9867 - val_loss: 0.7527 - val_soft_acc: 0.4543\n",
      "Epoch 810/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.0878 - soft_acc: 0.9867 - val_loss: 0.6870 - val_soft_acc: 0.4900\n",
      "Epoch 811/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0989 - soft_acc: 0.9833 - val_loss: 0.7077 - val_soft_acc: 0.5286\n",
      "Epoch 812/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0984 - soft_acc: 0.9711 - val_loss: 0.7397 - val_soft_acc: 0.4114\n",
      "Epoch 813/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1240 - soft_acc: 0.9456 - val_loss: 0.7641 - val_soft_acc: 0.4986\n",
      "Epoch 814/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1453 - soft_acc: 0.9583 - val_loss: 0.7424 - val_soft_acc: 0.4907\n",
      "Epoch 815/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1293 - soft_acc: 0.9650 - val_loss: 0.7172 - val_soft_acc: 0.4821\n",
      "Epoch 816/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1756 - soft_acc: 0.9306 - val_loss: 0.7032 - val_soft_acc: 0.4929\n",
      "Epoch 817/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1598 - soft_acc: 0.9450 - val_loss: 0.6718 - val_soft_acc: 0.4771\n",
      "Epoch 818/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1339 - soft_acc: 0.9644 - val_loss: 0.7089 - val_soft_acc: 0.4986\n",
      "Epoch 819/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1076 - soft_acc: 0.9767 - val_loss: 0.7232 - val_soft_acc: 0.4600\n",
      "Epoch 820/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0979 - soft_acc: 0.9800 - val_loss: 0.7208 - val_soft_acc: 0.4721\n",
      "Epoch 821/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0888 - soft_acc: 0.9833 - val_loss: 0.7198 - val_soft_acc: 0.4564\n",
      "Epoch 822/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0840 - soft_acc: 0.9850 - val_loss: 0.7215 - val_soft_acc: 0.4443\n",
      "Epoch 823/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0858 - soft_acc: 0.9817 - val_loss: 0.7399 - val_soft_acc: 0.4571\n",
      "Epoch 824/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1057 - soft_acc: 0.9850 - val_loss: 0.7659 - val_soft_acc: 0.4136\n",
      "Epoch 825/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1052 - soft_acc: 0.9850 - val_loss: 0.7455 - val_soft_acc: 0.4393\n",
      "Epoch 826/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0948 - soft_acc: 0.9850 - val_loss: 0.7092 - val_soft_acc: 0.4443\n",
      "Epoch 827/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1017 - soft_acc: 0.9800 - val_loss: 0.7147 - val_soft_acc: 0.5007\n",
      "Epoch 828/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0860 - soft_acc: 0.9867 - val_loss: 0.7229 - val_soft_acc: 0.4464\n",
      "Epoch 829/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0904 - soft_acc: 0.9817 - val_loss: 0.7016 - val_soft_acc: 0.4157\n",
      "Epoch 830/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1045 - soft_acc: 0.9817 - val_loss: 0.6983 - val_soft_acc: 0.4564\n",
      "Epoch 831/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1305 - soft_acc: 0.9561 - val_loss: 0.6952 - val_soft_acc: 0.4364\n",
      "Epoch 832/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1270 - soft_acc: 0.9683 - val_loss: 0.6973 - val_soft_acc: 0.4829\n",
      "Epoch 833/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1255 - soft_acc: 0.9522 - val_loss: 0.7078 - val_soft_acc: 0.4293\n",
      "Epoch 834/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1431 - soft_acc: 0.9600 - val_loss: 0.6817 - val_soft_acc: 0.5307\n",
      "Epoch 835/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1168 - soft_acc: 0.9644 - val_loss: 0.6746 - val_soft_acc: 0.4493\n",
      "Epoch 836/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1348 - soft_acc: 0.9700 - val_loss: 0.6887 - val_soft_acc: 0.4643\n",
      "Epoch 837/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1177 - soft_acc: 0.9817 - val_loss: 0.7131 - val_soft_acc: 0.3829\n",
      "Epoch 838/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1637 - soft_acc: 0.9256 - val_loss: 0.6628 - val_soft_acc: 0.4493\n",
      "Epoch 839/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1939 - soft_acc: 0.9128 - val_loss: 0.7296 - val_soft_acc: 0.4364\n",
      "Epoch 840/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1564 - soft_acc: 0.9322 - val_loss: 0.7619 - val_soft_acc: 0.4500\n",
      "Epoch 841/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1295 - soft_acc: 0.9700 - val_loss: 0.7117 - val_soft_acc: 0.4514\n",
      "Epoch 842/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1116 - soft_acc: 0.9833 - val_loss: 0.7519 - val_soft_acc: 0.4950\n",
      "Epoch 843/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1225 - soft_acc: 0.9661 - val_loss: 0.7582 - val_soft_acc: 0.5186\n",
      "Epoch 844/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1215 - soft_acc: 0.9783 - val_loss: 0.7660 - val_soft_acc: 0.3857\n",
      "Epoch 845/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1298 - soft_acc: 0.9556 - val_loss: 0.7100 - val_soft_acc: 0.5257\n",
      "Epoch 846/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1166 - soft_acc: 0.9817 - val_loss: 0.7573 - val_soft_acc: 0.4543\n",
      "Epoch 847/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1257 - soft_acc: 0.9717 - val_loss: 0.7079 - val_soft_acc: 0.4929\n",
      "Epoch 848/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1318 - soft_acc: 0.9667 - val_loss: 0.7608 - val_soft_acc: 0.4543\n",
      "Epoch 849/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1437 - soft_acc: 0.9500 - val_loss: 0.7668 - val_soft_acc: 0.3986\n",
      "Epoch 850/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1433 - soft_acc: 0.9783 - val_loss: 0.8565 - val_soft_acc: 0.3250\n",
      "Epoch 851/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1893 - soft_acc: 0.9217 - val_loss: 0.6972 - val_soft_acc: 0.5050\n",
      "Epoch 852/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1688 - soft_acc: 0.9567 - val_loss: 0.7016 - val_soft_acc: 0.4907\n",
      "Epoch 853/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1349 - soft_acc: 0.9700 - val_loss: 0.7241 - val_soft_acc: 0.4107\n",
      "Epoch 854/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1476 - soft_acc: 0.9411 - val_loss: 0.7372 - val_soft_acc: 0.4779\n",
      "Epoch 855/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0987 - soft_acc: 0.9867 - val_loss: 0.7156 - val_soft_acc: 0.5100\n",
      "Epoch 856/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1064 - soft_acc: 0.9733 - val_loss: 0.7155 - val_soft_acc: 0.5236\n",
      "Epoch 857/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1071 - soft_acc: 0.9817 - val_loss: 0.7230 - val_soft_acc: 0.4643\n",
      "Epoch 858/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0953 - soft_acc: 0.9833 - val_loss: 0.7097 - val_soft_acc: 0.5336\n",
      "Epoch 859/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1171 - soft_acc: 0.9783 - val_loss: 0.7365 - val_soft_acc: 0.5236\n",
      "Epoch 860/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0984 - soft_acc: 0.9833 - val_loss: 0.7327 - val_soft_acc: 0.4750\n",
      "Epoch 861/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.0941 - soft_acc: 0.9817 - val_loss: 0.7363 - val_soft_acc: 0.4029\n",
      "Epoch 862/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1066 - soft_acc: 0.9817 - val_loss: 0.7331 - val_soft_acc: 0.4879\n",
      "Epoch 863/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1107 - soft_acc: 0.9783 - val_loss: 0.7038 - val_soft_acc: 0.5643\n",
      "Epoch 864/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0975 - soft_acc: 0.9783 - val_loss: 0.7341 - val_soft_acc: 0.5414\n",
      "Epoch 865/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.0930 - soft_acc: 0.9850 - val_loss: 0.7572 - val_soft_acc: 0.4286\n",
      "Epoch 866/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0895 - soft_acc: 0.9833 - val_loss: 0.7102 - val_soft_acc: 0.4929\n",
      "Epoch 867/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0957 - soft_acc: 0.9833 - val_loss: 0.7565 - val_soft_acc: 0.4364\n",
      "Epoch 868/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1031 - soft_acc: 0.9833 - val_loss: 0.7558 - val_soft_acc: 0.4671\n",
      "Epoch 869/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0887 - soft_acc: 0.9728 - val_loss: 0.7378 - val_soft_acc: 0.4514\n",
      "Epoch 870/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0921 - soft_acc: 0.9728 - val_loss: 0.6980 - val_soft_acc: 0.5464\n",
      "Epoch 871/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1145 - soft_acc: 0.9817 - val_loss: 0.7313 - val_soft_acc: 0.4293\n",
      "Epoch 872/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1436 - soft_acc: 0.9628 - val_loss: 0.7201 - val_soft_acc: 0.4543\n",
      "Epoch 873/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1160 - soft_acc: 0.9800 - val_loss: 0.7432 - val_soft_acc: 0.4443\n",
      "Epoch 874/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1033 - soft_acc: 0.9767 - val_loss: 0.7528 - val_soft_acc: 0.3900\n",
      "Epoch 875/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0929 - soft_acc: 0.9783 - val_loss: 0.7187 - val_soft_acc: 0.4164\n",
      "Epoch 876/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1053 - soft_acc: 0.9817 - val_loss: 0.7299 - val_soft_acc: 0.4314\n",
      "Epoch 877/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1171 - soft_acc: 0.9817 - val_loss: 0.7184 - val_soft_acc: 0.4243\n",
      "Epoch 878/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1391 - soft_acc: 0.9733 - val_loss: 0.7305 - val_soft_acc: 0.4271\n",
      "Epoch 879/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1735 - soft_acc: 0.9500 - val_loss: 0.7247 - val_soft_acc: 0.5007\n",
      "Epoch 880/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1381 - soft_acc: 0.9389 - val_loss: 0.8167 - val_soft_acc: 0.3964\n",
      "Epoch 881/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1575 - soft_acc: 0.9583 - val_loss: 0.7108 - val_soft_acc: 0.4671\n",
      "Epoch 882/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1144 - soft_acc: 0.9817 - val_loss: 0.7282 - val_soft_acc: 0.4436\n",
      "Epoch 883/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1022 - soft_acc: 0.9833 - val_loss: 0.6886 - val_soft_acc: 0.4900\n",
      "Epoch 884/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0942 - soft_acc: 0.9728 - val_loss: 0.7112 - val_soft_acc: 0.5029\n",
      "Epoch 885/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0899 - soft_acc: 0.9817 - val_loss: 0.7508 - val_soft_acc: 0.4829\n",
      "Epoch 886/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.0925 - soft_acc: 0.9694 - val_loss: 0.7089 - val_soft_acc: 0.4621\n",
      "Epoch 887/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1167 - soft_acc: 0.9767 - val_loss: 0.7932 - val_soft_acc: 0.3936\n",
      "Epoch 888/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1673 - soft_acc: 0.9378 - val_loss: 0.7587 - val_soft_acc: 0.4700\n",
      "Epoch 889/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1337 - soft_acc: 0.9561 - val_loss: 0.6916 - val_soft_acc: 0.5129\n",
      "Epoch 890/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1488 - soft_acc: 0.9239 - val_loss: 0.7170 - val_soft_acc: 0.4671\n",
      "Epoch 891/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1448 - soft_acc: 0.9494 - val_loss: 0.6897 - val_soft_acc: 0.4729\n",
      "Epoch 892/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1656 - soft_acc: 0.9517 - val_loss: 0.7387 - val_soft_acc: 0.5336\n",
      "Epoch 893/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1263 - soft_acc: 0.9644 - val_loss: 0.7224 - val_soft_acc: 0.4721\n",
      "Epoch 894/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1090 - soft_acc: 0.9644 - val_loss: 0.7429 - val_soft_acc: 0.4157\n",
      "Epoch 895/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1051 - soft_acc: 0.9817 - val_loss: 0.6978 - val_soft_acc: 0.5457\n",
      "Epoch 896/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1151 - soft_acc: 0.9817 - val_loss: 0.7360 - val_soft_acc: 0.4693\n",
      "Epoch 897/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1052 - soft_acc: 0.9817 - val_loss: 0.7394 - val_soft_acc: 0.4629\n",
      "Epoch 898/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1725 - soft_acc: 0.9483 - val_loss: 0.7064 - val_soft_acc: 0.5357\n",
      "Epoch 899/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1284 - soft_acc: 0.9717 - val_loss: 0.7240 - val_soft_acc: 0.4950\n",
      "Epoch 900/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1158 - soft_acc: 0.9783 - val_loss: 0.7903 - val_soft_acc: 0.3471\n",
      "Epoch 901/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1356 - soft_acc: 0.9717 - val_loss: 0.7525 - val_soft_acc: 0.4543\n",
      "Epoch 902/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1044 - soft_acc: 0.9783 - val_loss: 0.7407 - val_soft_acc: 0.4514\n",
      "Epoch 903/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.0994 - soft_acc: 0.9833 - val_loss: 0.7046 - val_soft_acc: 0.4464\n",
      "Epoch 904/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.0984 - soft_acc: 0.9833 - val_loss: 0.7663 - val_soft_acc: 0.4779\n",
      "Epoch 905/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1073 - soft_acc: 0.9661 - val_loss: 0.6950 - val_soft_acc: 0.5079\n",
      "Epoch 906/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1039 - soft_acc: 0.9711 - val_loss: 0.7104 - val_soft_acc: 0.4314\n",
      "Epoch 907/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1141 - soft_acc: 0.9733 - val_loss: 0.7065 - val_soft_acc: 0.4414\n",
      "Epoch 908/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.0838 - soft_acc: 0.9728 - val_loss: 0.7337 - val_soft_acc: 0.4107\n",
      "Epoch 909/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0870 - soft_acc: 0.9589 - val_loss: 0.7109 - val_soft_acc: 0.4543\n",
      "Epoch 910/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.0921 - soft_acc: 0.9711 - val_loss: 0.7139 - val_soft_acc: 0.4900\n",
      "Epoch 911/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.0968 - soft_acc: 0.9678 - val_loss: 0.7810 - val_soft_acc: 0.4286\n",
      "Epoch 912/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1141 - soft_acc: 0.9800 - val_loss: 0.7985 - val_soft_acc: 0.4193\n",
      "Epoch 913/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1148 - soft_acc: 0.9783 - val_loss: 0.7690 - val_soft_acc: 0.4543\n",
      "Epoch 914/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.0937 - soft_acc: 0.9850 - val_loss: 0.7527 - val_soft_acc: 0.4643\n",
      "Epoch 915/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1302 - soft_acc: 0.9667 - val_loss: 0.7577 - val_soft_acc: 0.4107\n",
      "Epoch 916/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1167 - soft_acc: 0.9783 - val_loss: 0.7096 - val_soft_acc: 0.4493\n",
      "Epoch 917/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1234 - soft_acc: 0.9611 - val_loss: 0.7018 - val_soft_acc: 0.5000\n",
      "Epoch 918/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0976 - soft_acc: 0.9833 - val_loss: 0.7113 - val_soft_acc: 0.4829\n",
      "Epoch 919/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0851 - soft_acc: 0.9728 - val_loss: 0.7437 - val_soft_acc: 0.5157\n",
      "Epoch 920/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0849 - soft_acc: 0.9900 - val_loss: 0.7050 - val_soft_acc: 0.5029\n",
      "Epoch 921/1000\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.0968 - soft_acc: 0.9867 - val_loss: 0.7161 - val_soft_acc: 0.5129\n",
      "Epoch 922/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0844 - soft_acc: 0.9883 - val_loss: 0.7125 - val_soft_acc: 0.4564\n",
      "Epoch 923/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.0929 - soft_acc: 0.9800 - val_loss: 0.6872 - val_soft_acc: 0.5050\n",
      "Epoch 924/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1190 - soft_acc: 0.9650 - val_loss: 0.7389 - val_soft_acc: 0.5107\n",
      "Epoch 925/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1310 - soft_acc: 0.9600 - val_loss: 0.6928 - val_soft_acc: 0.4950\n",
      "Epoch 926/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1033 - soft_acc: 0.9728 - val_loss: 0.7443 - val_soft_acc: 0.4700\n",
      "Epoch 927/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.0976 - soft_acc: 0.9850 - val_loss: 0.7110 - val_soft_acc: 0.5079\n",
      "Epoch 928/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1025 - soft_acc: 0.9833 - val_loss: 0.7392 - val_soft_acc: 0.4414\n",
      "Epoch 929/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0934 - soft_acc: 0.9678 - val_loss: 0.7288 - val_soft_acc: 0.4543\n",
      "Epoch 930/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0922 - soft_acc: 0.9711 - val_loss: 0.6981 - val_soft_acc: 0.4493\n",
      "Epoch 931/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0892 - soft_acc: 0.9867 - val_loss: 0.7219 - val_soft_acc: 0.5007\n",
      "Epoch 932/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1053 - soft_acc: 0.9800 - val_loss: 0.6988 - val_soft_acc: 0.4593\n",
      "Epoch 933/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1183 - soft_acc: 0.9783 - val_loss: 0.7315 - val_soft_acc: 0.3850\n",
      "Epoch 934/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1212 - soft_acc: 0.9767 - val_loss: 0.6763 - val_soft_acc: 0.4750\n",
      "Epoch 935/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1625 - soft_acc: 0.9517 - val_loss: 0.7444 - val_soft_acc: 0.4750\n",
      "Epoch 936/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1327 - soft_acc: 0.9583 - val_loss: 0.7653 - val_soft_acc: 0.4093\n",
      "Epoch 937/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1435 - soft_acc: 0.9600 - val_loss: 0.7128 - val_soft_acc: 0.4593\n",
      "Epoch 938/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.0989 - soft_acc: 0.9711 - val_loss: 0.7568 - val_soft_acc: 0.4264\n",
      "Epoch 939/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1096 - soft_acc: 0.9717 - val_loss: 0.7047 - val_soft_acc: 0.4521\n",
      "Epoch 940/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1044 - soft_acc: 0.9678 - val_loss: 0.7507 - val_soft_acc: 0.4621\n",
      "Epoch 941/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0946 - soft_acc: 0.9711 - val_loss: 0.7297 - val_soft_acc: 0.4621\n",
      "Epoch 942/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.0995 - soft_acc: 0.9694 - val_loss: 0.7343 - val_soft_acc: 0.4343\n",
      "Epoch 943/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0898 - soft_acc: 0.9833 - val_loss: 0.7305 - val_soft_acc: 0.4850\n",
      "Epoch 944/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0916 - soft_acc: 0.9867 - val_loss: 0.8088 - val_soft_acc: 0.4343\n",
      "Epoch 945/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.0855 - soft_acc: 0.9817 - val_loss: 0.7276 - val_soft_acc: 0.4593\n",
      "Epoch 946/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0848 - soft_acc: 0.9883 - val_loss: 0.7399 - val_soft_acc: 0.4107\n",
      "Epoch 947/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.0844 - soft_acc: 0.9711 - val_loss: 0.7527 - val_soft_acc: 0.4800\n",
      "Epoch 948/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.0863 - soft_acc: 0.9833 - val_loss: 0.7191 - val_soft_acc: 0.4336\n",
      "Epoch 949/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.0811 - soft_acc: 0.9833 - val_loss: 0.7366 - val_soft_acc: 0.4464\n",
      "Epoch 950/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.0773 - soft_acc: 0.9883 - val_loss: 0.7386 - val_soft_acc: 0.4236\n",
      "Epoch 951/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0679 - soft_acc: 0.9867 - val_loss: 0.7636 - val_soft_acc: 0.4514\n",
      "Epoch 952/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.0666 - soft_acc: 0.9883 - val_loss: 0.7225 - val_soft_acc: 0.5107\n",
      "Epoch 953/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0701 - soft_acc: 0.9867 - val_loss: 0.7599 - val_soft_acc: 0.5186\n",
      "Epoch 954/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0691 - soft_acc: 0.9744 - val_loss: 0.7337 - val_soft_acc: 0.5007\n",
      "Epoch 955/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0683 - soft_acc: 0.9883 - val_loss: 0.7416 - val_soft_acc: 0.4950\n",
      "Epoch 956/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0706 - soft_acc: 0.9761 - val_loss: 0.7234 - val_soft_acc: 0.5136\n",
      "Epoch 957/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0821 - soft_acc: 0.9744 - val_loss: 0.7989 - val_soft_acc: 0.4650\n",
      "Epoch 958/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1023 - soft_acc: 0.9572 - val_loss: 0.7152 - val_soft_acc: 0.4236\n",
      "Epoch 959/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.0988 - soft_acc: 0.9800 - val_loss: 0.7360 - val_soft_acc: 0.4543\n",
      "Epoch 960/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.0805 - soft_acc: 0.9850 - val_loss: 0.7219 - val_soft_acc: 0.4643\n",
      "Epoch 961/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.0825 - soft_acc: 0.9867 - val_loss: 0.7527 - val_soft_acc: 0.5079\n",
      "Epoch 962/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.0773 - soft_acc: 0.9867 - val_loss: 0.7321 - val_soft_acc: 0.4700\n",
      "Epoch 963/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.0835 - soft_acc: 0.9900 - val_loss: 0.7118 - val_soft_acc: 0.4829\n",
      "Epoch 964/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0710 - soft_acc: 0.9761 - val_loss: 0.7283 - val_soft_acc: 0.4414\n",
      "Epoch 965/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1243 - soft_acc: 0.9733 - val_loss: 0.7232 - val_soft_acc: 0.3957\n",
      "Epoch 966/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1856 - soft_acc: 0.9300 - val_loss: 0.7895 - val_soft_acc: 0.3886\n",
      "Epoch 967/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1466 - soft_acc: 0.9594 - val_loss: 0.7968 - val_soft_acc: 0.4550\n",
      "Epoch 968/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1378 - soft_acc: 0.9600 - val_loss: 0.8058 - val_soft_acc: 0.4143\n",
      "Epoch 969/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1809 - soft_acc: 0.9417 - val_loss: 0.7499 - val_soft_acc: 0.4721\n",
      "Epoch 970/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1474 - soft_acc: 0.9378 - val_loss: 0.6992 - val_soft_acc: 0.4621\n",
      "Epoch 971/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1401 - soft_acc: 0.9683 - val_loss: 0.7031 - val_soft_acc: 0.4471\n",
      "Epoch 972/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1932 - soft_acc: 0.8900 - val_loss: 0.7383 - val_soft_acc: 0.5029\n",
      "Epoch 973/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1433 - soft_acc: 0.9667 - val_loss: 0.7609 - val_soft_acc: 0.4286\n",
      "Epoch 974/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1503 - soft_acc: 0.9517 - val_loss: 0.6925 - val_soft_acc: 0.5179\n",
      "Epoch 975/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1235 - soft_acc: 0.9733 - val_loss: 0.7146 - val_soft_acc: 0.4779\n",
      "Epoch 976/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1157 - soft_acc: 0.9833 - val_loss: 0.7099 - val_soft_acc: 0.4750\n",
      "Epoch 977/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0990 - soft_acc: 0.9833 - val_loss: 0.7385 - val_soft_acc: 0.5214\n",
      "Epoch 978/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1107 - soft_acc: 0.9800 - val_loss: 0.6821 - val_soft_acc: 0.4464\n",
      "Epoch 979/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.0982 - soft_acc: 0.9867 - val_loss: 0.7261 - val_soft_acc: 0.4571\n",
      "Epoch 980/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1005 - soft_acc: 0.9817 - val_loss: 0.7395 - val_soft_acc: 0.4614\n",
      "Epoch 981/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1145 - soft_acc: 0.9817 - val_loss: 0.7470 - val_soft_acc: 0.4950\n",
      "Epoch 982/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1182 - soft_acc: 0.9711 - val_loss: 0.7016 - val_soft_acc: 0.4393\n",
      "Epoch 983/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.0995 - soft_acc: 0.9900 - val_loss: 0.7454 - val_soft_acc: 0.4721\n",
      "Epoch 984/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.0876 - soft_acc: 0.9867 - val_loss: 0.7220 - val_soft_acc: 0.4950\n",
      "Epoch 985/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.0736 - soft_acc: 0.9900 - val_loss: 0.7445 - val_soft_acc: 0.4486\n",
      "Epoch 986/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0861 - soft_acc: 0.9900 - val_loss: 0.7412 - val_soft_acc: 0.4979\n",
      "Epoch 987/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0948 - soft_acc: 0.9883 - val_loss: 0.7762 - val_soft_acc: 0.4671\n",
      "Epoch 988/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0835 - soft_acc: 0.9850 - val_loss: 0.7259 - val_soft_acc: 0.4621\n",
      "Epoch 989/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0933 - soft_acc: 0.9761 - val_loss: 0.7341 - val_soft_acc: 0.4493\n",
      "Epoch 990/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0790 - soft_acc: 0.9900 - val_loss: 0.7343 - val_soft_acc: 0.4614\n",
      "Epoch 991/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0944 - soft_acc: 0.9761 - val_loss: 0.7625 - val_soft_acc: 0.4443\n",
      "Epoch 992/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.0955 - soft_acc: 0.9867 - val_loss: 0.7092 - val_soft_acc: 0.5186\n",
      "Epoch 993/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.0868 - soft_acc: 0.9900 - val_loss: 0.7129 - val_soft_acc: 0.5543\n",
      "Epoch 994/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.0900 - soft_acc: 0.9883 - val_loss: 0.7618 - val_soft_acc: 0.4829\n",
      "Epoch 995/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1009 - soft_acc: 0.9833 - val_loss: 0.7219 - val_soft_acc: 0.4907\n",
      "Epoch 996/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0944 - soft_acc: 0.9728 - val_loss: 0.7316 - val_soft_acc: 0.4543\n",
      "Epoch 997/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1063 - soft_acc: 0.9783 - val_loss: 0.7060 - val_soft_acc: 0.4929\n",
      "Epoch 998/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0916 - soft_acc: 0.9833 - val_loss: 0.7012 - val_soft_acc: 0.4779\n",
      "Epoch 999/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1038 - soft_acc: 0.9850 - val_loss: 0.7273 - val_soft_acc: 0.4879\n",
      "Epoch 1000/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0925 - soft_acc: 0.9867 - val_loss: 0.7070 - val_soft_acc: 0.5079\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.6887 - soft_acc: 0.5469\n",
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.8843 - soft_acc: 0.1700best occur in epoch 0\n",
      "512/512 [==============================] - 0s 421us/sample - loss: 19.5765 - soft_acc: 0.0467 - val_loss: 5.2420 - val_soft_acc: 0.0657\n",
      "Epoch 2/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.6663 - soft_acc: 0.0500best occur in epoch 1\n",
      "512/512 [==============================] - 0s 62us/sample - loss: 3.0146 - soft_acc: 0.1439 - val_loss: 1.0342 - val_soft_acc: 0.3029\n",
      "Epoch 3/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.1777 - soft_acc: 0.3300best occur in epoch 2\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 1.4476 - soft_acc: 0.2611 - val_loss: 2.3528 - val_soft_acc: 0.3036\n",
      "Epoch 4/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.7530 - soft_acc: 0.0700best occur in epoch 3\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 4.3736 - soft_acc: 0.0789 - val_loss: 0.7651 - val_soft_acc: 0.6193\n",
      "Epoch 5/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 2.2762 - soft_acc: 0.2661 - val_loss: 1.1515 - val_soft_acc: 0.4036\n",
      "Epoch 6/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 2.0091 - soft_acc: 0.1739 - val_loss: 0.7981 - val_soft_acc: 0.3836\n",
      "Epoch 7/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0084 - soft_acc: 0.3900best occur in epoch 6\n",
      "512/512 [==============================] - 0s 65us/sample - loss: 0.8928 - soft_acc: 0.3683 - val_loss: 0.6488 - val_soft_acc: 0.5936\n",
      "Epoch 8/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 1.5196 - soft_acc: 0.3094 - val_loss: 0.9230 - val_soft_acc: 0.3843\n",
      "Epoch 9/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 1.0976 - soft_acc: 0.3556 - val_loss: 1.3596 - val_soft_acc: 0.2907\n",
      "Epoch 10/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 1.2490 - soft_acc: 0.3150 - val_loss: 0.6940 - val_soft_acc: 0.3793\n",
      "Epoch 11/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6556 - soft_acc: 0.4900best occur in epoch 10\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 1.2157 - soft_acc: 0.3872 - val_loss: 0.8098 - val_soft_acc: 0.5957\n",
      "Epoch 12/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 1.1758 - soft_acc: 0.3078 - val_loss: 0.5914 - val_soft_acc: 0.6593\n",
      "Epoch 13/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.8467 - soft_acc: 0.4228 - val_loss: 0.6933 - val_soft_acc: 0.3386\n",
      "Epoch 14/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7109 - soft_acc: 0.3600best occur in epoch 13\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.8994 - soft_acc: 0.3600 - val_loss: 0.7178 - val_soft_acc: 0.6236\n",
      "Epoch 15/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 1.2475 - soft_acc: 0.2900 - val_loss: 0.8143 - val_soft_acc: 0.6500\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 1.4827 - soft_acc: 0.2633 - val_loss: 1.0329 - val_soft_acc: 0.4757\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 1.2823 - soft_acc: 0.3167 - val_loss: 0.5916 - val_soft_acc: 0.6536\n",
      "Epoch 18/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.8475 - soft_acc: 0.4278 - val_loss: 0.9117 - val_soft_acc: 0.3086\n",
      "Epoch 19/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.9300 - soft_acc: 0.3300best occur in epoch 18\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.7255 - soft_acc: 0.4922 - val_loss: 0.4913 - val_soft_acc: 0.5686\n",
      "Epoch 20/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4731 - soft_acc: 0.6100best occur in epoch 19\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.6038 - soft_acc: 0.5183 - val_loss: 0.5139 - val_soft_acc: 0.7121\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.8800 - soft_acc: 0.4333 - val_loss: 0.8584 - val_soft_acc: 0.4493\n",
      "Epoch 22/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 1.0864 - soft_acc: 0.3439 - val_loss: 0.7267 - val_soft_acc: 0.5536\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 1.1058 - soft_acc: 0.3056 - val_loss: 0.7493 - val_soft_acc: 0.5793\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 1.1273 - soft_acc: 0.3722 - val_loss: 0.6193 - val_soft_acc: 0.6821\n",
      "Epoch 25/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.9663 - soft_acc: 0.3967 - val_loss: 0.5738 - val_soft_acc: 0.7079\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 1.0156 - soft_acc: 0.3789 - val_loss: 0.5345 - val_soft_acc: 0.4714\n",
      "Epoch 27/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4943 - soft_acc: 0.6500best occur in epoch 26\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6317 - soft_acc: 0.5456 - val_loss: 0.4779 - val_soft_acc: 0.6921\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5883 - soft_acc: 0.5572 - val_loss: 0.5935 - val_soft_acc: 0.4450\n",
      "Epoch 29/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.5430 - soft_acc: 0.5811 - val_loss: 0.6497 - val_soft_acc: 0.4529\n",
      "Epoch 30/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5332 - soft_acc: 0.5656 - val_loss: 0.4905 - val_soft_acc: 0.5379\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4921 - soft_acc: 0.6139 - val_loss: 0.4842 - val_soft_acc: 0.6214\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5019 - soft_acc: 0.5944 - val_loss: 0.6358 - val_soft_acc: 0.4014\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.5594 - soft_acc: 0.5672 - val_loss: 0.9222 - val_soft_acc: 0.3286\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.8376 - soft_acc: 0.4489 - val_loss: 0.5059 - val_soft_acc: 0.4436\n",
      "Epoch 35/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4956 - soft_acc: 0.6389 - val_loss: 0.5029 - val_soft_acc: 0.5879\n",
      "Epoch 36/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5433 - soft_acc: 0.6300best occur in epoch 35\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.4859 - soft_acc: 0.6094 - val_loss: 0.4356 - val_soft_acc: 0.6643\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4694 - soft_acc: 0.6356 - val_loss: 0.4613 - val_soft_acc: 0.6257\n",
      "Epoch 38/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.5436 - soft_acc: 0.5489 - val_loss: 0.5073 - val_soft_acc: 0.4943\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.5684 - soft_acc: 0.5544 - val_loss: 0.8050 - val_soft_acc: 0.2657\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.9365 - soft_acc: 0.3217 - val_loss: 0.4934 - val_soft_acc: 0.5329\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.6771 - soft_acc: 0.4761 - val_loss: 0.4757 - val_soft_acc: 0.5857\n",
      "Epoch 42/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5713 - soft_acc: 0.5694 - val_loss: 0.5687 - val_soft_acc: 0.4136\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.5562 - soft_acc: 0.6361 - val_loss: 0.6864 - val_soft_acc: 0.4350\n",
      "Epoch 44/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.5512 - soft_acc: 0.5822 - val_loss: 0.7246 - val_soft_acc: 0.3307\n",
      "Epoch 45/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.6257 - soft_acc: 0.5494 - val_loss: 0.5047 - val_soft_acc: 0.5043\n",
      "Epoch 46/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4322 - soft_acc: 0.6900best occur in epoch 45\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.4870 - soft_acc: 0.6572 - val_loss: 0.4451 - val_soft_acc: 0.6793\n",
      "Epoch 47/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4436 - soft_acc: 0.6400best occur in epoch 46\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 0.4312 - soft_acc: 0.6756 - val_loss: 0.4373 - val_soft_acc: 0.7707\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5095 - soft_acc: 0.6050 - val_loss: 0.4469 - val_soft_acc: 0.6843\n",
      "Epoch 49/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.5461 - soft_acc: 0.5428 - val_loss: 0.4794 - val_soft_acc: 0.6714\n",
      "Epoch 50/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4719 - soft_acc: 0.6739 - val_loss: 0.4329 - val_soft_acc: 0.6607\n",
      "Epoch 51/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5208 - soft_acc: 0.6472 - val_loss: 0.4800 - val_soft_acc: 0.7221\n",
      "Epoch 52/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5205 - soft_acc: 0.6017 - val_loss: 0.4688 - val_soft_acc: 0.5786\n",
      "Epoch 53/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4453 - soft_acc: 0.6761 - val_loss: 0.4746 - val_soft_acc: 0.5171\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4326 - soft_acc: 0.6861 - val_loss: 0.4620 - val_soft_acc: 0.7579\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4864 - soft_acc: 0.6294 - val_loss: 0.4544 - val_soft_acc: 0.6900\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5349 - soft_acc: 0.6233 - val_loss: 0.5286 - val_soft_acc: 0.5479\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5236 - soft_acc: 0.5572 - val_loss: 0.6826 - val_soft_acc: 0.3993\n",
      "Epoch 58/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.7664 - soft_acc: 0.4411 - val_loss: 0.5891 - val_soft_acc: 0.4143\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.6151 - soft_acc: 0.5606 - val_loss: 0.4602 - val_soft_acc: 0.6321\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4533 - soft_acc: 0.6628 - val_loss: 0.4437 - val_soft_acc: 0.6207\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4835 - soft_acc: 0.6678 - val_loss: 0.6045 - val_soft_acc: 0.4143\n",
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5046 - soft_acc: 0.6322 - val_loss: 0.5984 - val_soft_acc: 0.3321\n",
      "Epoch 63/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5282 - soft_acc: 0.6128 - val_loss: 0.7253 - val_soft_acc: 0.3464\n",
      "Epoch 64/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5154 - soft_acc: 0.5889 - val_loss: 0.6070 - val_soft_acc: 0.4014\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.5043 - soft_acc: 0.6433 - val_loss: 0.7093 - val_soft_acc: 0.2464\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.6275 - soft_acc: 0.5106 - val_loss: 0.6214 - val_soft_acc: 0.3479\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.5967 - soft_acc: 0.5506 - val_loss: 0.4653 - val_soft_acc: 0.6036\n",
      "Epoch 68/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5189 - soft_acc: 0.6422 - val_loss: 0.4285 - val_soft_acc: 0.6686\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5059 - soft_acc: 0.6022 - val_loss: 0.4191 - val_soft_acc: 0.7807\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4884 - soft_acc: 0.6506 - val_loss: 0.4406 - val_soft_acc: 0.6257\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4260 - soft_acc: 0.6606 - val_loss: 0.4317 - val_soft_acc: 0.7707\n",
      "Epoch 72/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4816 - soft_acc: 0.6344 - val_loss: 0.4726 - val_soft_acc: 0.5629\n",
      "Epoch 73/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4372 - soft_acc: 0.6617 - val_loss: 0.4733 - val_soft_acc: 0.5271\n",
      "Epoch 74/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4209 - soft_acc: 0.7128 - val_loss: 0.5984 - val_soft_acc: 0.4371\n",
      "Epoch 75/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4955 - soft_acc: 0.5844 - val_loss: 0.5863 - val_soft_acc: 0.4521\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4219 - soft_acc: 0.6761 - val_loss: 0.4925 - val_soft_acc: 0.5329\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3805 - soft_acc: 0.7644 - val_loss: 0.5299 - val_soft_acc: 0.4850\n",
      "Epoch 78/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4937 - soft_acc: 0.6311 - val_loss: 0.5129 - val_soft_acc: 0.4900\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4985 - soft_acc: 0.6289 - val_loss: 0.4421 - val_soft_acc: 0.6314\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4365 - soft_acc: 0.6733 - val_loss: 0.4574 - val_soft_acc: 0.6921\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4448 - soft_acc: 0.6589 - val_loss: 0.4299 - val_soft_acc: 0.7321\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4563 - soft_acc: 0.6944 - val_loss: 0.4410 - val_soft_acc: 0.6186\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3868 - soft_acc: 0.7178 - val_loss: 0.4547 - val_soft_acc: 0.6879\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3995 - soft_acc: 0.7133 - val_loss: 0.4476 - val_soft_acc: 0.6593\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3872 - soft_acc: 0.7044 - val_loss: 0.4253 - val_soft_acc: 0.7000\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4148 - soft_acc: 0.6644 - val_loss: 0.4432 - val_soft_acc: 0.6029\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4096 - soft_acc: 0.7189 - val_loss: 0.4820 - val_soft_acc: 0.5557\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4136 - soft_acc: 0.7322 - val_loss: 0.4748 - val_soft_acc: 0.5679\n",
      "Epoch 89/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3906 - soft_acc: 0.6817 - val_loss: 0.4672 - val_soft_acc: 0.5936\n",
      "Epoch 90/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3824 - soft_acc: 0.7061 - val_loss: 0.4397 - val_soft_acc: 0.6643\n",
      "Epoch 91/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3561 - soft_acc: 0.7500best occur in epoch 90\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.3982 - soft_acc: 0.7583 - val_loss: 0.4181 - val_soft_acc: 0.7886\n",
      "Epoch 92/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4200 - soft_acc: 0.7017 - val_loss: 0.4251 - val_soft_acc: 0.6893\n",
      "Epoch 93/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4484 - soft_acc: 0.6178 - val_loss: 0.4520 - val_soft_acc: 0.6107\n",
      "Epoch 94/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4010 - soft_acc: 0.7000 - val_loss: 0.4994 - val_soft_acc: 0.4971\n",
      "Epoch 95/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3665 - soft_acc: 0.7556 - val_loss: 0.4610 - val_soft_acc: 0.6571\n",
      "Epoch 96/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3837 - soft_acc: 0.7456 - val_loss: 0.4665 - val_soft_acc: 0.5829\n",
      "Epoch 97/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3864 - soft_acc: 0.7472 - val_loss: 0.4740 - val_soft_acc: 0.5886\n",
      "Epoch 98/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3939 - soft_acc: 0.7039 - val_loss: 0.4767 - val_soft_acc: 0.5757\n",
      "Epoch 99/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3888 - soft_acc: 0.7506 - val_loss: 0.4288 - val_soft_acc: 0.7579\n",
      "Epoch 100/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4622 - soft_acc: 0.6694 - val_loss: 0.4469 - val_soft_acc: 0.6921\n",
      "Epoch 101/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3786 - soft_acc: 0.7056 - val_loss: 0.4949 - val_soft_acc: 0.5414\n",
      "Epoch 102/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3971 - soft_acc: 0.7167 - val_loss: 0.4719 - val_soft_acc: 0.5914\n",
      "Epoch 103/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3785 - soft_acc: 0.6950 - val_loss: 0.4411 - val_soft_acc: 0.6650\n",
      "Epoch 104/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3818 - soft_acc: 0.7239 - val_loss: 0.4810 - val_soft_acc: 0.5457\n",
      "Epoch 105/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3665 - soft_acc: 0.7644 - val_loss: 0.5144 - val_soft_acc: 0.5229\n",
      "Epoch 106/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3965 - soft_acc: 0.7322 - val_loss: 0.5245 - val_soft_acc: 0.5029\n",
      "Epoch 107/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4330 - soft_acc: 0.7294 - val_loss: 0.4798 - val_soft_acc: 0.5943\n",
      "Epoch 108/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3698 - soft_acc: 0.7017 - val_loss: 0.4465 - val_soft_acc: 0.6900\n",
      "Epoch 109/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3852 - soft_acc: 0.7367 - val_loss: 0.4122 - val_soft_acc: 0.8057\n",
      "Epoch 110/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4153 - soft_acc: 0.7217 - val_loss: 0.4756 - val_soft_acc: 0.6286\n",
      "Epoch 111/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3988 - soft_acc: 0.7356 - val_loss: 0.4111 - val_soft_acc: 0.7114\n",
      "Epoch 112/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3867 - soft_acc: 0.7389 - val_loss: 0.4348 - val_soft_acc: 0.7836\n",
      "Epoch 113/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.4232 - soft_acc: 0.6983 - val_loss: 0.4538 - val_soft_acc: 0.6236\n",
      "Epoch 114/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4716 - soft_acc: 0.6267 - val_loss: 0.4714 - val_soft_acc: 0.6221\n",
      "Epoch 115/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4459 - soft_acc: 0.6578 - val_loss: 0.7143 - val_soft_acc: 0.3364\n",
      "Epoch 116/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.6901 - soft_acc: 0.4439 - val_loss: 0.4434 - val_soft_acc: 0.5979\n",
      "Epoch 117/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4930 - soft_acc: 0.5806 - val_loss: 0.4513 - val_soft_acc: 0.7029\n",
      "Epoch 118/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3991 - soft_acc: 0.6928 - val_loss: 0.4260 - val_soft_acc: 0.6893\n",
      "Epoch 119/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3717 - soft_acc: 0.7400 - val_loss: 0.4167 - val_soft_acc: 0.7293\n",
      "Epoch 120/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4401 - soft_acc: 0.6817 - val_loss: 0.4393 - val_soft_acc: 0.6179\n",
      "Epoch 121/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3864 - soft_acc: 0.7128 - val_loss: 0.5476 - val_soft_acc: 0.4700\n",
      "Epoch 122/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4208 - soft_acc: 0.6950 - val_loss: 0.6042 - val_soft_acc: 0.3579\n",
      "Epoch 123/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4587 - soft_acc: 0.6322 - val_loss: 0.4524 - val_soft_acc: 0.6343\n",
      "Epoch 124/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4008 - soft_acc: 0.7011 - val_loss: 0.4780 - val_soft_acc: 0.5529\n",
      "Epoch 125/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3923 - soft_acc: 0.6961 - val_loss: 0.4621 - val_soft_acc: 0.5214\n",
      "Epoch 126/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4147 - soft_acc: 0.6700 - val_loss: 0.4377 - val_soft_acc: 0.6564\n",
      "Epoch 127/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3980 - soft_acc: 0.6906 - val_loss: 0.4694 - val_soft_acc: 0.5121\n",
      "Epoch 128/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3599 - soft_acc: 0.7361 - val_loss: 0.4464 - val_soft_acc: 0.5650\n",
      "Epoch 129/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3563 - soft_acc: 0.7344 - val_loss: 0.5057 - val_soft_acc: 0.4207\n",
      "Epoch 130/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3873 - soft_acc: 0.7300 - val_loss: 0.4431 - val_soft_acc: 0.6929\n",
      "Epoch 131/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3610 - soft_acc: 0.7194 - val_loss: 0.4309 - val_soft_acc: 0.7129\n",
      "Epoch 132/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3634 - soft_acc: 0.7189 - val_loss: 0.4861 - val_soft_acc: 0.5000\n",
      "Epoch 133/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3736 - soft_acc: 0.7233 - val_loss: 0.4886 - val_soft_acc: 0.5386\n",
      "Epoch 134/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3480 - soft_acc: 0.7806 - val_loss: 0.4350 - val_soft_acc: 0.6314\n",
      "Epoch 135/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3655 - soft_acc: 0.7722 - val_loss: 0.4058 - val_soft_acc: 0.7350\n",
      "Epoch 136/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3397 - soft_acc: 0.7833 - val_loss: 0.4246 - val_soft_acc: 0.6614\n",
      "Epoch 137/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3880 - soft_acc: 0.7267 - val_loss: 0.4733 - val_soft_acc: 0.4657\n",
      "Epoch 138/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3660 - soft_acc: 0.7383 - val_loss: 0.4563 - val_soft_acc: 0.6364\n",
      "Epoch 139/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3958 - soft_acc: 0.7322 - val_loss: 0.4443 - val_soft_acc: 0.5879\n",
      "Epoch 140/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3884 - soft_acc: 0.6950 - val_loss: 0.4844 - val_soft_acc: 0.5121\n",
      "Epoch 141/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.4254 - soft_acc: 0.6811 - val_loss: 0.4057 - val_soft_acc: 0.7807\n",
      "Epoch 142/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3739 - soft_acc: 0.7589 - val_loss: 0.4614 - val_soft_acc: 0.5321\n",
      "Epoch 143/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3496 - soft_acc: 0.7756 - val_loss: 0.4308 - val_soft_acc: 0.7057\n",
      "Epoch 144/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3384 - soft_acc: 0.7472 - val_loss: 0.4171 - val_soft_acc: 0.6657\n",
      "Epoch 145/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3438 - soft_acc: 0.7606 - val_loss: 0.4072 - val_soft_acc: 0.7193\n",
      "Epoch 146/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3894 - soft_acc: 0.7233 - val_loss: 0.4450 - val_soft_acc: 0.5857\n",
      "Epoch 147/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3480 - soft_acc: 0.7572 - val_loss: 0.4775 - val_soft_acc: 0.5329\n",
      "Epoch 148/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3519 - soft_acc: 0.7778 - val_loss: 0.4630 - val_soft_acc: 0.6064\n",
      "Epoch 149/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3461 - soft_acc: 0.7494 - val_loss: 0.5193 - val_soft_acc: 0.4614\n",
      "Epoch 150/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4445 - soft_acc: 0.6872 - val_loss: 0.4752 - val_soft_acc: 0.5379\n",
      "Epoch 151/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3706 - soft_acc: 0.7522 - val_loss: 0.4344 - val_soft_acc: 0.7207\n",
      "Epoch 152/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3679 - soft_acc: 0.7211 - val_loss: 0.4350 - val_soft_acc: 0.7021\n",
      "Epoch 153/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3478 - soft_acc: 0.7978 - val_loss: 0.4603 - val_soft_acc: 0.6043\n",
      "Epoch 154/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3429 - soft_acc: 0.7861 - val_loss: 0.4370 - val_soft_acc: 0.6336\n",
      "Epoch 155/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3300 - soft_acc: 0.7578 - val_loss: 0.4352 - val_soft_acc: 0.6871\n",
      "Epoch 156/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3698 - soft_acc: 0.7433 - val_loss: 0.4028 - val_soft_acc: 0.7321\n",
      "Epoch 157/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3568 - soft_acc: 0.7272 - val_loss: 0.4278 - val_soft_acc: 0.6943\n",
      "Epoch 158/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3763 - soft_acc: 0.7472 - val_loss: 0.4701 - val_soft_acc: 0.5686\n",
      "Epoch 159/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3426 - soft_acc: 0.7783 - val_loss: 0.4165 - val_soft_acc: 0.6993\n",
      "Epoch 160/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3512 - soft_acc: 0.7917 - val_loss: 0.4859 - val_soft_acc: 0.5564\n",
      "Epoch 161/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3526 - soft_acc: 0.7683 - val_loss: 0.4914 - val_soft_acc: 0.5557\n",
      "Epoch 162/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3720 - soft_acc: 0.7428 - val_loss: 0.5054 - val_soft_acc: 0.4464\n",
      "Epoch 163/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4046 - soft_acc: 0.7083 - val_loss: 0.4733 - val_soft_acc: 0.5636\n",
      "Epoch 164/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3773 - soft_acc: 0.7106 - val_loss: 0.4060 - val_soft_acc: 0.7600\n",
      "Epoch 165/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3819 - soft_acc: 0.7522 - val_loss: 0.4344 - val_soft_acc: 0.7507\n",
      "Epoch 166/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3552 - soft_acc: 0.7789 - val_loss: 0.4082 - val_soft_acc: 0.7321\n",
      "Epoch 167/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3976 - soft_acc: 0.7183 - val_loss: 0.4154 - val_soft_acc: 0.6507\n",
      "Epoch 168/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3990 - soft_acc: 0.7439 - val_loss: 0.4427 - val_soft_acc: 0.6950\n",
      "Epoch 169/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4285 - soft_acc: 0.6394 - val_loss: 0.4785 - val_soft_acc: 0.5100\n",
      "Epoch 170/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4073 - soft_acc: 0.6889 - val_loss: 0.4678 - val_soft_acc: 0.5993\n",
      "Epoch 171/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3381 - soft_acc: 0.7406 - val_loss: 0.4401 - val_soft_acc: 0.6279\n",
      "Epoch 172/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3863 - soft_acc: 0.7422 - val_loss: 0.4636 - val_soft_acc: 0.6057\n",
      "Epoch 173/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3603 - soft_acc: 0.7522 - val_loss: 0.4294 - val_soft_acc: 0.6436\n",
      "Epoch 174/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3288 - soft_acc: 0.8061 - val_loss: 0.4269 - val_soft_acc: 0.7300\n",
      "Epoch 175/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3444 - soft_acc: 0.7933 - val_loss: 0.4180 - val_soft_acc: 0.7050\n",
      "Epoch 176/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3254 - soft_acc: 0.7661 - val_loss: 0.4106 - val_soft_acc: 0.7171\n",
      "Epoch 177/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3681 - soft_acc: 0.7567 - val_loss: 0.4243 - val_soft_acc: 0.7143\n",
      "Epoch 178/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3549 - soft_acc: 0.7794 - val_loss: 0.4493 - val_soft_acc: 0.6100\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3253 - soft_acc: 0.8117 - val_loss: 0.4735 - val_soft_acc: 0.5150\n",
      "Epoch 180/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3111 - soft_acc: 0.8144 - val_loss: 0.4728 - val_soft_acc: 0.5407\n",
      "Epoch 181/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3403 - soft_acc: 0.7806 - val_loss: 0.4325 - val_soft_acc: 0.6643\n",
      "Epoch 182/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3324 - soft_acc: 0.7889 - val_loss: 0.4235 - val_soft_acc: 0.7043\n",
      "Epoch 183/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3330 - soft_acc: 0.8039 - val_loss: 0.4320 - val_soft_acc: 0.6157\n",
      "Epoch 184/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3053 - soft_acc: 0.8067 - val_loss: 0.4764 - val_soft_acc: 0.5279\n",
      "Epoch 185/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3270 - soft_acc: 0.7956 - val_loss: 0.4396 - val_soft_acc: 0.6086\n",
      "Epoch 186/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3147 - soft_acc: 0.8222 - val_loss: 0.4667 - val_soft_acc: 0.5964\n",
      "Epoch 187/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2943 - soft_acc: 0.8033 - val_loss: 0.4119 - val_soft_acc: 0.7429\n",
      "Epoch 188/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3759 - soft_acc: 0.7244 - val_loss: 0.4587 - val_soft_acc: 0.5907\n",
      "Epoch 189/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3544 - soft_acc: 0.7550 - val_loss: 0.4482 - val_soft_acc: 0.6543\n",
      "Epoch 190/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3446 - soft_acc: 0.7583 - val_loss: 0.4347 - val_soft_acc: 0.6314\n",
      "Epoch 191/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3481 - soft_acc: 0.7294 - val_loss: 0.4750 - val_soft_acc: 0.5607\n",
      "Epoch 192/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3144 - soft_acc: 0.8089 - val_loss: 0.4187 - val_soft_acc: 0.7350\n",
      "Epoch 193/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3167 - soft_acc: 0.7672 - val_loss: 0.4242 - val_soft_acc: 0.6050\n",
      "Epoch 194/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3354 - soft_acc: 0.7906 - val_loss: 0.4308 - val_soft_acc: 0.6643\n",
      "Epoch 195/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3280 - soft_acc: 0.7783 - val_loss: 0.4044 - val_soft_acc: 0.7271\n",
      "Epoch 196/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3215 - soft_acc: 0.7600 - val_loss: 0.4153 - val_soft_acc: 0.7250\n",
      "Epoch 197/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3319 - soft_acc: 0.7750 - val_loss: 0.4266 - val_soft_acc: 0.6893\n",
      "Epoch 198/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3105 - soft_acc: 0.8217 - val_loss: 0.3985 - val_soft_acc: 0.7043\n",
      "Epoch 199/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3474 - soft_acc: 0.7561 - val_loss: 0.4338 - val_soft_acc: 0.7000\n",
      "Epoch 200/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3165 - soft_acc: 0.7961 - val_loss: 0.4582 - val_soft_acc: 0.6243\n",
      "Epoch 201/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3499 - soft_acc: 0.8067 - val_loss: 0.4478 - val_soft_acc: 0.5571\n",
      "Epoch 202/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3202 - soft_acc: 0.7606 - val_loss: 0.4554 - val_soft_acc: 0.6221\n",
      "Epoch 203/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3400 - soft_acc: 0.7694 - val_loss: 0.4421 - val_soft_acc: 0.5571\n",
      "Epoch 204/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3263 - soft_acc: 0.7678 - val_loss: 0.4571 - val_soft_acc: 0.6193\n",
      "Epoch 205/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3739 - soft_acc: 0.7344 - val_loss: 0.5074 - val_soft_acc: 0.5257\n",
      "Epoch 206/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4133 - soft_acc: 0.7189 - val_loss: 0.4833 - val_soft_acc: 0.5171\n",
      "Epoch 207/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3930 - soft_acc: 0.7511 - val_loss: 0.4097 - val_soft_acc: 0.7121\n",
      "Epoch 208/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3321 - soft_acc: 0.7939 - val_loss: 0.4288 - val_soft_acc: 0.6286\n",
      "Epoch 209/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3145 - soft_acc: 0.7761 - val_loss: 0.4171 - val_soft_acc: 0.7129\n",
      "Epoch 210/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3007 - soft_acc: 0.8328 - val_loss: 0.4261 - val_soft_acc: 0.6871\n",
      "Epoch 211/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2965 - soft_acc: 0.8200best occur in epoch 210\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2991 - soft_acc: 0.8411 - val_loss: 0.4077 - val_soft_acc: 0.7421\n",
      "Epoch 212/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3577 - soft_acc: 0.7361 - val_loss: 0.4439 - val_soft_acc: 0.6864\n",
      "Epoch 213/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3661 - soft_acc: 0.8100 - val_loss: 0.3947 - val_soft_acc: 0.7300\n",
      "Epoch 214/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3861 - soft_acc: 0.7167 - val_loss: 0.4255 - val_soft_acc: 0.6000\n",
      "Epoch 215/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3684 - soft_acc: 0.7783 - val_loss: 0.4681 - val_soft_acc: 0.5657\n",
      "Epoch 216/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3332 - soft_acc: 0.7856 - val_loss: 0.3933 - val_soft_acc: 0.7321\n",
      "Epoch 217/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3142 - soft_acc: 0.8106 - val_loss: 0.3956 - val_soft_acc: 0.6993\n",
      "Epoch 218/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2982 - soft_acc: 0.8000 - val_loss: 0.3889 - val_soft_acc: 0.7679\n",
      "Epoch 219/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3468 - soft_acc: 0.7406 - val_loss: 0.3860 - val_soft_acc: 0.7757\n",
      "Epoch 220/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3955 - soft_acc: 0.7194 - val_loss: 0.4178 - val_soft_acc: 0.6564\n",
      "Epoch 221/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3883 - soft_acc: 0.6783 - val_loss: 0.4880 - val_soft_acc: 0.5307\n",
      "Epoch 222/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3758 - soft_acc: 0.7622 - val_loss: 0.4336 - val_soft_acc: 0.6079\n",
      "Epoch 223/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3509 - soft_acc: 0.7828 - val_loss: 0.4761 - val_soft_acc: 0.5379\n",
      "Epoch 224/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3434 - soft_acc: 0.7739 - val_loss: 0.4675 - val_soft_acc: 0.6014\n",
      "Epoch 225/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3620 - soft_acc: 0.7311 - val_loss: 0.4181 - val_soft_acc: 0.6357\n",
      "Epoch 226/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3263 - soft_acc: 0.8094 - val_loss: 0.3970 - val_soft_acc: 0.7121\n",
      "Epoch 227/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3480 - soft_acc: 0.7656 - val_loss: 0.4104 - val_soft_acc: 0.7279\n",
      "Epoch 228/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3104 - soft_acc: 0.8194 - val_loss: 0.3893 - val_soft_acc: 0.7550\n",
      "Epoch 229/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3099 - soft_acc: 0.8017 - val_loss: 0.3677 - val_soft_acc: 0.7779\n",
      "Epoch 230/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3195 - soft_acc: 0.8022 - val_loss: 0.4102 - val_soft_acc: 0.7436\n",
      "Epoch 231/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3007 - soft_acc: 0.8211 - val_loss: 0.3725 - val_soft_acc: 0.7600\n",
      "Epoch 232/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3339 - soft_acc: 0.8061 - val_loss: 0.3929 - val_soft_acc: 0.7221\n",
      "Epoch 233/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3542 - soft_acc: 0.7617 - val_loss: 0.3939 - val_soft_acc: 0.7064\n",
      "Epoch 234/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3300 - soft_acc: 0.8200best occur in epoch 233\n",
      "512/512 [==============================] - 0s 73us/sample - loss: 0.3125 - soft_acc: 0.8222 - val_loss: 0.3829 - val_soft_acc: 0.7707\n",
      "Epoch 235/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3538 - soft_acc: 0.7483 - val_loss: 0.3817 - val_soft_acc: 0.7579\n",
      "Epoch 236/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3215 - soft_acc: 0.8111 - val_loss: 0.3925 - val_soft_acc: 0.7707\n",
      "Epoch 237/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3161 - soft_acc: 0.7883 - val_loss: 0.4383 - val_soft_acc: 0.6314\n",
      "Epoch 238/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2904 - soft_acc: 0.8239 - val_loss: 0.4337 - val_soft_acc: 0.6443\n",
      "Epoch 239/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3184 - soft_acc: 0.7967 - val_loss: 0.4063 - val_soft_acc: 0.6864\n",
      "Epoch 240/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2972 - soft_acc: 0.8361 - val_loss: 0.4287 - val_soft_acc: 0.6236\n",
      "Epoch 241/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3233 - soft_acc: 0.7733 - val_loss: 0.4919 - val_soft_acc: 0.4457\n",
      "Epoch 242/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3751 - soft_acc: 0.7406 - val_loss: 0.5055 - val_soft_acc: 0.5007\n",
      "Epoch 243/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3795 - soft_acc: 0.7244 - val_loss: 0.4869 - val_soft_acc: 0.5200\n",
      "Epoch 244/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3092 - soft_acc: 0.8333 - val_loss: 0.3930 - val_soft_acc: 0.7479\n",
      "Epoch 245/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3147 - soft_acc: 0.8111 - val_loss: 0.4031 - val_soft_acc: 0.6943\n",
      "Epoch 246/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3193 - soft_acc: 0.7833 - val_loss: 0.4233 - val_soft_acc: 0.6386\n",
      "Epoch 247/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2861 - soft_acc: 0.8406 - val_loss: 0.3878 - val_soft_acc: 0.7350\n",
      "Epoch 248/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3069 - soft_acc: 0.7494 - val_loss: 0.4033 - val_soft_acc: 0.7500\n",
      "Epoch 249/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2894 - soft_acc: 0.8417 - val_loss: 0.3876 - val_soft_acc: 0.7350\n",
      "Epoch 250/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3886 - soft_acc: 0.7306 - val_loss: 0.3805 - val_soft_acc: 0.7679\n",
      "Epoch 251/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3176 - soft_acc: 0.8261 - val_loss: 0.3995 - val_soft_acc: 0.7043\n",
      "Epoch 252/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2830 - soft_acc: 0.8478 - val_loss: 0.4334 - val_soft_acc: 0.6821\n",
      "Epoch 253/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2921 - soft_acc: 0.8450 - val_loss: 0.4025 - val_soft_acc: 0.6614\n",
      "Epoch 254/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3216 - soft_acc: 0.8122 - val_loss: 0.4097 - val_soft_acc: 0.7300\n",
      "Epoch 255/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3097 - soft_acc: 0.8350 - val_loss: 0.4104 - val_soft_acc: 0.6671\n",
      "Epoch 256/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.3045 - soft_acc: 0.8222 - val_loss: 0.4254 - val_soft_acc: 0.6314\n",
      "Epoch 257/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3113 - soft_acc: 0.8050 - val_loss: 0.3900 - val_soft_acc: 0.6807\n",
      "Epoch 258/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2875 - soft_acc: 0.8428 - val_loss: 0.4237 - val_soft_acc: 0.6721\n",
      "Epoch 259/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3068 - soft_acc: 0.7950 - val_loss: 0.4898 - val_soft_acc: 0.4593\n",
      "Epoch 260/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3761 - soft_acc: 0.7172 - val_loss: 0.4119 - val_soft_acc: 0.7021\n",
      "Epoch 261/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3017 - soft_acc: 0.8033 - val_loss: 0.4624 - val_soft_acc: 0.5250\n",
      "Epoch 262/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3103 - soft_acc: 0.7917 - val_loss: 0.4028 - val_soft_acc: 0.7200\n",
      "Epoch 263/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2953 - soft_acc: 0.8311 - val_loss: 0.4097 - val_soft_acc: 0.7357\n",
      "Epoch 264/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2920 - soft_acc: 0.8339 - val_loss: 0.4573 - val_soft_acc: 0.5350\n",
      "Epoch 265/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3182 - soft_acc: 0.8350 - val_loss: 0.4330 - val_soft_acc: 0.6571\n",
      "Epoch 266/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3084 - soft_acc: 0.8278 - val_loss: 0.4569 - val_soft_acc: 0.5329\n",
      "Epoch 267/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2959 - soft_acc: 0.8272 - val_loss: 0.5313 - val_soft_acc: 0.4086\n",
      "Epoch 268/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4144 - soft_acc: 0.7206 - val_loss: 0.4843 - val_soft_acc: 0.5636\n",
      "Epoch 269/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3867 - soft_acc: 0.7317 - val_loss: 0.4203 - val_soft_acc: 0.6793\n",
      "Epoch 270/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3217 - soft_acc: 0.7922 - val_loss: 0.4257 - val_soft_acc: 0.7129\n",
      "Epoch 271/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2940 - soft_acc: 0.8339 - val_loss: 0.4039 - val_soft_acc: 0.7064\n",
      "Epoch 272/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3068 - soft_acc: 0.8600best occur in epoch 271\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2922 - soft_acc: 0.8289 - val_loss: 0.3835 - val_soft_acc: 0.7836\n",
      "Epoch 273/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3089 - soft_acc: 0.8106 - val_loss: 0.3886 - val_soft_acc: 0.7657\n",
      "Epoch 274/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2899 - soft_acc: 0.8206 - val_loss: 0.4006 - val_soft_acc: 0.7250\n",
      "Epoch 275/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2798 - soft_acc: 0.8250 - val_loss: 0.4384 - val_soft_acc: 0.5957\n",
      "Epoch 276/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2878 - soft_acc: 0.8311 - val_loss: 0.4377 - val_soft_acc: 0.6164\n",
      "Epoch 277/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3030 - soft_acc: 0.8211 - val_loss: 0.5016 - val_soft_acc: 0.5307\n",
      "Epoch 278/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3643 - soft_acc: 0.7744 - val_loss: 0.4770 - val_soft_acc: 0.4279\n",
      "Epoch 279/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4213 - soft_acc: 0.6828 - val_loss: 0.3777 - val_soft_acc: 0.7579\n",
      "Epoch 280/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3908 - soft_acc: 0.7283 - val_loss: 0.3847 - val_soft_acc: 0.7471\n",
      "Epoch 281/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4745 - soft_acc: 0.6239 - val_loss: 0.5695 - val_soft_acc: 0.3857\n",
      "Epoch 282/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4342 - soft_acc: 0.6717 - val_loss: 0.4400 - val_soft_acc: 0.5643\n",
      "Epoch 283/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4002 - soft_acc: 0.6594 - val_loss: 0.4213 - val_soft_acc: 0.7179\n",
      "Epoch 284/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3694 - soft_acc: 0.7472 - val_loss: 0.4048 - val_soft_acc: 0.7686\n",
      "Epoch 285/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3197 - soft_acc: 0.7989 - val_loss: 0.4061 - val_soft_acc: 0.7329\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3249 - soft_acc: 0.7956 - val_loss: 0.5231 - val_soft_acc: 0.4343\n",
      "Epoch 287/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3672 - soft_acc: 0.7878 - val_loss: 0.4137 - val_soft_acc: 0.7179\n",
      "Epoch 288/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3137 - soft_acc: 0.7639 - val_loss: 0.3942 - val_soft_acc: 0.6636\n",
      "Epoch 289/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3099 - soft_acc: 0.8417 - val_loss: 0.4322 - val_soft_acc: 0.6721\n",
      "Epoch 290/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2918 - soft_acc: 0.8306 - val_loss: 0.4318 - val_soft_acc: 0.6621\n",
      "Epoch 291/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2853 - soft_acc: 0.8289 - val_loss: 0.4465 - val_soft_acc: 0.5957\n",
      "Epoch 292/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3082 - soft_acc: 0.8222 - val_loss: 0.4494 - val_soft_acc: 0.6136\n",
      "Epoch 293/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3183 - soft_acc: 0.8000 - val_loss: 0.4507 - val_soft_acc: 0.6264\n",
      "Epoch 294/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2861 - soft_acc: 0.7911 - val_loss: 0.4331 - val_soft_acc: 0.6436\n",
      "Epoch 295/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2733 - soft_acc: 0.8456 - val_loss: 0.4518 - val_soft_acc: 0.5936\n",
      "Epoch 296/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3011 - soft_acc: 0.7800best occur in epoch 295\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.2825 - soft_acc: 0.8311 - val_loss: 0.3822 - val_soft_acc: 0.7857\n",
      "Epoch 297/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2702 - soft_acc: 0.8339 - val_loss: 0.3775 - val_soft_acc: 0.7529\n",
      "Epoch 298/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3019 - soft_acc: 0.8322 - val_loss: 0.4202 - val_soft_acc: 0.6229\n",
      "Epoch 299/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3004 - soft_acc: 0.8278 - val_loss: 0.4260 - val_soft_acc: 0.6543\n",
      "Epoch 300/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2813 - soft_acc: 0.8456 - val_loss: 0.3902 - val_soft_acc: 0.7293\n",
      "Epoch 301/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2749 - soft_acc: 0.8389 - val_loss: 0.3995 - val_soft_acc: 0.7050\n",
      "Epoch 302/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2575 - soft_acc: 0.8683 - val_loss: 0.3916 - val_soft_acc: 0.7479\n",
      "Epoch 303/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2909 - soft_acc: 0.7611 - val_loss: 0.4040 - val_soft_acc: 0.6743\n",
      "Epoch 304/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2829 - soft_acc: 0.8511 - val_loss: 0.4055 - val_soft_acc: 0.7200\n",
      "Epoch 305/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2634 - soft_acc: 0.8439 - val_loss: 0.4010 - val_soft_acc: 0.7093\n",
      "Epoch 306/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2711 - soft_acc: 0.8683 - val_loss: 0.3933 - val_soft_acc: 0.7043\n",
      "Epoch 307/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2596 - soft_acc: 0.8750 - val_loss: 0.3829 - val_soft_acc: 0.7171\n",
      "Epoch 308/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3013 - soft_acc: 0.7983 - val_loss: 0.4117 - val_soft_acc: 0.6893\n",
      "Epoch 309/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2714 - soft_acc: 0.8561 - val_loss: 0.3798 - val_soft_acc: 0.7343\n",
      "Epoch 310/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.2756 - soft_acc: 0.8367 - val_loss: 0.4058 - val_soft_acc: 0.7207\n",
      "Epoch 311/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3235 - soft_acc: 0.7906 - val_loss: 0.3845 - val_soft_acc: 0.7293\n",
      "Epoch 312/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2935 - soft_acc: 0.8161 - val_loss: 0.3899 - val_soft_acc: 0.6429\n",
      "Epoch 313/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2846 - soft_acc: 0.8094 - val_loss: 0.4181 - val_soft_acc: 0.6557\n",
      "Epoch 314/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2936 - soft_acc: 0.8000 - val_loss: 0.3975 - val_soft_acc: 0.6450\n",
      "Epoch 315/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2624 - soft_acc: 0.8594 - val_loss: 0.3937 - val_soft_acc: 0.7221\n",
      "Epoch 316/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2666 - soft_acc: 0.8494 - val_loss: 0.3858 - val_soft_acc: 0.7121\n",
      "Epoch 317/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3134 - soft_acc: 0.7989 - val_loss: 0.3679 - val_soft_acc: 0.7321\n",
      "Epoch 318/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3071 - soft_acc: 0.8244 - val_loss: 0.3998 - val_soft_acc: 0.6736\n",
      "Epoch 319/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2490 - soft_acc: 0.8700best occur in epoch 318\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2652 - soft_acc: 0.8506 - val_loss: 0.3728 - val_soft_acc: 0.7757\n",
      "Epoch 320/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2783 - soft_acc: 0.8128 - val_loss: 0.3788 - val_soft_acc: 0.7729\n",
      "Epoch 321/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2654 - soft_acc: 0.8694 - val_loss: 0.3922 - val_soft_acc: 0.7450\n",
      "Epoch 322/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2631 - soft_acc: 0.8161 - val_loss: 0.4211 - val_soft_acc: 0.6464\n",
      "Epoch 323/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2577 - soft_acc: 0.8800 - val_loss: 0.4149 - val_soft_acc: 0.6764\n",
      "Epoch 324/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2651 - soft_acc: 0.8494 - val_loss: 0.3873 - val_soft_acc: 0.7243\n",
      "Epoch 325/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2552 - soft_acc: 0.8472 - val_loss: 0.4068 - val_soft_acc: 0.6821\n",
      "Epoch 326/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2499 - soft_acc: 0.8933 - val_loss: 0.4033 - val_soft_acc: 0.7021\n",
      "Epoch 327/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2501 - soft_acc: 0.8556 - val_loss: 0.3961 - val_soft_acc: 0.7021\n",
      "Epoch 328/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2521 - soft_acc: 0.8572 - val_loss: 0.3726 - val_soft_acc: 0.7450\n",
      "Epoch 329/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2762 - soft_acc: 0.8356 - val_loss: 0.3893 - val_soft_acc: 0.7507\n",
      "Epoch 330/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2570 - soft_acc: 0.8717 - val_loss: 0.3983 - val_soft_acc: 0.7271\n",
      "Epoch 331/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2708 - soft_acc: 0.8406 - val_loss: 0.4092 - val_soft_acc: 0.6514\n",
      "Epoch 332/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2643 - soft_acc: 0.8694 - val_loss: 0.4568 - val_soft_acc: 0.6293\n",
      "Epoch 333/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2822 - soft_acc: 0.8394 - val_loss: 0.4008 - val_soft_acc: 0.6586\n",
      "Epoch 334/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3102 - soft_acc: 0.7817 - val_loss: 0.3568 - val_soft_acc: 0.7193\n",
      "Epoch 335/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3085 - soft_acc: 0.8178 - val_loss: 0.4015 - val_soft_acc: 0.7600\n",
      "Epoch 336/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3326 - soft_acc: 0.7983 - val_loss: 0.4235 - val_soft_acc: 0.6664\n",
      "Epoch 337/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3449 - soft_acc: 0.7389 - val_loss: 0.4081 - val_soft_acc: 0.6950\n",
      "Epoch 338/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3352 - soft_acc: 0.7839 - val_loss: 0.3907 - val_soft_acc: 0.7529\n",
      "Epoch 339/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4025 - soft_acc: 0.7306 - val_loss: 0.4039 - val_soft_acc: 0.6664\n",
      "Epoch 340/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3339 - soft_acc: 0.8300 - val_loss: 0.3964 - val_soft_acc: 0.7000\n",
      "Epoch 341/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3096 - soft_acc: 0.8272 - val_loss: 0.4397 - val_soft_acc: 0.6064\n",
      "Epoch 342/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3207 - soft_acc: 0.7917 - val_loss: 0.4979 - val_soft_acc: 0.4264\n",
      "Epoch 343/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3468 - soft_acc: 0.7633 - val_loss: 0.4448 - val_soft_acc: 0.6264\n",
      "Epoch 344/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3273 - soft_acc: 0.8011 - val_loss: 0.4504 - val_soft_acc: 0.5193\n",
      "Epoch 345/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2922 - soft_acc: 0.8261 - val_loss: 0.4578 - val_soft_acc: 0.6343\n",
      "Epoch 346/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3274 - soft_acc: 0.7956 - val_loss: 0.4623 - val_soft_acc: 0.5707\n",
      "Epoch 347/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3879 - soft_acc: 0.6989 - val_loss: 0.3981 - val_soft_acc: 0.6714\n",
      "Epoch 348/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3234 - soft_acc: 0.7594 - val_loss: 0.3701 - val_soft_acc: 0.6993\n",
      "Epoch 349/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2861 - soft_acc: 0.8156 - val_loss: 0.4036 - val_soft_acc: 0.7150\n",
      "Epoch 350/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2820 - soft_acc: 0.8444 - val_loss: 0.4028 - val_soft_acc: 0.6179\n",
      "Epoch 351/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2886 - soft_acc: 0.8411 - val_loss: 0.3873 - val_soft_acc: 0.6429\n",
      "Epoch 352/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2626 - soft_acc: 0.8406 - val_loss: 0.3909 - val_soft_acc: 0.7657\n",
      "Epoch 353/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2643 - soft_acc: 0.8650 - val_loss: 0.3880 - val_soft_acc: 0.7200\n",
      "Epoch 354/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2387 - soft_acc: 0.8500best occur in epoch 353\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2465 - soft_acc: 0.8800 - val_loss: 0.3863 - val_soft_acc: 0.7579\n",
      "Epoch 355/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2398 - soft_acc: 0.8394 - val_loss: 0.4019 - val_soft_acc: 0.7400\n",
      "Epoch 356/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2424 - soft_acc: 0.8539 - val_loss: 0.3788 - val_soft_acc: 0.7400\n",
      "Epoch 357/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2588 - soft_acc: 0.8783 - val_loss: 0.3730 - val_soft_acc: 0.7400\n",
      "Epoch 358/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2526 - soft_acc: 0.8733 - val_loss: 0.4232 - val_soft_acc: 0.7157\n",
      "Epoch 359/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2571 - soft_acc: 0.8556 - val_loss: 0.3600 - val_soft_acc: 0.7114\n",
      "Epoch 360/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3041 - soft_acc: 0.8222 - val_loss: 0.3930 - val_soft_acc: 0.7450\n",
      "Epoch 361/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3332 - soft_acc: 0.7994 - val_loss: 0.3984 - val_soft_acc: 0.7579\n",
      "Epoch 362/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2878 - soft_acc: 0.8467 - val_loss: 0.4416 - val_soft_acc: 0.6007\n",
      "Epoch 363/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2770 - soft_acc: 0.8767 - val_loss: 0.4124 - val_soft_acc: 0.6843\n",
      "Epoch 364/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3025 - soft_acc: 0.8189 - val_loss: 0.3838 - val_soft_acc: 0.6686\n",
      "Epoch 365/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2640 - soft_acc: 0.8439 - val_loss: 0.3846 - val_soft_acc: 0.6879\n",
      "Epoch 366/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2673 - soft_acc: 0.8700 - val_loss: 0.4065 - val_soft_acc: 0.6793\n",
      "Epoch 367/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2612 - soft_acc: 0.8489 - val_loss: 0.3671 - val_soft_acc: 0.7600\n",
      "Epoch 368/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2995 - soft_acc: 0.8517 - val_loss: 0.3818 - val_soft_acc: 0.6864\n",
      "Epoch 369/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2573 - soft_acc: 0.8472 - val_loss: 0.4273 - val_soft_acc: 0.6564\n",
      "Epoch 370/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2700 - soft_acc: 0.8678 - val_loss: 0.4957 - val_soft_acc: 0.5100\n",
      "Epoch 371/1000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.4600 - soft_acc: 0.63 - 0s 31us/sample - loss: 0.4065 - soft_acc: 0.6900 - val_loss: 0.4849 - val_soft_acc: 0.5121\n",
      "Epoch 372/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4031 - soft_acc: 0.7078 - val_loss: 0.3701 - val_soft_acc: 0.7836\n",
      "Epoch 373/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3482 - soft_acc: 0.7828 - val_loss: 0.3730 - val_soft_acc: 0.7679\n",
      "Epoch 374/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3981 - soft_acc: 0.7322 - val_loss: 0.4128 - val_soft_acc: 0.6843\n",
      "Epoch 375/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3069 - soft_acc: 0.8189 - val_loss: 0.4935 - val_soft_acc: 0.4836\n",
      "Epoch 376/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3337 - soft_acc: 0.7878 - val_loss: 0.4841 - val_soft_acc: 0.5350\n",
      "Epoch 377/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2743 - soft_acc: 0.8372 - val_loss: 0.3911 - val_soft_acc: 0.7043\n",
      "Epoch 378/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2788 - soft_acc: 0.8694 - val_loss: 0.3618 - val_soft_acc: 0.7679\n",
      "Epoch 379/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2558 - soft_acc: 0.8539 - val_loss: 0.3936 - val_soft_acc: 0.7021\n",
      "Epoch 380/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2441 - soft_acc: 0.8744 - val_loss: 0.4029 - val_soft_acc: 0.7100\n",
      "Epoch 381/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2444 - soft_acc: 0.8622 - val_loss: 0.4552 - val_soft_acc: 0.5679\n",
      "Epoch 382/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3130 - soft_acc: 0.8261 - val_loss: 0.3818 - val_soft_acc: 0.7450\n",
      "Epoch 383/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2597 - soft_acc: 0.8539 - val_loss: 0.3831 - val_soft_acc: 0.6843\n",
      "Epoch 384/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3180 - soft_acc: 0.8006 - val_loss: 0.3928 - val_soft_acc: 0.7043\n",
      "Epoch 385/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2982 - soft_acc: 0.8233 - val_loss: 0.4254 - val_soft_acc: 0.7000\n",
      "Epoch 386/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3040 - soft_acc: 0.7800best occur in epoch 385\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2608 - soft_acc: 0.8467 - val_loss: 0.3834 - val_soft_acc: 0.8093\n",
      "Epoch 387/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2868 - soft_acc: 0.8328 - val_loss: 0.4119 - val_soft_acc: 0.6614\n",
      "Epoch 388/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2514 - soft_acc: 0.8400 - val_loss: 0.3720 - val_soft_acc: 0.6943\n",
      "Epoch 389/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2609 - soft_acc: 0.8661 - val_loss: 0.3757 - val_soft_acc: 0.7093\n",
      "Epoch 390/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2529 - soft_acc: 0.8678 - val_loss: 0.4096 - val_soft_acc: 0.6207\n",
      "Epoch 391/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2423 - soft_acc: 0.8606 - val_loss: 0.3905 - val_soft_acc: 0.6814\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2517 - soft_acc: 0.8950 - val_loss: 0.3869 - val_soft_acc: 0.6357\n",
      "Epoch 393/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2643 - soft_acc: 0.8383 - val_loss: 0.4426 - val_soft_acc: 0.5979\n",
      "Epoch 394/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3201 - soft_acc: 0.7717 - val_loss: 0.4720 - val_soft_acc: 0.5907\n",
      "Epoch 395/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3002 - soft_acc: 0.7889 - val_loss: 0.4164 - val_soft_acc: 0.7050\n",
      "Epoch 396/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3124 - soft_acc: 0.8194 - val_loss: 0.3806 - val_soft_acc: 0.7707\n",
      "Epoch 397/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2697 - soft_acc: 0.7883 - val_loss: 0.3797 - val_soft_acc: 0.7143\n",
      "Epoch 398/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2885 - soft_acc: 0.7961 - val_loss: 0.3787 - val_soft_acc: 0.7629\n",
      "Epoch 399/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2771 - soft_acc: 0.8017 - val_loss: 0.3868 - val_soft_acc: 0.7321\n",
      "Epoch 400/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2599 - soft_acc: 0.8783 - val_loss: 0.3703 - val_soft_acc: 0.7607\n",
      "Epoch 401/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2621 - soft_acc: 0.8422 - val_loss: 0.3629 - val_soft_acc: 0.7243\n",
      "Epoch 402/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3023 - soft_acc: 0.8261 - val_loss: 0.3938 - val_soft_acc: 0.7407\n",
      "Epoch 403/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2548 - soft_acc: 0.8628 - val_loss: 0.4008 - val_soft_acc: 0.6614\n",
      "Epoch 404/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2367 - soft_acc: 0.8811 - val_loss: 0.3817 - val_soft_acc: 0.6864\n",
      "Epoch 405/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2424 - soft_acc: 0.8628 - val_loss: 0.3886 - val_soft_acc: 0.7629\n",
      "Epoch 406/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2338 - soft_acc: 0.8794 - val_loss: 0.4045 - val_soft_acc: 0.6764\n",
      "Epoch 407/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2416 - soft_acc: 0.8428 - val_loss: 0.4263 - val_soft_acc: 0.6564\n",
      "Epoch 408/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2530 - soft_acc: 0.8417 - val_loss: 0.3834 - val_soft_acc: 0.7100\n",
      "Epoch 409/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3044 - soft_acc: 0.8106 - val_loss: 0.3858 - val_soft_acc: 0.6843\n",
      "Epoch 410/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2674 - soft_acc: 0.8694 - val_loss: 0.4135 - val_soft_acc: 0.7100\n",
      "Epoch 411/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2896 - soft_acc: 0.8356 - val_loss: 0.4075 - val_soft_acc: 0.7000\n",
      "Epoch 412/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2557 - soft_acc: 0.8661 - val_loss: 0.3594 - val_soft_acc: 0.7629\n",
      "Epoch 413/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2482 - soft_acc: 0.8933 - val_loss: 0.4346 - val_soft_acc: 0.6214\n",
      "Epoch 414/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2613 - soft_acc: 0.8494 - val_loss: 0.4540 - val_soft_acc: 0.6107\n",
      "Epoch 415/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2716 - soft_acc: 0.8633 - val_loss: 0.3906 - val_soft_acc: 0.7321\n",
      "Epoch 416/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2378 - soft_acc: 0.8650 - val_loss: 0.4102 - val_soft_acc: 0.6843\n",
      "Epoch 417/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2413 - soft_acc: 0.8589 - val_loss: 0.3825 - val_soft_acc: 0.7579\n",
      "Epoch 418/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2645 - soft_acc: 0.8661 - val_loss: 0.3891 - val_soft_acc: 0.7500\n",
      "Epoch 419/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2441 - soft_acc: 0.8722 - val_loss: 0.4185 - val_soft_acc: 0.6593\n",
      "Epoch 420/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2684 - soft_acc: 0.8506 - val_loss: 0.3921 - val_soft_acc: 0.7479\n",
      "Epoch 421/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2587 - soft_acc: 0.8472 - val_loss: 0.4208 - val_soft_acc: 0.6921\n",
      "Epoch 422/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2616 - soft_acc: 0.8450 - val_loss: 0.4162 - val_soft_acc: 0.6250\n",
      "Epoch 423/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2801 - soft_acc: 0.8394 - val_loss: 0.4462 - val_soft_acc: 0.6214\n",
      "Epoch 424/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2814 - soft_acc: 0.8583 - val_loss: 0.4083 - val_soft_acc: 0.7179\n",
      "Epoch 425/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2484 - soft_acc: 0.8778 - val_loss: 0.3714 - val_soft_acc: 0.7407\n",
      "Epoch 426/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2334 - soft_acc: 0.9100 - val_loss: 0.3848 - val_soft_acc: 0.7071\n",
      "Epoch 427/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2353 - soft_acc: 0.8722 - val_loss: 0.3806 - val_soft_acc: 0.6836\n",
      "Epoch 428/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2991 - soft_acc: 0.8256 - val_loss: 0.3889 - val_soft_acc: 0.7171\n",
      "Epoch 429/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2525 - soft_acc: 0.8622 - val_loss: 0.3855 - val_soft_acc: 0.7093\n",
      "Epoch 430/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3197 - soft_acc: 0.8200 - val_loss: 0.4149 - val_soft_acc: 0.6871\n",
      "Epoch 431/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2422 - soft_acc: 0.8672 - val_loss: 0.3953 - val_soft_acc: 0.7250\n",
      "Epoch 432/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2509 - soft_acc: 0.8711 - val_loss: 0.3799 - val_soft_acc: 0.6807\n",
      "Epoch 433/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2319 - soft_acc: 0.8778 - val_loss: 0.4081 - val_soft_acc: 0.6586\n",
      "Epoch 434/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2490 - soft_acc: 0.8783 - val_loss: 0.3982 - val_soft_acc: 0.7479\n",
      "Epoch 435/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2342 - soft_acc: 0.8672 - val_loss: 0.3771 - val_soft_acc: 0.7500\n",
      "Epoch 436/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2257 - soft_acc: 0.8878 - val_loss: 0.3859 - val_soft_acc: 0.7250\n",
      "Epoch 437/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2249 - soft_acc: 0.9033 - val_loss: 0.3677 - val_soft_acc: 0.7171\n",
      "Epoch 438/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2437 - soft_acc: 0.8589 - val_loss: 0.3936 - val_soft_acc: 0.6614\n",
      "Epoch 439/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2341 - soft_acc: 0.9017 - val_loss: 0.4138 - val_soft_acc: 0.6436\n",
      "Epoch 440/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2397 - soft_acc: 0.8861 - val_loss: 0.4024 - val_soft_acc: 0.6279\n",
      "Epoch 441/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2357 - soft_acc: 0.8744 - val_loss: 0.3805 - val_soft_acc: 0.6814\n",
      "Epoch 442/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2261 - soft_acc: 0.8683 - val_loss: 0.3682 - val_soft_acc: 0.7557\n",
      "Epoch 443/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2861 - soft_acc: 0.8272 - val_loss: 0.3745 - val_soft_acc: 0.7350\n",
      "Epoch 444/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2156 - soft_acc: 0.9044 - val_loss: 0.3904 - val_soft_acc: 0.7429\n",
      "Epoch 445/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2187 - soft_acc: 0.8617 - val_loss: 0.3933 - val_soft_acc: 0.6971\n",
      "Epoch 446/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2197 - soft_acc: 0.8894 - val_loss: 0.3795 - val_soft_acc: 0.6936\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2151 - soft_acc: 0.9183 - val_loss: 0.3959 - val_soft_acc: 0.6821\n",
      "Epoch 448/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2323 - soft_acc: 0.8883 - val_loss: 0.4143 - val_soft_acc: 0.6950\n",
      "Epoch 449/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2585 - soft_acc: 0.8883 - val_loss: 0.4216 - val_soft_acc: 0.6079\n",
      "Epoch 450/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2397 - soft_acc: 0.8639 - val_loss: 0.3926 - val_soft_acc: 0.7100\n",
      "Epoch 451/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2306 - soft_acc: 0.8828 - val_loss: 0.3860 - val_soft_acc: 0.7579\n",
      "Epoch 452/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2526 - soft_acc: 0.8867 - val_loss: 0.3816 - val_soft_acc: 0.7457\n",
      "Epoch 453/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2561 - soft_acc: 0.8700best occur in epoch 452\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2409 - soft_acc: 0.8828 - val_loss: 0.3757 - val_soft_acc: 0.7836\n",
      "Epoch 454/1000\n",
      "512/512 [==============================] - 0s 56us/sample - loss: 0.2503 - soft_acc: 0.8967 - val_loss: 0.4018 - val_soft_acc: 0.7100\n",
      "Epoch 455/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2274 - soft_acc: 0.8911 - val_loss: 0.3959 - val_soft_acc: 0.7250\n",
      "Epoch 456/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2311 - soft_acc: 0.9067 - val_loss: 0.4793 - val_soft_acc: 0.6200\n",
      "Epoch 457/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3541 - soft_acc: 0.7794 - val_loss: 0.4115 - val_soft_acc: 0.7129\n",
      "Epoch 458/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2780 - soft_acc: 0.8367 - val_loss: 0.3998 - val_soft_acc: 0.6686\n",
      "Epoch 459/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2536 - soft_acc: 0.8267 - val_loss: 0.4063 - val_soft_acc: 0.7329\n",
      "Epoch 460/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2641 - soft_acc: 0.8578 - val_loss: 0.3930 - val_soft_acc: 0.6864\n",
      "Epoch 461/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3030 - soft_acc: 0.8294 - val_loss: 0.4228 - val_soft_acc: 0.6643\n",
      "Epoch 462/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2540 - soft_acc: 0.8933 - val_loss: 0.3712 - val_soft_acc: 0.7400\n",
      "Epoch 463/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3387 - soft_acc: 0.7744 - val_loss: 0.3797 - val_soft_acc: 0.7271\n",
      "Epoch 464/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2730 - soft_acc: 0.8511 - val_loss: 0.3841 - val_soft_acc: 0.7229\n",
      "Epoch 465/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2660 - soft_acc: 0.8367 - val_loss: 0.3882 - val_soft_acc: 0.6607\n",
      "Epoch 466/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2518 - soft_acc: 0.8589 - val_loss: 0.3694 - val_soft_acc: 0.7736\n",
      "Epoch 467/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2366 - soft_acc: 0.9033 - val_loss: 0.3839 - val_soft_acc: 0.7557\n",
      "Epoch 468/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2330 - soft_acc: 0.8950 - val_loss: 0.3676 - val_soft_acc: 0.7450\n",
      "Epoch 469/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2474 - soft_acc: 0.8811 - val_loss: 0.3929 - val_soft_acc: 0.6871\n",
      "Epoch 470/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2451 - soft_acc: 0.8433 - val_loss: 0.4059 - val_soft_acc: 0.7764\n",
      "Epoch 471/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2456 - soft_acc: 0.8378 - val_loss: 0.4043 - val_soft_acc: 0.6614\n",
      "Epoch 472/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2564 - soft_acc: 0.8900 - val_loss: 0.3967 - val_soft_acc: 0.7507\n",
      "Epoch 473/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2499 - soft_acc: 0.8628 - val_loss: 0.3781 - val_soft_acc: 0.6864\n",
      "Epoch 474/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2619 - soft_acc: 0.8533 - val_loss: 0.3938 - val_soft_acc: 0.7229\n",
      "Epoch 475/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2249 - soft_acc: 0.8861 - val_loss: 0.4048 - val_soft_acc: 0.6993\n",
      "Epoch 476/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2675 - soft_acc: 0.8122 - val_loss: 0.4740 - val_soft_acc: 0.6014\n",
      "Epoch 477/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3241 - soft_acc: 0.8317 - val_loss: 0.4086 - val_soft_acc: 0.6843\n",
      "Epoch 478/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2911 - soft_acc: 0.8067 - val_loss: 0.3756 - val_soft_acc: 0.7400\n",
      "Epoch 479/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2570 - soft_acc: 0.8483 - val_loss: 0.4025 - val_soft_acc: 0.6814\n",
      "Epoch 480/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2701 - soft_acc: 0.8394 - val_loss: 0.3938 - val_soft_acc: 0.6543\n",
      "Epoch 481/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2951 - soft_acc: 0.8078 - val_loss: 0.4000 - val_soft_acc: 0.7221\n",
      "Epoch 482/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3025 - soft_acc: 0.8367 - val_loss: 0.3821 - val_soft_acc: 0.6964\n",
      "Epoch 483/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2755 - soft_acc: 0.8272 - val_loss: 0.3706 - val_soft_acc: 0.7171\n",
      "Epoch 484/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2782 - soft_acc: 0.8300 - val_loss: 0.3670 - val_soft_acc: 0.7529\n",
      "Epoch 485/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3032 - soft_acc: 0.8350 - val_loss: 0.3742 - val_soft_acc: 0.7221\n",
      "Epoch 486/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2773 - soft_acc: 0.8356 - val_loss: 0.3978 - val_soft_acc: 0.6179\n",
      "Epoch 487/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2467 - soft_acc: 0.8850 - val_loss: 0.3731 - val_soft_acc: 0.7043\n",
      "Epoch 488/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2328 - soft_acc: 0.8867 - val_loss: 0.3968 - val_soft_acc: 0.7300\n",
      "Epoch 489/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2466 - soft_acc: 0.8967 - val_loss: 0.3683 - val_soft_acc: 0.7629\n",
      "Epoch 490/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2505 - soft_acc: 0.8589 - val_loss: 0.4011 - val_soft_acc: 0.6993\n",
      "Epoch 491/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2521 - soft_acc: 0.8711 - val_loss: 0.3965 - val_soft_acc: 0.7300\n",
      "Epoch 492/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2380 - soft_acc: 0.8711 - val_loss: 0.4142 - val_soft_acc: 0.6943\n",
      "Epoch 493/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2407 - soft_acc: 0.8867 - val_loss: 0.4371 - val_soft_acc: 0.5957\n",
      "Epoch 494/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2847 - soft_acc: 0.8372 - val_loss: 0.4089 - val_soft_acc: 0.6257\n",
      "Epoch 495/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2934 - soft_acc: 0.8494 - val_loss: 0.4185 - val_soft_acc: 0.6971\n",
      "Epoch 496/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2580 - soft_acc: 0.8644 - val_loss: 0.4355 - val_soft_acc: 0.6079\n",
      "Epoch 497/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3609 - soft_acc: 0.7572 - val_loss: 0.3796 - val_soft_acc: 0.7707\n",
      "Epoch 498/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3504 - soft_acc: 0.7589 - val_loss: 0.4629 - val_soft_acc: 0.5600\n",
      "Epoch 499/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2986 - soft_acc: 0.7800 - val_loss: 0.4484 - val_soft_acc: 0.6157\n",
      "Epoch 500/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2775 - soft_acc: 0.8228 - val_loss: 0.4242 - val_soft_acc: 0.6721\n",
      "Epoch 501/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2923 - soft_acc: 0.8078 - val_loss: 0.4264 - val_soft_acc: 0.6436\n",
      "Epoch 502/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2635 - soft_acc: 0.8250 - val_loss: 0.4000 - val_soft_acc: 0.6793\n",
      "Epoch 503/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2412 - soft_acc: 0.8567 - val_loss: 0.3670 - val_soft_acc: 0.7450\n",
      "Epoch 504/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2621 - soft_acc: 0.8611 - val_loss: 0.3959 - val_soft_acc: 0.7043\n",
      "Epoch 505/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2911 - soft_acc: 0.8450 - val_loss: 0.3858 - val_soft_acc: 0.7093\n",
      "Epoch 506/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2675 - soft_acc: 0.8522 - val_loss: 0.4024 - val_soft_acc: 0.7457\n",
      "Epoch 507/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2219 - soft_acc: 0.8861 - val_loss: 0.3985 - val_soft_acc: 0.7371\n",
      "Epoch 508/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2259 - soft_acc: 0.8944 - val_loss: 0.4286 - val_soft_acc: 0.6329\n",
      "Epoch 509/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2075 - soft_acc: 0.9028 - val_loss: 0.3737 - val_soft_acc: 0.7350\n",
      "Epoch 510/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2213 - soft_acc: 0.9028 - val_loss: 0.4000 - val_soft_acc: 0.7279\n",
      "Epoch 511/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2196 - soft_acc: 0.9061 - val_loss: 0.3696 - val_soft_acc: 0.6786\n",
      "Epoch 512/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2074 - soft_acc: 0.8906 - val_loss: 0.3871 - val_soft_acc: 0.7579\n",
      "Epoch 513/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2067 - soft_acc: 0.8956 - val_loss: 0.3999 - val_soft_acc: 0.6279\n",
      "Epoch 514/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2024 - soft_acc: 0.9028 - val_loss: 0.3931 - val_soft_acc: 0.6429\n",
      "Epoch 515/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2004 - soft_acc: 0.9061 - val_loss: 0.3836 - val_soft_acc: 0.6764\n",
      "Epoch 516/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1920 - soft_acc: 0.8950 - val_loss: 0.3756 - val_soft_acc: 0.7350\n",
      "Epoch 517/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1990 - soft_acc: 0.9006 - val_loss: 0.3712 - val_soft_acc: 0.7657\n",
      "Epoch 518/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2321 - soft_acc: 0.8600 - val_loss: 0.3802 - val_soft_acc: 0.6914\n",
      "Epoch 519/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2242 - soft_acc: 0.8894 - val_loss: 0.3731 - val_soft_acc: 0.7500\n",
      "Epoch 520/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2146 - soft_acc: 0.9044 - val_loss: 0.4515 - val_soft_acc: 0.6136\n",
      "Epoch 521/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3053 - soft_acc: 0.8294 - val_loss: 0.3916 - val_soft_acc: 0.7350\n",
      "Epoch 522/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2792 - soft_acc: 0.8600 - val_loss: 0.3800 - val_soft_acc: 0.7679\n",
      "Epoch 523/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2298 - soft_acc: 0.8600 - val_loss: 0.3839 - val_soft_acc: 0.7479\n",
      "Epoch 524/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2227 - soft_acc: 0.8944 - val_loss: 0.3766 - val_soft_acc: 0.7250\n",
      "Epoch 525/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2179 - soft_acc: 0.8856 - val_loss: 0.3725 - val_soft_acc: 0.7321\n",
      "Epoch 526/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2098 - soft_acc: 0.8939 - val_loss: 0.3974 - val_soft_acc: 0.6714\n",
      "Epoch 527/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2410 - soft_acc: 0.8950 - val_loss: 0.3842 - val_soft_acc: 0.6836\n",
      "Epoch 528/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2289 - soft_acc: 0.9133 - val_loss: 0.4016 - val_soft_acc: 0.7279\n",
      "Epoch 529/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2394 - soft_acc: 0.8911 - val_loss: 0.3885 - val_soft_acc: 0.7557\n",
      "Epoch 530/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2076 - soft_acc: 0.9111 - val_loss: 0.4146 - val_soft_acc: 0.6436\n",
      "Epoch 531/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2161 - soft_acc: 0.9061 - val_loss: 0.3753 - val_soft_acc: 0.6764\n",
      "Epoch 532/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2149 - soft_acc: 0.9150 - val_loss: 0.3812 - val_soft_acc: 0.6714\n",
      "Epoch 533/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2396 - soft_acc: 0.8861 - val_loss: 0.5288 - val_soft_acc: 0.4521\n",
      "Epoch 534/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4674 - soft_acc: 0.6150 - val_loss: 0.3634 - val_soft_acc: 0.7907\n",
      "Epoch 535/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4111 - soft_acc: 0.7072 - val_loss: 0.3786 - val_soft_acc: 0.7400\n",
      "Epoch 536/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2990 - soft_acc: 0.8239 - val_loss: 0.4563 - val_soft_acc: 0.6236\n",
      "Epoch 537/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3006 - soft_acc: 0.8550 - val_loss: 0.4621 - val_soft_acc: 0.6421\n",
      "Epoch 538/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3375 - soft_acc: 0.7650 - val_loss: 0.3711 - val_soft_acc: 0.7650\n",
      "Epoch 539/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2679 - soft_acc: 0.8567 - val_loss: 0.3594 - val_soft_acc: 0.7779\n",
      "Epoch 540/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3101 - soft_acc: 0.8056 - val_loss: 0.3843 - val_soft_acc: 0.6614\n",
      "Epoch 541/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2544 - soft_acc: 0.8867 - val_loss: 0.3965 - val_soft_acc: 0.7100\n",
      "Epoch 542/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2369 - soft_acc: 0.9083 - val_loss: 0.4281 - val_soft_acc: 0.6543\n",
      "Epoch 543/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2143 - soft_acc: 0.9044 - val_loss: 0.4115 - val_soft_acc: 0.6843\n",
      "Epoch 544/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2113 - soft_acc: 0.8922 - val_loss: 0.3692 - val_soft_acc: 0.7657\n",
      "Epoch 545/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2060 - soft_acc: 0.9111 - val_loss: 0.4049 - val_soft_acc: 0.6543\n",
      "Epoch 546/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2029 - soft_acc: 0.8989 - val_loss: 0.3987 - val_soft_acc: 0.6943\n",
      "Epoch 547/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1978 - soft_acc: 0.9039 - val_loss: 0.4008 - val_soft_acc: 0.7171\n",
      "Epoch 548/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2006 - soft_acc: 0.9061 - val_loss: 0.3812 - val_soft_acc: 0.6579\n",
      "Epoch 549/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2000 - soft_acc: 0.9111 - val_loss: 0.3792 - val_soft_acc: 0.6636\n",
      "Epoch 550/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1915 - soft_acc: 0.9278 - val_loss: 0.3766 - val_soft_acc: 0.6993\n",
      "Epoch 551/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1913 - soft_acc: 0.9228 - val_loss: 0.3902 - val_soft_acc: 0.7171\n",
      "Epoch 552/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2026 - soft_acc: 0.9244 - val_loss: 0.3964 - val_soft_acc: 0.6764\n",
      "Epoch 553/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2165 - soft_acc: 0.8961 - val_loss: 0.4072 - val_soft_acc: 0.6329\n",
      "Epoch 554/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1870 - soft_acc: 0.9200best occur in epoch 553\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1961 - soft_acc: 0.9317 - val_loss: 0.3835 - val_soft_acc: 0.7607\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1860 - soft_acc: 0.9178 - val_loss: 0.3938 - val_soft_acc: 0.6714\n",
      "Epoch 556/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1863 - soft_acc: 0.9033 - val_loss: 0.4257 - val_soft_acc: 0.7071\n",
      "Epoch 557/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1975 - soft_acc: 0.8883 - val_loss: 0.3726 - val_soft_acc: 0.6786\n",
      "Epoch 558/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2318 - soft_acc: 0.8861 - val_loss: 0.3830 - val_soft_acc: 0.7779\n",
      "Epoch 559/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2513 - soft_acc: 0.9083 - val_loss: 0.3738 - val_soft_acc: 0.7114\n",
      "Epoch 560/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2277 - soft_acc: 0.8689 - val_loss: 0.3783 - val_soft_acc: 0.7400\n",
      "Epoch 561/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2212 - soft_acc: 0.9000 - val_loss: 0.4164 - val_soft_acc: 0.6921\n",
      "Epoch 562/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2399 - soft_acc: 0.8917 - val_loss: 0.4252 - val_soft_acc: 0.6336\n",
      "Epoch 563/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2070 - soft_acc: 0.9056 - val_loss: 0.4043 - val_soft_acc: 0.6764\n",
      "Epoch 564/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2013 - soft_acc: 0.9039 - val_loss: 0.3986 - val_soft_acc: 0.7536\n",
      "Epoch 565/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2022 - soft_acc: 0.8761 - val_loss: 0.3950 - val_soft_acc: 0.7329\n",
      "Epoch 566/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2121 - soft_acc: 0.9150 - val_loss: 0.4113 - val_soft_acc: 0.6893\n",
      "Epoch 567/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2168 - soft_acc: 0.9167 - val_loss: 0.4269 - val_soft_acc: 0.6307\n",
      "Epoch 568/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2381 - soft_acc: 0.9000best occur in epoch 567\n",
      "512/512 [==============================] - 0s 63us/sample - loss: 0.2008 - soft_acc: 0.9106 - val_loss: 0.3704 - val_soft_acc: 0.7986\n",
      "Epoch 569/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1830 - soft_acc: 0.9400 - val_loss: 0.3800 - val_soft_acc: 0.7479\n",
      "Epoch 570/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2018 - soft_acc: 0.9333 - val_loss: 0.3796 - val_soft_acc: 0.7171\n",
      "Epoch 571/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1997 - soft_acc: 0.8939 - val_loss: 0.3710 - val_soft_acc: 0.6814\n",
      "Epoch 572/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2083 - soft_acc: 0.9072 - val_loss: 0.4040 - val_soft_acc: 0.5850\n",
      "Epoch 573/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1923 - soft_acc: 0.9161 - val_loss: 0.4137 - val_soft_acc: 0.7079\n",
      "Epoch 574/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1886 - soft_acc: 0.9300 - val_loss: 0.3893 - val_soft_acc: 0.7171\n",
      "Epoch 575/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1766 - soft_acc: 0.9278 - val_loss: 0.3649 - val_soft_acc: 0.6864\n",
      "Epoch 576/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1849 - soft_acc: 0.9033 - val_loss: 0.3861 - val_soft_acc: 0.7557\n",
      "Epoch 577/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2075 - soft_acc: 0.9028 - val_loss: 0.3806 - val_soft_acc: 0.7021\n",
      "Epoch 578/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2306 - soft_acc: 0.9067 - val_loss: 0.3697 - val_soft_acc: 0.7807\n",
      "Epoch 579/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2684 - soft_acc: 0.8389 - val_loss: 0.3793 - val_soft_acc: 0.7964\n",
      "Epoch 580/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2337 - soft_acc: 0.8778 - val_loss: 0.3904 - val_soft_acc: 0.6586\n",
      "Epoch 581/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2433 - soft_acc: 0.8794 - val_loss: 0.3917 - val_soft_acc: 0.6971\n",
      "Epoch 582/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2208 - soft_acc: 0.9000 - val_loss: 0.3734 - val_soft_acc: 0.7729\n",
      "Epoch 583/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2560 - soft_acc: 0.8622 - val_loss: 0.3900 - val_soft_acc: 0.7200\n",
      "Epoch 584/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2679 - soft_acc: 0.8544 - val_loss: 0.3686 - val_soft_acc: 0.7271\n",
      "Epoch 585/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2245 - soft_acc: 0.8872 - val_loss: 0.3862 - val_soft_acc: 0.7121\n",
      "Epoch 586/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2808 - soft_acc: 0.8444 - val_loss: 0.3690 - val_soft_acc: 0.7193\n",
      "Epoch 587/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3250 - soft_acc: 0.7939 - val_loss: 0.3967 - val_soft_acc: 0.6921\n",
      "Epoch 588/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2437 - soft_acc: 0.8672 - val_loss: 0.4289 - val_soft_acc: 0.6564\n",
      "Epoch 589/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2066 - soft_acc: 0.9211 - val_loss: 0.3616 - val_soft_acc: 0.7857\n",
      "Epoch 590/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2044 - soft_acc: 0.9033 - val_loss: 0.3692 - val_soft_acc: 0.7579\n",
      "Epoch 591/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2345 - soft_acc: 0.8839 - val_loss: 0.3864 - val_soft_acc: 0.6686\n",
      "Epoch 592/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2111 - soft_acc: 0.8922 - val_loss: 0.3995 - val_soft_acc: 0.6307\n",
      "Epoch 593/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2050 - soft_acc: 0.9022 - val_loss: 0.4010 - val_soft_acc: 0.6914\n",
      "Epoch 594/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2234 - soft_acc: 0.8950 - val_loss: 0.3594 - val_soft_acc: 0.7729\n",
      "Epoch 595/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2420 - soft_acc: 0.8778 - val_loss: 0.3750 - val_soft_acc: 0.7193\n",
      "Epoch 596/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2088 - soft_acc: 0.9178 - val_loss: 0.3617 - val_soft_acc: 0.7550\n",
      "Epoch 597/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2147 - soft_acc: 0.8800 - val_loss: 0.3618 - val_soft_acc: 0.7986\n",
      "Epoch 598/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2090 - soft_acc: 0.9083 - val_loss: 0.3917 - val_soft_acc: 0.7379\n",
      "Epoch 599/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2326 - soft_acc: 0.8656 - val_loss: 0.3625 - val_soft_acc: 0.7271\n",
      "Epoch 600/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2618 - soft_acc: 0.8744 - val_loss: 0.3768 - val_soft_acc: 0.7479\n",
      "Epoch 601/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2178 - soft_acc: 0.9061 - val_loss: 0.3911 - val_soft_acc: 0.6686\n",
      "Epoch 602/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2058 - soft_acc: 0.8972 - val_loss: 0.3943 - val_soft_acc: 0.7021\n",
      "Epoch 603/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1785 - soft_acc: 0.9244 - val_loss: 0.3984 - val_soft_acc: 0.6129\n",
      "Epoch 604/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2013 - soft_acc: 0.9022 - val_loss: 0.4255 - val_soft_acc: 0.6543\n",
      "Epoch 605/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2019 - soft_acc: 0.9228 - val_loss: 0.4006 - val_soft_acc: 0.6764\n",
      "Epoch 606/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2006 - soft_acc: 0.9022 - val_loss: 0.3916 - val_soft_acc: 0.7329\n",
      "Epoch 607/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2251 - soft_acc: 0.8978 - val_loss: 0.3835 - val_soft_acc: 0.7479\n",
      "Epoch 608/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2573 - soft_acc: 0.8522 - val_loss: 0.3916 - val_soft_acc: 0.7050\n",
      "Epoch 609/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2013 - soft_acc: 0.9194 - val_loss: 0.4053 - val_soft_acc: 0.7000\n",
      "Epoch 610/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1733 - soft_acc: 0.9517 - val_loss: 0.3992 - val_soft_acc: 0.7507\n",
      "Epoch 611/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1857 - soft_acc: 0.9294 - val_loss: 0.4354 - val_soft_acc: 0.6286\n",
      "Epoch 612/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2554 - soft_acc: 0.8950 - val_loss: 0.5152 - val_soft_acc: 0.5536\n",
      "Epoch 613/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3624 - soft_acc: 0.7094 - val_loss: 0.3864 - val_soft_acc: 0.7636\n",
      "Epoch 614/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2968 - soft_acc: 0.8372 - val_loss: 0.4015 - val_soft_acc: 0.6786\n",
      "Epoch 615/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2975 - soft_acc: 0.8211 - val_loss: 0.4001 - val_soft_acc: 0.6743\n",
      "Epoch 616/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2201 - soft_acc: 0.9300 - val_loss: 0.4174 - val_soft_acc: 0.6750\n",
      "Epoch 617/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2027 - soft_acc: 0.9300best occur in epoch 616\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 0.2012 - soft_acc: 0.9072 - val_loss: 0.3675 - val_soft_acc: 0.8064\n",
      "Epoch 618/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2100 - soft_acc: 0.8833 - val_loss: 0.3744 - val_soft_acc: 0.7171\n",
      "Epoch 619/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1852 - soft_acc: 0.9300 - val_loss: 0.3816 - val_soft_acc: 0.6586\n",
      "Epoch 620/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2029 - soft_acc: 0.9161 - val_loss: 0.3783 - val_soft_acc: 0.6964\n",
      "Epoch 621/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1747 - soft_acc: 0.9172 - val_loss: 0.4027 - val_soft_acc: 0.6179\n",
      "Epoch 622/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1805 - soft_acc: 0.9211 - val_loss: 0.3809 - val_soft_acc: 0.6350\n",
      "Epoch 623/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1680 - soft_acc: 0.9378 - val_loss: 0.4078 - val_soft_acc: 0.6514\n",
      "Epoch 624/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1943 - soft_acc: 0.9217 - val_loss: 0.4050 - val_soft_acc: 0.6229\n",
      "Epoch 625/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1954 - soft_acc: 0.9317 - val_loss: 0.3930 - val_soft_acc: 0.6657\n",
      "Epoch 626/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1901 - soft_acc: 0.9139 - val_loss: 0.4220 - val_soft_acc: 0.6721\n",
      "Epoch 627/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2039 - soft_acc: 0.9194 - val_loss: 0.4230 - val_soft_acc: 0.6586\n",
      "Epoch 628/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1930 - soft_acc: 0.9300 - val_loss: 0.3848 - val_soft_acc: 0.7579\n",
      "Epoch 629/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2308 - soft_acc: 0.9100 - val_loss: 0.3759 - val_soft_acc: 0.7350\n",
      "Epoch 630/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2045 - soft_acc: 0.9311 - val_loss: 0.3917 - val_soft_acc: 0.6764\n",
      "Epoch 631/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1904 - soft_acc: 0.9417 - val_loss: 0.3742 - val_soft_acc: 0.6864\n",
      "Epoch 632/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2122 - soft_acc: 0.8878 - val_loss: 0.3818 - val_soft_acc: 0.7350\n",
      "Epoch 633/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2595 - soft_acc: 0.8744 - val_loss: 0.4094 - val_soft_acc: 0.6871\n",
      "Epoch 634/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1880 - soft_acc: 0.9106 - val_loss: 0.3938 - val_soft_acc: 0.7279\n",
      "Epoch 635/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1800 - soft_acc: 0.9450 - val_loss: 0.3991 - val_soft_acc: 0.7329\n",
      "Epoch 636/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2192 - soft_acc: 0.9044 - val_loss: 0.3756 - val_soft_acc: 0.6657\n",
      "Epoch 637/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2098 - soft_acc: 0.9250 - val_loss: 0.3719 - val_soft_acc: 0.7271\n",
      "Epoch 638/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2098 - soft_acc: 0.9039 - val_loss: 0.3883 - val_soft_acc: 0.7121\n",
      "Epoch 639/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1971 - soft_acc: 0.9233 - val_loss: 0.3818 - val_soft_acc: 0.7050\n",
      "Epoch 640/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1954 - soft_acc: 0.9450 - val_loss: 0.4122 - val_soft_acc: 0.6307\n",
      "Epoch 641/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1776 - soft_acc: 0.9067 - val_loss: 0.4083 - val_soft_acc: 0.6771\n",
      "Epoch 642/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1851 - soft_acc: 0.9311 - val_loss: 0.4162 - val_soft_acc: 0.6564\n",
      "Epoch 643/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2051 - soft_acc: 0.8961 - val_loss: 0.4019 - val_soft_acc: 0.6614\n",
      "Epoch 644/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1767 - soft_acc: 0.9394 - val_loss: 0.4067 - val_soft_acc: 0.7000\n",
      "Epoch 645/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1772 - soft_acc: 0.9483 - val_loss: 0.4125 - val_soft_acc: 0.6150\n",
      "Epoch 646/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1863 - soft_acc: 0.9467 - val_loss: 0.3876 - val_soft_acc: 0.7043\n",
      "Epoch 647/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1723 - soft_acc: 0.9400 - val_loss: 0.3975 - val_soft_acc: 0.6971\n",
      "Epoch 648/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1883 - soft_acc: 0.9311 - val_loss: 0.3929 - val_soft_acc: 0.7093\n",
      "Epoch 649/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1814 - soft_acc: 0.9106 - val_loss: 0.4147 - val_soft_acc: 0.6671\n",
      "Epoch 650/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2081 - soft_acc: 0.9094 - val_loss: 0.4112 - val_soft_acc: 0.6564\n",
      "Epoch 651/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2027 - soft_acc: 0.9244 - val_loss: 0.3978 - val_soft_acc: 0.7357\n",
      "Epoch 652/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1782 - soft_acc: 0.9361 - val_loss: 0.4073 - val_soft_acc: 0.7129\n",
      "Epoch 653/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1726 - soft_acc: 0.9467 - val_loss: 0.4025 - val_soft_acc: 0.6743\n",
      "Epoch 654/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1902 - soft_acc: 0.9350 - val_loss: 0.4408 - val_soft_acc: 0.6443\n",
      "Epoch 655/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2329 - soft_acc: 0.9033 - val_loss: 0.3863 - val_soft_acc: 0.6864\n",
      "Epoch 656/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1791 - soft_acc: 0.9467 - val_loss: 0.3820 - val_soft_acc: 0.6864\n",
      "Epoch 657/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1901 - soft_acc: 0.9083 - val_loss: 0.3991 - val_soft_acc: 0.6586\n",
      "Epoch 658/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1808 - soft_acc: 0.9467 - val_loss: 0.4114 - val_soft_acc: 0.7329\n",
      "Epoch 659/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2164 - soft_acc: 0.8961 - val_loss: 0.4463 - val_soft_acc: 0.6643\n",
      "Epoch 660/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2191 - soft_acc: 0.8750 - val_loss: 0.4476 - val_soft_acc: 0.5621\n",
      "Epoch 661/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2135 - soft_acc: 0.9317 - val_loss: 0.3950 - val_soft_acc: 0.7229\n",
      "Epoch 662/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1822 - soft_acc: 0.9433 - val_loss: 0.4159 - val_soft_acc: 0.6593\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1849 - soft_acc: 0.9433 - val_loss: 0.4088 - val_soft_acc: 0.6814\n",
      "Epoch 664/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1875 - soft_acc: 0.9417 - val_loss: 0.3662 - val_soft_acc: 0.7121\n",
      "Epoch 665/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2191 - soft_acc: 0.9161 - val_loss: 0.3723 - val_soft_acc: 0.7379\n",
      "Epoch 666/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2424 - soft_acc: 0.8800 - val_loss: 0.4009 - val_soft_acc: 0.6971\n",
      "Epoch 667/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2037 - soft_acc: 0.9128 - val_loss: 0.3991 - val_soft_acc: 0.7607\n",
      "Epoch 668/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2017 - soft_acc: 0.9317 - val_loss: 0.3607 - val_soft_acc: 0.7686\n",
      "Epoch 669/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1699 - soft_acc: 0.9378 - val_loss: 0.3952 - val_soft_acc: 0.6150\n",
      "Epoch 670/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2066 - soft_acc: 0.9144 - val_loss: 0.3632 - val_soft_acc: 0.7400\n",
      "Epoch 671/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1926 - soft_acc: 0.9467 - val_loss: 0.3751 - val_soft_acc: 0.7429\n",
      "Epoch 672/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2161 - soft_acc: 0.9267 - val_loss: 0.4203 - val_soft_acc: 0.6336\n",
      "Epoch 673/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1722 - soft_acc: 0.9222 - val_loss: 0.3858 - val_soft_acc: 0.6664\n",
      "Epoch 674/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2173 - soft_acc: 0.9056 - val_loss: 0.4509 - val_soft_acc: 0.6107\n",
      "Epoch 675/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2170 - soft_acc: 0.8750 - val_loss: 0.4018 - val_soft_acc: 0.7050\n",
      "Epoch 676/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2534 - soft_acc: 0.8606 - val_loss: 0.4143 - val_soft_acc: 0.7229\n",
      "Epoch 677/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2586 - soft_acc: 0.8711 - val_loss: 0.4508 - val_soft_acc: 0.5750\n",
      "Epoch 678/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2207 - soft_acc: 0.8733 - val_loss: 0.4193 - val_soft_acc: 0.7329\n",
      "Epoch 679/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2326 - soft_acc: 0.8633 - val_loss: 0.3861 - val_soft_acc: 0.7121\n",
      "Epoch 680/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2392 - soft_acc: 0.9028 - val_loss: 0.3677 - val_soft_acc: 0.7536\n",
      "Epoch 681/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1936 - soft_acc: 0.9278 - val_loss: 0.3560 - val_soft_acc: 0.7164\n",
      "Epoch 682/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2026 - soft_acc: 0.8922 - val_loss: 0.4052 - val_soft_acc: 0.6671\n",
      "Epoch 683/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2014 - soft_acc: 0.9078 - val_loss: 0.4117 - val_soft_acc: 0.6357\n",
      "Epoch 684/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1795 - soft_acc: 0.9450 - val_loss: 0.4261 - val_soft_acc: 0.5929\n",
      "Epoch 685/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1907 - soft_acc: 0.9417 - val_loss: 0.3659 - val_soft_acc: 0.7043\n",
      "Epoch 686/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2055 - soft_acc: 0.9300 - val_loss: 0.3595 - val_soft_acc: 0.7400\n",
      "Epoch 687/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1938 - soft_acc: 0.9106 - val_loss: 0.3877 - val_soft_acc: 0.6764\n",
      "Epoch 688/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1734 - soft_acc: 0.9417 - val_loss: 0.3940 - val_soft_acc: 0.6971\n",
      "Epoch 689/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1757 - soft_acc: 0.9467 - val_loss: 0.4169 - val_soft_acc: 0.7107\n",
      "Epoch 690/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1550 - soft_acc: 0.9461 - val_loss: 0.4071 - val_soft_acc: 0.6279\n",
      "Epoch 691/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1865 - soft_acc: 0.9450 - val_loss: 0.3992 - val_soft_acc: 0.7050\n",
      "Epoch 692/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1640 - soft_acc: 0.9294 - val_loss: 0.3718 - val_soft_acc: 0.7300\n",
      "Epoch 693/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1727 - soft_acc: 0.9467 - val_loss: 0.3765 - val_soft_acc: 0.6557\n",
      "Epoch 694/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1969 - soft_acc: 0.9089 - val_loss: 0.4278 - val_soft_acc: 0.6057\n",
      "Epoch 695/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1695 - soft_acc: 0.9378 - val_loss: 0.3948 - val_soft_acc: 0.7171\n",
      "Epoch 696/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1683 - soft_acc: 0.9206 - val_loss: 0.3702 - val_soft_acc: 0.7579\n",
      "Epoch 697/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1715 - soft_acc: 0.9517 - val_loss: 0.3728 - val_soft_acc: 0.7229\n",
      "Epoch 698/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1570 - soft_acc: 0.9133 - val_loss: 0.4052 - val_soft_acc: 0.6879\n",
      "Epoch 699/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1774 - soft_acc: 0.9450 - val_loss: 0.3903 - val_soft_acc: 0.6871\n",
      "Epoch 700/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1604 - soft_acc: 0.9394 - val_loss: 0.3975 - val_soft_acc: 0.6693\n",
      "Epoch 701/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1770 - soft_acc: 0.9367 - val_loss: 0.4148 - val_soft_acc: 0.7000\n",
      "Epoch 702/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2170 - soft_acc: 0.9078 - val_loss: 0.3884 - val_soft_acc: 0.6714\n",
      "Epoch 703/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1681 - soft_acc: 0.9328 - val_loss: 0.3984 - val_soft_acc: 0.7257\n",
      "Epoch 704/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1749 - soft_acc: 0.9311 - val_loss: 0.3917 - val_soft_acc: 0.6871\n",
      "Epoch 705/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1687 - soft_acc: 0.9550 - val_loss: 0.3846 - val_soft_acc: 0.7486\n",
      "Epoch 706/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1497 - soft_acc: 0.9372 - val_loss: 0.3885 - val_soft_acc: 0.6971\n",
      "Epoch 707/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1704 - soft_acc: 0.9294 - val_loss: 0.3632 - val_soft_acc: 0.7557\n",
      "Epoch 708/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1543 - soft_acc: 0.9583 - val_loss: 0.3673 - val_soft_acc: 0.7479\n",
      "Epoch 709/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1626 - soft_acc: 0.9433 - val_loss: 0.4227 - val_soft_acc: 0.6921\n",
      "Epoch 710/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2138 - soft_acc: 0.9317 - val_loss: 0.4062 - val_soft_acc: 0.6743\n",
      "Epoch 711/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1620 - soft_acc: 0.9200 - val_loss: 0.3732 - val_soft_acc: 0.7300\n",
      "Epoch 712/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1528 - soft_acc: 0.9650 - val_loss: 0.3615 - val_soft_acc: 0.7250\n",
      "Epoch 713/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2944 - soft_acc: 0.8000 - val_loss: 0.4049 - val_soft_acc: 0.6821\n",
      "Epoch 714/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2135 - soft_acc: 0.9094 - val_loss: 0.3654 - val_soft_acc: 0.7736\n",
      "Epoch 715/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2225 - soft_acc: 0.8928 - val_loss: 0.3667 - val_soft_acc: 0.7507\n",
      "Epoch 716/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2217 - soft_acc: 0.8856 - val_loss: 0.4019 - val_soft_acc: 0.7257\n",
      "Epoch 717/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1914 - soft_acc: 0.9333 - val_loss: 0.3730 - val_soft_acc: 0.7714\n",
      "Epoch 718/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1626 - soft_acc: 0.9533 - val_loss: 0.3840 - val_soft_acc: 0.6843\n",
      "Epoch 719/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1770 - soft_acc: 0.9467 - val_loss: 0.3737 - val_soft_acc: 0.7250\n",
      "Epoch 720/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1747 - soft_acc: 0.9378 - val_loss: 0.3816 - val_soft_acc: 0.7071\n",
      "Epoch 721/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1695 - soft_acc: 0.9467 - val_loss: 0.3887 - val_soft_acc: 0.7129\n",
      "Epoch 722/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1817 - soft_acc: 0.9517 - val_loss: 0.4364 - val_soft_acc: 0.6621\n",
      "Epoch 723/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2096 - soft_acc: 0.9317 - val_loss: 0.4427 - val_soft_acc: 0.6364\n",
      "Epoch 724/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1977 - soft_acc: 0.9367 - val_loss: 0.3854 - val_soft_acc: 0.6971\n",
      "Epoch 725/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1797 - soft_acc: 0.9344 - val_loss: 0.3845 - val_soft_acc: 0.6607\n",
      "Epoch 726/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1773 - soft_acc: 0.9550 - val_loss: 0.3799 - val_soft_acc: 0.7150\n",
      "Epoch 727/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1739 - soft_acc: 0.9400 - val_loss: 0.3769 - val_soft_acc: 0.6843\n",
      "Epoch 728/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2119 - soft_acc: 0.9200 - val_loss: 0.3868 - val_soft_acc: 0.7071\n",
      "Epoch 729/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1931 - soft_acc: 0.9294 - val_loss: 0.3943 - val_soft_acc: 0.7686\n",
      "Epoch 730/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1869 - soft_acc: 0.9189 - val_loss: 0.4280 - val_soft_acc: 0.6336\n",
      "Epoch 731/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1848 - soft_acc: 0.9517 - val_loss: 0.4056 - val_soft_acc: 0.7200\n",
      "Epoch 732/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1810 - soft_acc: 0.9122 - val_loss: 0.3982 - val_soft_acc: 0.7000\n",
      "Epoch 733/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2223 - soft_acc: 0.9011 - val_loss: 0.4139 - val_soft_acc: 0.6593\n",
      "Epoch 734/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1708 - soft_acc: 0.9394 - val_loss: 0.3804 - val_soft_acc: 0.7179\n",
      "Epoch 735/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1604 - soft_acc: 0.9361 - val_loss: 0.3862 - val_soft_acc: 0.6714\n",
      "Epoch 736/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1595 - soft_acc: 0.9344 - val_loss: 0.3837 - val_soft_acc: 0.7607\n",
      "Epoch 737/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1833 - soft_acc: 0.9517 - val_loss: 0.3989 - val_soft_acc: 0.6614\n",
      "Epoch 738/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1949 - soft_acc: 0.9450 - val_loss: 0.4320 - val_soft_acc: 0.6900\n",
      "Epoch 739/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1917 - soft_acc: 0.9161 - val_loss: 0.4040 - val_soft_acc: 0.5929\n",
      "Epoch 740/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2145 - soft_acc: 0.9056 - val_loss: 0.3775 - val_soft_acc: 0.7143\n",
      "Epoch 741/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1976 - soft_acc: 0.9122 - val_loss: 0.4133 - val_soft_acc: 0.6929\n",
      "Epoch 742/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1929 - soft_acc: 0.9211 - val_loss: 0.4183 - val_soft_acc: 0.6236\n",
      "Epoch 743/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1642 - soft_acc: 0.9411 - val_loss: 0.4109 - val_soft_acc: 0.6307\n",
      "Epoch 744/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1996 - soft_acc: 0.9094 - val_loss: 0.4181 - val_soft_acc: 0.6079\n",
      "Epoch 745/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1927 - soft_acc: 0.9317 - val_loss: 0.3903 - val_soft_acc: 0.7329\n",
      "Epoch 746/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1826 - soft_acc: 0.9361 - val_loss: 0.4134 - val_soft_acc: 0.6671\n",
      "Epoch 747/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1644 - soft_acc: 0.9600 - val_loss: 0.3973 - val_soft_acc: 0.6943\n",
      "Epoch 748/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1716 - soft_acc: 0.9189 - val_loss: 0.4110 - val_soft_acc: 0.6671\n",
      "Epoch 749/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2185 - soft_acc: 0.9094 - val_loss: 0.4260 - val_soft_acc: 0.6514\n",
      "Epoch 750/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2075 - soft_acc: 0.9111 - val_loss: 0.4108 - val_soft_acc: 0.6236\n",
      "Epoch 751/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1897 - soft_acc: 0.9106 - val_loss: 0.3971 - val_soft_acc: 0.6564\n",
      "Epoch 752/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1907 - soft_acc: 0.9350 - val_loss: 0.3966 - val_soft_acc: 0.7536\n",
      "Epoch 753/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1741 - soft_acc: 0.9256 - val_loss: 0.3972 - val_soft_acc: 0.6279\n",
      "Epoch 754/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1610 - soft_acc: 0.9550 - val_loss: 0.3759 - val_soft_acc: 0.7179\n",
      "Epoch 755/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1906 - soft_acc: 0.9267 - val_loss: 0.3838 - val_soft_acc: 0.6843\n",
      "Epoch 756/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1728 - soft_acc: 0.9378 - val_loss: 0.3969 - val_soft_acc: 0.6793\n",
      "Epoch 757/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1689 - soft_acc: 0.9517 - val_loss: 0.3877 - val_soft_acc: 0.7400\n",
      "Epoch 758/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1521 - soft_acc: 0.9533 - val_loss: 0.4064 - val_soft_acc: 0.6514\n",
      "Epoch 759/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1787 - soft_acc: 0.9172 - val_loss: 0.3700 - val_soft_acc: 0.7579\n",
      "Epoch 760/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2110 - soft_acc: 0.8883 - val_loss: 0.3706 - val_soft_acc: 0.7429\n",
      "Epoch 761/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2238 - soft_acc: 0.9144 - val_loss: 0.3530 - val_soft_acc: 0.7143\n",
      "Epoch 762/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2575 - soft_acc: 0.8917 - val_loss: 0.3850 - val_soft_acc: 0.7071\n",
      "Epoch 763/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2252 - soft_acc: 0.9050 - val_loss: 0.4298 - val_soft_acc: 0.6179\n",
      "Epoch 764/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1706 - soft_acc: 0.9206 - val_loss: 0.3790 - val_soft_acc: 0.7121\n",
      "Epoch 765/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1885 - soft_acc: 0.9039 - val_loss: 0.3699 - val_soft_acc: 0.7121\n",
      "Epoch 766/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1654 - soft_acc: 0.9600 - val_loss: 0.3952 - val_soft_acc: 0.7457\n",
      "Epoch 767/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1862 - soft_acc: 0.9239 - val_loss: 0.3810 - val_soft_acc: 0.6664\n",
      "Epoch 768/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1775 - soft_acc: 0.9467 - val_loss: 0.3916 - val_soft_acc: 0.7150\n",
      "Epoch 769/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1708 - soft_acc: 0.9450 - val_loss: 0.4203 - val_soft_acc: 0.6443\n",
      "Epoch 770/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1827 - soft_acc: 0.9206 - val_loss: 0.4031 - val_soft_acc: 0.6793\n",
      "Epoch 771/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1541 - soft_acc: 0.9344 - val_loss: 0.4053 - val_soft_acc: 0.7100\n",
      "Epoch 772/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1853 - soft_acc: 0.9433 - val_loss: 0.4116 - val_soft_acc: 0.6436\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1810 - soft_acc: 0.9367 - val_loss: 0.3986 - val_soft_acc: 0.6514\n",
      "Epoch 774/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1603 - soft_acc: 0.9517 - val_loss: 0.3914 - val_soft_acc: 0.7379\n",
      "Epoch 775/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1765 - soft_acc: 0.9311 - val_loss: 0.4185 - val_soft_acc: 0.6236\n",
      "Epoch 776/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1768 - soft_acc: 0.9533 - val_loss: 0.3775 - val_soft_acc: 0.6764\n",
      "Epoch 777/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1528 - soft_acc: 0.9700best occur in epoch 776\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 0.1735 - soft_acc: 0.9567 - val_loss: 0.3821 - val_soft_acc: 0.7586\n",
      "Epoch 778/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1634 - soft_acc: 0.9461 - val_loss: 0.4015 - val_soft_acc: 0.6486\n",
      "Epoch 779/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1547 - soft_acc: 0.9600 - val_loss: 0.3622 - val_soft_acc: 0.7400\n",
      "Epoch 780/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1585 - soft_acc: 0.9356 - val_loss: 0.3743 - val_soft_acc: 0.7350\n",
      "Epoch 781/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1545 - soft_acc: 0.9428 - val_loss: 0.4092 - val_soft_acc: 0.6950\n",
      "Epoch 782/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1303 - soft_acc: 0.9650 - val_loss: 0.3764 - val_soft_acc: 0.6943\n",
      "Epoch 783/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1455 - soft_acc: 0.9428 - val_loss: 0.4077 - val_soft_acc: 0.6186\n",
      "Epoch 784/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1598 - soft_acc: 0.9483 - val_loss: 0.3907 - val_soft_acc: 0.7079\n",
      "Epoch 785/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1545 - soft_acc: 0.9411 - val_loss: 0.4094 - val_soft_acc: 0.6564\n",
      "Epoch 786/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1357 - soft_acc: 0.9667 - val_loss: 0.3925 - val_soft_acc: 0.6714\n",
      "Epoch 787/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1392 - soft_acc: 0.9683 - val_loss: 0.4203 - val_soft_acc: 0.5821\n",
      "Epoch 788/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1487 - soft_acc: 0.9478 - val_loss: 0.3857 - val_soft_acc: 0.7171\n",
      "Epoch 789/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1542 - soft_acc: 0.9372 - val_loss: 0.3893 - val_soft_acc: 0.6614\n",
      "Epoch 790/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1553 - soft_acc: 0.9600 - val_loss: 0.3945 - val_soft_acc: 0.6614\n",
      "Epoch 791/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2161 - soft_acc: 0.9117 - val_loss: 0.3825 - val_soft_acc: 0.7407\n",
      "Epoch 792/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2033 - soft_acc: 0.9211 - val_loss: 0.3760 - val_soft_acc: 0.6893\n",
      "Epoch 793/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1827 - soft_acc: 0.9450 - val_loss: 0.3835 - val_soft_acc: 0.6693\n",
      "Epoch 794/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1624 - soft_acc: 0.9617 - val_loss: 0.3729 - val_soft_acc: 0.6714\n",
      "Epoch 795/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1694 - soft_acc: 0.9361 - val_loss: 0.3714 - val_soft_acc: 0.7021\n",
      "Epoch 796/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1625 - soft_acc: 0.9394 - val_loss: 0.3829 - val_soft_acc: 0.6814\n",
      "Epoch 797/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1618 - soft_acc: 0.9444 - val_loss: 0.3646 - val_soft_acc: 0.6864\n",
      "Epoch 798/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1983 - soft_acc: 0.9333 - val_loss: 0.3588 - val_soft_acc: 0.7450\n",
      "Epoch 799/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2028 - soft_acc: 0.9383 - val_loss: 0.3865 - val_soft_acc: 0.7300\n",
      "Epoch 800/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2515 - soft_acc: 0.8756 - val_loss: 0.3755 - val_soft_acc: 0.7250\n",
      "Epoch 801/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2854 - soft_acc: 0.8361 - val_loss: 0.4972 - val_soft_acc: 0.5350\n",
      "Epoch 802/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2568 - soft_acc: 0.8656 - val_loss: 0.4138 - val_soft_acc: 0.6136\n",
      "Epoch 803/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2312 - soft_acc: 0.8822 - val_loss: 0.3702 - val_soft_acc: 0.6893\n",
      "Epoch 804/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1833 - soft_acc: 0.9317 - val_loss: 0.3524 - val_soft_acc: 0.6300\n",
      "Epoch 805/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1895 - soft_acc: 0.9333 - val_loss: 0.3639 - val_soft_acc: 0.7329\n",
      "Epoch 806/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1612 - soft_acc: 0.9567 - val_loss: 0.3764 - val_soft_acc: 0.6664\n",
      "Epoch 807/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1379 - soft_acc: 0.9561 - val_loss: 0.3933 - val_soft_acc: 0.7071\n",
      "Epoch 808/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1428 - soft_acc: 0.9578 - val_loss: 0.3493 - val_soft_acc: 0.7500\n",
      "Epoch 809/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1594 - soft_acc: 0.9533 - val_loss: 0.3604 - val_soft_acc: 0.7429\n",
      "Epoch 810/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1462 - soft_acc: 0.9633 - val_loss: 0.3732 - val_soft_acc: 0.6743\n",
      "Epoch 811/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1447 - soft_acc: 0.9683 - val_loss: 0.3893 - val_soft_acc: 0.6721\n",
      "Epoch 812/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1583 - soft_acc: 0.9500 - val_loss: 0.4377 - val_soft_acc: 0.6850\n",
      "Epoch 813/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2224 - soft_acc: 0.9011 - val_loss: 0.4009 - val_soft_acc: 0.6764\n",
      "Epoch 814/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1682 - soft_acc: 0.9533 - val_loss: 0.3729 - val_soft_acc: 0.7250\n",
      "Epoch 815/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1661 - soft_acc: 0.9378 - val_loss: 0.4049 - val_soft_acc: 0.6457\n",
      "Epoch 816/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1498 - soft_acc: 0.9567 - val_loss: 0.3721 - val_soft_acc: 0.7200\n",
      "Epoch 817/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1337 - soft_acc: 0.9617 - val_loss: 0.3903 - val_soft_acc: 0.6764\n",
      "Epoch 818/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1274 - soft_acc: 0.9667 - val_loss: 0.3685 - val_soft_acc: 0.7071\n",
      "Epoch 819/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1439 - soft_acc: 0.9733 - val_loss: 0.3928 - val_soft_acc: 0.7121\n",
      "Epoch 820/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1355 - soft_acc: 0.9650 - val_loss: 0.4086 - val_soft_acc: 0.6593\n",
      "Epoch 821/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1448 - soft_acc: 0.9461 - val_loss: 0.3832 - val_soft_acc: 0.7143\n",
      "Epoch 822/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1241 - soft_acc: 0.9733 - val_loss: 0.3808 - val_soft_acc: 0.6843\n",
      "Epoch 823/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1325 - soft_acc: 0.9511 - val_loss: 0.3632 - val_soft_acc: 0.6736\n",
      "Epoch 824/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1375 - soft_acc: 0.9561 - val_loss: 0.4054 - val_soft_acc: 0.6307\n",
      "Epoch 825/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1291 - soft_acc: 0.9561 - val_loss: 0.3866 - val_soft_acc: 0.7479\n",
      "Epoch 826/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1574 - soft_acc: 0.9389 - val_loss: 0.3842 - val_soft_acc: 0.7250\n",
      "Epoch 827/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1561 - soft_acc: 0.9411 - val_loss: 0.4009 - val_soft_acc: 0.6279\n",
      "Epoch 828/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1619 - soft_acc: 0.9600 - val_loss: 0.3915 - val_soft_acc: 0.6893\n",
      "Epoch 829/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1624 - soft_acc: 0.9428 - val_loss: 0.4000 - val_soft_acc: 0.6486\n",
      "Epoch 830/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1520 - soft_acc: 0.9478 - val_loss: 0.3980 - val_soft_acc: 0.6943\n",
      "Epoch 831/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1632 - soft_acc: 0.9583 - val_loss: 0.3743 - val_soft_acc: 0.6329\n",
      "Epoch 832/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1710 - soft_acc: 0.9483 - val_loss: 0.3951 - val_soft_acc: 0.6871\n",
      "Epoch 833/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1705 - soft_acc: 0.9417 - val_loss: 0.4022 - val_soft_acc: 0.6000\n",
      "Epoch 834/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1558 - soft_acc: 0.9411 - val_loss: 0.3937 - val_soft_acc: 0.7407\n",
      "Epoch 835/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1406 - soft_acc: 0.9683 - val_loss: 0.3925 - val_soft_acc: 0.7100\n",
      "Epoch 836/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1391 - soft_acc: 0.9561 - val_loss: 0.3774 - val_soft_acc: 0.6943\n",
      "Epoch 837/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1403 - soft_acc: 0.9733 - val_loss: 0.3768 - val_soft_acc: 0.7379\n",
      "Epoch 838/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1473 - soft_acc: 0.9800best occur in epoch 837\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1402 - soft_acc: 0.9578 - val_loss: 0.3974 - val_soft_acc: 0.7993\n",
      "Epoch 839/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1299 - soft_acc: 0.9733 - val_loss: 0.4094 - val_soft_acc: 0.6993\n",
      "Epoch 840/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1610 - soft_acc: 0.9461 - val_loss: 0.3894 - val_soft_acc: 0.6893\n",
      "Epoch 841/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1372 - soft_acc: 0.9650 - val_loss: 0.4084 - val_soft_acc: 0.6743\n",
      "Epoch 842/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1349 - soft_acc: 0.9700 - val_loss: 0.3804 - val_soft_acc: 0.6564\n",
      "Epoch 843/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1506 - soft_acc: 0.9667 - val_loss: 0.3862 - val_soft_acc: 0.6793\n",
      "Epoch 844/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1420 - soft_acc: 0.9389 - val_loss: 0.4063 - val_soft_acc: 0.7000\n",
      "Epoch 845/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1494 - soft_acc: 0.9633 - val_loss: 0.3771 - val_soft_acc: 0.7707\n",
      "Epoch 846/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1355 - soft_acc: 0.9611 - val_loss: 0.3755 - val_soft_acc: 0.7171\n",
      "Epoch 847/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1415 - soft_acc: 0.9650 - val_loss: 0.3856 - val_soft_acc: 0.6200\n",
      "Epoch 848/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1486 - soft_acc: 0.9683 - val_loss: 0.3977 - val_soft_acc: 0.6843\n",
      "Epoch 849/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1258 - soft_acc: 0.9717 - val_loss: 0.4140 - val_soft_acc: 0.6921\n",
      "Epoch 850/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1770 - soft_acc: 0.9517 - val_loss: 0.3881 - val_soft_acc: 0.7021\n",
      "Epoch 851/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1442 - soft_acc: 0.9733 - val_loss: 0.3900 - val_soft_acc: 0.7279\n",
      "Epoch 852/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1475 - soft_acc: 0.9667 - val_loss: 0.4007 - val_soft_acc: 0.6407\n",
      "Epoch 853/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1397 - soft_acc: 0.9628 - val_loss: 0.3916 - val_soft_acc: 0.6814\n",
      "Epoch 854/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1359 - soft_acc: 0.9494 - val_loss: 0.3765 - val_soft_acc: 0.6686\n",
      "Epoch 855/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1464 - soft_acc: 0.9767 - val_loss: 0.3815 - val_soft_acc: 0.7686\n",
      "Epoch 856/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1376 - soft_acc: 0.9617 - val_loss: 0.4190 - val_soft_acc: 0.6871\n",
      "Epoch 857/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2443 - soft_acc: 0.8689 - val_loss: 0.3631 - val_soft_acc: 0.7143\n",
      "Epoch 858/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2163 - soft_acc: 0.9267 - val_loss: 0.3556 - val_soft_acc: 0.7193\n",
      "Epoch 859/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2372 - soft_acc: 0.8650 - val_loss: 0.3797 - val_soft_acc: 0.7271\n",
      "Epoch 860/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1908 - soft_acc: 0.9417 - val_loss: 0.3852 - val_soft_acc: 0.7221\n",
      "Epoch 861/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1470 - soft_acc: 0.9650 - val_loss: 0.4070 - val_soft_acc: 0.6771\n",
      "Epoch 862/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1433 - soft_acc: 0.9717 - val_loss: 0.3752 - val_soft_acc: 0.7200\n",
      "Epoch 863/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1370 - soft_acc: 0.9617 - val_loss: 0.4005 - val_soft_acc: 0.5821\n",
      "Epoch 864/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1470 - soft_acc: 0.9717 - val_loss: 0.4049 - val_soft_acc: 0.6229\n",
      "Epoch 865/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1852 - soft_acc: 0.9211 - val_loss: 0.4355 - val_soft_acc: 0.6407\n",
      "Epoch 866/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1833 - soft_acc: 0.9433 - val_loss: 0.4580 - val_soft_acc: 0.6929\n",
      "Epoch 867/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1772 - soft_acc: 0.9533 - val_loss: 0.4455 - val_soft_acc: 0.6393\n",
      "Epoch 868/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3277 - soft_acc: 0.7411 - val_loss: 0.3704 - val_soft_acc: 0.6579\n",
      "Epoch 869/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2728 - soft_acc: 0.8578 - val_loss: 0.3747 - val_soft_acc: 0.7243\n",
      "Epoch 870/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2488 - soft_acc: 0.8744 - val_loss: 0.4014 - val_soft_acc: 0.7200\n",
      "Epoch 871/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2080 - soft_acc: 0.9233 - val_loss: 0.3849 - val_soft_acc: 0.6714\n",
      "Epoch 872/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1840 - soft_acc: 0.9228 - val_loss: 0.3918 - val_soft_acc: 0.6636\n",
      "Epoch 873/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1577 - soft_acc: 0.9600 - val_loss: 0.3694 - val_soft_acc: 0.6993\n",
      "Epoch 874/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1576 - soft_acc: 0.9494 - val_loss: 0.3803 - val_soft_acc: 0.6971\n",
      "Epoch 875/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1680 - soft_acc: 0.9272 - val_loss: 0.3663 - val_soft_acc: 0.6586\n",
      "Epoch 876/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1349 - soft_acc: 0.9717 - val_loss: 0.4009 - val_soft_acc: 0.6921\n",
      "Epoch 877/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1350 - soft_acc: 0.9750 - val_loss: 0.4022 - val_soft_acc: 0.6057\n",
      "Epoch 878/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1362 - soft_acc: 0.9644 - val_loss: 0.3970 - val_soft_acc: 0.6786\n",
      "Epoch 879/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1312 - soft_acc: 0.9767 - val_loss: 0.4079 - val_soft_acc: 0.6457\n",
      "Epoch 880/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1355 - soft_acc: 0.9650 - val_loss: 0.3949 - val_soft_acc: 0.6586\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1276 - soft_acc: 0.9700 - val_loss: 0.3773 - val_soft_acc: 0.7450\n",
      "Epoch 882/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1367 - soft_acc: 0.9683 - val_loss: 0.3803 - val_soft_acc: 0.7607\n",
      "Epoch 883/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1450 - soft_acc: 0.9561 - val_loss: 0.3948 - val_soft_acc: 0.6771\n",
      "Epoch 884/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1268 - soft_acc: 0.9717 - val_loss: 0.3941 - val_soft_acc: 0.6843\n",
      "Epoch 885/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1277 - soft_acc: 0.9767 - val_loss: 0.3777 - val_soft_acc: 0.6843\n",
      "Epoch 886/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1232 - soft_acc: 0.9767 - val_loss: 0.3855 - val_soft_acc: 0.6843\n",
      "Epoch 887/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1318 - soft_acc: 0.9650 - val_loss: 0.3820 - val_soft_acc: 0.7150\n",
      "Epoch 888/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1528 - soft_acc: 0.9511 - val_loss: 0.3999 - val_soft_acc: 0.6436\n",
      "Epoch 889/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1521 - soft_acc: 0.9356 - val_loss: 0.3839 - val_soft_acc: 0.6871\n",
      "Epoch 890/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1493 - soft_acc: 0.9683 - val_loss: 0.3653 - val_soft_acc: 0.6993\n",
      "Epoch 891/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1347 - soft_acc: 0.9650 - val_loss: 0.3805 - val_soft_acc: 0.7021\n",
      "Epoch 892/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1159 - soft_acc: 0.9594 - val_loss: 0.3765 - val_soft_acc: 0.6686\n",
      "Epoch 893/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1418 - soft_acc: 0.9683 - val_loss: 0.3771 - val_soft_acc: 0.6786\n",
      "Epoch 894/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1421 - soft_acc: 0.9594 - val_loss: 0.4318 - val_soft_acc: 0.6036\n",
      "Epoch 895/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2168 - soft_acc: 0.9317 - val_loss: 0.4115 - val_soft_acc: 0.6343\n",
      "Epoch 896/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1857 - soft_acc: 0.9361 - val_loss: 0.3838 - val_soft_acc: 0.7171\n",
      "Epoch 897/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1635 - soft_acc: 0.9633 - val_loss: 0.3703 - val_soft_acc: 0.7121\n",
      "Epoch 898/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1527 - soft_acc: 0.9561 - val_loss: 0.3816 - val_soft_acc: 0.7171\n",
      "Epoch 899/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1396 - soft_acc: 0.9650 - val_loss: 0.3838 - val_soft_acc: 0.6536\n",
      "Epoch 900/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1063 - soft_acc: 0.9900best occur in epoch 899\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1310 - soft_acc: 0.9767 - val_loss: 0.3800 - val_soft_acc: 0.7914\n",
      "Epoch 901/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1314 - soft_acc: 0.9733 - val_loss: 0.4024 - val_soft_acc: 0.6414\n",
      "Epoch 902/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1393 - soft_acc: 0.9422 - val_loss: 0.3777 - val_soft_acc: 0.6886\n",
      "Epoch 903/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1150 - soft_acc: 0.9717 - val_loss: 0.3644 - val_soft_acc: 0.7550\n",
      "Epoch 904/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1212 - soft_acc: 0.9717 - val_loss: 0.3781 - val_soft_acc: 0.6893\n",
      "Epoch 905/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1492 - soft_acc: 0.9456 - val_loss: 0.3687 - val_soft_acc: 0.7607\n",
      "Epoch 906/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1462 - soft_acc: 0.9700 - val_loss: 0.3739 - val_soft_acc: 0.7150\n",
      "Epoch 907/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1739 - soft_acc: 0.9467 - val_loss: 0.4008 - val_soft_acc: 0.6057\n",
      "Epoch 908/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1725 - soft_acc: 0.9600 - val_loss: 0.4289 - val_soft_acc: 0.6950\n",
      "Epoch 909/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1989 - soft_acc: 0.9111 - val_loss: 0.3996 - val_soft_acc: 0.6286\n",
      "Epoch 910/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1960 - soft_acc: 0.9400 - val_loss: 0.3867 - val_soft_acc: 0.6107\n",
      "Epoch 911/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1680 - soft_acc: 0.9411 - val_loss: 0.4126 - val_soft_acc: 0.6414\n",
      "Epoch 912/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1983 - soft_acc: 0.9039 - val_loss: 0.3656 - val_soft_acc: 0.6864\n",
      "Epoch 913/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1488 - soft_acc: 0.9528 - val_loss: 0.3824 - val_soft_acc: 0.6971\n",
      "Epoch 914/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1273 - soft_acc: 0.9683 - val_loss: 0.3943 - val_soft_acc: 0.6714\n",
      "Epoch 915/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1530 - soft_acc: 0.9667 - val_loss: 0.3674 - val_soft_acc: 0.6536\n",
      "Epoch 916/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1205 - soft_acc: 0.9767 - val_loss: 0.3762 - val_soft_acc: 0.6764\n",
      "Epoch 917/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1224 - soft_acc: 0.9783 - val_loss: 0.3874 - val_soft_acc: 0.6407\n",
      "Epoch 918/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1217 - soft_acc: 0.9700 - val_loss: 0.3836 - val_soft_acc: 0.6714\n",
      "Epoch 919/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1194 - soft_acc: 0.9817 - val_loss: 0.3839 - val_soft_acc: 0.6664\n",
      "Epoch 920/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1200 - soft_acc: 0.9678 - val_loss: 0.3759 - val_soft_acc: 0.6636\n",
      "Epoch 921/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1336 - soft_acc: 0.9750 - val_loss: 0.3814 - val_soft_acc: 0.6979\n",
      "Epoch 922/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1232 - soft_acc: 0.9556 - val_loss: 0.3764 - val_soft_acc: 0.6843\n",
      "Epoch 923/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1356 - soft_acc: 0.9683 - val_loss: 0.3852 - val_soft_acc: 0.7000\n",
      "Epoch 924/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1200 - soft_acc: 0.9817 - val_loss: 0.3759 - val_soft_acc: 0.6950\n",
      "Epoch 925/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1545 - soft_acc: 0.9511 - val_loss: 0.3951 - val_soft_acc: 0.6257\n",
      "Epoch 926/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1499 - soft_acc: 0.9550 - val_loss: 0.4071 - val_soft_acc: 0.6464\n",
      "Epoch 927/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1339 - soft_acc: 0.9683 - val_loss: 0.3735 - val_soft_acc: 0.7250\n",
      "Epoch 928/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1272 - soft_acc: 0.9594 - val_loss: 0.3681 - val_soft_acc: 0.6664\n",
      "Epoch 929/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1536 - soft_acc: 0.9683 - val_loss: 0.3885 - val_soft_acc: 0.6407\n",
      "Epoch 930/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1351 - soft_acc: 0.9594 - val_loss: 0.3818 - val_soft_acc: 0.7379\n",
      "Epoch 931/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1346 - soft_acc: 0.9644 - val_loss: 0.3693 - val_soft_acc: 0.7071\n",
      "Epoch 932/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1386 - soft_acc: 0.9750 - val_loss: 0.3549 - val_soft_acc: 0.7757\n",
      "Epoch 933/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1318 - soft_acc: 0.9644 - val_loss: 0.3691 - val_soft_acc: 0.6586\n",
      "Epoch 934/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1242 - soft_acc: 0.9300 - val_loss: 0.3520 - val_soft_acc: 0.7350\n",
      "Epoch 935/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1316 - soft_acc: 0.9750 - val_loss: 0.3659 - val_soft_acc: 0.7864\n",
      "Epoch 936/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1428 - soft_acc: 0.9833 - val_loss: 0.3762 - val_soft_acc: 0.6636\n",
      "Epoch 937/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1586 - soft_acc: 0.9394 - val_loss: 0.3531 - val_soft_acc: 0.6986\n",
      "Epoch 938/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1617 - soft_acc: 0.9583 - val_loss: 0.3660 - val_soft_acc: 0.7557\n",
      "Epoch 939/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1650 - soft_acc: 0.9511 - val_loss: 0.3475 - val_soft_acc: 0.7879\n",
      "Epoch 940/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1603 - soft_acc: 0.9528 - val_loss: 0.3771 - val_soft_acc: 0.7379\n",
      "Epoch 941/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1208 - soft_acc: 0.9661 - val_loss: 0.4087 - val_soft_acc: 0.6264\n",
      "Epoch 942/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1778 - soft_acc: 0.9206 - val_loss: 0.3872 - val_soft_acc: 0.7357\n",
      "Epoch 943/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1277 - soft_acc: 0.9817 - val_loss: 0.4280 - val_soft_acc: 0.6007\n",
      "Epoch 944/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1555 - soft_acc: 0.9717 - val_loss: 0.3831 - val_soft_acc: 0.6686\n",
      "Epoch 945/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1577 - soft_acc: 0.9528 - val_loss: 0.4233 - val_soft_acc: 0.6564\n",
      "Epoch 946/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2082 - soft_acc: 0.9328 - val_loss: 0.3710 - val_soft_acc: 0.7014\n",
      "Epoch 947/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2190 - soft_acc: 0.8978 - val_loss: 0.3810 - val_soft_acc: 0.7121\n",
      "Epoch 948/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1542 - soft_acc: 0.9700 - val_loss: 0.4090 - val_soft_acc: 0.6357\n",
      "Epoch 949/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1391 - soft_acc: 0.9783 - val_loss: 0.3951 - val_soft_acc: 0.6693\n",
      "Epoch 950/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1194 - soft_acc: 0.9783 - val_loss: 0.3784 - val_soft_acc: 0.7479\n",
      "Epoch 951/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1158 - soft_acc: 0.9800 - val_loss: 0.3836 - val_soft_acc: 0.6636\n",
      "Epoch 952/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1138 - soft_acc: 0.9883 - val_loss: 0.3949 - val_soft_acc: 0.7150\n",
      "Epoch 953/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1367 - soft_acc: 0.9683 - val_loss: 0.3703 - val_soft_acc: 0.7093\n",
      "Epoch 954/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1115 - soft_acc: 0.9783 - val_loss: 0.3758 - val_soft_acc: 0.7350\n",
      "Epoch 955/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1077 - soft_acc: 0.9850 - val_loss: 0.3635 - val_soft_acc: 0.6886\n",
      "Epoch 956/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1052 - soft_acc: 0.9833 - val_loss: 0.3608 - val_soft_acc: 0.6936\n",
      "Epoch 957/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1137 - soft_acc: 0.9850 - val_loss: 0.3681 - val_soft_acc: 0.7807\n",
      "Epoch 958/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1665 - soft_acc: 0.9583 - val_loss: 0.3765 - val_soft_acc: 0.7150\n",
      "Epoch 959/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1676 - soft_acc: 0.9322 - val_loss: 0.3631 - val_soft_acc: 0.7329\n",
      "Epoch 960/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1281 - soft_acc: 0.9733 - val_loss: 0.3528 - val_soft_acc: 0.7271\n",
      "Epoch 961/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1122 - soft_acc: 0.9800 - val_loss: 0.3633 - val_soft_acc: 0.7507\n",
      "Epoch 962/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1354 - soft_acc: 0.9783 - val_loss: 0.3549 - val_soft_acc: 0.7343\n",
      "Epoch 963/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1287 - soft_acc: 0.9783 - val_loss: 0.3619 - val_soft_acc: 0.6864\n",
      "Epoch 964/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1203 - soft_acc: 0.9767 - val_loss: 0.4433 - val_soft_acc: 0.5950\n",
      "Epoch 965/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1447 - soft_acc: 0.9800 - val_loss: 0.3763 - val_soft_acc: 0.7457\n",
      "Epoch 966/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1243 - soft_acc: 0.9800 - val_loss: 0.3887 - val_soft_acc: 0.6821\n",
      "Epoch 967/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1134 - soft_acc: 0.9833 - val_loss: 0.3756 - val_soft_acc: 0.6843\n",
      "Epoch 968/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1296 - soft_acc: 0.9644 - val_loss: 0.3629 - val_soft_acc: 0.7043\n",
      "Epoch 969/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1355 - soft_acc: 0.9667 - val_loss: 0.3713 - val_soft_acc: 0.6871\n",
      "Epoch 970/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1207 - soft_acc: 0.9683 - val_loss: 0.3519 - val_soft_acc: 0.6836\n",
      "Epoch 971/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1330 - soft_acc: 0.9767 - val_loss: 0.3618 - val_soft_acc: 0.6943\n",
      "Epoch 972/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1243 - soft_acc: 0.9833 - val_loss: 0.3605 - val_soft_acc: 0.7600\n",
      "Epoch 973/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1321 - soft_acc: 0.9628 - val_loss: 0.3839 - val_soft_acc: 0.7329\n",
      "Epoch 974/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1117 - soft_acc: 0.9750 - val_loss: 0.3710 - val_soft_acc: 0.7279\n",
      "Epoch 975/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1110 - soft_acc: 0.9783 - val_loss: 0.3586 - val_soft_acc: 0.7421\n",
      "Epoch 976/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1126 - soft_acc: 0.9850 - val_loss: 0.3631 - val_soft_acc: 0.7607\n",
      "Epoch 977/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1081 - soft_acc: 0.9433 - val_loss: 0.3837 - val_soft_acc: 0.7357\n",
      "Epoch 978/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1300 - soft_acc: 0.9628 - val_loss: 0.3901 - val_soft_acc: 0.6664\n",
      "Epoch 979/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1355 - soft_acc: 0.9544 - val_loss: 0.3778 - val_soft_acc: 0.7171\n",
      "Epoch 980/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1407 - soft_acc: 0.9644 - val_loss: 0.3844 - val_soft_acc: 0.6843\n",
      "Epoch 981/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1375 - soft_acc: 0.9717 - val_loss: 0.3823 - val_soft_acc: 0.6457\n",
      "Epoch 982/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1350 - soft_acc: 0.9783 - val_loss: 0.3877 - val_soft_acc: 0.7429\n",
      "Epoch 983/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1388 - soft_acc: 0.9661 - val_loss: 0.3575 - val_soft_acc: 0.7193\n",
      "Epoch 984/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1569 - soft_acc: 0.9356 - val_loss: 0.3755 - val_soft_acc: 0.6664\n",
      "Epoch 985/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1389 - soft_acc: 0.9733 - val_loss: 0.3769 - val_soft_acc: 0.7043\n",
      "Epoch 986/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1246 - soft_acc: 0.9767 - val_loss: 0.3686 - val_soft_acc: 0.7579\n",
      "Epoch 987/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1278 - soft_acc: 0.9644 - val_loss: 0.3818 - val_soft_acc: 0.6871\n",
      "Epoch 988/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1221 - soft_acc: 0.9767 - val_loss: 0.3635 - val_soft_acc: 0.6864\n",
      "Epoch 989/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1962 - soft_acc: 0.9361 - val_loss: 0.3683 - val_soft_acc: 0.7329\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 8us/sample - loss: 0.1480 - soft_acc: 0.9750 - val_loss: 0.3520 - val_soft_acc: 0.7579\n",
      "Epoch 991/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1386 - soft_acc: 0.9800 - val_loss: 0.3723 - val_soft_acc: 0.6486\n",
      "Epoch 992/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1293 - soft_acc: 0.9750 - val_loss: 0.3684 - val_soft_acc: 0.7171\n",
      "Epoch 993/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1013 - soft_acc: 0.9883 - val_loss: 0.3800 - val_soft_acc: 0.6814\n",
      "Epoch 994/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1018 - soft_acc: 0.9728 - val_loss: 0.3615 - val_soft_acc: 0.7271\n",
      "Epoch 995/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1063 - soft_acc: 0.9867 - val_loss: 0.3581 - val_soft_acc: 0.7321\n",
      "Epoch 996/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1113 - soft_acc: 0.9850 - val_loss: 0.3654 - val_soft_acc: 0.6536\n",
      "Epoch 997/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1272 - soft_acc: 0.9667 - val_loss: 0.3650 - val_soft_acc: 0.6914\n",
      "Epoch 998/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1150 - soft_acc: 0.9783 - val_loss: 0.3765 - val_soft_acc: 0.7686\n",
      "Epoch 999/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1203 - soft_acc: 0.9767 - val_loss: 0.3725 - val_soft_acc: 0.6943\n",
      "Epoch 1000/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1217 - soft_acc: 0.9817 - val_loss: 0.3797 - val_soft_acc: 0.6914\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.3800 - soft_acc: 0.7344\n",
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 9.0979 - soft_acc: 0.0300best occur in epoch 0\n",
      "512/512 [==============================] - 0s 416us/sample - loss: 11.7864 - soft_acc: 0.0794 - val_loss: 2.4880 - val_soft_acc: 0.1464\n",
      "Epoch 2/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.0968 - soft_acc: 0.2200best occur in epoch 1\n",
      "512/512 [==============================] - 0s 62us/sample - loss: 3.1816 - soft_acc: 0.1856 - val_loss: 0.9395 - val_soft_acc: 0.3893\n",
      "Epoch 3/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 1.4296 - soft_acc: 0.3233 - val_loss: 1.9703 - val_soft_acc: 0.1107\n",
      "Epoch 4/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 1.2535 - soft_acc: 0.3633 - val_loss: 1.3140 - val_soft_acc: 0.1864\n",
      "Epoch 5/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.9359 - soft_acc: 0.2400best occur in epoch 4\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 1.8789 - soft_acc: 0.3228 - val_loss: 0.8362 - val_soft_acc: 0.4650\n",
      "Epoch 6/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.9343 - soft_acc: 0.4067 - val_loss: 0.8750 - val_soft_acc: 0.3507\n",
      "Epoch 7/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6938 - soft_acc: 0.5200best occur in epoch 6\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 0.8381 - soft_acc: 0.4344 - val_loss: 0.6135 - val_soft_acc: 0.4600\n",
      "Epoch 8/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.7648 - soft_acc: 0.4706 - val_loss: 0.9737 - val_soft_acc: 0.3286\n",
      "Epoch 9/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 1.1728 - soft_acc: 0.3228 - val_loss: 0.6555 - val_soft_acc: 0.5186\n",
      "Epoch 10/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5803 - soft_acc: 0.6300best occur in epoch 9\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.7402 - soft_acc: 0.5017 - val_loss: 0.5834 - val_soft_acc: 0.5307\n",
      "Epoch 11/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.7004 - soft_acc: 0.4944 - val_loss: 1.1430 - val_soft_acc: 0.2479\n",
      "Epoch 12/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.9404 - soft_acc: 0.3939 - val_loss: 0.6645 - val_soft_acc: 0.4029\n",
      "Epoch 13/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.7454 - soft_acc: 0.4544 - val_loss: 0.6668 - val_soft_acc: 0.5050\n",
      "Epoch 14/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.7538 - soft_acc: 0.4789 - val_loss: 0.5407 - val_soft_acc: 0.5300\n",
      "Epoch 15/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7667 - soft_acc: 0.4500best occur in epoch 14\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5659 - soft_acc: 0.5728 - val_loss: 0.5511 - val_soft_acc: 0.5736\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5435 - soft_acc: 0.6083 - val_loss: 0.6753 - val_soft_acc: 0.4850\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6883 - soft_acc: 0.4939 - val_loss: 0.6656 - val_soft_acc: 0.5600\n",
      "Epoch 18/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5803 - soft_acc: 0.5700best occur in epoch 17\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6051 - soft_acc: 0.5722 - val_loss: 0.5741 - val_soft_acc: 0.5814\n",
      "Epoch 19/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5734 - soft_acc: 0.6600best occur in epoch 18\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.5541 - soft_acc: 0.6461 - val_loss: 0.5292 - val_soft_acc: 0.6043\n",
      "Epoch 20/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.6721 - soft_acc: 0.4906 - val_loss: 0.9796 - val_soft_acc: 0.3100\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.9088 - soft_acc: 0.3983 - val_loss: 1.6548 - val_soft_acc: 0.1964\n",
      "Epoch 22/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 1.6503 - soft_acc: 0.2533 - val_loss: 0.6540 - val_soft_acc: 0.5500\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.9098 - soft_acc: 0.4883 - val_loss: 0.5639 - val_soft_acc: 0.5000\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.6630 - soft_acc: 0.5344 - val_loss: 0.5202 - val_soft_acc: 0.5700\n",
      "Epoch 25/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5827 - soft_acc: 0.5722 - val_loss: 0.8853 - val_soft_acc: 0.3000\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.6018 - soft_acc: 0.5489 - val_loss: 0.6714 - val_soft_acc: 0.4264\n",
      "Epoch 27/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5558 - soft_acc: 0.6050 - val_loss: 0.4337 - val_soft_acc: 0.6386\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4377 - soft_acc: 0.6872 - val_loss: 0.5784 - val_soft_acc: 0.4771\n",
      "Epoch 29/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4120 - soft_acc: 0.6900best occur in epoch 28\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4514 - soft_acc: 0.6433 - val_loss: 0.4313 - val_soft_acc: 0.6364\n",
      "Epoch 30/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.5322 - soft_acc: 0.6317 - val_loss: 0.7038 - val_soft_acc: 0.4321\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5889 - soft_acc: 0.5628 - val_loss: 0.5235 - val_soft_acc: 0.5814\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4621 - soft_acc: 0.6689 - val_loss: 0.4840 - val_soft_acc: 0.5500\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4160 - soft_acc: 0.7133 - val_loss: 0.5415 - val_soft_acc: 0.5529\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4599 - soft_acc: 0.6106 - val_loss: 0.4649 - val_soft_acc: 0.6543\n",
      "Epoch 35/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.6492 - soft_acc: 0.5372 - val_loss: 0.8708 - val_soft_acc: 0.3436\n",
      "Epoch 36/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 1.2925 - soft_acc: 0.2706 - val_loss: 0.6097 - val_soft_acc: 0.5386\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 1.1107 - soft_acc: 0.3467 - val_loss: 0.7403 - val_soft_acc: 0.3957\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 30us/sample - loss: 1.0644 - soft_acc: 0.3878 - val_loss: 1.0392 - val_soft_acc: 0.2586\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.7728 - soft_acc: 0.4728 - val_loss: 0.7509 - val_soft_acc: 0.4064\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5710 - soft_acc: 0.5639 - val_loss: 0.4870 - val_soft_acc: 0.6443\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4719 - soft_acc: 0.6356 - val_loss: 0.4693 - val_soft_acc: 0.5829\n",
      "Epoch 42/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4412 - soft_acc: 0.6600best occur in epoch 41\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4362 - soft_acc: 0.7133 - val_loss: 0.5184 - val_soft_acc: 0.5936\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4580 - soft_acc: 0.6572 - val_loss: 0.4913 - val_soft_acc: 0.6164\n",
      "Epoch 44/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4492 - soft_acc: 0.6661 - val_loss: 0.4610 - val_soft_acc: 0.6236\n",
      "Epoch 45/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4187 - soft_acc: 0.7406 - val_loss: 0.4959 - val_soft_acc: 0.5600\n",
      "Epoch 46/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4095 - soft_acc: 0.7000best occur in epoch 45\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4279 - soft_acc: 0.7033 - val_loss: 0.4608 - val_soft_acc: 0.6521\n",
      "Epoch 47/1000\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.4365 - soft_acc: 0.7017 - val_loss: 0.4257 - val_soft_acc: 0.6207\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4240 - soft_acc: 0.7150 - val_loss: 0.4954 - val_soft_acc: 0.5936\n",
      "Epoch 49/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4561 - soft_acc: 0.6639 - val_loss: 0.5203 - val_soft_acc: 0.5836\n",
      "Epoch 50/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4011 - soft_acc: 0.7133 - val_loss: 0.6008 - val_soft_acc: 0.4314\n",
      "Epoch 51/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4302 - soft_acc: 0.7189 - val_loss: 0.6665 - val_soft_acc: 0.4521\n",
      "Epoch 52/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3831 - soft_acc: 0.7300best occur in epoch 51\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4001 - soft_acc: 0.7728 - val_loss: 0.4583 - val_soft_acc: 0.6029\n",
      "Epoch 53/1000\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.4674 - soft_acc: 0.6406 - val_loss: 0.4831 - val_soft_acc: 0.6193\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4681 - soft_acc: 0.6506 - val_loss: 0.7498 - val_soft_acc: 0.3843\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.5820 - soft_acc: 0.5761 - val_loss: 0.4637 - val_soft_acc: 0.6850\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3938 - soft_acc: 0.7144 - val_loss: 0.5149 - val_soft_acc: 0.5529\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4205 - soft_acc: 0.7206 - val_loss: 0.5499 - val_soft_acc: 0.5179\n",
      "Epoch 58/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3852 - soft_acc: 0.7572 - val_loss: 0.6022 - val_soft_acc: 0.5364\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3985 - soft_acc: 0.7233 - val_loss: 0.5810 - val_soft_acc: 0.5679\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3818 - soft_acc: 0.7361 - val_loss: 0.5317 - val_soft_acc: 0.6236\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3938 - soft_acc: 0.7411 - val_loss: 0.5338 - val_soft_acc: 0.6343\n",
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4047 - soft_acc: 0.7167 - val_loss: 0.6586 - val_soft_acc: 0.4079\n",
      "Epoch 63/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4455 - soft_acc: 0.6728 - val_loss: 0.7583 - val_soft_acc: 0.3229\n",
      "Epoch 64/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4578 - soft_acc: 0.6161 - val_loss: 0.4718 - val_soft_acc: 0.6421\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5254 - soft_acc: 0.6450 - val_loss: 0.4573 - val_soft_acc: 0.6264\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4420 - soft_acc: 0.6578 - val_loss: 0.4365 - val_soft_acc: 0.6493\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4897 - soft_acc: 0.6311 - val_loss: 0.4623 - val_soft_acc: 0.6500\n",
      "Epoch 68/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4180 - soft_acc: 0.6894 - val_loss: 0.4590 - val_soft_acc: 0.5779\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4528 - soft_acc: 0.6783 - val_loss: 0.4958 - val_soft_acc: 0.5629\n",
      "Epoch 70/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4528 - soft_acc: 0.6683 - val_loss: 0.4414 - val_soft_acc: 0.6057\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4590 - soft_acc: 0.6706 - val_loss: 0.4365 - val_soft_acc: 0.6521\n",
      "Epoch 72/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3807 - soft_acc: 0.6967 - val_loss: 0.5216 - val_soft_acc: 0.6143\n",
      "Epoch 73/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3717 - soft_acc: 0.7083 - val_loss: 0.6105 - val_soft_acc: 0.4157\n",
      "Epoch 74/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4310 - soft_acc: 0.6850 - val_loss: 0.6097 - val_soft_acc: 0.4621\n",
      "Epoch 75/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4071 - soft_acc: 0.6928 - val_loss: 0.5849 - val_soft_acc: 0.4614\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3862 - soft_acc: 0.7439 - val_loss: 0.7402 - val_soft_acc: 0.3557\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5893 - soft_acc: 0.5506 - val_loss: 0.4712 - val_soft_acc: 0.5907\n",
      "Epoch 78/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4554 - soft_acc: 0.6406 - val_loss: 0.4577 - val_soft_acc: 0.6243\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4266 - soft_acc: 0.6889 - val_loss: 0.4767 - val_soft_acc: 0.6143\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4371 - soft_acc: 0.6883 - val_loss: 0.5088 - val_soft_acc: 0.6007\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4936 - soft_acc: 0.6161 - val_loss: 0.4887 - val_soft_acc: 0.5700\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4128 - soft_acc: 0.7050 - val_loss: 0.5438 - val_soft_acc: 0.5479\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3888 - soft_acc: 0.7561 - val_loss: 0.4986 - val_soft_acc: 0.5479\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4037 - soft_acc: 0.7067 - val_loss: 0.4376 - val_soft_acc: 0.6264\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3872 - soft_acc: 0.7561 - val_loss: 0.6359 - val_soft_acc: 0.4650\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4091 - soft_acc: 0.7422 - val_loss: 0.5151 - val_soft_acc: 0.5200\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4037 - soft_acc: 0.7356 - val_loss: 0.6505 - val_soft_acc: 0.4057\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4319 - soft_acc: 0.7022 - val_loss: 0.4716 - val_soft_acc: 0.6493\n",
      "Epoch 89/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3768 - soft_acc: 0.7456 - val_loss: 0.4641 - val_soft_acc: 0.5393\n",
      "Epoch 90/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3917 - soft_acc: 0.6883 - val_loss: 0.4987 - val_soft_acc: 0.5886\n",
      "Epoch 91/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3506 - soft_acc: 0.7700best occur in epoch 90\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.3632 - soft_acc: 0.7583 - val_loss: 0.4961 - val_soft_acc: 0.6293\n",
      "Epoch 92/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3363 - soft_acc: 0.7900 - val_loss: 0.5296 - val_soft_acc: 0.5686\n",
      "Epoch 93/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3142 - soft_acc: 0.8100best occur in epoch 92\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3466 - soft_acc: 0.7867 - val_loss: 0.5020 - val_soft_acc: 0.6293\n",
      "Epoch 94/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3406 - soft_acc: 0.7889 - val_loss: 0.5620 - val_soft_acc: 0.5307\n",
      "Epoch 95/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3688 - soft_acc: 0.7300best occur in epoch 94\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3488 - soft_acc: 0.7772 - val_loss: 0.4888 - val_soft_acc: 0.6471\n",
      "Epoch 96/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3425 - soft_acc: 0.7944 - val_loss: 0.4814 - val_soft_acc: 0.5757\n",
      "Epoch 97/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3606 - soft_acc: 0.7528 - val_loss: 0.4635 - val_soft_acc: 0.5829\n",
      "Epoch 98/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4275 - soft_acc: 0.7283 - val_loss: 0.5129 - val_soft_acc: 0.5529\n",
      "Epoch 99/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3387 - soft_acc: 0.8100best occur in epoch 98\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.3531 - soft_acc: 0.7733 - val_loss: 0.4304 - val_soft_acc: 0.6779\n",
      "Epoch 100/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3799 - soft_acc: 0.6972 - val_loss: 0.4580 - val_soft_acc: 0.6314\n",
      "Epoch 101/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3633 - soft_acc: 0.7422 - val_loss: 0.4780 - val_soft_acc: 0.5221\n",
      "Epoch 102/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3224 - soft_acc: 0.7922 - val_loss: 0.6110 - val_soft_acc: 0.4336\n",
      "Epoch 103/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3340 - soft_acc: 0.7872 - val_loss: 0.5431 - val_soft_acc: 0.4943\n",
      "Epoch 104/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3338 - soft_acc: 0.7756 - val_loss: 0.5973 - val_soft_acc: 0.4621\n",
      "Epoch 105/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4496 - soft_acc: 0.6494 - val_loss: 0.5151 - val_soft_acc: 0.5886\n",
      "Epoch 106/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4241 - soft_acc: 0.6511 - val_loss: 0.4577 - val_soft_acc: 0.5779\n",
      "Epoch 107/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4083 - soft_acc: 0.7306 - val_loss: 0.4812 - val_soft_acc: 0.5629\n",
      "Epoch 108/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4417 - soft_acc: 0.6378 - val_loss: 0.4433 - val_soft_acc: 0.5700\n",
      "Epoch 109/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3421 - soft_acc: 0.7717 - val_loss: 0.6393 - val_soft_acc: 0.4314\n",
      "Epoch 110/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3696 - soft_acc: 0.7194 - val_loss: 0.6789 - val_soft_acc: 0.4243\n",
      "Epoch 111/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4432 - soft_acc: 0.6200best occur in epoch 110\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3680 - soft_acc: 0.7517 - val_loss: 0.4262 - val_soft_acc: 0.7029\n",
      "Epoch 112/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3247 - soft_acc: 0.7661 - val_loss: 0.4654 - val_soft_acc: 0.6650\n",
      "Epoch 113/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3187 - soft_acc: 0.7567 - val_loss: 0.4936 - val_soft_acc: 0.6343\n",
      "Epoch 114/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3033 - soft_acc: 0.7917 - val_loss: 0.5392 - val_soft_acc: 0.5129\n",
      "Epoch 115/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3265 - soft_acc: 0.7733 - val_loss: 0.5157 - val_soft_acc: 0.5707\n",
      "Epoch 116/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3388 - soft_acc: 0.8028 - val_loss: 0.4872 - val_soft_acc: 0.6093\n",
      "Epoch 117/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3696 - soft_acc: 0.7622 - val_loss: 0.4377 - val_soft_acc: 0.6286\n",
      "Epoch 118/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3429 - soft_acc: 0.8183 - val_loss: 0.5006 - val_soft_acc: 0.5421\n",
      "Epoch 119/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3230 - soft_acc: 0.7950 - val_loss: 0.4519 - val_soft_acc: 0.5986\n",
      "Epoch 120/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3630 - soft_acc: 0.7394 - val_loss: 0.4739 - val_soft_acc: 0.6243\n",
      "Epoch 121/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3211 - soft_acc: 0.7394 - val_loss: 0.5052 - val_soft_acc: 0.5964\n",
      "Epoch 122/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3237 - soft_acc: 0.8167 - val_loss: 0.5524 - val_soft_acc: 0.5179\n",
      "Epoch 123/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3259 - soft_acc: 0.7700 - val_loss: 0.6142 - val_soft_acc: 0.4336\n",
      "Epoch 124/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3158 - soft_acc: 0.7789 - val_loss: 0.5247 - val_soft_acc: 0.4993\n",
      "Epoch 125/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3299 - soft_acc: 0.8150 - val_loss: 0.5121 - val_soft_acc: 0.5043\n",
      "Epoch 126/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3270 - soft_acc: 0.8094 - val_loss: 0.6726 - val_soft_acc: 0.4493\n",
      "Epoch 127/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3181 - soft_acc: 0.7983 - val_loss: 0.5169 - val_soft_acc: 0.5914\n",
      "Epoch 128/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3509 - soft_acc: 0.7700best occur in epoch 127\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3177 - soft_acc: 0.8056 - val_loss: 0.4700 - val_soft_acc: 0.6521\n",
      "Epoch 129/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4649 - soft_acc: 0.6600 - val_loss: 0.5363 - val_soft_acc: 0.5486\n",
      "Epoch 130/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3391 - soft_acc: 0.7556 - val_loss: 0.5147 - val_soft_acc: 0.5071\n",
      "Epoch 131/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3597 - soft_acc: 0.7272 - val_loss: 0.4434 - val_soft_acc: 0.6621\n",
      "Epoch 132/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3659 - soft_acc: 0.7589 - val_loss: 0.4936 - val_soft_acc: 0.5836\n",
      "Epoch 133/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3440 - soft_acc: 0.7667 - val_loss: 0.5319 - val_soft_acc: 0.4943\n",
      "Epoch 134/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3874 - soft_acc: 0.7217 - val_loss: 0.4674 - val_soft_acc: 0.5936\n",
      "Epoch 135/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3762 - soft_acc: 0.7122 - val_loss: 0.5253 - val_soft_acc: 0.4943\n",
      "Epoch 136/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3553 - soft_acc: 0.7472 - val_loss: 0.4812 - val_soft_acc: 0.5500\n",
      "Epoch 137/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3337 - soft_acc: 0.7783 - val_loss: 0.5564 - val_soft_acc: 0.4793\n",
      "Epoch 138/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3273 - soft_acc: 0.8233 - val_loss: 0.4465 - val_soft_acc: 0.5700\n",
      "Epoch 139/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3815 - soft_acc: 0.7422 - val_loss: 0.5346 - val_soft_acc: 0.4664\n",
      "Epoch 140/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3454 - soft_acc: 0.7678 - val_loss: 0.6295 - val_soft_acc: 0.4464\n",
      "Epoch 141/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3541 - soft_acc: 0.7722 - val_loss: 0.5106 - val_soft_acc: 0.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3518 - soft_acc: 0.8050 - val_loss: 0.4582 - val_soft_acc: 0.5857\n",
      "Epoch 143/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2996 - soft_acc: 0.8289 - val_loss: 0.4735 - val_soft_acc: 0.5757\n",
      "Epoch 144/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2898 - soft_acc: 0.8400best occur in epoch 143\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3081 - soft_acc: 0.8139 - val_loss: 0.4271 - val_soft_acc: 0.6750\n",
      "Epoch 145/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3200 - soft_acc: 0.7939 - val_loss: 0.4375 - val_soft_acc: 0.6500\n",
      "Epoch 146/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2922 - soft_acc: 0.8256 - val_loss: 0.5064 - val_soft_acc: 0.5836\n",
      "Epoch 147/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2864 - soft_acc: 0.8133 - val_loss: 0.5835 - val_soft_acc: 0.5279\n",
      "Epoch 148/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2879 - soft_acc: 0.8011 - val_loss: 0.5520 - val_soft_acc: 0.5843\n",
      "Epoch 149/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3378 - soft_acc: 0.8011 - val_loss: 0.5970 - val_soft_acc: 0.5236\n",
      "Epoch 150/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3872 - soft_acc: 0.6894 - val_loss: 0.4516 - val_soft_acc: 0.6057\n",
      "Epoch 151/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3828 - soft_acc: 0.6850 - val_loss: 0.4412 - val_soft_acc: 0.6643\n",
      "Epoch 152/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3679 - soft_acc: 0.7583 - val_loss: 0.4351 - val_soft_acc: 0.6621\n",
      "Epoch 153/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3876 - soft_acc: 0.7339 - val_loss: 0.4473 - val_soft_acc: 0.6564\n",
      "Epoch 154/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3810 - soft_acc: 0.7228 - val_loss: 0.4793 - val_soft_acc: 0.5500\n",
      "Epoch 155/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3414 - soft_acc: 0.7344 - val_loss: 0.5954 - val_soft_acc: 0.4593\n",
      "Epoch 156/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3385 - soft_acc: 0.7922 - val_loss: 0.5519 - val_soft_acc: 0.4636\n",
      "Epoch 157/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3180 - soft_acc: 0.7606 - val_loss: 0.4520 - val_soft_acc: 0.6421\n",
      "Epoch 158/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3376 - soft_acc: 0.7722 - val_loss: 0.4538 - val_soft_acc: 0.6036\n",
      "Epoch 159/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2983 - soft_acc: 0.8000 - val_loss: 0.4413 - val_soft_acc: 0.6157\n",
      "Epoch 160/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3145 - soft_acc: 0.7917 - val_loss: 0.4488 - val_soft_acc: 0.6157\n",
      "Epoch 161/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3574 - soft_acc: 0.7022 - val_loss: 0.4919 - val_soft_acc: 0.5707\n",
      "Epoch 162/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3561 - soft_acc: 0.7589 - val_loss: 0.4748 - val_soft_acc: 0.6164\n",
      "Epoch 163/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3559 - soft_acc: 0.7606 - val_loss: 0.4748 - val_soft_acc: 0.5657\n",
      "Epoch 164/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3270 - soft_acc: 0.7767 - val_loss: 0.4593 - val_soft_acc: 0.6264\n",
      "Epoch 165/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3311 - soft_acc: 0.7978 - val_loss: 0.4718 - val_soft_acc: 0.5779\n",
      "Epoch 166/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3136 - soft_acc: 0.8122 - val_loss: 0.4726 - val_soft_acc: 0.6064\n",
      "Epoch 167/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3108 - soft_acc: 0.8106 - val_loss: 0.4816 - val_soft_acc: 0.5757\n",
      "Epoch 168/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3095 - soft_acc: 0.8172 - val_loss: 0.5897 - val_soft_acc: 0.5336\n",
      "Epoch 169/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3183 - soft_acc: 0.8106 - val_loss: 0.5899 - val_soft_acc: 0.4850\n",
      "Epoch 170/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3065 - soft_acc: 0.7583 - val_loss: 0.5058 - val_soft_acc: 0.5450\n",
      "Epoch 171/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3317 - soft_acc: 0.7856 - val_loss: 0.5279 - val_soft_acc: 0.5279\n",
      "Epoch 172/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3045 - soft_acc: 0.8300 - val_loss: 0.4964 - val_soft_acc: 0.5914\n",
      "Epoch 173/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2864 - soft_acc: 0.8367 - val_loss: 0.5372 - val_soft_acc: 0.5250\n",
      "Epoch 174/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2925 - soft_acc: 0.8261 - val_loss: 0.5683 - val_soft_acc: 0.5307\n",
      "Epoch 175/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3317 - soft_acc: 0.7733 - val_loss: 0.6874 - val_soft_acc: 0.4579\n",
      "Epoch 176/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3932 - soft_acc: 0.7217 - val_loss: 0.5845 - val_soft_acc: 0.4343\n",
      "Epoch 177/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3405 - soft_acc: 0.7589 - val_loss: 0.4519 - val_soft_acc: 0.6364\n",
      "Epoch 178/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3348 - soft_acc: 0.7633 - val_loss: 0.5101 - val_soft_acc: 0.5707\n",
      "Epoch 179/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3259 - soft_acc: 0.7833 - val_loss: 0.4694 - val_soft_acc: 0.6036\n",
      "Epoch 180/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2884 - soft_acc: 0.8300 - val_loss: 0.4524 - val_soft_acc: 0.6064\n",
      "Epoch 181/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2808 - soft_acc: 0.8289 - val_loss: 0.4518 - val_soft_acc: 0.6343\n",
      "Epoch 182/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3326 - soft_acc: 0.7717 - val_loss: 0.4546 - val_soft_acc: 0.5721\n",
      "Epoch 183/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3602 - soft_acc: 0.7417 - val_loss: 0.6271 - val_soft_acc: 0.4650\n",
      "Epoch 184/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3831 - soft_acc: 0.7494 - val_loss: 0.5982 - val_soft_acc: 0.5714\n",
      "Epoch 185/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2995 - soft_acc: 0.8289 - val_loss: 0.4924 - val_soft_acc: 0.5993\n",
      "Epoch 186/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3048 - soft_acc: 0.8222 - val_loss: 0.4596 - val_soft_acc: 0.6421\n",
      "Epoch 187/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3015 - soft_acc: 0.8206 - val_loss: 0.5830 - val_soft_acc: 0.5229\n",
      "Epoch 188/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3015 - soft_acc: 0.8067 - val_loss: 0.6281 - val_soft_acc: 0.4671\n",
      "Epoch 189/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2987 - soft_acc: 0.8378 - val_loss: 0.6341 - val_soft_acc: 0.4414\n",
      "Epoch 190/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2862 - soft_acc: 0.8256 - val_loss: 0.6617 - val_soft_acc: 0.4579\n",
      "Epoch 191/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3199 - soft_acc: 0.7906 - val_loss: 0.5085 - val_soft_acc: 0.5736\n",
      "Epoch 192/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3033 - soft_acc: 0.8300best occur in epoch 191\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2894 - soft_acc: 0.8411 - val_loss: 0.4590 - val_soft_acc: 0.7007\n",
      "Epoch 193/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3302 - soft_acc: 0.7922 - val_loss: 0.4656 - val_soft_acc: 0.6450\n",
      "Epoch 194/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2918 - soft_acc: 0.8344 - val_loss: 0.4902 - val_soft_acc: 0.5114\n",
      "Epoch 195/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2860 - soft_acc: 0.8617 - val_loss: 0.5321 - val_soft_acc: 0.5400\n",
      "Epoch 196/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2765 - soft_acc: 0.8306 - val_loss: 0.4745 - val_soft_acc: 0.6293\n",
      "Epoch 197/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3748 - soft_acc: 0.7456 - val_loss: 0.4462 - val_soft_acc: 0.6264\n",
      "Epoch 198/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3736 - soft_acc: 0.7456 - val_loss: 0.5059 - val_soft_acc: 0.6064\n",
      "Epoch 199/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3437 - soft_acc: 0.7511 - val_loss: 0.5548 - val_soft_acc: 0.4843\n",
      "Epoch 200/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3031 - soft_acc: 0.7756 - val_loss: 0.5027 - val_soft_acc: 0.5893\n",
      "Epoch 201/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3018 - soft_acc: 0.8111 - val_loss: 0.5530 - val_soft_acc: 0.5050\n",
      "Epoch 202/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2728 - soft_acc: 0.8456 - val_loss: 0.4981 - val_soft_acc: 0.5914\n",
      "Epoch 203/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2742 - soft_acc: 0.8256 - val_loss: 0.5417 - val_soft_acc: 0.4814\n",
      "Epoch 204/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2788 - soft_acc: 0.8450 - val_loss: 0.5745 - val_soft_acc: 0.5000\n",
      "Epoch 205/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3033 - soft_acc: 0.7983 - val_loss: 0.4405 - val_soft_acc: 0.6471\n",
      "Epoch 206/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2596 - soft_acc: 0.8489 - val_loss: 0.4708 - val_soft_acc: 0.5700\n",
      "Epoch 207/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2691 - soft_acc: 0.8144 - val_loss: 0.4931 - val_soft_acc: 0.5529\n",
      "Epoch 208/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2597 - soft_acc: 0.8611 - val_loss: 0.5024 - val_soft_acc: 0.5450\n",
      "Epoch 209/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2699 - soft_acc: 0.8733 - val_loss: 0.5305 - val_soft_acc: 0.5529\n",
      "Epoch 210/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2749 - soft_acc: 0.8272 - val_loss: 0.5067 - val_soft_acc: 0.5686\n",
      "Epoch 211/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2598 - soft_acc: 0.8539 - val_loss: 0.4884 - val_soft_acc: 0.5321\n",
      "Epoch 212/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2567 - soft_acc: 0.8578 - val_loss: 0.4683 - val_soft_acc: 0.6114\n",
      "Epoch 213/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2634 - soft_acc: 0.8711 - val_loss: 0.4962 - val_soft_acc: 0.5450\n",
      "Epoch 214/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2504 - soft_acc: 0.8733 - val_loss: 0.5291 - val_soft_acc: 0.4407\n",
      "Epoch 215/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2704 - soft_acc: 0.8456 - val_loss: 0.4471 - val_soft_acc: 0.6186\n",
      "Epoch 216/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2716 - soft_acc: 0.8478 - val_loss: 0.5090 - val_soft_acc: 0.6014\n",
      "Epoch 217/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2667 - soft_acc: 0.8406 - val_loss: 0.5705 - val_soft_acc: 0.5636\n",
      "Epoch 218/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2774 - soft_acc: 0.8483 - val_loss: 0.4492 - val_soft_acc: 0.5650\n",
      "Epoch 219/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2620 - soft_acc: 0.8678 - val_loss: 0.5356 - val_soft_acc: 0.5071\n",
      "Epoch 220/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2606 - soft_acc: 0.8300 - val_loss: 0.5093 - val_soft_acc: 0.5350\n",
      "Epoch 221/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2655 - soft_acc: 0.8217 - val_loss: 0.4433 - val_soft_acc: 0.6671\n",
      "Epoch 222/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2819 - soft_acc: 0.7867 - val_loss: 0.5132 - val_soft_acc: 0.4943\n",
      "Epoch 223/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3043 - soft_acc: 0.8000 - val_loss: 0.5373 - val_soft_acc: 0.5100\n",
      "Epoch 224/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2718 - soft_acc: 0.8422 - val_loss: 0.4557 - val_soft_acc: 0.6057\n",
      "Epoch 225/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3052 - soft_acc: 0.7928 - val_loss: 0.4709 - val_soft_acc: 0.6521\n",
      "Epoch 226/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3743 - soft_acc: 0.7417 - val_loss: 0.5188 - val_soft_acc: 0.5964\n",
      "Epoch 227/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3012 - soft_acc: 0.8228 - val_loss: 0.7081 - val_soft_acc: 0.3986\n",
      "Epoch 228/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4209 - soft_acc: 0.6911 - val_loss: 0.4850 - val_soft_acc: 0.5807\n",
      "Epoch 229/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3110 - soft_acc: 0.7833 - val_loss: 0.4450 - val_soft_acc: 0.6314\n",
      "Epoch 230/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2769 - soft_acc: 0.8633 - val_loss: 0.4608 - val_soft_acc: 0.6086\n",
      "Epoch 231/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2488 - soft_acc: 0.8556 - val_loss: 0.6490 - val_soft_acc: 0.4643\n",
      "Epoch 232/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2844 - soft_acc: 0.8239 - val_loss: 0.6112 - val_soft_acc: 0.5107\n",
      "Epoch 233/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3017 - soft_acc: 0.8000 - val_loss: 0.5253 - val_soft_acc: 0.5379\n",
      "Epoch 234/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2580 - soft_acc: 0.8367 - val_loss: 0.4863 - val_soft_acc: 0.5629\n",
      "Epoch 235/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2519 - soft_acc: 0.8539 - val_loss: 0.4713 - val_soft_acc: 0.6343\n",
      "Epoch 236/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2918 - soft_acc: 0.8139 - val_loss: 0.5085 - val_soft_acc: 0.5557\n",
      "Epoch 237/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2790 - soft_acc: 0.8289 - val_loss: 0.4339 - val_soft_acc: 0.6700\n",
      "Epoch 238/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3094 - soft_acc: 0.8278 - val_loss: 0.4415 - val_soft_acc: 0.5929\n",
      "Epoch 239/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3969 - soft_acc: 0.6878 - val_loss: 0.6828 - val_soft_acc: 0.3679\n",
      "Epoch 240/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4162 - soft_acc: 0.6794 - val_loss: 0.5097 - val_soft_acc: 0.5736\n",
      "Epoch 241/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4034 - soft_acc: 0.6622 - val_loss: 0.5004 - val_soft_acc: 0.5757\n",
      "Epoch 242/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3464 - soft_acc: 0.7794 - val_loss: 0.4364 - val_soft_acc: 0.6186\n",
      "Epoch 243/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3077 - soft_acc: 0.7778 - val_loss: 0.4655 - val_soft_acc: 0.6343\n",
      "Epoch 244/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2875 - soft_acc: 0.8239 - val_loss: 0.5662 - val_soft_acc: 0.5721\n",
      "Epoch 245/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2869 - soft_acc: 0.8189 - val_loss: 0.6367 - val_soft_acc: 0.4364\n",
      "Epoch 246/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3576 - soft_acc: 0.7744 - val_loss: 0.4926 - val_soft_acc: 0.6243\n",
      "Epoch 247/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3390 - soft_acc: 0.7694 - val_loss: 0.4696 - val_soft_acc: 0.6421\n",
      "Epoch 248/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3520 - soft_acc: 0.7278 - val_loss: 0.4426 - val_soft_acc: 0.5521\n",
      "Epoch 249/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3368 - soft_acc: 0.7617 - val_loss: 0.6942 - val_soft_acc: 0.3679\n",
      "Epoch 250/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3401 - soft_acc: 0.7739 - val_loss: 0.4683 - val_soft_acc: 0.5807\n",
      "Epoch 251/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2980 - soft_acc: 0.8361 - val_loss: 0.4588 - val_soft_acc: 0.6214\n",
      "Epoch 252/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2869 - soft_acc: 0.8344 - val_loss: 0.4747 - val_soft_acc: 0.5629\n",
      "Epoch 253/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2720 - soft_acc: 0.8333 - val_loss: 0.4523 - val_soft_acc: 0.5650\n",
      "Epoch 254/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2782 - soft_acc: 0.8494 - val_loss: 0.5020 - val_soft_acc: 0.5679\n",
      "Epoch 255/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2612 - soft_acc: 0.8594 - val_loss: 0.4477 - val_soft_acc: 0.5879\n",
      "Epoch 256/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2741 - soft_acc: 0.8539 - val_loss: 0.4244 - val_soft_acc: 0.5921\n",
      "Epoch 257/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2781 - soft_acc: 0.8528 - val_loss: 0.4715 - val_soft_acc: 0.5650\n",
      "Epoch 258/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2438 - soft_acc: 0.8711 - val_loss: 0.4910 - val_soft_acc: 0.5500\n",
      "Epoch 259/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2431 - soft_acc: 0.8644 - val_loss: 0.4575 - val_soft_acc: 0.6007\n",
      "Epoch 260/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2483 - soft_acc: 0.8833 - val_loss: 0.5185 - val_soft_acc: 0.5636\n",
      "Epoch 261/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2402 - soft_acc: 0.8656 - val_loss: 0.4960 - val_soft_acc: 0.6500\n",
      "Epoch 262/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2458 - soft_acc: 0.8400 - val_loss: 0.4981 - val_soft_acc: 0.5579\n",
      "Epoch 263/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2343 - soft_acc: 0.8606 - val_loss: 0.4747 - val_soft_acc: 0.5936\n",
      "Epoch 264/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2893 - soft_acc: 0.8294 - val_loss: 0.4556 - val_soft_acc: 0.5986\n",
      "Epoch 265/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2531 - soft_acc: 0.8578 - val_loss: 0.4654 - val_soft_acc: 0.6043\n",
      "Epoch 266/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2399 - soft_acc: 0.8644 - val_loss: 0.4670 - val_soft_acc: 0.6086\n",
      "Epoch 267/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3096 - soft_acc: 0.8350 - val_loss: 0.5703 - val_soft_acc: 0.5071\n",
      "Epoch 268/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2696 - soft_acc: 0.8128 - val_loss: 0.4685 - val_soft_acc: 0.6829\n",
      "Epoch 269/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2636 - soft_acc: 0.8500 - val_loss: 0.4916 - val_soft_acc: 0.5500\n",
      "Epoch 270/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2623 - soft_acc: 0.8678 - val_loss: 0.6167 - val_soft_acc: 0.4643\n",
      "Epoch 271/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2683 - soft_acc: 0.8717 - val_loss: 0.4834 - val_soft_acc: 0.5243\n",
      "Epoch 272/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2499 - soft_acc: 0.8833 - val_loss: 0.5980 - val_soft_acc: 0.5714\n",
      "Epoch 273/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2392 - soft_acc: 0.8678 - val_loss: 0.5232 - val_soft_acc: 0.5221\n",
      "Epoch 274/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2509 - soft_acc: 0.8539 - val_loss: 0.5231 - val_soft_acc: 0.6164\n",
      "Epoch 275/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2360 - soft_acc: 0.8950 - val_loss: 0.4722 - val_soft_acc: 0.5907\n",
      "Epoch 276/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2379 - soft_acc: 0.8739 - val_loss: 0.4622 - val_soft_acc: 0.5679\n",
      "Epoch 277/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2544 - soft_acc: 0.8633 - val_loss: 0.4562 - val_soft_acc: 0.6443\n",
      "Epoch 278/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2513 - soft_acc: 0.8661 - val_loss: 0.4628 - val_soft_acc: 0.6286\n",
      "Epoch 279/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3371 - soft_acc: 0.7772 - val_loss: 0.4795 - val_soft_acc: 0.5807\n",
      "Epoch 280/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2729 - soft_acc: 0.8028 - val_loss: 0.4385 - val_soft_acc: 0.6236\n",
      "Epoch 281/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2493 - soft_acc: 0.8144 - val_loss: 0.4712 - val_soft_acc: 0.5757\n",
      "Epoch 282/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2585 - soft_acc: 0.8167 - val_loss: 0.4964 - val_soft_acc: 0.5729\n",
      "Epoch 283/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2894 - soft_acc: 0.8483 - val_loss: 0.4811 - val_soft_acc: 0.6036\n",
      "Epoch 284/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2934 - soft_acc: 0.8111 - val_loss: 0.4654 - val_soft_acc: 0.5879\n",
      "Epoch 285/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2875 - soft_acc: 0.8306 - val_loss: 0.5066 - val_soft_acc: 0.6450\n",
      "Epoch 286/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3014 - soft_acc: 0.8300 - val_loss: 0.5583 - val_soft_acc: 0.5250\n",
      "Epoch 287/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2547 - soft_acc: 0.8472 - val_loss: 0.4651 - val_soft_acc: 0.6521\n",
      "Epoch 288/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2406 - soft_acc: 0.8694 - val_loss: 0.4768 - val_soft_acc: 0.5729\n",
      "Epoch 289/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2693 - soft_acc: 0.8394 - val_loss: 0.4756 - val_soft_acc: 0.6236\n",
      "Epoch 290/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2421 - soft_acc: 0.8794 - val_loss: 0.4803 - val_soft_acc: 0.5371\n",
      "Epoch 291/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2639 - soft_acc: 0.8544 - val_loss: 0.4712 - val_soft_acc: 0.5800\n",
      "Epoch 292/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2927 - soft_acc: 0.8400best occur in epoch 291\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.2406 - soft_acc: 0.8606 - val_loss: 0.4756 - val_soft_acc: 0.6907\n",
      "Epoch 293/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2944 - soft_acc: 0.8367 - val_loss: 0.5236 - val_soft_acc: 0.6143\n",
      "Epoch 294/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2827 - soft_acc: 0.8250 - val_loss: 0.5314 - val_soft_acc: 0.5529\n",
      "Epoch 295/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2564 - soft_acc: 0.8589 - val_loss: 0.4969 - val_soft_acc: 0.4836\n",
      "Epoch 296/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2254 - soft_acc: 0.8756 - val_loss: 0.4583 - val_soft_acc: 0.5629\n",
      "Epoch 297/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2415 - soft_acc: 0.8711 - val_loss: 0.4677 - val_soft_acc: 0.6629\n",
      "Epoch 298/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2348 - soft_acc: 0.8322 - val_loss: 0.6268 - val_soft_acc: 0.4800\n",
      "Epoch 299/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3216 - soft_acc: 0.8094 - val_loss: 0.4444 - val_soft_acc: 0.6007\n",
      "Epoch 300/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2685 - soft_acc: 0.8217 - val_loss: 0.4473 - val_soft_acc: 0.6314\n",
      "Epoch 301/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2529 - soft_acc: 0.8678 - val_loss: 0.5078 - val_soft_acc: 0.5757\n",
      "Epoch 302/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2661 - soft_acc: 0.8750 - val_loss: 0.5138 - val_soft_acc: 0.4893\n",
      "Epoch 303/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2426 - soft_acc: 0.8278 - val_loss: 0.6052 - val_soft_acc: 0.4614\n",
      "Epoch 304/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3152 - soft_acc: 0.7728 - val_loss: 0.4904 - val_soft_acc: 0.5550\n",
      "Epoch 305/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2456 - soft_acc: 0.8917 - val_loss: 0.4957 - val_soft_acc: 0.5350\n",
      "Epoch 306/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2418 - soft_acc: 0.8533 - val_loss: 0.4319 - val_soft_acc: 0.6050\n",
      "Epoch 307/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2643 - soft_acc: 0.8472 - val_loss: 0.5502 - val_soft_acc: 0.5814\n",
      "Epoch 308/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2668 - soft_acc: 0.8606 - val_loss: 0.4463 - val_soft_acc: 0.6107\n",
      "Epoch 309/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2638 - soft_acc: 0.8733 - val_loss: 0.5203 - val_soft_acc: 0.4736\n",
      "Epoch 310/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2987 - soft_acc: 0.8228 - val_loss: 0.4311 - val_soft_acc: 0.6079\n",
      "Epoch 311/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3245 - soft_acc: 0.7817 - val_loss: 0.4571 - val_soft_acc: 0.5986\n",
      "Epoch 312/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2840 - soft_acc: 0.8167 - val_loss: 0.5390 - val_soft_acc: 0.5400\n",
      "Epoch 313/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2635 - soft_acc: 0.8572 - val_loss: 0.4472 - val_soft_acc: 0.6036\n",
      "Epoch 314/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2412 - soft_acc: 0.8811 - val_loss: 0.4820 - val_soft_acc: 0.6064\n",
      "Epoch 315/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2379 - soft_acc: 0.8722 - val_loss: 0.4741 - val_soft_acc: 0.5629\n",
      "Epoch 316/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2276 - soft_acc: 0.8811 - val_loss: 0.4745 - val_soft_acc: 0.5779\n",
      "Epoch 317/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2231 - soft_acc: 0.8828 - val_loss: 0.5000 - val_soft_acc: 0.6036\n",
      "Epoch 318/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2354 - soft_acc: 0.8694 - val_loss: 0.5173 - val_soft_acc: 0.5500\n",
      "Epoch 319/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2143 - soft_acc: 0.9000 - val_loss: 0.5138 - val_soft_acc: 0.5657\n",
      "Epoch 320/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2283 - soft_acc: 0.8894 - val_loss: 0.5656 - val_soft_acc: 0.5629\n",
      "Epoch 321/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2299 - soft_acc: 0.8639 - val_loss: 0.5040 - val_soft_acc: 0.6164\n",
      "Epoch 322/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2712 - soft_acc: 0.8528 - val_loss: 0.6302 - val_soft_acc: 0.4514\n",
      "Epoch 323/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2973 - soft_acc: 0.8050 - val_loss: 0.5977 - val_soft_acc: 0.5536\n",
      "Epoch 324/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2898 - soft_acc: 0.8000 - val_loss: 0.5737 - val_soft_acc: 0.5557\n",
      "Epoch 325/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2758 - soft_acc: 0.8406 - val_loss: 0.5064 - val_soft_acc: 0.6450\n",
      "Epoch 326/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2816 - soft_acc: 0.8256 - val_loss: 0.4674 - val_soft_acc: 0.5957\n",
      "Epoch 327/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2823 - soft_acc: 0.8361 - val_loss: 0.4576 - val_soft_acc: 0.5286\n",
      "Epoch 328/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2268 - soft_acc: 0.8878 - val_loss: 0.4937 - val_soft_acc: 0.5421\n",
      "Epoch 329/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2741 - soft_acc: 0.8194 - val_loss: 0.4687 - val_soft_acc: 0.5779\n",
      "Epoch 330/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2517 - soft_acc: 0.8911 - val_loss: 0.6073 - val_soft_acc: 0.5357\n",
      "Epoch 331/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3185 - soft_acc: 0.8006 - val_loss: 0.5457 - val_soft_acc: 0.5171\n",
      "Epoch 332/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2689 - soft_acc: 0.8322 - val_loss: 0.4856 - val_soft_acc: 0.5807\n",
      "Epoch 333/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3006 - soft_acc: 0.8450 - val_loss: 0.4835 - val_soft_acc: 0.5757\n",
      "Epoch 334/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2513 - soft_acc: 0.8728 - val_loss: 0.4771 - val_soft_acc: 0.5550\n",
      "Epoch 335/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2412 - soft_acc: 0.8606 - val_loss: 0.4913 - val_soft_acc: 0.5757\n",
      "Epoch 336/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2501 - soft_acc: 0.8833 - val_loss: 0.4987 - val_soft_acc: 0.5993\n",
      "Epoch 337/1000\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.2232 - soft_acc: 0.8628 - val_loss: 0.4639 - val_soft_acc: 0.5579\n",
      "Epoch 338/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2651 - soft_acc: 0.8444 - val_loss: 0.4998 - val_soft_acc: 0.5400\n",
      "Epoch 339/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2605 - soft_acc: 0.8461 - val_loss: 0.5648 - val_soft_acc: 0.4714\n",
      "Epoch 340/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2201 - soft_acc: 0.8806 - val_loss: 0.5315 - val_soft_acc: 0.5607\n",
      "Epoch 341/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2388 - soft_acc: 0.8711 - val_loss: 0.5595 - val_soft_acc: 0.5507\n",
      "Epoch 342/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2204 - soft_acc: 0.8961 - val_loss: 0.4439 - val_soft_acc: 0.6471\n",
      "Epoch 343/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2449 - soft_acc: 0.8828 - val_loss: 0.4672 - val_soft_acc: 0.6064\n",
      "Epoch 344/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2366 - soft_acc: 0.8967 - val_loss: 0.4845 - val_soft_acc: 0.5657\n",
      "Epoch 345/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2490 - soft_acc: 0.8678 - val_loss: 0.4950 - val_soft_acc: 0.5550\n",
      "Epoch 346/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2323 - soft_acc: 0.8811 - val_loss: 0.5312 - val_soft_acc: 0.5300\n",
      "Epoch 347/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2278 - soft_acc: 0.8933 - val_loss: 0.5572 - val_soft_acc: 0.5786\n",
      "Epoch 348/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2235 - soft_acc: 0.8806 - val_loss: 0.4579 - val_soft_acc: 0.5571\n",
      "Epoch 349/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2213 - soft_acc: 0.8917 - val_loss: 0.4946 - val_soft_acc: 0.5936\n",
      "Epoch 350/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3001 - soft_acc: 0.8278 - val_loss: 0.4753 - val_soft_acc: 0.5421\n",
      "Epoch 351/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3029 - soft_acc: 0.8106 - val_loss: 0.5034 - val_soft_acc: 0.5707\n",
      "Epoch 352/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2564 - soft_acc: 0.8594 - val_loss: 0.6116 - val_soft_acc: 0.5229\n",
      "Epoch 353/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2720 - soft_acc: 0.8406 - val_loss: 0.5326 - val_soft_acc: 0.5664\n",
      "Epoch 354/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2800 - soft_acc: 0.8333 - val_loss: 0.5306 - val_soft_acc: 0.4964\n",
      "Epoch 355/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2809 - soft_acc: 0.8344 - val_loss: 0.4763 - val_soft_acc: 0.5729\n",
      "Epoch 356/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2817 - soft_acc: 0.8600 - val_loss: 0.4682 - val_soft_acc: 0.6293\n",
      "Epoch 357/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2336 - soft_acc: 0.8622 - val_loss: 0.4904 - val_soft_acc: 0.5629\n",
      "Epoch 358/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2294 - soft_acc: 0.8533 - val_loss: 0.4498 - val_soft_acc: 0.6593\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2245 - soft_acc: 0.8756 - val_loss: 0.5025 - val_soft_acc: 0.5836\n",
      "Epoch 360/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2167 - soft_acc: 0.8700 - val_loss: 0.4747 - val_soft_acc: 0.6493\n",
      "Epoch 361/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2229 - soft_acc: 0.8856 - val_loss: 0.4583 - val_soft_acc: 0.5679\n",
      "Epoch 362/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2414 - soft_acc: 0.8728 - val_loss: 0.4825 - val_soft_acc: 0.6264\n",
      "Epoch 363/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2627 - soft_acc: 0.8439 - val_loss: 0.4640 - val_soft_acc: 0.6871\n",
      "Epoch 364/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2373 - soft_acc: 0.8794 - val_loss: 0.5946 - val_soft_acc: 0.5000\n",
      "Epoch 365/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2501 - soft_acc: 0.8422 - val_loss: 0.4723 - val_soft_acc: 0.5343\n",
      "Epoch 366/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2309 - soft_acc: 0.8806 - val_loss: 0.5315 - val_soft_acc: 0.5486\n",
      "Epoch 367/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2194 - soft_acc: 0.9033 - val_loss: 0.5379 - val_soft_acc: 0.5179\n",
      "Epoch 368/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2213 - soft_acc: 0.8911 - val_loss: 0.5235 - val_soft_acc: 0.5329\n",
      "Epoch 369/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2206 - soft_acc: 0.8789 - val_loss: 0.6096 - val_soft_acc: 0.4236\n",
      "Epoch 370/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2297 - soft_acc: 0.8844 - val_loss: 0.5363 - val_soft_acc: 0.6043\n",
      "Epoch 371/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2419 - soft_acc: 0.8589 - val_loss: 0.5576 - val_soft_acc: 0.4771\n",
      "Epoch 372/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2282 - soft_acc: 0.9133 - val_loss: 0.4531 - val_soft_acc: 0.6314\n",
      "Epoch 373/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2267 - soft_acc: 0.8900 - val_loss: 0.5219 - val_soft_acc: 0.5864\n",
      "Epoch 374/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2109 - soft_acc: 0.8683 - val_loss: 0.4754 - val_soft_acc: 0.5500\n",
      "Epoch 375/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2344 - soft_acc: 0.8778 - val_loss: 0.4617 - val_soft_acc: 0.5679\n",
      "Epoch 376/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2165 - soft_acc: 0.9033 - val_loss: 0.5056 - val_soft_acc: 0.5450\n",
      "Epoch 377/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2039 - soft_acc: 0.8783 - val_loss: 0.5112 - val_soft_acc: 0.5864\n",
      "Epoch 378/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2060 - soft_acc: 0.8822 - val_loss: 0.5394 - val_soft_acc: 0.6200\n",
      "Epoch 379/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2037 - soft_acc: 0.8578 - val_loss: 0.4886 - val_soft_acc: 0.5907\n",
      "Epoch 380/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2270 - soft_acc: 0.9000 - val_loss: 0.4677 - val_soft_acc: 0.6036\n",
      "Epoch 381/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2120 - soft_acc: 0.9083 - val_loss: 0.5077 - val_soft_acc: 0.5529\n",
      "Epoch 382/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2182 - soft_acc: 0.8994 - val_loss: 0.5142 - val_soft_acc: 0.5707\n",
      "Epoch 383/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2151 - soft_acc: 0.8789 - val_loss: 0.7110 - val_soft_acc: 0.4550\n",
      "Epoch 384/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2870 - soft_acc: 0.8011 - val_loss: 0.5176 - val_soft_acc: 0.5250\n",
      "Epoch 385/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2349 - soft_acc: 0.8778 - val_loss: 0.5293 - val_soft_acc: 0.5479\n",
      "Epoch 386/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2368 - soft_acc: 0.8894 - val_loss: 0.4636 - val_soft_acc: 0.5779\n",
      "Epoch 387/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2277 - soft_acc: 0.8772 - val_loss: 0.6209 - val_soft_acc: 0.4150\n",
      "Epoch 388/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2501 - soft_acc: 0.8606 - val_loss: 0.5410 - val_soft_acc: 0.5786\n",
      "Epoch 389/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2735 - soft_acc: 0.8250 - val_loss: 0.5325 - val_soft_acc: 0.5636\n",
      "Epoch 390/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2724 - soft_acc: 0.8422 - val_loss: 0.4875 - val_soft_acc: 0.5500\n",
      "Epoch 391/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2167 - soft_acc: 0.8978 - val_loss: 0.4602 - val_soft_acc: 0.6193\n",
      "Epoch 392/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2420 - soft_acc: 0.8850 - val_loss: 0.5213 - val_soft_acc: 0.5143\n",
      "Epoch 393/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2176 - soft_acc: 0.8844 - val_loss: 0.4803 - val_soft_acc: 0.5936\n",
      "Epoch 394/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2161 - soft_acc: 0.8806 - val_loss: 0.5258 - val_soft_acc: 0.5964\n",
      "Epoch 395/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2288 - soft_acc: 0.8772 - val_loss: 0.4491 - val_soft_acc: 0.6364\n",
      "Epoch 396/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2283 - soft_acc: 0.8983 - val_loss: 0.4979 - val_soft_acc: 0.6243\n",
      "Epoch 397/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2355 - soft_acc: 0.8794 - val_loss: 0.4624 - val_soft_acc: 0.6314\n",
      "Epoch 398/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2511 - soft_acc: 0.8717 - val_loss: 0.4948 - val_soft_acc: 0.5757\n",
      "Epoch 399/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2200 - soft_acc: 0.8633 - val_loss: 0.4729 - val_soft_acc: 0.6243\n",
      "Epoch 400/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2232 - soft_acc: 0.8944 - val_loss: 0.5123 - val_soft_acc: 0.5121\n",
      "Epoch 401/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2755 - soft_acc: 0.8489 - val_loss: 0.5403 - val_soft_acc: 0.5300\n",
      "Epoch 402/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2697 - soft_acc: 0.8683 - val_loss: 0.6599 - val_soft_acc: 0.5036\n",
      "Epoch 403/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3311 - soft_acc: 0.8006 - val_loss: 0.5854 - val_soft_acc: 0.5457\n",
      "Epoch 404/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3153 - soft_acc: 0.7700 - val_loss: 0.4747 - val_soft_acc: 0.5350\n",
      "Epoch 405/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2829 - soft_acc: 0.8717 - val_loss: 0.4769 - val_soft_acc: 0.5500\n",
      "Epoch 406/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2224 - soft_acc: 0.8861 - val_loss: 0.5036 - val_soft_acc: 0.5450\n",
      "Epoch 407/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2714 - soft_acc: 0.9100best occur in epoch 406\n",
      "512/512 [==============================] - 0s 69us/sample - loss: 0.2366 - soft_acc: 0.9083 - val_loss: 0.4533 - val_soft_acc: 0.6443\n",
      "Epoch 408/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2160 - soft_acc: 0.8872 - val_loss: 0.5878 - val_soft_acc: 0.5357\n",
      "Epoch 409/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2217 - soft_acc: 0.8839 - val_loss: 0.4586 - val_soft_acc: 0.6293\n",
      "Epoch 410/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2124 - soft_acc: 0.9011 - val_loss: 0.4899 - val_soft_acc: 0.6014\n",
      "Epoch 411/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2377 - soft_acc: 0.8411 - val_loss: 0.4713 - val_soft_acc: 0.6264\n",
      "Epoch 412/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2135 - soft_acc: 0.8878 - val_loss: 0.5974 - val_soft_acc: 0.5586\n",
      "Epoch 413/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2347 - soft_acc: 0.8867 - val_loss: 0.4743 - val_soft_acc: 0.5986\n",
      "Epoch 414/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2073 - soft_acc: 0.8611 - val_loss: 0.5814 - val_soft_acc: 0.5179\n",
      "Epoch 415/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2183 - soft_acc: 0.8839 - val_loss: 0.4684 - val_soft_acc: 0.5679\n",
      "Epoch 416/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2149 - soft_acc: 0.8906 - val_loss: 0.5349 - val_soft_acc: 0.5200\n",
      "Epoch 417/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2119 - soft_acc: 0.8544 - val_loss: 0.4852 - val_soft_acc: 0.6114\n",
      "Epoch 418/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2098 - soft_acc: 0.8872 - val_loss: 0.5318 - val_soft_acc: 0.5864\n",
      "Epoch 419/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2003 - soft_acc: 0.8733 - val_loss: 0.4397 - val_soft_acc: 0.5907\n",
      "Epoch 420/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2766 - soft_acc: 0.8411 - val_loss: 0.4894 - val_soft_acc: 0.5914\n",
      "Epoch 421/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2084 - soft_acc: 0.8661 - val_loss: 0.6108 - val_soft_acc: 0.5357\n",
      "Epoch 422/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2111 - soft_acc: 0.8856 - val_loss: 0.4725 - val_soft_acc: 0.6057\n",
      "Epoch 423/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1900 - soft_acc: 0.8956 - val_loss: 0.4931 - val_soft_acc: 0.6114\n",
      "Epoch 424/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1995 - soft_acc: 0.8939 - val_loss: 0.4523 - val_soft_acc: 0.6157\n",
      "Epoch 425/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2187 - soft_acc: 0.9033 - val_loss: 0.5590 - val_soft_acc: 0.4793\n",
      "Epoch 426/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2302 - soft_acc: 0.8828 - val_loss: 0.5232 - val_soft_acc: 0.5607\n",
      "Epoch 427/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2050 - soft_acc: 0.8956 - val_loss: 0.5998 - val_soft_acc: 0.4921\n",
      "Epoch 428/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2407 - soft_acc: 0.8617 - val_loss: 0.5207 - val_soft_acc: 0.5507\n",
      "Epoch 429/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2197 - soft_acc: 0.8933 - val_loss: 0.5241 - val_soft_acc: 0.6021\n",
      "Epoch 430/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2500 - soft_acc: 0.8367 - val_loss: 0.4705 - val_soft_acc: 0.5293\n",
      "Epoch 431/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2528 - soft_acc: 0.8711 - val_loss: 0.4930 - val_soft_acc: 0.6071\n",
      "Epoch 432/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3168 - soft_acc: 0.7383 - val_loss: 0.5352 - val_soft_acc: 0.5407\n",
      "Epoch 433/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2634 - soft_acc: 0.8456 - val_loss: 0.6684 - val_soft_acc: 0.4779\n",
      "Epoch 434/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2803 - soft_acc: 0.8422 - val_loss: 0.4866 - val_soft_acc: 0.5729\n",
      "Epoch 435/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2721 - soft_acc: 0.8044 - val_loss: 0.4880 - val_soft_acc: 0.6114\n",
      "Epoch 436/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2592 - soft_acc: 0.8622 - val_loss: 0.4770 - val_soft_acc: 0.5529\n",
      "Epoch 437/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2453 - soft_acc: 0.8689 - val_loss: 0.4930 - val_soft_acc: 0.5171\n",
      "Epoch 438/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2593 - soft_acc: 0.8678 - val_loss: 0.5005 - val_soft_acc: 0.5579\n",
      "Epoch 439/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1993 - soft_acc: 0.8994 - val_loss: 0.5267 - val_soft_acc: 0.5250\n",
      "Epoch 440/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2100 - soft_acc: 0.8994 - val_loss: 0.4861 - val_soft_acc: 0.6293\n",
      "Epoch 441/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1988 - soft_acc: 0.9117 - val_loss: 0.5135 - val_soft_acc: 0.5657\n",
      "Epoch 442/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1977 - soft_acc: 0.9117 - val_loss: 0.4959 - val_soft_acc: 0.5986\n",
      "Epoch 443/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2019 - soft_acc: 0.8889 - val_loss: 0.4674 - val_soft_acc: 0.6550\n",
      "Epoch 444/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2205 - soft_acc: 0.8994 - val_loss: 0.5319 - val_soft_acc: 0.5071\n",
      "Epoch 445/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2866 - soft_acc: 0.8256 - val_loss: 0.5363 - val_soft_acc: 0.5250\n",
      "Epoch 446/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2105 - soft_acc: 0.8872 - val_loss: 0.5577 - val_soft_acc: 0.5021\n",
      "Epoch 447/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2024 - soft_acc: 0.8783 - val_loss: 0.4824 - val_soft_acc: 0.6164\n",
      "Epoch 448/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1829 - soft_acc: 0.9233 - val_loss: 0.5180 - val_soft_acc: 0.4921\n",
      "Epoch 449/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1883 - soft_acc: 0.8817 - val_loss: 0.4922 - val_soft_acc: 0.5886\n",
      "Epoch 450/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1896 - soft_acc: 0.9217 - val_loss: 0.5006 - val_soft_acc: 0.5371\n",
      "Epoch 451/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1922 - soft_acc: 0.9028 - val_loss: 0.5050 - val_soft_acc: 0.6400\n",
      "Epoch 452/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2108 - soft_acc: 0.8839 - val_loss: 0.5132 - val_soft_acc: 0.5636\n",
      "Epoch 453/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1878 - soft_acc: 0.9217 - val_loss: 0.5200 - val_soft_acc: 0.5429\n",
      "Epoch 454/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1960 - soft_acc: 0.8678 - val_loss: 0.4850 - val_soft_acc: 0.5657\n",
      "Epoch 455/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2281 - soft_acc: 0.9133 - val_loss: 0.4876 - val_soft_acc: 0.6014\n",
      "Epoch 456/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2537 - soft_acc: 0.8483 - val_loss: 0.5207 - val_soft_acc: 0.5914\n",
      "Epoch 457/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2744 - soft_acc: 0.8394 - val_loss: 0.6505 - val_soft_acc: 0.5107\n",
      "Epoch 458/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2668 - soft_acc: 0.8733 - val_loss: 0.5187 - val_soft_acc: 0.6121\n",
      "Epoch 459/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2113 - soft_acc: 0.8856 - val_loss: 0.5263 - val_soft_acc: 0.5943\n",
      "Epoch 460/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2069 - soft_acc: 0.8806 - val_loss: 0.5253 - val_soft_acc: 0.5500\n",
      "Epoch 461/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2104 - soft_acc: 0.8700 - val_loss: 0.5903 - val_soft_acc: 0.4179\n",
      "Epoch 462/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2094 - soft_acc: 0.8789 - val_loss: 0.5293 - val_soft_acc: 0.5536\n",
      "Epoch 463/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2234 - soft_acc: 0.8928 - val_loss: 0.6391 - val_soft_acc: 0.5086\n",
      "Epoch 464/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2219 - soft_acc: 0.9083 - val_loss: 0.4694 - val_soft_acc: 0.6293\n",
      "Epoch 465/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2238 - soft_acc: 0.8583 - val_loss: 0.5827 - val_soft_acc: 0.5407\n",
      "Epoch 466/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2205 - soft_acc: 0.9133 - val_loss: 0.4691 - val_soft_acc: 0.6136\n",
      "Epoch 467/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2083 - soft_acc: 0.8789 - val_loss: 0.5179 - val_soft_acc: 0.6200\n",
      "Epoch 468/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2356 - soft_acc: 0.8983 - val_loss: 0.4804 - val_soft_acc: 0.6321\n",
      "Epoch 469/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2573 - soft_acc: 0.8611 - val_loss: 0.5672 - val_soft_acc: 0.5607\n",
      "Epoch 470/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2457 - soft_acc: 0.8583 - val_loss: 0.6007 - val_soft_acc: 0.5457\n",
      "Epoch 471/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2228 - soft_acc: 0.8822 - val_loss: 0.4969 - val_soft_acc: 0.6086\n",
      "Epoch 472/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2228 - soft_acc: 0.8572 - val_loss: 0.5286 - val_soft_acc: 0.5179\n",
      "Epoch 473/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2073 - soft_acc: 0.9083 - val_loss: 0.4955 - val_soft_acc: 0.5600\n",
      "Epoch 474/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1910 - soft_acc: 0.9194 - val_loss: 0.4854 - val_soft_acc: 0.5986\n",
      "Epoch 475/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1987 - soft_acc: 0.9133 - val_loss: 0.4632 - val_soft_acc: 0.5343\n",
      "Epoch 476/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2303 - soft_acc: 0.8978 - val_loss: 0.4539 - val_soft_acc: 0.6086\n",
      "Epoch 477/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2649 - soft_acc: 0.8800 - val_loss: 0.5663 - val_soft_acc: 0.4900\n",
      "Epoch 478/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2232 - soft_acc: 0.8822 - val_loss: 0.4723 - val_soft_acc: 0.5550\n",
      "Epoch 479/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2247 - soft_acc: 0.9033 - val_loss: 0.6115 - val_soft_acc: 0.5514\n",
      "Epoch 480/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2116 - soft_acc: 0.9078 - val_loss: 0.5055 - val_soft_acc: 0.5786\n",
      "Epoch 481/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2048 - soft_acc: 0.8733 - val_loss: 0.4758 - val_soft_acc: 0.5600\n",
      "Epoch 482/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1995 - soft_acc: 0.8572 - val_loss: 0.5372 - val_soft_acc: 0.5171\n",
      "Epoch 483/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2017 - soft_acc: 0.9028 - val_loss: 0.4868 - val_soft_acc: 0.6014\n",
      "Epoch 484/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2077 - soft_acc: 0.9078 - val_loss: 0.5139 - val_soft_acc: 0.4993\n",
      "Epoch 485/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1789 - soft_acc: 0.9317 - val_loss: 0.5278 - val_soft_acc: 0.5071\n",
      "Epoch 486/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1769 - soft_acc: 0.9300 - val_loss: 0.5188 - val_soft_acc: 0.5529\n",
      "Epoch 487/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1741 - soft_acc: 0.9367 - val_loss: 0.5726 - val_soft_acc: 0.5329\n",
      "Epoch 488/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1873 - soft_acc: 0.9283 - val_loss: 0.4853 - val_soft_acc: 0.6014\n",
      "Epoch 489/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1877 - soft_acc: 0.8833 - val_loss: 0.5522 - val_soft_acc: 0.4893\n",
      "Epoch 490/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1759 - soft_acc: 0.9178 - val_loss: 0.4964 - val_soft_acc: 0.5829\n",
      "Epoch 491/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1891 - soft_acc: 0.9100best occur in epoch 490\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2015 - soft_acc: 0.9267 - val_loss: 0.4640 - val_soft_acc: 0.6471\n",
      "Epoch 492/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2163 - soft_acc: 0.8717 - val_loss: 0.5091 - val_soft_acc: 0.5300\n",
      "Epoch 493/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2372 - soft_acc: 0.8678 - val_loss: 0.5409 - val_soft_acc: 0.5150\n",
      "Epoch 494/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2105 - soft_acc: 0.8928 - val_loss: 0.5589 - val_soft_acc: 0.4921\n",
      "Epoch 495/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2168 - soft_acc: 0.8961 - val_loss: 0.5464 - val_soft_acc: 0.5050\n",
      "Epoch 496/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1993 - soft_acc: 0.9006 - val_loss: 0.6272 - val_soft_acc: 0.5079\n",
      "Epoch 497/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2321 - soft_acc: 0.8606 - val_loss: 0.5737 - val_soft_acc: 0.5764\n",
      "Epoch 498/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1909 - soft_acc: 0.9283 - val_loss: 0.5159 - val_soft_acc: 0.5629\n",
      "Epoch 499/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1756 - soft_acc: 0.9317 - val_loss: 0.5555 - val_soft_acc: 0.5814\n",
      "Epoch 500/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1753 - soft_acc: 0.9161 - val_loss: 0.5399 - val_soft_acc: 0.5964\n",
      "Epoch 501/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2033 - soft_acc: 0.8767 - val_loss: 0.6411 - val_soft_acc: 0.4800\n",
      "Epoch 502/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2231 - soft_acc: 0.8961 - val_loss: 0.5707 - val_soft_acc: 0.4843\n",
      "Epoch 503/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2192 - soft_acc: 0.9150 - val_loss: 0.5633 - val_soft_acc: 0.5664\n",
      "Epoch 504/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2588 - soft_acc: 0.8461 - val_loss: 0.5004 - val_soft_acc: 0.6193\n",
      "Epoch 505/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1819 - soft_acc: 0.9267 - val_loss: 0.5142 - val_soft_acc: 0.5050\n",
      "Epoch 506/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1887 - soft_acc: 0.8750 - val_loss: 0.4857 - val_soft_acc: 0.5679\n",
      "Epoch 507/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2329 - soft_acc: 0.8633 - val_loss: 0.4976 - val_soft_acc: 0.5936\n",
      "Epoch 508/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2428 - soft_acc: 0.8483 - val_loss: 0.5869 - val_soft_acc: 0.5486\n",
      "Epoch 509/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2563 - soft_acc: 0.8317 - val_loss: 0.5107 - val_soft_acc: 0.5786\n",
      "Epoch 510/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2493 - soft_acc: 0.8883 - val_loss: 0.5656 - val_soft_acc: 0.5100\n",
      "Epoch 511/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2313 - soft_acc: 0.9033 - val_loss: 0.5804 - val_soft_acc: 0.5129\n",
      "Epoch 512/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2238 - soft_acc: 0.8994 - val_loss: 0.4759 - val_soft_acc: 0.5529\n",
      "Epoch 513/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2202 - soft_acc: 0.9011 - val_loss: 0.5128 - val_soft_acc: 0.5400\n",
      "Epoch 514/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1949 - soft_acc: 0.8694 - val_loss: 0.4757 - val_soft_acc: 0.5679\n",
      "Epoch 515/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1944 - soft_acc: 0.9283 - val_loss: 0.5163 - val_soft_acc: 0.5686\n",
      "Epoch 516/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1854 - soft_acc: 0.9300best occur in epoch 515\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1805 - soft_acc: 0.9383 - val_loss: 0.4563 - val_soft_acc: 0.6750\n",
      "Epoch 517/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2088 - soft_acc: 0.8789 - val_loss: 0.4772 - val_soft_acc: 0.5729\n",
      "Epoch 518/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2552 - soft_acc: 0.8406 - val_loss: 0.4568 - val_soft_acc: 0.5907\n",
      "Epoch 519/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2546 - soft_acc: 0.8472 - val_loss: 0.5572 - val_soft_acc: 0.5686\n",
      "Epoch 520/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2179 - soft_acc: 0.8711 - val_loss: 0.5063 - val_soft_acc: 0.5243\n",
      "Epoch 521/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1852 - soft_acc: 0.9106 - val_loss: 0.5443 - val_soft_acc: 0.5221\n",
      "Epoch 522/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2153 - soft_acc: 0.9094 - val_loss: 0.5826 - val_soft_acc: 0.5179\n",
      "Epoch 523/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2277 - soft_acc: 0.8867 - val_loss: 0.5531 - val_soft_acc: 0.5250\n",
      "Epoch 524/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2066 - soft_acc: 0.8994 - val_loss: 0.4560 - val_soft_acc: 0.6057\n",
      "Epoch 525/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1907 - soft_acc: 0.9178 - val_loss: 0.5221 - val_soft_acc: 0.5350\n",
      "Epoch 526/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1933 - soft_acc: 0.9311 - val_loss: 0.5240 - val_soft_acc: 0.5629\n",
      "Epoch 527/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2196 - soft_acc: 0.8789 - val_loss: 0.4910 - val_soft_acc: 0.5686\n",
      "Epoch 528/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1933 - soft_acc: 0.9250 - val_loss: 0.5146 - val_soft_acc: 0.6171\n",
      "Epoch 529/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1854 - soft_acc: 0.8867 - val_loss: 0.5203 - val_soft_acc: 0.5807\n",
      "Epoch 530/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1840 - soft_acc: 0.9367 - val_loss: 0.4642 - val_soft_acc: 0.5657\n",
      "Epoch 531/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1821 - soft_acc: 0.9211 - val_loss: 0.5612 - val_soft_acc: 0.5379\n",
      "Epoch 532/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1887 - soft_acc: 0.8972 - val_loss: 0.4879 - val_soft_acc: 0.5636\n",
      "Epoch 533/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1827 - soft_acc: 0.9178 - val_loss: 0.5083 - val_soft_acc: 0.5071\n",
      "Epoch 534/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1940 - soft_acc: 0.9094 - val_loss: 0.7053 - val_soft_acc: 0.4114\n",
      "Epoch 535/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2711 - soft_acc: 0.8528 - val_loss: 0.5365 - val_soft_acc: 0.5429\n",
      "Epoch 536/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2434 - soft_acc: 0.8661 - val_loss: 0.4903 - val_soft_acc: 0.6164\n",
      "Epoch 537/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2045 - soft_acc: 0.8683 - val_loss: 0.5381 - val_soft_acc: 0.5236\n",
      "Epoch 538/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1985 - soft_acc: 0.9144 - val_loss: 0.5124 - val_soft_acc: 0.5043\n",
      "Epoch 539/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2195 - soft_acc: 0.8961 - val_loss: 0.5141 - val_soft_acc: 0.6014\n",
      "Epoch 540/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2179 - soft_acc: 0.9217 - val_loss: 0.4807 - val_soft_acc: 0.6036\n",
      "Epoch 541/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1905 - soft_acc: 0.9261 - val_loss: 0.4984 - val_soft_acc: 0.5786\n",
      "Epoch 542/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1988 - soft_acc: 0.8989 - val_loss: 0.6201 - val_soft_acc: 0.5850\n",
      "Epoch 543/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2401 - soft_acc: 0.8767 - val_loss: 0.6256 - val_soft_acc: 0.4900\n",
      "Epoch 544/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1982 - soft_acc: 0.9217 - val_loss: 0.4883 - val_soft_acc: 0.6086\n",
      "Epoch 545/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1947 - soft_acc: 0.8956 - val_loss: 0.4927 - val_soft_acc: 0.5779\n",
      "Epoch 546/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2042 - soft_acc: 0.9050 - val_loss: 0.4913 - val_soft_acc: 0.5679\n",
      "Epoch 547/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1976 - soft_acc: 0.9117 - val_loss: 0.5010 - val_soft_acc: 0.4864\n",
      "Epoch 548/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2210 - soft_acc: 0.8828 - val_loss: 0.4952 - val_soft_acc: 0.5986\n",
      "Epoch 549/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2071 - soft_acc: 0.9228 - val_loss: 0.5671 - val_soft_acc: 0.5429\n",
      "Epoch 550/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1924 - soft_acc: 0.9267 - val_loss: 0.5127 - val_soft_acc: 0.5736\n",
      "Epoch 551/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1874 - soft_acc: 0.9267 - val_loss: 0.5266 - val_soft_acc: 0.5429\n",
      "Epoch 552/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1762 - soft_acc: 0.9417 - val_loss: 0.4733 - val_soft_acc: 0.6650\n",
      "Epoch 553/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1721 - soft_acc: 0.9450 - val_loss: 0.5413 - val_soft_acc: 0.4993\n",
      "Epoch 554/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1659 - soft_acc: 0.9278 - val_loss: 0.6034 - val_soft_acc: 0.5079\n",
      "Epoch 555/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1948 - soft_acc: 0.9044 - val_loss: 0.5416 - val_soft_acc: 0.5050\n",
      "Epoch 556/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1844 - soft_acc: 0.9267 - val_loss: 0.5673 - val_soft_acc: 0.5179\n",
      "Epoch 557/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1713 - soft_acc: 0.9417 - val_loss: 0.5175 - val_soft_acc: 0.5479\n",
      "Epoch 558/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1733 - soft_acc: 0.9417 - val_loss: 0.5087 - val_soft_acc: 0.5657\n",
      "Epoch 559/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2367 - soft_acc: 0.9100 - val_loss: 0.5007 - val_soft_acc: 0.6007\n",
      "Epoch 560/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2105 - soft_acc: 0.8889 - val_loss: 0.5292 - val_soft_acc: 0.5507\n",
      "Epoch 561/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1759 - soft_acc: 0.9367 - val_loss: 0.5040 - val_soft_acc: 0.5736\n",
      "Epoch 562/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1727 - soft_acc: 0.9483 - val_loss: 0.5549 - val_soft_acc: 0.4614\n",
      "Epoch 563/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1726 - soft_acc: 0.9417 - val_loss: 0.5270 - val_soft_acc: 0.5686\n",
      "Epoch 564/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1589 - soft_acc: 0.9483 - val_loss: 0.5244 - val_soft_acc: 0.5529\n",
      "Epoch 565/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1911 - soft_acc: 0.9178 - val_loss: 0.5358 - val_soft_acc: 0.5736\n",
      "Epoch 566/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1964 - soft_acc: 0.9022 - val_loss: 0.4780 - val_soft_acc: 0.5986\n",
      "Epoch 567/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1853 - soft_acc: 0.9178 - val_loss: 0.4990 - val_soft_acc: 0.6471\n",
      "Epoch 568/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2079 - soft_acc: 0.9128 - val_loss: 0.4891 - val_soft_acc: 0.5557\n",
      "Epoch 569/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2051 - soft_acc: 0.9161 - val_loss: 0.5564 - val_soft_acc: 0.5429\n",
      "Epoch 570/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1831 - soft_acc: 0.9261 - val_loss: 0.5963 - val_soft_acc: 0.5336\n",
      "Epoch 571/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1934 - soft_acc: 0.9278 - val_loss: 0.5852 - val_soft_acc: 0.5379\n",
      "Epoch 572/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1750 - soft_acc: 0.9172 - val_loss: 0.5185 - val_soft_acc: 0.5550\n",
      "Epoch 573/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1892 - soft_acc: 0.9056 - val_loss: 0.5162 - val_soft_acc: 0.5300\n",
      "Epoch 574/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1793 - soft_acc: 0.9056 - val_loss: 0.5385 - val_soft_acc: 0.5507\n",
      "Epoch 575/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2277 - soft_acc: 0.8950 - val_loss: 0.5263 - val_soft_acc: 0.5064\n",
      "Epoch 576/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1921 - soft_acc: 0.9006 - val_loss: 0.5452 - val_soft_acc: 0.5479\n",
      "Epoch 577/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1695 - soft_acc: 0.9100 - val_loss: 0.5293 - val_soft_acc: 0.5143\n",
      "Epoch 578/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1603 - soft_acc: 0.9467 - val_loss: 0.5098 - val_soft_acc: 0.5757\n",
      "Epoch 579/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1607 - soft_acc: 0.9450 - val_loss: 0.4996 - val_soft_acc: 0.5757\n",
      "Epoch 580/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1625 - soft_acc: 0.9106 - val_loss: 0.5522 - val_soft_acc: 0.5793\n",
      "Epoch 581/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1583 - soft_acc: 0.9261 - val_loss: 0.5409 - val_soft_acc: 0.5100\n",
      "Epoch 582/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1626 - soft_acc: 0.9433 - val_loss: 0.5078 - val_soft_acc: 0.6036\n",
      "Epoch 583/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1858 - soft_acc: 0.9178 - val_loss: 0.6253 - val_soft_acc: 0.4564\n",
      "Epoch 584/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1847 - soft_acc: 0.9139 - val_loss: 0.5121 - val_soft_acc: 0.5193\n",
      "Epoch 585/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1520 - soft_acc: 0.9222 - val_loss: 0.5779 - val_soft_acc: 0.5536\n",
      "Epoch 586/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2864 - soft_acc: 0.8222 - val_loss: 0.4804 - val_soft_acc: 0.5700\n",
      "Epoch 587/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2606 - soft_acc: 0.8622 - val_loss: 0.5041 - val_soft_acc: 0.5500\n",
      "Epoch 588/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2474 - soft_acc: 0.8739 - val_loss: 0.4922 - val_soft_acc: 0.6400\n",
      "Epoch 589/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2538 - soft_acc: 0.8639 - val_loss: 0.5885 - val_soft_acc: 0.4993\n",
      "Epoch 590/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1992 - soft_acc: 0.9144 - val_loss: 0.5032 - val_soft_acc: 0.5679\n",
      "Epoch 591/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2052 - soft_acc: 0.8839 - val_loss: 0.6071 - val_soft_acc: 0.5564\n",
      "Epoch 592/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2334 - soft_acc: 0.8794 - val_loss: 0.4611 - val_soft_acc: 0.5907\n",
      "Epoch 593/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1961 - soft_acc: 0.9200 - val_loss: 0.4858 - val_soft_acc: 0.5829\n",
      "Epoch 594/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2021 - soft_acc: 0.9078 - val_loss: 0.4740 - val_soft_acc: 0.5857\n",
      "Epoch 595/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1797 - soft_acc: 0.9156 - val_loss: 0.4824 - val_soft_acc: 0.5907\n",
      "Epoch 596/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1922 - soft_acc: 0.9206 - val_loss: 0.4682 - val_soft_acc: 0.5986\n",
      "Epoch 597/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1884 - soft_acc: 0.9194 - val_loss: 0.5324 - val_soft_acc: 0.5529\n",
      "Epoch 598/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1645 - soft_acc: 0.9189 - val_loss: 0.5281 - val_soft_acc: 0.4736\n",
      "Epoch 599/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1495 - soft_acc: 0.9428 - val_loss: 0.5268 - val_soft_acc: 0.5707\n",
      "Epoch 600/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1528 - soft_acc: 0.9239 - val_loss: 0.5255 - val_soft_acc: 0.5507\n",
      "Epoch 601/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1631 - soft_acc: 0.9433 - val_loss: 0.5229 - val_soft_acc: 0.5500\n",
      "Epoch 602/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1849 - soft_acc: 0.9106 - val_loss: 0.5519 - val_soft_acc: 0.5864\n",
      "Epoch 603/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1867 - soft_acc: 0.9017 - val_loss: 0.4975 - val_soft_acc: 0.5500\n",
      "Epoch 604/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1775 - soft_acc: 0.9117 - val_loss: 0.5595 - val_soft_acc: 0.5271\n",
      "Epoch 605/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1708 - soft_acc: 0.9067 - val_loss: 0.6026 - val_soft_acc: 0.4643\n",
      "Epoch 606/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1709 - soft_acc: 0.9344 - val_loss: 0.5448 - val_soft_acc: 0.5350\n",
      "Epoch 607/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1785 - soft_acc: 0.9417 - val_loss: 0.5306 - val_soft_acc: 0.4993\n",
      "Epoch 608/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1570 - soft_acc: 0.9483 - val_loss: 0.5054 - val_soft_acc: 0.5757\n",
      "Epoch 609/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1539 - soft_acc: 0.9394 - val_loss: 0.5083 - val_soft_acc: 0.5479\n",
      "Epoch 610/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2264 - soft_acc: 0.9050 - val_loss: 0.5020 - val_soft_acc: 0.5986\n",
      "Epoch 611/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1680 - soft_acc: 0.9378 - val_loss: 0.5610 - val_soft_acc: 0.5714\n",
      "Epoch 612/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1761 - soft_acc: 0.8983 - val_loss: 0.4952 - val_soft_acc: 0.5371\n",
      "Epoch 613/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1762 - soft_acc: 0.9261 - val_loss: 0.5431 - val_soft_acc: 0.5429\n",
      "Epoch 614/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1627 - soft_acc: 0.9272 - val_loss: 0.5948 - val_soft_acc: 0.5129\n",
      "Epoch 615/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1747 - soft_acc: 0.9450 - val_loss: 0.5204 - val_soft_acc: 0.6093\n",
      "Epoch 616/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1731 - soft_acc: 0.9350 - val_loss: 0.5095 - val_soft_acc: 0.5764\n",
      "Epoch 617/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1985 - soft_acc: 0.9022 - val_loss: 0.4843 - val_soft_acc: 0.5321\n",
      "Epoch 618/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2187 - soft_acc: 0.9094 - val_loss: 0.4753 - val_soft_acc: 0.5650\n",
      "Epoch 619/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2274 - soft_acc: 0.8967 - val_loss: 0.5350 - val_soft_acc: 0.5121\n",
      "Epoch 620/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2057 - soft_acc: 0.9150 - val_loss: 0.5773 - val_soft_acc: 0.4714\n",
      "Epoch 621/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2039 - soft_acc: 0.9333 - val_loss: 0.5118 - val_soft_acc: 0.5300\n",
      "Epoch 622/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1749 - soft_acc: 0.9400 - val_loss: 0.5329 - val_soft_acc: 0.5836\n",
      "Epoch 623/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1583 - soft_acc: 0.9517 - val_loss: 0.5791 - val_soft_acc: 0.5564\n",
      "Epoch 624/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1737 - soft_acc: 0.9467 - val_loss: 0.5589 - val_soft_acc: 0.4643\n",
      "Epoch 625/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1762 - soft_acc: 0.9278 - val_loss: 0.5370 - val_soft_acc: 0.6171\n",
      "Epoch 626/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1617 - soft_acc: 0.9567 - val_loss: 0.5239 - val_soft_acc: 0.5350\n",
      "Epoch 627/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1625 - soft_acc: 0.9417 - val_loss: 0.5854 - val_soft_acc: 0.5407\n",
      "Epoch 628/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1909 - soft_acc: 0.9278 - val_loss: 0.5086 - val_soft_acc: 0.5193\n",
      "Epoch 629/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1778 - soft_acc: 0.9333 - val_loss: 0.5540 - val_soft_acc: 0.5329\n",
      "Epoch 630/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1700 - soft_acc: 0.9400 - val_loss: 0.5651 - val_soft_acc: 0.5329\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1925 - soft_acc: 0.9250 - val_loss: 0.5791 - val_soft_acc: 0.5150\n",
      "Epoch 632/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1593 - soft_acc: 0.9517 - val_loss: 0.5079 - val_soft_acc: 0.5100\n",
      "Epoch 633/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1634 - soft_acc: 0.9450 - val_loss: 0.5318 - val_soft_acc: 0.5607\n",
      "Epoch 634/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1598 - soft_acc: 0.9428 - val_loss: 0.5892 - val_soft_acc: 0.5050\n",
      "Epoch 635/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1708 - soft_acc: 0.9344 - val_loss: 0.5935 - val_soft_acc: 0.5536\n",
      "Epoch 636/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1579 - soft_acc: 0.9361 - val_loss: 0.5741 - val_soft_acc: 0.5407\n",
      "Epoch 637/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1425 - soft_acc: 0.9461 - val_loss: 0.5040 - val_soft_acc: 0.5986\n",
      "Epoch 638/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1556 - soft_acc: 0.9428 - val_loss: 0.5092 - val_soft_acc: 0.6071\n",
      "Epoch 639/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1572 - soft_acc: 0.9394 - val_loss: 0.4964 - val_soft_acc: 0.6014\n",
      "Epoch 640/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1528 - soft_acc: 0.9428 - val_loss: 0.5583 - val_soft_acc: 0.5636\n",
      "Epoch 641/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1504 - soft_acc: 0.9428 - val_loss: 0.5177 - val_soft_acc: 0.5371\n",
      "Epoch 642/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1522 - soft_acc: 0.9417 - val_loss: 0.5309 - val_soft_acc: 0.5636\n",
      "Epoch 643/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1559 - soft_acc: 0.9600 - val_loss: 0.5126 - val_soft_acc: 0.5350\n",
      "Epoch 644/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1789 - soft_acc: 0.9467 - val_loss: 0.5159 - val_soft_acc: 0.5450\n",
      "Epoch 645/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1616 - soft_acc: 0.9344 - val_loss: 0.5275 - val_soft_acc: 0.5243\n",
      "Epoch 646/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1889 - soft_acc: 0.9194 - val_loss: 0.5437 - val_soft_acc: 0.4964\n",
      "Epoch 647/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1708 - soft_acc: 0.9433 - val_loss: 0.5502 - val_soft_acc: 0.5529\n",
      "Epoch 648/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1654 - soft_acc: 0.9311 - val_loss: 0.5300 - val_soft_acc: 0.5757\n",
      "Epoch 649/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1605 - soft_acc: 0.9378 - val_loss: 0.4762 - val_soft_acc: 0.5807\n",
      "Epoch 650/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1823 - soft_acc: 0.9394 - val_loss: 0.5932 - val_soft_acc: 0.5307\n",
      "Epoch 651/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1961 - soft_acc: 0.8994 - val_loss: 0.4971 - val_soft_acc: 0.5450\n",
      "Epoch 652/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1950 - soft_acc: 0.9128 - val_loss: 0.5762 - val_soft_acc: 0.5400\n",
      "Epoch 653/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1806 - soft_acc: 0.9350 - val_loss: 0.5224 - val_soft_acc: 0.6014\n",
      "Epoch 654/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1718 - soft_acc: 0.9378 - val_loss: 0.6118 - val_soft_acc: 0.5257\n",
      "Epoch 655/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1587 - soft_acc: 0.9378 - val_loss: 0.4944 - val_soft_acc: 0.5736\n",
      "Epoch 656/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1584 - soft_acc: 0.9428 - val_loss: 0.5441 - val_soft_acc: 0.4964\n",
      "Epoch 657/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1571 - soft_acc: 0.9517 - val_loss: 0.4729 - val_soft_acc: 0.6114\n",
      "Epoch 658/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1582 - soft_acc: 0.9428 - val_loss: 0.5517 - val_soft_acc: 0.5479\n",
      "Epoch 659/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1704 - soft_acc: 0.9344 - val_loss: 0.4878 - val_soft_acc: 0.5886\n",
      "Epoch 660/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1670 - soft_acc: 0.9394 - val_loss: 0.5684 - val_soft_acc: 0.4843\n",
      "Epoch 661/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1755 - soft_acc: 0.9294 - val_loss: 0.6216 - val_soft_acc: 0.4664\n",
      "Epoch 662/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2089 - soft_acc: 0.9078 - val_loss: 0.6388 - val_soft_acc: 0.4564\n",
      "Epoch 663/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3141 - soft_acc: 0.7750 - val_loss: 0.4767 - val_soft_acc: 0.5736\n",
      "Epoch 664/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2318 - soft_acc: 0.8933 - val_loss: 0.5140 - val_soft_acc: 0.5707\n",
      "Epoch 665/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2377 - soft_acc: 0.8422 - val_loss: 0.5333 - val_soft_acc: 0.5607\n",
      "Epoch 666/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2227 - soft_acc: 0.8956 - val_loss: 0.5448 - val_soft_acc: 0.5250\n",
      "Epoch 667/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1952 - soft_acc: 0.9300 - val_loss: 0.5776 - val_soft_acc: 0.5229\n",
      "Epoch 668/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1842 - soft_acc: 0.9350 - val_loss: 0.5137 - val_soft_acc: 0.5579\n",
      "Epoch 669/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1689 - soft_acc: 0.9450 - val_loss: 0.6157 - val_soft_acc: 0.5129\n",
      "Epoch 670/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1830 - soft_acc: 0.9228 - val_loss: 0.5411 - val_soft_acc: 0.5814\n",
      "Epoch 671/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1839 - soft_acc: 0.8867 - val_loss: 0.6067 - val_soft_acc: 0.4921\n",
      "Epoch 672/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2548 - soft_acc: 0.8800 - val_loss: 0.5058 - val_soft_acc: 0.5300\n",
      "Epoch 673/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2757 - soft_acc: 0.8183 - val_loss: 0.4884 - val_soft_acc: 0.6471\n",
      "Epoch 674/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2419 - soft_acc: 0.8417 - val_loss: 0.6600 - val_soft_acc: 0.4950\n",
      "Epoch 675/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2386 - soft_acc: 0.8750 - val_loss: 0.5443 - val_soft_acc: 0.4914\n",
      "Epoch 676/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2116 - soft_acc: 0.8911 - val_loss: 0.5522 - val_soft_acc: 0.5329\n",
      "Epoch 677/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1739 - soft_acc: 0.9550 - val_loss: 0.4980 - val_soft_acc: 0.6186\n",
      "Epoch 678/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1591 - soft_acc: 0.9361 - val_loss: 0.5192 - val_soft_acc: 0.5429\n",
      "Epoch 679/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1651 - soft_acc: 0.9222 - val_loss: 0.5692 - val_soft_acc: 0.5329\n",
      "Epoch 680/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2077 - soft_acc: 0.9144 - val_loss: 0.5765 - val_soft_acc: 0.5150\n",
      "Epoch 681/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2049 - soft_acc: 0.9011 - val_loss: 0.5024 - val_soft_acc: 0.5836\n",
      "Epoch 682/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1730 - soft_acc: 0.9417 - val_loss: 0.5410 - val_soft_acc: 0.5507\n",
      "Epoch 683/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1494 - soft_acc: 0.9517 - val_loss: 0.5075 - val_soft_acc: 0.5557\n",
      "Epoch 684/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1551 - soft_acc: 0.9567 - val_loss: 0.4967 - val_soft_acc: 0.5350\n",
      "Epoch 685/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1620 - soft_acc: 0.9483 - val_loss: 0.4917 - val_soft_acc: 0.5707\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2299 - soft_acc: 0.8944 - val_loss: 0.5022 - val_soft_acc: 0.5529\n",
      "Epoch 687/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1756 - soft_acc: 0.9311 - val_loss: 0.4806 - val_soft_acc: 0.5271\n",
      "Epoch 688/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1665 - soft_acc: 0.9256 - val_loss: 0.5058 - val_soft_acc: 0.6243\n",
      "Epoch 689/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1538 - soft_acc: 0.9206 - val_loss: 0.4931 - val_soft_acc: 0.5936\n",
      "Epoch 690/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1636 - soft_acc: 0.9500 - val_loss: 0.5380 - val_soft_acc: 0.5736\n",
      "Epoch 691/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.1629 - soft_acc: 0.9100 - val_loss: 0.4698 - val_soft_acc: 0.5779\n",
      "Epoch 692/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1827 - soft_acc: 0.9383 - val_loss: 0.5156 - val_soft_acc: 0.5429\n",
      "Epoch 693/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1975 - soft_acc: 0.8972 - val_loss: 0.5068 - val_soft_acc: 0.5329\n",
      "Epoch 694/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1788 - soft_acc: 0.9200 - val_loss: 0.5687 - val_soft_acc: 0.5300\n",
      "Epoch 695/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1774 - soft_acc: 0.9294 - val_loss: 0.5944 - val_soft_acc: 0.5021\n",
      "Epoch 696/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1566 - soft_acc: 0.9378 - val_loss: 0.5063 - val_soft_acc: 0.5200\n",
      "Epoch 697/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1680 - soft_acc: 0.9500 - val_loss: 0.4955 - val_soft_acc: 0.5736\n",
      "Epoch 698/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2244 - soft_acc: 0.9067 - val_loss: 0.5237 - val_soft_acc: 0.5729\n",
      "Epoch 699/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1733 - soft_acc: 0.9261 - val_loss: 0.5170 - val_soft_acc: 0.5629\n",
      "Epoch 700/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1505 - soft_acc: 0.9617 - val_loss: 0.5295 - val_soft_acc: 0.6143\n",
      "Epoch 701/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1389 - soft_acc: 0.9533 - val_loss: 0.5027 - val_soft_acc: 0.5964\n",
      "Epoch 702/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1526 - soft_acc: 0.9517 - val_loss: 0.5423 - val_soft_acc: 0.5864\n",
      "Epoch 703/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1341 - soft_acc: 0.9583 - val_loss: 0.4988 - val_soft_acc: 0.6093\n",
      "Epoch 704/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1576 - soft_acc: 0.9483 - val_loss: 0.5461 - val_soft_acc: 0.5479\n",
      "Epoch 705/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1608 - soft_acc: 0.9378 - val_loss: 0.5831 - val_soft_acc: 0.5357\n",
      "Epoch 706/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1858 - soft_acc: 0.9300 - val_loss: 0.5754 - val_soft_acc: 0.5171\n",
      "Epoch 707/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1913 - soft_acc: 0.9250 - val_loss: 0.5412 - val_soft_acc: 0.5529\n",
      "Epoch 708/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1752 - soft_acc: 0.9272 - val_loss: 0.5042 - val_soft_acc: 0.5143\n",
      "Epoch 709/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1475 - soft_acc: 0.9600 - val_loss: 0.5379 - val_soft_acc: 0.5864\n",
      "Epoch 710/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1430 - soft_acc: 0.9444 - val_loss: 0.5292 - val_soft_acc: 0.5200\n",
      "Epoch 711/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1505 - soft_acc: 0.9461 - val_loss: 0.5748 - val_soft_acc: 0.5586\n",
      "Epoch 712/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1503 - soft_acc: 0.9189 - val_loss: 0.5012 - val_soft_acc: 0.5557\n",
      "Epoch 713/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1520 - soft_acc: 0.9483 - val_loss: 0.4913 - val_soft_acc: 0.5486\n",
      "Epoch 714/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1637 - soft_acc: 0.9239 - val_loss: 0.4984 - val_soft_acc: 0.5657\n",
      "Epoch 715/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1487 - soft_acc: 0.9583 - val_loss: 0.5089 - val_soft_acc: 0.5607\n",
      "Epoch 716/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1763 - soft_acc: 0.9350 - val_loss: 0.5193 - val_soft_acc: 0.6114\n",
      "Epoch 717/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1629 - soft_acc: 0.9328 - val_loss: 0.4859 - val_soft_acc: 0.5964\n",
      "Epoch 718/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1785 - soft_acc: 0.9433 - val_loss: 0.5067 - val_soft_acc: 0.5457\n",
      "Epoch 719/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1500 - soft_acc: 0.9500 - val_loss: 0.4814 - val_soft_acc: 0.5321\n",
      "Epoch 720/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1675 - soft_acc: 0.9356 - val_loss: 0.5514 - val_soft_acc: 0.5843\n",
      "Epoch 721/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1530 - soft_acc: 0.9222 - val_loss: 0.5540 - val_soft_acc: 0.5607\n",
      "Epoch 722/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1986 - soft_acc: 0.9061 - val_loss: 0.5671 - val_soft_acc: 0.4557\n",
      "Epoch 723/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1860 - soft_acc: 0.9350 - val_loss: 0.5611 - val_soft_acc: 0.5636\n",
      "Epoch 724/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1458 - soft_acc: 0.9428 - val_loss: 0.5483 - val_soft_acc: 0.5300\n",
      "Epoch 725/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1441 - soft_acc: 0.9339 - val_loss: 0.5334 - val_soft_acc: 0.5193\n",
      "Epoch 726/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1448 - soft_acc: 0.9583 - val_loss: 0.5368 - val_soft_acc: 0.5479\n",
      "Epoch 727/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1540 - soft_acc: 0.9550 - val_loss: 0.5465 - val_soft_acc: 0.5614\n",
      "Epoch 728/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1491 - soft_acc: 0.9567 - val_loss: 0.5145 - val_soft_acc: 0.5914\n",
      "Epoch 729/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1424 - soft_acc: 0.9428 - val_loss: 0.6016 - val_soft_acc: 0.4893\n",
      "Epoch 730/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1624 - soft_acc: 0.9067 - val_loss: 0.5651 - val_soft_acc: 0.4921\n",
      "Epoch 731/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1583 - soft_acc: 0.9306 - val_loss: 0.5672 - val_soft_acc: 0.5250\n",
      "Epoch 732/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1421 - soft_acc: 0.9567 - val_loss: 0.5346 - val_soft_acc: 0.5221\n",
      "Epoch 733/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1461 - soft_acc: 0.9239 - val_loss: 0.4965 - val_soft_acc: 0.6293\n",
      "Epoch 734/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1300 - soft_acc: 0.9633 - val_loss: 0.5274 - val_soft_acc: 0.6014\n",
      "Epoch 735/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1344 - soft_acc: 0.9511 - val_loss: 0.5302 - val_soft_acc: 0.5607\n",
      "Epoch 736/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1348 - soft_acc: 0.9322 - val_loss: 0.4854 - val_soft_acc: 0.5807\n",
      "Epoch 737/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1657 - soft_acc: 0.9344 - val_loss: 0.5640 - val_soft_acc: 0.5450\n",
      "Epoch 738/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1517 - soft_acc: 0.9550 - val_loss: 0.5160 - val_soft_acc: 0.5886\n",
      "Epoch 739/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1393 - soft_acc: 0.9550 - val_loss: 0.5235 - val_soft_acc: 0.5657\n",
      "Epoch 740/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1538 - soft_acc: 0.9483 - val_loss: 0.5126 - val_soft_acc: 0.5586\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1536 - soft_acc: 0.9600 - val_loss: 0.5312 - val_soft_acc: 0.6250\n",
      "Epoch 742/1000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.1329 - soft_acc: 0.96 - 0s 14us/sample - loss: 0.1417 - soft_acc: 0.9600 - val_loss: 0.5490 - val_soft_acc: 0.5329\n",
      "Epoch 743/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1455 - soft_acc: 0.9617 - val_loss: 0.5508 - val_soft_acc: 0.5557\n",
      "Epoch 744/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1521 - soft_acc: 0.9256 - val_loss: 0.6123 - val_soft_acc: 0.5514\n",
      "Epoch 745/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2033 - soft_acc: 0.9078 - val_loss: 0.5649 - val_soft_acc: 0.4414\n",
      "Epoch 746/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2107 - soft_acc: 0.8817 - val_loss: 0.5337 - val_soft_acc: 0.5714\n",
      "Epoch 747/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2065 - soft_acc: 0.8800 - val_loss: 0.4941 - val_soft_acc: 0.6014\n",
      "Epoch 748/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2005 - soft_acc: 0.9111 - val_loss: 0.5267 - val_soft_acc: 0.6064\n",
      "Epoch 749/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1623 - soft_acc: 0.9428 - val_loss: 0.4990 - val_soft_acc: 0.5171\n",
      "Epoch 750/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1940 - soft_acc: 0.9178 - val_loss: 0.5079 - val_soft_acc: 0.5864\n",
      "Epoch 751/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1732 - soft_acc: 0.9256 - val_loss: 0.5694 - val_soft_acc: 0.4943\n",
      "Epoch 752/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1556 - soft_acc: 0.9411 - val_loss: 0.5803 - val_soft_acc: 0.5021\n",
      "Epoch 753/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1540 - soft_acc: 0.9339 - val_loss: 0.5443 - val_soft_acc: 0.5764\n",
      "Epoch 754/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1466 - soft_acc: 0.9600 - val_loss: 0.5333 - val_soft_acc: 0.5757\n",
      "Epoch 755/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1511 - soft_acc: 0.9550 - val_loss: 0.5228 - val_soft_acc: 0.5121\n",
      "Epoch 756/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1381 - soft_acc: 0.9650 - val_loss: 0.5731 - val_soft_acc: 0.4893\n",
      "Epoch 757/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1369 - soft_acc: 0.9478 - val_loss: 0.5466 - val_soft_acc: 0.5636\n",
      "Epoch 758/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1457 - soft_acc: 0.9372 - val_loss: 0.5347 - val_soft_acc: 0.5657\n",
      "Epoch 759/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1543 - soft_acc: 0.9483 - val_loss: 0.5363 - val_soft_acc: 0.5579\n",
      "Epoch 760/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1650 - soft_acc: 0.9500 - val_loss: 0.5693 - val_soft_acc: 0.6221\n",
      "Epoch 761/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1408 - soft_acc: 0.9544 - val_loss: 0.5090 - val_soft_acc: 0.6014\n",
      "Epoch 762/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1414 - soft_acc: 0.9372 - val_loss: 0.5124 - val_soft_acc: 0.5807\n",
      "Epoch 763/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1547 - soft_acc: 0.9583 - val_loss: 0.5137 - val_soft_acc: 0.5857\n",
      "Epoch 764/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1482 - soft_acc: 0.9428 - val_loss: 0.5315 - val_soft_acc: 0.5043\n",
      "Epoch 765/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1386 - soft_acc: 0.9561 - val_loss: 0.5554 - val_soft_acc: 0.5250\n",
      "Epoch 766/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1408 - soft_acc: 0.9567 - val_loss: 0.5011 - val_soft_acc: 0.5607\n",
      "Epoch 767/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1439 - soft_acc: 0.9700 - val_loss: 0.5783 - val_soft_acc: 0.5843\n",
      "Epoch 768/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1586 - soft_acc: 0.9517 - val_loss: 0.4980 - val_soft_acc: 0.4914\n",
      "Epoch 769/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1492 - soft_acc: 0.9617 - val_loss: 0.5363 - val_soft_acc: 0.4993\n",
      "Epoch 770/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1420 - soft_acc: 0.9583 - val_loss: 0.5075 - val_soft_acc: 0.5471\n",
      "Epoch 771/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1515 - soft_acc: 0.9500 - val_loss: 0.5209 - val_soft_acc: 0.5736\n",
      "Epoch 772/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1298 - soft_acc: 0.9667 - val_loss: 0.5377 - val_soft_acc: 0.5179\n",
      "Epoch 773/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1315 - soft_acc: 0.9528 - val_loss: 0.5705 - val_soft_acc: 0.5629\n",
      "Epoch 774/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1456 - soft_acc: 0.9617 - val_loss: 0.5150 - val_soft_acc: 0.5607\n",
      "Epoch 775/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1373 - soft_acc: 0.9422 - val_loss: 0.5250 - val_soft_acc: 0.5221\n",
      "Epoch 776/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1432 - soft_acc: 0.9600 - val_loss: 0.5351 - val_soft_acc: 0.4993\n",
      "Epoch 777/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1402 - soft_acc: 0.9700 - val_loss: 0.5359 - val_soft_acc: 0.5814\n",
      "Epoch 778/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1453 - soft_acc: 0.9633 - val_loss: 0.5866 - val_soft_acc: 0.5357\n",
      "Epoch 779/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1532 - soft_acc: 0.9533 - val_loss: 0.5234 - val_soft_acc: 0.5064\n",
      "Epoch 780/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1681 - soft_acc: 0.9550 - val_loss: 0.6023 - val_soft_acc: 0.5279\n",
      "Epoch 781/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1561 - soft_acc: 0.9567 - val_loss: 0.5058 - val_soft_acc: 0.5586\n",
      "Epoch 782/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1972 - soft_acc: 0.9011 - val_loss: 0.5077 - val_soft_acc: 0.6479\n",
      "Epoch 783/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1719 - soft_acc: 0.9211 - val_loss: 0.5295 - val_soft_acc: 0.5557\n",
      "Epoch 784/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1462 - soft_acc: 0.9650 - val_loss: 0.5446 - val_soft_acc: 0.5479\n",
      "Epoch 785/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1556 - soft_acc: 0.9411 - val_loss: 0.6077 - val_soft_acc: 0.4793\n",
      "Epoch 786/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1718 - soft_acc: 0.9400 - val_loss: 0.5505 - val_soft_acc: 0.5271\n",
      "Epoch 787/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1486 - soft_acc: 0.9617 - val_loss: 0.5842 - val_soft_acc: 0.5229\n",
      "Epoch 788/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1370 - soft_acc: 0.9667 - val_loss: 0.5750 - val_soft_acc: 0.5536\n",
      "Epoch 789/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1722 - soft_acc: 0.9244 - val_loss: 0.5262 - val_soft_acc: 0.5943\n",
      "Epoch 790/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1396 - soft_acc: 0.9633 - val_loss: 0.5001 - val_soft_acc: 0.5507\n",
      "Epoch 791/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1782 - soft_acc: 0.9400 - val_loss: 0.5024 - val_soft_acc: 0.5507\n",
      "Epoch 792/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1984 - soft_acc: 0.9350 - val_loss: 0.5213 - val_soft_acc: 0.5329\n",
      "Epoch 793/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1814 - soft_acc: 0.9383 - val_loss: 0.6153 - val_soft_acc: 0.4693\n",
      "Epoch 794/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2307 - soft_acc: 0.8756 - val_loss: 0.5405 - val_soft_acc: 0.5607\n",
      "Epoch 795/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1905 - soft_acc: 0.9250 - val_loss: 0.5012 - val_soft_acc: 0.5764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 796/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1561 - soft_acc: 0.9583 - val_loss: 0.4968 - val_soft_acc: 0.5886\n",
      "Epoch 797/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1578 - soft_acc: 0.9567 - val_loss: 0.5119 - val_soft_acc: 0.5336\n",
      "Epoch 798/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1463 - soft_acc: 0.9444 - val_loss: 0.5064 - val_soft_acc: 0.5100\n",
      "Epoch 799/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1492 - soft_acc: 0.9583 - val_loss: 0.5651 - val_soft_acc: 0.5507\n",
      "Epoch 800/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1505 - soft_acc: 0.9494 - val_loss: 0.5207 - val_soft_acc: 0.5229\n",
      "Epoch 801/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1331 - soft_acc: 0.9594 - val_loss: 0.5449 - val_soft_acc: 0.5379\n",
      "Epoch 802/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1251 - soft_acc: 0.9472 - val_loss: 0.5055 - val_soft_acc: 0.5529\n",
      "Epoch 803/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1231 - soft_acc: 0.9544 - val_loss: 0.5408 - val_soft_acc: 0.5786\n",
      "Epoch 804/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1152 - soft_acc: 0.9683 - val_loss: 0.5121 - val_soft_acc: 0.5557\n",
      "Epoch 805/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1227 - soft_acc: 0.9667 - val_loss: 0.5172 - val_soft_acc: 0.5893\n",
      "Epoch 806/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1404 - soft_acc: 0.9667 - val_loss: 0.5367 - val_soft_acc: 0.4893\n",
      "Epoch 807/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1489 - soft_acc: 0.9650 - val_loss: 0.5238 - val_soft_acc: 0.5329\n",
      "Epoch 808/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1613 - soft_acc: 0.9206 - val_loss: 0.5338 - val_soft_acc: 0.5250\n",
      "Epoch 809/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1577 - soft_acc: 0.9383 - val_loss: 0.5615 - val_soft_acc: 0.5636\n",
      "Epoch 810/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1651 - soft_acc: 0.9344 - val_loss: 0.5491 - val_soft_acc: 0.4821\n",
      "Epoch 811/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1974 - soft_acc: 0.8817 - val_loss: 0.5050 - val_soft_acc: 0.5121\n",
      "Epoch 812/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1773 - soft_acc: 0.9328 - val_loss: 0.5090 - val_soft_acc: 0.5150\n",
      "Epoch 813/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1719 - soft_acc: 0.9400 - val_loss: 0.5212 - val_soft_acc: 0.5179\n",
      "Epoch 814/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1916 - soft_acc: 0.9317 - val_loss: 0.5229 - val_soft_acc: 0.5250\n",
      "Epoch 815/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1577 - soft_acc: 0.9617 - val_loss: 0.5585 - val_soft_acc: 0.4993\n",
      "Epoch 816/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1634 - soft_acc: 0.9517 - val_loss: 0.5387 - val_soft_acc: 0.4893\n",
      "Epoch 817/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1510 - soft_acc: 0.9667 - val_loss: 0.5483 - val_soft_acc: 0.5679\n",
      "Epoch 818/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1431 - soft_acc: 0.9683 - val_loss: 0.5006 - val_soft_acc: 0.5064\n",
      "Epoch 819/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1374 - soft_acc: 0.9683 - val_loss: 0.5454 - val_soft_acc: 0.5557\n",
      "Epoch 820/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1396 - soft_acc: 0.9494 - val_loss: 0.5266 - val_soft_acc: 0.5043\n",
      "Epoch 821/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1349 - soft_acc: 0.9717 - val_loss: 0.4940 - val_soft_acc: 0.6064\n",
      "Epoch 822/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1410 - soft_acc: 0.9683 - val_loss: 0.5548 - val_soft_acc: 0.5350\n",
      "Epoch 823/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1541 - soft_acc: 0.9500 - val_loss: 0.5263 - val_soft_acc: 0.5836\n",
      "Epoch 824/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1274 - soft_acc: 0.9600 - val_loss: 0.5289 - val_soft_acc: 0.6271\n",
      "Epoch 825/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1242 - soft_acc: 0.9594 - val_loss: 0.5689 - val_soft_acc: 0.5407\n",
      "Epoch 826/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1374 - soft_acc: 0.9578 - val_loss: 0.4940 - val_soft_acc: 0.5714\n",
      "Epoch 827/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1469 - soft_acc: 0.9267 - val_loss: 0.5085 - val_soft_acc: 0.4864\n",
      "Epoch 828/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1735 - soft_acc: 0.9344 - val_loss: 0.5077 - val_soft_acc: 0.4707\n",
      "Epoch 829/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1624 - soft_acc: 0.9517 - val_loss: 0.5128 - val_soft_acc: 0.5321\n",
      "Epoch 830/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2019 - soft_acc: 0.9028 - val_loss: 0.5174 - val_soft_acc: 0.4664\n",
      "Epoch 831/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1764 - soft_acc: 0.9400 - val_loss: 0.5829 - val_soft_acc: 0.4814\n",
      "Epoch 832/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1402 - soft_acc: 0.9528 - val_loss: 0.5669 - val_soft_acc: 0.5250\n",
      "Epoch 833/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1365 - soft_acc: 0.9561 - val_loss: 0.5132 - val_soft_acc: 0.6221\n",
      "Epoch 834/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1495 - soft_acc: 0.9439 - val_loss: 0.5511 - val_soft_acc: 0.5557\n",
      "Epoch 835/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1349 - soft_acc: 0.9650 - val_loss: 0.5911 - val_soft_acc: 0.5357\n",
      "Epoch 836/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1552 - soft_acc: 0.9583 - val_loss: 0.5855 - val_soft_acc: 0.5150\n",
      "Epoch 837/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2115 - soft_acc: 0.8700 - val_loss: 0.5741 - val_soft_acc: 0.5793\n",
      "Epoch 838/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2085 - soft_acc: 0.9111 - val_loss: 0.5126 - val_soft_acc: 0.5507\n",
      "Epoch 839/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2126 - soft_acc: 0.9050 - val_loss: 0.5193 - val_soft_acc: 0.5507\n",
      "Epoch 840/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1773 - soft_acc: 0.9467 - val_loss: 0.5659 - val_soft_acc: 0.5279\n",
      "Epoch 841/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1564 - soft_acc: 0.9444 - val_loss: 0.5295 - val_soft_acc: 0.5993\n",
      "Epoch 842/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1538 - soft_acc: 0.9150 - val_loss: 0.5668 - val_soft_acc: 0.5457\n",
      "Epoch 843/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1731 - soft_acc: 0.9167 - val_loss: 0.4992 - val_soft_acc: 0.5607\n",
      "Epoch 844/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1940 - soft_acc: 0.9333 - val_loss: 0.5048 - val_soft_acc: 0.5200\n",
      "Epoch 845/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1686 - soft_acc: 0.9294 - val_loss: 0.5170 - val_soft_acc: 0.5379\n",
      "Epoch 846/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1484 - soft_acc: 0.9633 - val_loss: 0.5264 - val_soft_acc: 0.5614\n",
      "Epoch 847/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1393 - soft_acc: 0.9667 - val_loss: 0.5274 - val_soft_acc: 0.5714\n",
      "Epoch 848/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1356 - soft_acc: 0.9633 - val_loss: 0.5290 - val_soft_acc: 0.5636\n",
      "Epoch 849/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1407 - soft_acc: 0.9667 - val_loss: 0.5124 - val_soft_acc: 0.5250\n",
      "Epoch 850/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2015 - soft_acc: 0.9311 - val_loss: 0.4986 - val_soft_acc: 0.4964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 851/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1817 - soft_acc: 0.9450 - val_loss: 0.5925 - val_soft_acc: 0.4950\n",
      "Epoch 852/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1784 - soft_acc: 0.9450 - val_loss: 0.5406 - val_soft_acc: 0.5886\n",
      "Epoch 853/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1412 - soft_acc: 0.9544 - val_loss: 0.5366 - val_soft_acc: 0.6121\n",
      "Epoch 854/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1363 - soft_acc: 0.9750 - val_loss: 0.5272 - val_soft_acc: 0.5379\n",
      "Epoch 855/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1321 - soft_acc: 0.9750 - val_loss: 0.5558 - val_soft_acc: 0.4864\n",
      "Epoch 856/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1458 - soft_acc: 0.9478 - val_loss: 0.5867 - val_soft_acc: 0.5279\n",
      "Epoch 857/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1480 - soft_acc: 0.9461 - val_loss: 0.5854 - val_soft_acc: 0.5407\n",
      "Epoch 858/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2063 - soft_acc: 0.9144 - val_loss: 0.5154 - val_soft_acc: 0.5429\n",
      "Epoch 859/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1604 - soft_acc: 0.9511 - val_loss: 0.5183 - val_soft_acc: 0.5479\n",
      "Epoch 860/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1506 - soft_acc: 0.9617 - val_loss: 0.5096 - val_soft_acc: 0.5429\n",
      "Epoch 861/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1609 - soft_acc: 0.9322 - val_loss: 0.5254 - val_soft_acc: 0.4764\n",
      "Epoch 862/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1246 - soft_acc: 0.9683 - val_loss: 0.5370 - val_soft_acc: 0.5150\n",
      "Epoch 863/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1138 - soft_acc: 0.9717 - val_loss: 0.5408 - val_soft_acc: 0.4843\n",
      "Epoch 864/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1398 - soft_acc: 0.9633 - val_loss: 0.5337 - val_soft_acc: 0.5079\n",
      "Epoch 865/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1417 - soft_acc: 0.9600 - val_loss: 0.5187 - val_soft_acc: 0.5614\n",
      "Epoch 866/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1546 - soft_acc: 0.9478 - val_loss: 0.5632 - val_soft_acc: 0.5257\n",
      "Epoch 867/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1312 - soft_acc: 0.9561 - val_loss: 0.5445 - val_soft_acc: 0.5407\n",
      "Epoch 868/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1490 - soft_acc: 0.9533 - val_loss: 0.5901 - val_soft_acc: 0.5714\n",
      "Epoch 869/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1399 - soft_acc: 0.9528 - val_loss: 0.5632 - val_soft_acc: 0.5043\n",
      "Epoch 870/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1361 - soft_acc: 0.9494 - val_loss: 0.5599 - val_soft_acc: 0.5279\n",
      "Epoch 871/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1376 - soft_acc: 0.9511 - val_loss: 0.5721 - val_soft_acc: 0.4893\n",
      "Epoch 872/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1418 - soft_acc: 0.9444 - val_loss: 0.5514 - val_soft_acc: 0.4793\n",
      "Epoch 873/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1465 - soft_acc: 0.9600 - val_loss: 0.5499 - val_soft_acc: 0.4486\n",
      "Epoch 874/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1162 - soft_acc: 0.9611 - val_loss: 0.5514 - val_soft_acc: 0.5486\n",
      "Epoch 875/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1131 - soft_acc: 0.9783 - val_loss: 0.5907 - val_soft_acc: 0.4714\n",
      "Epoch 876/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1248 - soft_acc: 0.9733 - val_loss: 0.5603 - val_soft_acc: 0.5150\n",
      "Epoch 877/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1170 - soft_acc: 0.9750 - val_loss: 0.5811 - val_soft_acc: 0.5586\n",
      "Epoch 878/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1384 - soft_acc: 0.9617 - val_loss: 0.5807 - val_soft_acc: 0.5250\n",
      "Epoch 879/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1203 - soft_acc: 0.9683 - val_loss: 0.5807 - val_soft_acc: 0.5636\n",
      "Epoch 880/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1494 - soft_acc: 0.9633 - val_loss: 0.5720 - val_soft_acc: 0.4843\n",
      "Epoch 881/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1583 - soft_acc: 0.9600 - val_loss: 0.5866 - val_soft_acc: 0.5279\n",
      "Epoch 882/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1362 - soft_acc: 0.9561 - val_loss: 0.5661 - val_soft_acc: 0.5200\n",
      "Epoch 883/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1361 - soft_acc: 0.9406 - val_loss: 0.5931 - val_soft_acc: 0.4900\n",
      "Epoch 884/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1259 - soft_acc: 0.9506 - val_loss: 0.5816 - val_soft_acc: 0.5150\n",
      "Epoch 885/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1287 - soft_acc: 0.9356 - val_loss: 0.5593 - val_soft_acc: 0.5436\n",
      "Epoch 886/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1187 - soft_acc: 0.9628 - val_loss: 0.5173 - val_soft_acc: 0.5357\n",
      "Epoch 887/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1490 - soft_acc: 0.9528 - val_loss: 0.5600 - val_soft_acc: 0.5657\n",
      "Epoch 888/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1422 - soft_acc: 0.9700 - val_loss: 0.5632 - val_soft_acc: 0.5300\n",
      "Epoch 889/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1204 - soft_acc: 0.9733 - val_loss: 0.5655 - val_soft_acc: 0.5100\n",
      "Epoch 890/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1232 - soft_acc: 0.9733 - val_loss: 0.5705 - val_soft_acc: 0.5329\n",
      "Epoch 891/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1362 - soft_acc: 0.9528 - val_loss: 0.5966 - val_soft_acc: 0.5329\n",
      "Epoch 892/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1786 - soft_acc: 0.9417 - val_loss: 0.5487 - val_soft_acc: 0.5357\n",
      "Epoch 893/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1229 - soft_acc: 0.9628 - val_loss: 0.5805 - val_soft_acc: 0.5507\n",
      "Epoch 894/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1353 - soft_acc: 0.9544 - val_loss: 0.5357 - val_soft_acc: 0.5714\n",
      "Epoch 895/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1223 - soft_acc: 0.9750 - val_loss: 0.6091 - val_soft_acc: 0.5457\n",
      "Epoch 896/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1489 - soft_acc: 0.9667 - val_loss: 0.5673 - val_soft_acc: 0.5093\n",
      "Epoch 897/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1295 - soft_acc: 0.9667 - val_loss: 0.5371 - val_soft_acc: 0.5686\n",
      "Epoch 898/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1208 - soft_acc: 0.9700 - val_loss: 0.5423 - val_soft_acc: 0.5407\n",
      "Epoch 899/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1126 - soft_acc: 0.9661 - val_loss: 0.5098 - val_soft_acc: 0.5607\n",
      "Epoch 900/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1421 - soft_acc: 0.9667 - val_loss: 0.5343 - val_soft_acc: 0.5557\n",
      "Epoch 901/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1285 - soft_acc: 0.9650 - val_loss: 0.5389 - val_soft_acc: 0.5071\n",
      "Epoch 902/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1369 - soft_acc: 0.9700 - val_loss: 0.5660 - val_soft_acc: 0.4664\n",
      "Epoch 903/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1356 - soft_acc: 0.9511 - val_loss: 0.5360 - val_soft_acc: 0.5814\n",
      "Epoch 904/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1401 - soft_acc: 0.9633 - val_loss: 0.5396 - val_soft_acc: 0.5557\n",
      "Epoch 905/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1421 - soft_acc: 0.9567 - val_loss: 0.5161 - val_soft_acc: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1399 - soft_acc: 0.9683 - val_loss: 0.5789 - val_soft_acc: 0.5793\n",
      "Epoch 907/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.1271 - soft_acc: 0.9700 - val_loss: 0.5501 - val_soft_acc: 0.5436\n",
      "Epoch 908/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1555 - soft_acc: 0.9394 - val_loss: 0.5663 - val_soft_acc: 0.5457\n",
      "Epoch 909/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1320 - soft_acc: 0.9700 - val_loss: 0.5926 - val_soft_acc: 0.4893\n",
      "Epoch 910/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1531 - soft_acc: 0.9444 - val_loss: 0.6083 - val_soft_acc: 0.4336\n",
      "Epoch 911/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1828 - soft_acc: 0.9333 - val_loss: 0.5696 - val_soft_acc: 0.5079\n",
      "Epoch 912/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1480 - soft_acc: 0.9633 - val_loss: 0.5487 - val_soft_acc: 0.5129\n",
      "Epoch 913/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1314 - soft_acc: 0.9667 - val_loss: 0.5367 - val_soft_acc: 0.5457\n",
      "Epoch 914/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1459 - soft_acc: 0.9461 - val_loss: 0.5382 - val_soft_acc: 0.4636\n",
      "Epoch 915/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1763 - soft_acc: 0.9417 - val_loss: 0.5490 - val_soft_acc: 0.4564\n",
      "Epoch 916/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1509 - soft_acc: 0.9600 - val_loss: 0.5283 - val_soft_acc: 0.4743\n",
      "Epoch 917/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1593 - soft_acc: 0.9583 - val_loss: 0.5786 - val_soft_acc: 0.5257\n",
      "Epoch 918/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1234 - soft_acc: 0.9628 - val_loss: 0.5549 - val_soft_acc: 0.4407\n",
      "Epoch 919/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1370 - soft_acc: 0.9678 - val_loss: 0.5868 - val_soft_acc: 0.5564\n",
      "Epoch 920/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1265 - soft_acc: 0.9633 - val_loss: 0.5492 - val_soft_acc: 0.5664\n",
      "Epoch 921/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1250 - soft_acc: 0.9733 - val_loss: 0.5460 - val_soft_acc: 0.4643\n",
      "Epoch 922/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1472 - soft_acc: 0.9544 - val_loss: 0.5287 - val_soft_acc: 0.4900\n",
      "Epoch 923/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1337 - soft_acc: 0.9717 - val_loss: 0.5152 - val_soft_acc: 0.5150\n",
      "Epoch 924/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1486 - soft_acc: 0.9633 - val_loss: 0.5098 - val_soft_acc: 0.5964\n",
      "Epoch 925/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1299 - soft_acc: 0.9700 - val_loss: 0.5372 - val_soft_acc: 0.5607\n",
      "Epoch 926/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1288 - soft_acc: 0.9544 - val_loss: 0.5233 - val_soft_acc: 0.5400\n",
      "Epoch 927/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1224 - soft_acc: 0.9783 - val_loss: 0.5443 - val_soft_acc: 0.5379\n",
      "Epoch 928/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1086 - soft_acc: 0.9783 - val_loss: 0.5512 - val_soft_acc: 0.5143\n",
      "Epoch 929/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1144 - soft_acc: 0.9628 - val_loss: 0.5299 - val_soft_acc: 0.5536\n",
      "Epoch 930/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1134 - soft_acc: 0.9783 - val_loss: 0.5713 - val_soft_acc: 0.5250\n",
      "Epoch 931/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1218 - soft_acc: 0.9750 - val_loss: 0.5407 - val_soft_acc: 0.5307\n",
      "Epoch 932/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1185 - soft_acc: 0.9767 - val_loss: 0.5752 - val_soft_acc: 0.4864\n",
      "Epoch 933/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1153 - soft_acc: 0.9539 - val_loss: 0.5723 - val_soft_acc: 0.5429\n",
      "Epoch 934/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1442 - soft_acc: 0.9700 - val_loss: 0.6009 - val_soft_acc: 0.5693\n",
      "Epoch 935/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1263 - soft_acc: 0.9717 - val_loss: 0.5400 - val_soft_acc: 0.5329\n",
      "Epoch 936/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1225 - soft_acc: 0.9683 - val_loss: 0.5595 - val_soft_acc: 0.5636\n",
      "Epoch 937/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1033 - soft_acc: 0.9767 - val_loss: 0.5424 - val_soft_acc: 0.4821\n",
      "Epoch 938/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1500 - soft_acc: 0.9633 - val_loss: 0.5316 - val_soft_acc: 0.5336\n",
      "Epoch 939/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1141 - soft_acc: 0.9489 - val_loss: 0.5528 - val_soft_acc: 0.6100\n",
      "Epoch 940/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1166 - soft_acc: 0.9767 - val_loss: 0.5422 - val_soft_acc: 0.4714\n",
      "Epoch 941/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1146 - soft_acc: 0.9733 - val_loss: 0.5328 - val_soft_acc: 0.5150\n",
      "Epoch 942/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1382 - soft_acc: 0.9633 - val_loss: 0.5303 - val_soft_acc: 0.5150\n",
      "Epoch 943/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1028 - soft_acc: 0.9750 - val_loss: 0.5246 - val_soft_acc: 0.5171\n",
      "Epoch 944/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1241 - soft_acc: 0.9683 - val_loss: 0.5425 - val_soft_acc: 0.5250\n",
      "Epoch 945/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1319 - soft_acc: 0.9444 - val_loss: 0.5395 - val_soft_acc: 0.6021\n",
      "Epoch 946/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1784 - soft_acc: 0.9328 - val_loss: 0.5441 - val_soft_acc: 0.5814\n",
      "Epoch 947/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1585 - soft_acc: 0.9467 - val_loss: 0.5263 - val_soft_acc: 0.5229\n",
      "Epoch 948/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1333 - soft_acc: 0.9650 - val_loss: 0.5733 - val_soft_acc: 0.5279\n",
      "Epoch 949/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1384 - soft_acc: 0.9389 - val_loss: 0.5824 - val_soft_acc: 0.5586\n",
      "Epoch 950/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1367 - soft_acc: 0.9544 - val_loss: 0.6038 - val_soft_acc: 0.5329\n",
      "Epoch 951/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1627 - soft_acc: 0.9600 - val_loss: 0.5777 - val_soft_acc: 0.5279\n",
      "Epoch 952/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1718 - soft_acc: 0.9433 - val_loss: 0.5703 - val_soft_acc: 0.5814\n",
      "Epoch 953/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1377 - soft_acc: 0.9650 - val_loss: 0.5189 - val_soft_acc: 0.5050\n",
      "Epoch 954/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1282 - soft_acc: 0.9750 - val_loss: 0.5229 - val_soft_acc: 0.4971\n",
      "Epoch 955/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1353 - soft_acc: 0.9494 - val_loss: 0.5507 - val_soft_acc: 0.4921\n",
      "Epoch 956/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1160 - soft_acc: 0.9800 - val_loss: 0.5626 - val_soft_acc: 0.4614\n",
      "Epoch 957/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1168 - soft_acc: 0.9817 - val_loss: 0.6101 - val_soft_acc: 0.5179\n",
      "Epoch 958/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1598 - soft_acc: 0.9550 - val_loss: 0.5634 - val_soft_acc: 0.5843\n",
      "Epoch 959/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1143 - soft_acc: 0.9717 - val_loss: 0.5527 - val_soft_acc: 0.5736\n",
      "Epoch 960/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1394 - soft_acc: 0.9650 - val_loss: 0.5430 - val_soft_acc: 0.4693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1465 - soft_acc: 0.9683 - val_loss: 0.5521 - val_soft_acc: 0.5457\n",
      "Epoch 962/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1257 - soft_acc: 0.9422 - val_loss: 0.5195 - val_soft_acc: 0.4921\n",
      "Epoch 963/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1385 - soft_acc: 0.9528 - val_loss: 0.5380 - val_soft_acc: 0.4843\n",
      "Epoch 964/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1421 - soft_acc: 0.9611 - val_loss: 0.5482 - val_soft_acc: 0.4921\n",
      "Epoch 965/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1237 - soft_acc: 0.9594 - val_loss: 0.5477 - val_soft_acc: 0.5386\n",
      "Epoch 966/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1295 - soft_acc: 0.9717 - val_loss: 0.5455 - val_soft_acc: 0.5814\n",
      "Epoch 967/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1297 - soft_acc: 0.9494 - val_loss: 0.5389 - val_soft_acc: 0.4793\n",
      "Epoch 968/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1259 - soft_acc: 0.9700 - val_loss: 0.5770 - val_soft_acc: 0.5029\n",
      "Epoch 969/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1264 - soft_acc: 0.9611 - val_loss: 0.5369 - val_soft_acc: 0.5564\n",
      "Epoch 970/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1054 - soft_acc: 0.9750 - val_loss: 0.5321 - val_soft_acc: 0.4693\n",
      "Epoch 971/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1230 - soft_acc: 0.9767 - val_loss: 0.5339 - val_soft_acc: 0.5336\n",
      "Epoch 972/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1362 - soft_acc: 0.9767 - val_loss: 0.5920 - val_soft_acc: 0.5693\n",
      "Epoch 973/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1297 - soft_acc: 0.9750 - val_loss: 0.5405 - val_soft_acc: 0.5257\n",
      "Epoch 974/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1119 - soft_acc: 0.9767 - val_loss: 0.5706 - val_soft_acc: 0.5229\n",
      "Epoch 975/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1104 - soft_acc: 0.9644 - val_loss: 0.5489 - val_soft_acc: 0.5229\n",
      "Epoch 976/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1150 - soft_acc: 0.9817 - val_loss: 0.5355 - val_soft_acc: 0.5100\n",
      "Epoch 977/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1029 - soft_acc: 0.9767 - val_loss: 0.5466 - val_soft_acc: 0.5071\n",
      "Epoch 978/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.0937 - soft_acc: 0.9817 - val_loss: 0.5525 - val_soft_acc: 0.5071\n",
      "Epoch 979/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1151 - soft_acc: 0.9733 - val_loss: 0.5955 - val_soft_acc: 0.5100\n",
      "Epoch 980/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1460 - soft_acc: 0.9444 - val_loss: 0.5927 - val_soft_acc: 0.5229\n",
      "Epoch 981/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1570 - soft_acc: 0.9494 - val_loss: 0.5881 - val_soft_acc: 0.5429\n",
      "Epoch 982/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1840 - soft_acc: 0.9194 - val_loss: 0.5536 - val_soft_acc: 0.4743\n",
      "Epoch 983/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1613 - soft_acc: 0.9383 - val_loss: 0.5475 - val_soft_acc: 0.4771\n",
      "Epoch 984/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1820 - soft_acc: 0.9172 - val_loss: 0.5216 - val_soft_acc: 0.5686\n",
      "Epoch 985/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1475 - soft_acc: 0.9683 - val_loss: 0.5455 - val_soft_acc: 0.5557\n",
      "Epoch 986/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1248 - soft_acc: 0.9700 - val_loss: 0.5579 - val_soft_acc: 0.6021\n",
      "Epoch 987/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1134 - soft_acc: 0.9800 - val_loss: 0.5307 - val_soft_acc: 0.5357\n",
      "Epoch 988/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1201 - soft_acc: 0.9750 - val_loss: 0.5741 - val_soft_acc: 0.5100\n",
      "Epoch 989/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1133 - soft_acc: 0.9783 - val_loss: 0.5331 - val_soft_acc: 0.4893\n",
      "Epoch 990/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1176 - soft_acc: 0.9628 - val_loss: 0.5901 - val_soft_acc: 0.4814\n",
      "Epoch 991/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1527 - soft_acc: 0.9633 - val_loss: 0.6233 - val_soft_acc: 0.5336\n",
      "Epoch 992/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1985 - soft_acc: 0.8850 - val_loss: 0.5674 - val_soft_acc: 0.5614\n",
      "Epoch 993/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1417 - soft_acc: 0.9667 - val_loss: 0.5154 - val_soft_acc: 0.5100\n",
      "Epoch 994/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1282 - soft_acc: 0.9633 - val_loss: 0.5475 - val_soft_acc: 0.5943\n",
      "Epoch 995/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1084 - soft_acc: 0.9767 - val_loss: 0.5446 - val_soft_acc: 0.5021\n",
      "Epoch 996/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1153 - soft_acc: 0.9767 - val_loss: 0.5402 - val_soft_acc: 0.4436\n",
      "Epoch 997/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1387 - soft_acc: 0.9650 - val_loss: 0.5823 - val_soft_acc: 0.5300\n",
      "Epoch 998/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1304 - soft_acc: 0.9561 - val_loss: 0.5401 - val_soft_acc: 0.4771\n",
      "Epoch 999/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1206 - soft_acc: 0.9833 - val_loss: 0.5502 - val_soft_acc: 0.3979\n",
      "Epoch 1000/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1203 - soft_acc: 0.9717 - val_loss: 0.5341 - val_soft_acc: 0.5864\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4563 - soft_acc: 0.6328\n",
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.0090 - soft_acc: 0.2100best occur in epoch 0\n",
      "512/512 [==============================] - 0s 425us/sample - loss: 15.2288 - soft_acc: 0.0400 - val_loss: 5.2039 - val_soft_acc: 0.0807\n",
      "Epoch 2/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.1807 - soft_acc: 0.2500best occur in epoch 1\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 3.7979 - soft_acc: 0.1683 - val_loss: 10.6401 - val_soft_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 4.0832 - soft_acc: 0.1483 - val_loss: 6.1501 - val_soft_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.4811 - soft_acc: 0.1800best occur in epoch 3\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 2.5085 - soft_acc: 0.1856 - val_loss: 5.0648 - val_soft_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.2819 - soft_acc: 0.1500best occur in epoch 4\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 1.4853 - soft_acc: 0.3106 - val_loss: 1.5485 - val_soft_acc: 0.2529\n",
      "Epoch 6/1000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 1.1771 - soft_acc: 0.3572 - val_loss: 1.6697 - val_soft_acc: 0.1786\n",
      "Epoch 7/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.1559 - soft_acc: 0.4000best occur in epoch 6\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 1.2207 - soft_acc: 0.3828 - val_loss: 1.6294 - val_soft_acc: 0.1864\n",
      "Epoch 8/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.9239 - soft_acc: 0.4200best occur in epoch 7\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.9348 - soft_acc: 0.4456 - val_loss: 1.4651 - val_soft_acc: 0.2300\n",
      "Epoch 9/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5820 - soft_acc: 0.5400best occur in epoch 8\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.7063 - soft_acc: 0.4839 - val_loss: 1.4131 - val_soft_acc: 0.2100\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7097 - soft_acc: 0.5400best occur in epoch 9\n",
      "512/512 [==============================] - 0s 62us/sample - loss: 0.7125 - soft_acc: 0.5389 - val_loss: 1.1982 - val_soft_acc: 0.2907\n",
      "Epoch 11/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 1.0683 - soft_acc: 0.3861 - val_loss: 3.3272 - val_soft_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.1761 - soft_acc: 0.3517 - val_loss: 1.2257 - val_soft_acc: 0.1736\n",
      "Epoch 13/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 1.1167 - soft_acc: 0.3456 - val_loss: 1.1327 - val_soft_acc: 0.1657\n",
      "Epoch 14/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 1.2228 - soft_acc: 0.3389 - val_loss: 1.4567 - val_soft_acc: 0.2000\n",
      "Epoch 15/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0829 - soft_acc: 0.2900best occur in epoch 14\n",
      "512/512 [==============================] - 0s 64us/sample - loss: 0.9370 - soft_acc: 0.3956 - val_loss: 0.8540 - val_soft_acc: 0.4479\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.9275 - soft_acc: 0.5000 - val_loss: 3.0489 - val_soft_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 1.5052 - soft_acc: 0.2461 - val_loss: 0.8054 - val_soft_acc: 0.4214\n",
      "Epoch 18/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.8448 - soft_acc: 0.4583 - val_loss: 0.8791 - val_soft_acc: 0.3229\n",
      "Epoch 19/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.8441 - soft_acc: 0.4244 - val_loss: 0.7768 - val_soft_acc: 0.4136\n",
      "Epoch 20/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.6643 - soft_acc: 0.5300 - val_loss: 2.0083 - val_soft_acc: 0.0200\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.6253 - soft_acc: 0.5778 - val_loss: 1.2207 - val_soft_acc: 0.1007\n",
      "Epoch 22/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4895 - soft_acc: 0.6300best occur in epoch 21\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.5170 - soft_acc: 0.6367 - val_loss: 0.5701 - val_soft_acc: 0.6629\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4663 - soft_acc: 0.6528 - val_loss: 0.5748 - val_soft_acc: 0.6371\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4315 - soft_acc: 0.6656 - val_loss: 0.5671 - val_soft_acc: 0.5757\n",
      "Epoch 25/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4370 - soft_acc: 0.6800 - val_loss: 0.6435 - val_soft_acc: 0.5921\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4373 - soft_acc: 0.6822 - val_loss: 0.6757 - val_soft_acc: 0.5300\n",
      "Epoch 27/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4854 - soft_acc: 0.6550 - val_loss: 0.8891 - val_soft_acc: 0.3836\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4437 - soft_acc: 0.6583 - val_loss: 1.0626 - val_soft_acc: 0.2507\n",
      "Epoch 29/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4854 - soft_acc: 0.6256 - val_loss: 0.6661 - val_soft_acc: 0.5736\n",
      "Epoch 30/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4539 - soft_acc: 0.6450 - val_loss: 1.5283 - val_soft_acc: 0.0557\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5686 - soft_acc: 0.5778 - val_loss: 0.6782 - val_soft_acc: 0.4879\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.5022 - soft_acc: 0.5967 - val_loss: 1.5603 - val_soft_acc: 0.0607\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6262 - soft_acc: 0.5956 - val_loss: 1.3064 - val_soft_acc: 0.1164\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4983 - soft_acc: 0.6617 - val_loss: 0.9931 - val_soft_acc: 0.2271\n",
      "Epoch 35/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4266 - soft_acc: 0.6856 - val_loss: 0.8435 - val_soft_acc: 0.3871\n",
      "Epoch 36/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5225 - soft_acc: 0.6300 - val_loss: 0.7215 - val_soft_acc: 0.5607\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5393 - soft_acc: 0.5739 - val_loss: 1.3041 - val_soft_acc: 0.0957\n",
      "Epoch 38/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5404 - soft_acc: 0.6100best occur in epoch 37\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.4622 - soft_acc: 0.6856 - val_loss: 0.6268 - val_soft_acc: 0.6143\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4678 - soft_acc: 0.6156 - val_loss: 1.1807 - val_soft_acc: 0.1664\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4804 - soft_acc: 0.6711 - val_loss: 0.6810 - val_soft_acc: 0.4414\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5551 - soft_acc: 0.6089 - val_loss: 1.2024 - val_soft_acc: 0.1736\n",
      "Epoch 42/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.6060 - soft_acc: 0.5644 - val_loss: 0.5606 - val_soft_acc: 0.6064\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5131 - soft_acc: 0.6756 - val_loss: 1.1481 - val_soft_acc: 0.1971\n",
      "Epoch 44/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4917 - soft_acc: 0.5822 - val_loss: 1.1701 - val_soft_acc: 0.2121\n",
      "Epoch 45/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4628 - soft_acc: 0.6767 - val_loss: 0.8862 - val_soft_acc: 0.2236\n",
      "Epoch 46/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5327 - soft_acc: 0.6333 - val_loss: 0.7833 - val_soft_acc: 0.3936\n",
      "Epoch 47/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.5262 - soft_acc: 0.6189 - val_loss: 0.5815 - val_soft_acc: 0.6214\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5082 - soft_acc: 0.6500 - val_loss: 1.1889 - val_soft_acc: 0.1486\n",
      "Epoch 49/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4674 - soft_acc: 0.6517 - val_loss: 0.5913 - val_soft_acc: 0.5507\n",
      "Epoch 50/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4578 - soft_acc: 0.6350 - val_loss: 0.5501 - val_soft_acc: 0.5936\n",
      "Epoch 51/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4077 - soft_acc: 0.7067 - val_loss: 1.2613 - val_soft_acc: 0.0750\n",
      "Epoch 52/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4603 - soft_acc: 0.6589 - val_loss: 0.5852 - val_soft_acc: 0.5864\n",
      "Epoch 53/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2937 - soft_acc: 0.8100best occur in epoch 52\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.4042 - soft_acc: 0.7217 - val_loss: 0.5438 - val_soft_acc: 0.6057\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3864 - soft_acc: 0.7250 - val_loss: 1.1166 - val_soft_acc: 0.1764\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4514 - soft_acc: 0.7239 - val_loss: 1.1340 - val_soft_acc: 0.2071\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4057 - soft_acc: 0.7611 - val_loss: 0.6156 - val_soft_acc: 0.5407\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4585 - soft_acc: 0.6794 - val_loss: 0.5551 - val_soft_acc: 0.5679\n",
      "Epoch 58/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4084 - soft_acc: 0.7322 - val_loss: 1.7481 - val_soft_acc: 0.0429\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6160 - soft_acc: 0.5006 - val_loss: 2.1672 - val_soft_acc: 0.0279\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.9233 - soft_acc: 0.4028 - val_loss: 0.5962 - val_soft_acc: 0.5300\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.7053 - soft_acc: 0.5106 - val_loss: 1.2560 - val_soft_acc: 0.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.6155 - soft_acc: 0.5556 - val_loss: 0.6251 - val_soft_acc: 0.5279\n",
      "Epoch 63/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4488 - soft_acc: 0.6711 - val_loss: 0.6625 - val_soft_acc: 0.5229\n",
      "Epoch 64/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3960 - soft_acc: 0.7500best occur in epoch 63\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3960 - soft_acc: 0.7439 - val_loss: 0.5242 - val_soft_acc: 0.6443\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3899 - soft_acc: 0.7333 - val_loss: 0.7210 - val_soft_acc: 0.4421\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5094 - soft_acc: 0.6489 - val_loss: 0.7745 - val_soft_acc: 0.3986\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3925 - soft_acc: 0.6689 - val_loss: 0.6968 - val_soft_acc: 0.4443\n",
      "Epoch 68/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4624 - soft_acc: 0.6322 - val_loss: 0.7627 - val_soft_acc: 0.3886\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4353 - soft_acc: 0.6917 - val_loss: 1.0423 - val_soft_acc: 0.2679\n",
      "Epoch 70/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4069 - soft_acc: 0.6850 - val_loss: 0.5325 - val_soft_acc: 0.5857\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3729 - soft_acc: 0.7444 - val_loss: 0.7202 - val_soft_acc: 0.3986\n",
      "Epoch 72/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.4673 - soft_acc: 0.6706 - val_loss: 0.5932 - val_soft_acc: 0.5836\n",
      "Epoch 73/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.4197 - soft_acc: 0.6961 - val_loss: 0.5502 - val_soft_acc: 0.5750\n",
      "Epoch 74/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4318 - soft_acc: 0.6733 - val_loss: 0.7252 - val_soft_acc: 0.4393\n",
      "Epoch 75/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4275 - soft_acc: 0.6844 - val_loss: 0.7013 - val_soft_acc: 0.4821\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4321 - soft_acc: 0.6933 - val_loss: 1.5639 - val_soft_acc: 0.1064\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5460 - soft_acc: 0.6072 - val_loss: 0.6711 - val_soft_acc: 0.4386\n",
      "Epoch 78/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3748 - soft_acc: 0.7500best occur in epoch 77\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3895 - soft_acc: 0.7478 - val_loss: 0.4983 - val_soft_acc: 0.6643\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3740 - soft_acc: 0.7528 - val_loss: 0.5774 - val_soft_acc: 0.5707\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4118 - soft_acc: 0.6689 - val_loss: 0.5084 - val_soft_acc: 0.5879\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3543 - soft_acc: 0.7633 - val_loss: 0.6171 - val_soft_acc: 0.4614\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3405 - soft_acc: 0.7750 - val_loss: 1.1486 - val_soft_acc: 0.1821\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4139 - soft_acc: 0.7039 - val_loss: 1.5520 - val_soft_acc: 0.0636\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6449 - soft_acc: 0.5156 - val_loss: 0.8125 - val_soft_acc: 0.3229\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4725 - soft_acc: 0.6544 - val_loss: 0.5988 - val_soft_acc: 0.4993\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4232 - soft_acc: 0.7328 - val_loss: 0.6979 - val_soft_acc: 0.4343\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3760 - soft_acc: 0.7278 - val_loss: 0.6136 - val_soft_acc: 0.5436\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3396 - soft_acc: 0.7794 - val_loss: 0.5730 - val_soft_acc: 0.5993\n",
      "Epoch 89/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3358 - soft_acc: 0.7717 - val_loss: 0.5130 - val_soft_acc: 0.5986\n",
      "Epoch 90/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2713 - soft_acc: 0.8400best occur in epoch 89\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3330 - soft_acc: 0.8283 - val_loss: 0.5330 - val_soft_acc: 0.6393\n",
      "Epoch 91/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3552 - soft_acc: 0.7828 - val_loss: 0.5171 - val_soft_acc: 0.6364\n",
      "Epoch 92/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3534 - soft_acc: 0.7500 - val_loss: 0.4828 - val_soft_acc: 0.6493\n",
      "Epoch 93/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3289 - soft_acc: 0.7700 - val_loss: 0.5911 - val_soft_acc: 0.4893\n",
      "Epoch 94/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3933 - soft_acc: 0.7272 - val_loss: 0.6418 - val_soft_acc: 0.4750\n",
      "Epoch 95/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3514 - soft_acc: 0.7828 - val_loss: 0.7495 - val_soft_acc: 0.4121\n",
      "Epoch 96/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3364 - soft_acc: 0.7750 - val_loss: 0.7710 - val_soft_acc: 0.2893\n",
      "Epoch 97/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3534 - soft_acc: 0.7556 - val_loss: 0.6168 - val_soft_acc: 0.4593\n",
      "Epoch 98/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3371 - soft_acc: 0.7806 - val_loss: 0.7629 - val_soft_acc: 0.3229\n",
      "Epoch 99/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.3153 - soft_acc: 0.8183 - val_loss: 0.7017 - val_soft_acc: 0.4321\n",
      "Epoch 100/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3448 - soft_acc: 0.7344 - val_loss: 0.7217 - val_soft_acc: 0.4014\n",
      "Epoch 101/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3403 - soft_acc: 0.7550 - val_loss: 0.6846 - val_soft_acc: 0.4521\n",
      "Epoch 102/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3499 - soft_acc: 0.7367 - val_loss: 0.5347 - val_soft_acc: 0.5729\n",
      "Epoch 103/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3353 - soft_acc: 0.7783 - val_loss: 0.5282 - val_soft_acc: 0.6057\n",
      "Epoch 104/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3750 - soft_acc: 0.7672 - val_loss: 0.7631 - val_soft_acc: 0.4171\n",
      "Epoch 105/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3389 - soft_acc: 0.7856 - val_loss: 0.9131 - val_soft_acc: 0.2343\n",
      "Epoch 106/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3719 - soft_acc: 0.7539 - val_loss: 0.5647 - val_soft_acc: 0.5579\n",
      "Epoch 107/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3205 - soft_acc: 0.7778 - val_loss: 0.6719 - val_soft_acc: 0.4979\n",
      "Epoch 108/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3729 - soft_acc: 0.7522 - val_loss: 0.5496 - val_soft_acc: 0.5550\n",
      "Epoch 109/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3197 - soft_acc: 0.7794 - val_loss: 0.5362 - val_soft_acc: 0.5193\n",
      "Epoch 110/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3001 - soft_acc: 0.7939 - val_loss: 0.5486 - val_soft_acc: 0.5200\n",
      "Epoch 111/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2875 - soft_acc: 0.8372 - val_loss: 0.5683 - val_soft_acc: 0.5000\n",
      "Epoch 112/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2921 - soft_acc: 0.8278 - val_loss: 0.6200 - val_soft_acc: 0.4871\n",
      "Epoch 113/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3085 - soft_acc: 0.8006 - val_loss: 0.6498 - val_soft_acc: 0.4471\n",
      "Epoch 114/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2967 - soft_acc: 0.7717 - val_loss: 0.4833 - val_soft_acc: 0.6036\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2977 - soft_acc: 0.7967 - val_loss: 0.5095 - val_soft_acc: 0.6493\n",
      "Epoch 116/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3100 - soft_acc: 0.7900 - val_loss: 0.4826 - val_soft_acc: 0.5671\n",
      "Epoch 117/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2861 - soft_acc: 0.8511 - val_loss: 0.5378 - val_soft_acc: 0.4714\n",
      "Epoch 118/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3045 - soft_acc: 0.8106 - val_loss: 0.5752 - val_soft_acc: 0.5664\n",
      "Epoch 119/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2564 - soft_acc: 0.8600best occur in epoch 118\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.3131 - soft_acc: 0.7756 - val_loss: 0.5078 - val_soft_acc: 0.6936\n",
      "Epoch 120/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3072 - soft_acc: 0.8156 - val_loss: 0.4818 - val_soft_acc: 0.6443\n",
      "Epoch 121/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2999 - soft_acc: 0.8194 - val_loss: 0.5032 - val_soft_acc: 0.6093\n",
      "Epoch 122/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2825 - soft_acc: 0.8100best occur in epoch 121\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.2881 - soft_acc: 0.8267 - val_loss: 0.4793 - val_soft_acc: 0.6743\n",
      "Epoch 123/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2988 - soft_acc: 0.8328 - val_loss: 0.4528 - val_soft_acc: 0.6507\n",
      "Epoch 124/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3112 - soft_acc: 0.7722 - val_loss: 0.4768 - val_soft_acc: 0.6364\n",
      "Epoch 125/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2757 - soft_acc: 0.8200 - val_loss: 0.8022 - val_soft_acc: 0.3386\n",
      "Epoch 126/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3245 - soft_acc: 0.8111 - val_loss: 0.6967 - val_soft_acc: 0.4143\n",
      "Epoch 127/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3395 - soft_acc: 0.7839 - val_loss: 0.5395 - val_soft_acc: 0.5686\n",
      "Epoch 128/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3380 - soft_acc: 0.7683 - val_loss: 0.5243 - val_soft_acc: 0.5429\n",
      "Epoch 129/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3328 - soft_acc: 0.7467 - val_loss: 0.5033 - val_soft_acc: 0.6207\n",
      "Epoch 130/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3250 - soft_acc: 0.7906 - val_loss: 0.5824 - val_soft_acc: 0.5507\n",
      "Epoch 131/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3686 - soft_acc: 0.7556 - val_loss: 0.5248 - val_soft_acc: 0.5729\n",
      "Epoch 132/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3133 - soft_acc: 0.7794 - val_loss: 0.4939 - val_soft_acc: 0.6443\n",
      "Epoch 133/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2240 - soft_acc: 0.8900best occur in epoch 132\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2767 - soft_acc: 0.8217 - val_loss: 0.4814 - val_soft_acc: 0.6850\n",
      "Epoch 134/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2852 - soft_acc: 0.8633 - val_loss: 0.5617 - val_soft_acc: 0.5429\n",
      "Epoch 135/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2777 - soft_acc: 0.8422 - val_loss: 0.6238 - val_soft_acc: 0.5179\n",
      "Epoch 136/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2787 - soft_acc: 0.8683 - val_loss: 0.6997 - val_soft_acc: 0.4393\n",
      "Epoch 137/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2857 - soft_acc: 0.8067 - val_loss: 0.5392 - val_soft_acc: 0.6121\n",
      "Epoch 138/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2709 - soft_acc: 0.8478 - val_loss: 0.5094 - val_soft_acc: 0.6286\n",
      "Epoch 139/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3276 - soft_acc: 0.8061 - val_loss: 0.5073 - val_soft_acc: 0.6471\n",
      "Epoch 140/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3077 - soft_acc: 0.8433 - val_loss: 0.4595 - val_soft_acc: 0.6379\n",
      "Epoch 141/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2699 - soft_acc: 0.8583 - val_loss: 0.7055 - val_soft_acc: 0.3529\n",
      "Epoch 142/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2961 - soft_acc: 0.8089 - val_loss: 0.4886 - val_soft_acc: 0.6314\n",
      "Epoch 143/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2758 - soft_acc: 0.8322 - val_loss: 0.8837 - val_soft_acc: 0.2957\n",
      "Epoch 144/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3625 - soft_acc: 0.7744 - val_loss: 0.6610 - val_soft_acc: 0.4350\n",
      "Epoch 145/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3248 - soft_acc: 0.7989 - val_loss: 0.4766 - val_soft_acc: 0.5829\n",
      "Epoch 146/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3157 - soft_acc: 0.7983 - val_loss: 0.6222 - val_soft_acc: 0.5336\n",
      "Epoch 147/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3353 - soft_acc: 0.7789 - val_loss: 0.5757 - val_soft_acc: 0.5714\n",
      "Epoch 148/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3449 - soft_acc: 0.7650 - val_loss: 0.4828 - val_soft_acc: 0.6514\n",
      "Epoch 149/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3154 - soft_acc: 0.8228 - val_loss: 0.7066 - val_soft_acc: 0.4493\n",
      "Epoch 150/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3805 - soft_acc: 0.7328 - val_loss: 0.4715 - val_soft_acc: 0.5907\n",
      "Epoch 151/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2995 - soft_acc: 0.8272 - val_loss: 0.5776 - val_soft_acc: 0.4721\n",
      "Epoch 152/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3021 - soft_acc: 0.8178 - val_loss: 0.6597 - val_soft_acc: 0.4800\n",
      "Epoch 153/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2982 - soft_acc: 0.7967 - val_loss: 0.5065 - val_soft_acc: 0.5936\n",
      "Epoch 154/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2760 - soft_acc: 0.8511 - val_loss: 0.5041 - val_soft_acc: 0.5914\n",
      "Epoch 155/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2752 - soft_acc: 0.8283 - val_loss: 0.4604 - val_soft_acc: 0.6029\n",
      "Epoch 156/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2836 - soft_acc: 0.8667 - val_loss: 0.5041 - val_soft_acc: 0.6043\n",
      "Epoch 157/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2996 - soft_acc: 0.7900best occur in epoch 156\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.2724 - soft_acc: 0.8217 - val_loss: 0.4957 - val_soft_acc: 0.6893\n",
      "Epoch 158/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2775 - soft_acc: 0.8389 - val_loss: 0.4955 - val_soft_acc: 0.5900\n",
      "Epoch 159/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2877 - soft_acc: 0.8272 - val_loss: 0.5764 - val_soft_acc: 0.5600\n",
      "Epoch 160/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3050 - soft_acc: 0.7756 - val_loss: 0.4885 - val_soft_acc: 0.5957\n",
      "Epoch 161/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3092 - soft_acc: 0.7983 - val_loss: 0.5310 - val_soft_acc: 0.6371\n",
      "Epoch 162/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2807 - soft_acc: 0.8400 - val_loss: 0.5136 - val_soft_acc: 0.5771\n",
      "Epoch 163/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2828 - soft_acc: 0.8578 - val_loss: 0.5202 - val_soft_acc: 0.5929\n",
      "Epoch 164/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2855 - soft_acc: 0.8050 - val_loss: 0.4759 - val_soft_acc: 0.6514\n",
      "Epoch 165/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2801 - soft_acc: 0.8150 - val_loss: 0.6877 - val_soft_acc: 0.3757\n",
      "Epoch 166/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3046 - soft_acc: 0.8006 - val_loss: 0.9233 - val_soft_acc: 0.2421\n",
      "Epoch 167/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4189 - soft_acc: 0.6689 - val_loss: 0.4583 - val_soft_acc: 0.6821\n",
      "Epoch 168/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2949 - soft_acc: 0.8033 - val_loss: 0.4762 - val_soft_acc: 0.6593\n",
      "Epoch 169/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2760 - soft_acc: 0.8356 - val_loss: 0.4804 - val_soft_acc: 0.6150\n",
      "Epoch 170/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2632 - soft_acc: 0.8122 - val_loss: 0.4695 - val_soft_acc: 0.6693\n",
      "Epoch 171/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3104 - soft_acc: 0.7683 - val_loss: 0.5788 - val_soft_acc: 0.5336\n",
      "Epoch 172/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3614 - soft_acc: 0.7344 - val_loss: 0.4617 - val_soft_acc: 0.6336\n",
      "Epoch 173/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3503 - soft_acc: 0.8000 - val_loss: 0.5043 - val_soft_acc: 0.6357\n",
      "Epoch 174/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2888 - soft_acc: 0.8583 - val_loss: 0.6023 - val_soft_acc: 0.5764\n",
      "Epoch 175/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3224 - soft_acc: 0.7661 - val_loss: 0.4671 - val_soft_acc: 0.6793\n",
      "Epoch 176/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3331 - soft_acc: 0.7800 - val_loss: 0.5288 - val_soft_acc: 0.6207\n",
      "Epoch 177/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2866 - soft_acc: 0.8444 - val_loss: 0.5380 - val_soft_acc: 0.6464\n",
      "Epoch 178/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3162 - soft_acc: 0.7983 - val_loss: 0.4929 - val_soft_acc: 0.6771\n",
      "Epoch 179/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2840 - soft_acc: 0.8444 - val_loss: 0.4988 - val_soft_acc: 0.5879\n",
      "Epoch 180/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2653 - soft_acc: 0.8333 - val_loss: 0.4913 - val_soft_acc: 0.6186\n",
      "Epoch 181/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2509 - soft_acc: 0.8744 - val_loss: 0.5856 - val_soft_acc: 0.4179\n",
      "Epoch 182/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2753 - soft_acc: 0.8444 - val_loss: 0.8039 - val_soft_acc: 0.3121\n",
      "Epoch 183/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3296 - soft_acc: 0.7894 - val_loss: 0.4772 - val_soft_acc: 0.6079\n",
      "Epoch 184/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2591 - soft_acc: 0.8589 - val_loss: 0.5834 - val_soft_acc: 0.6114\n",
      "Epoch 185/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2652 - soft_acc: 0.8700 - val_loss: 0.5066 - val_soft_acc: 0.5936\n",
      "Epoch 186/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2610 - soft_acc: 0.8528 - val_loss: 0.5391 - val_soft_acc: 0.5221\n",
      "Epoch 187/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2733 - soft_acc: 0.8444 - val_loss: 0.4932 - val_soft_acc: 0.5900\n",
      "Epoch 188/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2806 - soft_acc: 0.8617 - val_loss: 0.5144 - val_soft_acc: 0.5700\n",
      "Epoch 189/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2727 - soft_acc: 0.8389 - val_loss: 0.6350 - val_soft_acc: 0.4921\n",
      "Epoch 190/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3393 - soft_acc: 0.8028 - val_loss: 0.4911 - val_soft_acc: 0.5829\n",
      "Epoch 191/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2746 - soft_acc: 0.8183 - val_loss: 0.6278 - val_soft_acc: 0.5007\n",
      "Epoch 192/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2832 - soft_acc: 0.8461 - val_loss: 0.7832 - val_soft_acc: 0.2950\n",
      "Epoch 193/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2902 - soft_acc: 0.8156 - val_loss: 0.5110 - val_soft_acc: 0.6014\n",
      "Epoch 194/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2823 - soft_acc: 0.8256 - val_loss: 0.4994 - val_soft_acc: 0.6564\n",
      "Epoch 195/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2644 - soft_acc: 0.8678 - val_loss: 0.5575 - val_soft_acc: 0.5557\n",
      "Epoch 196/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2655 - soft_acc: 0.8561 - val_loss: 0.6326 - val_soft_acc: 0.3879\n",
      "Epoch 197/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2793 - soft_acc: 0.8200 - val_loss: 0.5071 - val_soft_acc: 0.6850\n",
      "Epoch 198/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2694 - soft_acc: 0.7956 - val_loss: 0.6055 - val_soft_acc: 0.5843\n",
      "Epoch 199/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3165 - soft_acc: 0.8039 - val_loss: 0.5031 - val_soft_acc: 0.5543\n",
      "Epoch 200/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2775 - soft_acc: 0.8183 - val_loss: 0.4988 - val_soft_acc: 0.6186\n",
      "Epoch 201/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2900 - soft_acc: 0.8028 - val_loss: 0.6763 - val_soft_acc: 0.4321\n",
      "Epoch 202/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2869 - soft_acc: 0.7961 - val_loss: 0.8372 - val_soft_acc: 0.3136\n",
      "Epoch 203/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2791 - soft_acc: 0.8322 - val_loss: 0.6493 - val_soft_acc: 0.4236\n",
      "Epoch 204/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2630 - soft_acc: 0.8544 - val_loss: 0.5537 - val_soft_acc: 0.6164\n",
      "Epoch 205/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2740 - soft_acc: 0.8683 - val_loss: 0.5525 - val_soft_acc: 0.5521\n",
      "Epoch 206/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2856 - soft_acc: 0.8272 - val_loss: 0.6151 - val_soft_acc: 0.5636\n",
      "Epoch 207/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3256 - soft_acc: 0.7522 - val_loss: 0.5117 - val_soft_acc: 0.6393\n",
      "Epoch 208/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3536 - soft_acc: 0.7589 - val_loss: 1.0836 - val_soft_acc: 0.1514\n",
      "Epoch 209/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3652 - soft_acc: 0.7572 - val_loss: 0.6032 - val_soft_acc: 0.5100\n",
      "Epoch 210/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2989 - soft_acc: 0.8017 - val_loss: 0.5161 - val_soft_acc: 0.6364\n",
      "Epoch 211/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2925 - soft_acc: 0.8194 - val_loss: 0.5383 - val_soft_acc: 0.5600\n",
      "Epoch 212/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2758 - soft_acc: 0.8144 - val_loss: 0.7666 - val_soft_acc: 0.3793\n",
      "Epoch 213/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3367 - soft_acc: 0.7478 - val_loss: 0.5334 - val_soft_acc: 0.5757\n",
      "Epoch 214/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2919 - soft_acc: 0.8400 - val_loss: 0.5365 - val_soft_acc: 0.6214\n",
      "Epoch 215/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3040 - soft_acc: 0.8017 - val_loss: 0.6671 - val_soft_acc: 0.4393\n",
      "Epoch 216/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2867 - soft_acc: 0.8150 - val_loss: 0.6232 - val_soft_acc: 0.5157\n",
      "Epoch 217/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2511 - soft_acc: 0.8383 - val_loss: 0.7402 - val_soft_acc: 0.3329\n",
      "Epoch 218/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3123 - soft_acc: 0.7794 - val_loss: 0.5469 - val_soft_acc: 0.4843\n",
      "Epoch 219/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3059 - soft_acc: 0.7900 - val_loss: 0.4866 - val_soft_acc: 0.6414\n",
      "Epoch 220/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3116 - soft_acc: 0.8189 - val_loss: 0.5538 - val_soft_acc: 0.5321\n",
      "Epoch 221/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2790 - soft_acc: 0.8200 - val_loss: 0.5410 - val_soft_acc: 0.4993\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2450 - soft_acc: 0.8239 - val_loss: 0.5016 - val_soft_acc: 0.6800\n",
      "Epoch 223/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2549 - soft_acc: 0.8267 - val_loss: 0.5162 - val_soft_acc: 0.6193\n",
      "Epoch 224/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2327 - soft_acc: 0.8600best occur in epoch 223\n",
      "512/512 [==============================] - 0s 65us/sample - loss: 0.2422 - soft_acc: 0.8639 - val_loss: 0.4947 - val_soft_acc: 0.6621\n",
      "Epoch 225/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2669 - soft_acc: 0.8500best occur in epoch 224\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2430 - soft_acc: 0.8744 - val_loss: 0.4794 - val_soft_acc: 0.6671\n",
      "Epoch 226/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2347 - soft_acc: 0.8844 - val_loss: 0.5736 - val_soft_acc: 0.5050\n",
      "Epoch 227/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2533 - soft_acc: 0.8606 - val_loss: 0.5929 - val_soft_acc: 0.4821\n",
      "Epoch 228/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2627 - soft_acc: 0.8456 - val_loss: 0.7070 - val_soft_acc: 0.4343\n",
      "Epoch 229/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2836 - soft_acc: 0.8267 - val_loss: 0.5111 - val_soft_acc: 0.6271\n",
      "Epoch 230/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2552 - soft_acc: 0.8694 - val_loss: 0.4812 - val_soft_acc: 0.6307\n",
      "Epoch 231/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2591 - soft_acc: 0.8678 - val_loss: 0.5692 - val_soft_acc: 0.5964\n",
      "Epoch 232/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2674 - soft_acc: 0.8478 - val_loss: 0.5198 - val_soft_acc: 0.5886\n",
      "Epoch 233/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2710 - soft_acc: 0.8356 - val_loss: 0.5398 - val_soft_acc: 0.5836\n",
      "Epoch 234/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2515 - soft_acc: 0.8628 - val_loss: 0.5237 - val_soft_acc: 0.6086\n",
      "Epoch 235/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2448 - soft_acc: 0.8500 - val_loss: 0.5601 - val_soft_acc: 0.5229\n",
      "Epoch 236/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2500 - soft_acc: 0.8800 - val_loss: 0.5757 - val_soft_acc: 0.5557\n",
      "Epoch 237/1000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.2529 - soft_acc: 0.8728 - val_loss: 0.5705 - val_soft_acc: 0.5964\n",
      "Epoch 238/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2519 - soft_acc: 0.8450 - val_loss: 0.5057 - val_soft_acc: 0.6157\n",
      "Epoch 239/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2457 - soft_acc: 0.8656 - val_loss: 0.5453 - val_soft_acc: 0.5807\n",
      "Epoch 240/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2319 - soft_acc: 0.9117 - val_loss: 0.6685 - val_soft_acc: 0.3757\n",
      "Epoch 241/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2757 - soft_acc: 0.8217 - val_loss: 0.5090 - val_soft_acc: 0.6471\n",
      "Epoch 242/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2526 - soft_acc: 0.8350 - val_loss: 0.5251 - val_soft_acc: 0.6629\n",
      "Epoch 243/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2561 - soft_acc: 0.8672 - val_loss: 0.4956 - val_soft_acc: 0.5879\n",
      "Epoch 244/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2565 - soft_acc: 0.8561 - val_loss: 0.5643 - val_soft_acc: 0.5300\n",
      "Epoch 245/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2760 - soft_acc: 0.8478 - val_loss: 0.6677 - val_soft_acc: 0.3993\n",
      "Epoch 246/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2607 - soft_acc: 0.8700 - val_loss: 0.5347 - val_soft_acc: 0.5986\n",
      "Epoch 247/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2873 - soft_acc: 0.8300best occur in epoch 246\n",
      "512/512 [==============================] - 0s 58us/sample - loss: 0.2456 - soft_acc: 0.8744 - val_loss: 0.5127 - val_soft_acc: 0.6800\n",
      "Epoch 248/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2267 - soft_acc: 0.8844 - val_loss: 0.5312 - val_soft_acc: 0.6700\n",
      "Epoch 249/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2307 - soft_acc: 0.8828 - val_loss: 0.5194 - val_soft_acc: 0.6214\n",
      "Epoch 250/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2619 - soft_acc: 0.8733 - val_loss: 0.4796 - val_soft_acc: 0.5621\n",
      "Epoch 251/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2550 - soft_acc: 0.8350 - val_loss: 0.5844 - val_soft_acc: 0.5229\n",
      "Epoch 252/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3181 - soft_acc: 0.7933 - val_loss: 0.6575 - val_soft_acc: 0.4500\n",
      "Epoch 253/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2654 - soft_acc: 0.8561 - val_loss: 0.4774 - val_soft_acc: 0.6850\n",
      "Epoch 254/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2440 - soft_acc: 0.8817 - val_loss: 0.5850 - val_soft_acc: 0.4771\n",
      "Epoch 255/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2606 - soft_acc: 0.8461 - val_loss: 0.4851 - val_soft_acc: 0.5979\n",
      "Epoch 256/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2420 - soft_acc: 0.8394 - val_loss: 0.6445 - val_soft_acc: 0.5564\n",
      "Epoch 257/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2893 - soft_acc: 0.8328 - val_loss: 0.5683 - val_soft_acc: 0.5864\n",
      "Epoch 258/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3099 - soft_acc: 0.8039 - val_loss: 0.7418 - val_soft_acc: 0.3507\n",
      "Epoch 259/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2843 - soft_acc: 0.8650 - val_loss: 0.5577 - val_soft_acc: 0.5229\n",
      "Epoch 260/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2456 - soft_acc: 0.8711 - val_loss: 0.5492 - val_soft_acc: 0.5607\n",
      "Epoch 261/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2568 - soft_acc: 0.8439 - val_loss: 0.5305 - val_soft_acc: 0.6064\n",
      "Epoch 262/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2657 - soft_acc: 0.8406 - val_loss: 0.5873 - val_soft_acc: 0.5243\n",
      "Epoch 263/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2446 - soft_acc: 0.8361 - val_loss: 0.5430 - val_soft_acc: 0.5221\n",
      "Epoch 264/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2738 - soft_acc: 0.8550 - val_loss: 0.4900 - val_soft_acc: 0.6386\n",
      "Epoch 265/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2642 - soft_acc: 0.8694 - val_loss: 0.5300 - val_soft_acc: 0.5757\n",
      "Epoch 266/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2860 - soft_acc: 0.7994 - val_loss: 0.6998 - val_soft_acc: 0.4036\n",
      "Epoch 267/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2989 - soft_acc: 0.8289 - val_loss: 0.5504 - val_soft_acc: 0.6243\n",
      "Epoch 268/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2902 - soft_acc: 0.7528 - val_loss: 0.5414 - val_soft_acc: 0.5421\n",
      "Epoch 269/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2402 - soft_acc: 0.8783 - val_loss: 0.5076 - val_soft_acc: 0.6721\n",
      "Epoch 270/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2197 - soft_acc: 0.9117 - val_loss: 0.5026 - val_soft_acc: 0.5907\n",
      "Epoch 271/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2486 - soft_acc: 0.8517 - val_loss: 0.5039 - val_soft_acc: 0.6393\n",
      "Epoch 272/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2420 - soft_acc: 0.8539 - val_loss: 0.5360 - val_soft_acc: 0.5829\n",
      "Epoch 273/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2264 - soft_acc: 0.8961 - val_loss: 0.5156 - val_soft_acc: 0.6079\n",
      "Epoch 274/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2295 - soft_acc: 0.8344 - val_loss: 0.4964 - val_soft_acc: 0.5950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2591 - soft_acc: 0.8539 - val_loss: 0.5169 - val_soft_acc: 0.5729\n",
      "Epoch 276/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2258 - soft_acc: 0.8533 - val_loss: 0.6006 - val_soft_acc: 0.5286\n",
      "Epoch 277/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2239 - soft_acc: 0.9033 - val_loss: 0.5825 - val_soft_acc: 0.5000\n",
      "Epoch 278/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2292 - soft_acc: 0.8550 - val_loss: 0.5044 - val_soft_acc: 0.5857\n",
      "Epoch 279/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2217 - soft_acc: 0.8822 - val_loss: 0.5844 - val_soft_acc: 0.5329\n",
      "Epoch 280/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2358 - soft_acc: 0.8589 - val_loss: 0.5312 - val_soft_acc: 0.6114\n",
      "Epoch 281/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2259 - soft_acc: 0.8422 - val_loss: 0.6874 - val_soft_acc: 0.4293\n",
      "Epoch 282/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2443 - soft_acc: 0.8644 - val_loss: 0.6076 - val_soft_acc: 0.4593\n",
      "Epoch 283/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2468 - soft_acc: 0.8883 - val_loss: 0.5100 - val_soft_acc: 0.5936\n",
      "Epoch 284/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2401 - soft_acc: 0.8722 - val_loss: 0.4947 - val_soft_acc: 0.5707\n",
      "Epoch 285/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2269 - soft_acc: 0.8911 - val_loss: 0.5974 - val_soft_acc: 0.5079\n",
      "Epoch 286/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2434 - soft_acc: 0.8761 - val_loss: 0.5085 - val_soft_acc: 0.5500\n",
      "Epoch 287/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2285 - soft_acc: 0.8650 - val_loss: 0.5283 - val_soft_acc: 0.5836\n",
      "Epoch 288/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2437 - soft_acc: 0.8844 - val_loss: 0.5448 - val_soft_acc: 0.5786\n",
      "Epoch 289/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2280 - soft_acc: 0.9100 - val_loss: 0.5369 - val_soft_acc: 0.5657\n",
      "Epoch 290/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2571 - soft_acc: 0.8528 - val_loss: 0.5292 - val_soft_acc: 0.6579\n",
      "Epoch 291/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2334 - soft_acc: 0.8622 - val_loss: 0.4994 - val_soft_acc: 0.6207\n",
      "Epoch 292/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2353 - soft_acc: 0.8589 - val_loss: 0.4997 - val_soft_acc: 0.6393\n",
      "Epoch 293/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2343 - soft_acc: 0.8539 - val_loss: 0.5390 - val_soft_acc: 0.5707\n",
      "Epoch 294/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2065 - soft_acc: 0.8733 - val_loss: 0.5141 - val_soft_acc: 0.5936\n",
      "Epoch 295/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2201 - soft_acc: 0.8722 - val_loss: 0.6593 - val_soft_acc: 0.4057\n",
      "Epoch 296/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2446 - soft_acc: 0.8933 - val_loss: 0.6277 - val_soft_acc: 0.4750\n",
      "Epoch 297/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2273 - soft_acc: 0.8822 - val_loss: 0.5538 - val_soft_acc: 0.4536\n",
      "Epoch 298/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2183 - soft_acc: 0.9017 - val_loss: 0.4844 - val_soft_acc: 0.6307\n",
      "Epoch 299/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2062 - soft_acc: 0.9044 - val_loss: 0.5934 - val_soft_acc: 0.5793\n",
      "Epoch 300/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2431 - soft_acc: 0.8672 - val_loss: 0.5817 - val_soft_acc: 0.5300\n",
      "Epoch 301/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2133 - soft_acc: 0.8800best occur in epoch 300\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.2332 - soft_acc: 0.8761 - val_loss: 0.4910 - val_soft_acc: 0.6821\n",
      "Epoch 302/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1900 - soft_acc: 0.9200 - val_loss: 0.5150 - val_soft_acc: 0.6243\n",
      "Epoch 303/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1904 - soft_acc: 0.9178 - val_loss: 0.5788 - val_soft_acc: 0.4993\n",
      "Epoch 304/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2200 - soft_acc: 0.9061 - val_loss: 0.5903 - val_soft_acc: 0.5157\n",
      "Epoch 305/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2395 - soft_acc: 0.8633 - val_loss: 0.5121 - val_soft_acc: 0.5700\n",
      "Epoch 306/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1996 - soft_acc: 0.9006 - val_loss: 0.5565 - val_soft_acc: 0.5757\n",
      "Epoch 307/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2412 - soft_acc: 0.8800 - val_loss: 0.5556 - val_soft_acc: 0.5021\n",
      "Epoch 308/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2166 - soft_acc: 0.9117 - val_loss: 0.4967 - val_soft_acc: 0.5929\n",
      "Epoch 309/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1802 - soft_acc: 0.9400best occur in epoch 308\n",
      "512/512 [==============================] - 0s 56us/sample - loss: 0.2194 - soft_acc: 0.8972 - val_loss: 0.5244 - val_soft_acc: 0.6679\n",
      "Epoch 310/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2031 - soft_acc: 0.9078 - val_loss: 0.6333 - val_soft_acc: 0.4879\n",
      "Epoch 311/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.2368 - soft_acc: 0.8794 - val_loss: 0.5989 - val_soft_acc: 0.5179\n",
      "Epoch 312/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2274 - soft_acc: 0.8894 - val_loss: 0.4994 - val_soft_acc: 0.6521\n",
      "Epoch 313/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1905 - soft_acc: 0.9150 - val_loss: 0.5062 - val_soft_acc: 0.6136\n",
      "Epoch 314/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1813 - soft_acc: 0.9233 - val_loss: 0.5290 - val_soft_acc: 0.5836\n",
      "Epoch 315/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2019 - soft_acc: 0.8906 - val_loss: 0.4841 - val_soft_acc: 0.5971\n",
      "Epoch 316/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2195 - soft_acc: 0.8978 - val_loss: 0.6011 - val_soft_acc: 0.4771\n",
      "Epoch 317/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2486 - soft_acc: 0.8744 - val_loss: 0.4955 - val_soft_acc: 0.6107\n",
      "Epoch 318/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2018 - soft_acc: 0.9044 - val_loss: 0.5538 - val_soft_acc: 0.4921\n",
      "Epoch 319/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1962 - soft_acc: 0.9194 - val_loss: 0.4778 - val_soft_acc: 0.6286\n",
      "Epoch 320/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2044 - soft_acc: 0.9117 - val_loss: 0.5400 - val_soft_acc: 0.6121\n",
      "Epoch 321/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2154 - soft_acc: 0.8939 - val_loss: 0.6506 - val_soft_acc: 0.4243\n",
      "Epoch 322/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2452 - soft_acc: 0.8883 - val_loss: 0.5593 - val_soft_acc: 0.5786\n",
      "Epoch 323/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2435 - soft_acc: 0.8756 - val_loss: 0.5659 - val_soft_acc: 0.5300\n",
      "Epoch 324/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2220 - soft_acc: 0.8861 - val_loss: 0.5991 - val_soft_acc: 0.5236\n",
      "Epoch 325/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2827 - soft_acc: 0.8339 - val_loss: 0.6061 - val_soft_acc: 0.5479\n",
      "Epoch 326/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2537 - soft_acc: 0.8539 - val_loss: 0.5834 - val_soft_acc: 0.5864\n",
      "Epoch 327/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2137 - soft_acc: 0.8944 - val_loss: 0.5448 - val_soft_acc: 0.5979\n",
      "Epoch 328/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2032 - soft_acc: 0.8889 - val_loss: 0.5291 - val_soft_acc: 0.6064\n",
      "Epoch 329/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2112 - soft_acc: 0.9094 - val_loss: 0.5913 - val_soft_acc: 0.5050\n",
      "Epoch 330/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1990 - soft_acc: 0.9028 - val_loss: 0.5296 - val_soft_acc: 0.5986\n",
      "Epoch 331/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1994 - soft_acc: 0.9183 - val_loss: 0.5114 - val_soft_acc: 0.6236\n",
      "Epoch 332/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1911 - soft_acc: 0.9283 - val_loss: 0.4911 - val_soft_acc: 0.6336\n",
      "Epoch 333/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1513 - soft_acc: 0.9500best occur in epoch 332\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.1814 - soft_acc: 0.9367 - val_loss: 0.5157 - val_soft_acc: 0.6593\n",
      "Epoch 334/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1776 - soft_acc: 0.9367 - val_loss: 0.5371 - val_soft_acc: 0.5879\n",
      "Epoch 335/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1987 - soft_acc: 0.9028 - val_loss: 0.5229 - val_soft_acc: 0.5014\n",
      "Epoch 336/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2084 - soft_acc: 0.8939 - val_loss: 0.5031 - val_soft_acc: 0.6857\n",
      "Epoch 337/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1955 - soft_acc: 0.8833 - val_loss: 0.5322 - val_soft_acc: 0.6314\n",
      "Epoch 338/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2150 - soft_acc: 0.9128 - val_loss: 0.5334 - val_soft_acc: 0.5064\n",
      "Epoch 339/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2123 - soft_acc: 0.8906 - val_loss: 0.7657 - val_soft_acc: 0.3793\n",
      "Epoch 340/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3244 - soft_acc: 0.7450 - val_loss: 0.5646 - val_soft_acc: 0.6321\n",
      "Epoch 341/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2857 - soft_acc: 0.8217 - val_loss: 0.5290 - val_soft_acc: 0.5936\n",
      "Epoch 342/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2212 - soft_acc: 0.8744 - val_loss: 0.5565 - val_soft_acc: 0.5371\n",
      "Epoch 343/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2054 - soft_acc: 0.9028 - val_loss: 0.5590 - val_soft_acc: 0.5329\n",
      "Epoch 344/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2354 - soft_acc: 0.8800 - val_loss: 0.5544 - val_soft_acc: 0.5279\n",
      "Epoch 345/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2229 - soft_acc: 0.8978 - val_loss: 0.5541 - val_soft_acc: 0.6164\n",
      "Epoch 346/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2098 - soft_acc: 0.8972 - val_loss: 0.5031 - val_soft_acc: 0.6057\n",
      "Epoch 347/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2219 - soft_acc: 0.8933 - val_loss: 0.5592 - val_soft_acc: 0.5936\n",
      "Epoch 348/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2363 - soft_acc: 0.8678 - val_loss: 0.5531 - val_soft_acc: 0.5400\n",
      "Epoch 349/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2529 - soft_acc: 0.8589 - val_loss: 0.5022 - val_soft_acc: 0.6193\n",
      "Epoch 350/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1960 - soft_acc: 0.9250 - val_loss: 0.5444 - val_soft_acc: 0.6036\n",
      "Epoch 351/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2109 - soft_acc: 0.9217 - val_loss: 0.5440 - val_soft_acc: 0.5629\n",
      "Epoch 352/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1965 - soft_acc: 0.8989 - val_loss: 0.6799 - val_soft_acc: 0.4829\n",
      "Epoch 353/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2456 - soft_acc: 0.8900 - val_loss: 0.5394 - val_soft_acc: 0.6164\n",
      "Epoch 354/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2015 - soft_acc: 0.9250 - val_loss: 0.6198 - val_soft_acc: 0.4614\n",
      "Epoch 355/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2316 - soft_acc: 0.8600 - val_loss: 0.5558 - val_soft_acc: 0.6400\n",
      "Epoch 356/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1877 - soft_acc: 0.8728 - val_loss: 0.5338 - val_soft_acc: 0.4814\n",
      "Epoch 357/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1805 - soft_acc: 0.9317 - val_loss: 0.5501 - val_soft_acc: 0.5479\n",
      "Epoch 358/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2123 - soft_acc: 0.8972 - val_loss: 0.5445 - val_soft_acc: 0.5629\n",
      "Epoch 359/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1970 - soft_acc: 0.9044 - val_loss: 0.4828 - val_soft_acc: 0.6286\n",
      "Epoch 360/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1971 - soft_acc: 0.9094 - val_loss: 0.5822 - val_soft_acc: 0.5786\n",
      "Epoch 361/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2237 - soft_acc: 0.9067 - val_loss: 0.5525 - val_soft_acc: 0.5529\n",
      "Epoch 362/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1617 - soft_acc: 0.9500best occur in epoch 361\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1871 - soft_acc: 0.9211 - val_loss: 0.4844 - val_soft_acc: 0.6771\n",
      "Epoch 363/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1957 - soft_acc: 0.8828 - val_loss: 0.6163 - val_soft_acc: 0.5029\n",
      "Epoch 364/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2016 - soft_acc: 0.8989 - val_loss: 0.5052 - val_soft_acc: 0.5800\n",
      "Epoch 365/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1838 - soft_acc: 0.9244 - val_loss: 0.6436 - val_soft_acc: 0.5486\n",
      "Epoch 366/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2097 - soft_acc: 0.9100 - val_loss: 0.5171 - val_soft_acc: 0.6314\n",
      "Epoch 367/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2105 - soft_acc: 0.9044 - val_loss: 0.6023 - val_soft_acc: 0.5000\n",
      "Epoch 368/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2136 - soft_acc: 0.8856 - val_loss: 0.6162 - val_soft_acc: 0.4564\n",
      "Epoch 369/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2420 - soft_acc: 0.8728 - val_loss: 0.5419 - val_soft_acc: 0.6057\n",
      "Epoch 370/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2326 - soft_acc: 0.8794 - val_loss: 0.5868 - val_soft_acc: 0.6300\n",
      "Epoch 371/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2161 - soft_acc: 0.9044 - val_loss: 0.5279 - val_soft_acc: 0.5650\n",
      "Epoch 372/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1998 - soft_acc: 0.8956 - val_loss: 0.6639 - val_soft_acc: 0.4186\n",
      "Epoch 373/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2762 - soft_acc: 0.8350 - val_loss: 0.5962 - val_soft_acc: 0.5029\n",
      "Epoch 374/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2366 - soft_acc: 0.9083 - val_loss: 0.9136 - val_soft_acc: 0.2707\n",
      "Epoch 375/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3005 - soft_acc: 0.7744 - val_loss: 0.5452 - val_soft_acc: 0.5457\n",
      "Epoch 376/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3153 - soft_acc: 0.7728 - val_loss: 0.5601 - val_soft_acc: 0.6114\n",
      "Epoch 377/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2797 - soft_acc: 0.8289 - val_loss: 0.6409 - val_soft_acc: 0.4079\n",
      "Epoch 378/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2419 - soft_acc: 0.8461 - val_loss: 0.6095 - val_soft_acc: 0.5079\n",
      "Epoch 379/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2473 - soft_acc: 0.8811 - val_loss: 0.5183 - val_soft_acc: 0.6036\n",
      "Epoch 380/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2132 - soft_acc: 0.8889 - val_loss: 0.5139 - val_soft_acc: 0.5629\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2050 - soft_acc: 0.8961 - val_loss: 0.6908 - val_soft_acc: 0.4679\n",
      "Epoch 382/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2927 - soft_acc: 0.8017 - val_loss: 0.7124 - val_soft_acc: 0.3864\n",
      "Epoch 383/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2389 - soft_acc: 0.8761 - val_loss: 0.5375 - val_soft_acc: 0.5707\n",
      "Epoch 384/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2067 - soft_acc: 0.8972 - val_loss: 0.5503 - val_soft_acc: 0.5936\n",
      "Epoch 385/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1896 - soft_acc: 0.9011 - val_loss: 0.5122 - val_soft_acc: 0.5750\n",
      "Epoch 386/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2026 - soft_acc: 0.9028 - val_loss: 0.5779 - val_soft_acc: 0.5243\n",
      "Epoch 387/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2120 - soft_acc: 0.8856 - val_loss: 0.5447 - val_soft_acc: 0.5986\n",
      "Epoch 388/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2150 - soft_acc: 0.8978 - val_loss: 0.5362 - val_soft_acc: 0.6214\n",
      "Epoch 389/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1953 - soft_acc: 0.9183 - val_loss: 0.5433 - val_soft_acc: 0.5521\n",
      "Epoch 390/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2277 - soft_acc: 0.9044 - val_loss: 0.5570 - val_soft_acc: 0.5450\n",
      "Epoch 391/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2193 - soft_acc: 0.9033 - val_loss: 0.5629 - val_soft_acc: 0.5993\n",
      "Epoch 392/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1946 - soft_acc: 0.9178 - val_loss: 0.5637 - val_soft_acc: 0.5736\n",
      "Epoch 393/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2047 - soft_acc: 0.9094 - val_loss: 0.5281 - val_soft_acc: 0.5571\n",
      "Epoch 394/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1889 - soft_acc: 0.9283 - val_loss: 0.5023 - val_soft_acc: 0.6236\n",
      "Epoch 395/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1640 - soft_acc: 0.9106 - val_loss: 0.5016 - val_soft_acc: 0.5779\n",
      "Epoch 396/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1619 - soft_acc: 0.9172 - val_loss: 0.5134 - val_soft_acc: 0.6036\n",
      "Epoch 397/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1772 - soft_acc: 0.9500 - val_loss: 0.5614 - val_soft_acc: 0.5579\n",
      "Epoch 398/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1762 - soft_acc: 0.9217 - val_loss: 0.5234 - val_soft_acc: 0.6271\n",
      "Epoch 399/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1775 - soft_acc: 0.9417 - val_loss: 0.5440 - val_soft_acc: 0.5193\n",
      "Epoch 400/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1760 - soft_acc: 0.9261 - val_loss: 0.5057 - val_soft_acc: 0.5979\n",
      "Epoch 401/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1653 - soft_acc: 0.9294 - val_loss: 0.5664 - val_soft_acc: 0.5679\n",
      "Epoch 402/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1787 - soft_acc: 0.8917 - val_loss: 0.5284 - val_soft_acc: 0.6529\n",
      "Epoch 403/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1721 - soft_acc: 0.9400 - val_loss: 0.5791 - val_soft_acc: 0.5457\n",
      "Epoch 404/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1942 - soft_acc: 0.9156 - val_loss: 0.5985 - val_soft_acc: 0.5179\n",
      "Epoch 405/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2092 - soft_acc: 0.9111 - val_loss: 0.5540 - val_soft_acc: 0.5936\n",
      "Epoch 406/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1684 - soft_acc: 0.9417 - val_loss: 0.5364 - val_soft_acc: 0.5907\n",
      "Epoch 407/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1634 - soft_acc: 0.9344 - val_loss: 0.5354 - val_soft_acc: 0.6293\n",
      "Epoch 408/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1734 - soft_acc: 0.9189 - val_loss: 0.5639 - val_soft_acc: 0.4536\n",
      "Epoch 409/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1815 - soft_acc: 0.9294 - val_loss: 0.5096 - val_soft_acc: 0.6521\n",
      "Epoch 410/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1603 - soft_acc: 0.9411 - val_loss: 0.5262 - val_soft_acc: 0.6143\n",
      "Epoch 411/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1494 - soft_acc: 0.9411 - val_loss: 0.5010 - val_soft_acc: 0.6543\n",
      "Epoch 412/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1722 - soft_acc: 0.9483 - val_loss: 0.5217 - val_soft_acc: 0.5471\n",
      "Epoch 413/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1599 - soft_acc: 0.9500 - val_loss: 0.5950 - val_soft_acc: 0.4714\n",
      "Epoch 414/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1842 - soft_acc: 0.9194 - val_loss: 0.5663 - val_soft_acc: 0.5964\n",
      "Epoch 415/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1899 - soft_acc: 0.9194 - val_loss: 0.6164 - val_soft_acc: 0.4714\n",
      "Epoch 416/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2125 - soft_acc: 0.9117 - val_loss: 0.4973 - val_soft_acc: 0.6393\n",
      "Epoch 417/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1665 - soft_acc: 0.9361 - val_loss: 0.5063 - val_soft_acc: 0.6029\n",
      "Epoch 418/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1564 - soft_acc: 0.9483 - val_loss: 0.5388 - val_soft_acc: 0.5886\n",
      "Epoch 419/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1551 - soft_acc: 0.9222 - val_loss: 0.5311 - val_soft_acc: 0.5957\n",
      "Epoch 420/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1578 - soft_acc: 0.9467 - val_loss: 0.5483 - val_soft_acc: 0.5736\n",
      "Epoch 421/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1629 - soft_acc: 0.9417 - val_loss: 0.5765 - val_soft_acc: 0.4664\n",
      "Epoch 422/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1985 - soft_acc: 0.9228 - val_loss: 0.6100 - val_soft_acc: 0.5257\n",
      "Epoch 423/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1966 - soft_acc: 0.9061 - val_loss: 0.6027 - val_soft_acc: 0.4821\n",
      "Epoch 424/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2039 - soft_acc: 0.8922 - val_loss: 0.5360 - val_soft_acc: 0.6243\n",
      "Epoch 425/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1931 - soft_acc: 0.9333 - val_loss: 0.6416 - val_soft_acc: 0.4850\n",
      "Epoch 426/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2034 - soft_acc: 0.9128 - val_loss: 0.5931 - val_soft_acc: 0.5743\n",
      "Epoch 427/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1886 - soft_acc: 0.9089 - val_loss: 0.5543 - val_soft_acc: 0.5814\n",
      "Epoch 428/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2158 - soft_acc: 0.9100 - val_loss: 0.5594 - val_soft_acc: 0.5607\n",
      "Epoch 429/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1746 - soft_acc: 0.9350 - val_loss: 0.5027 - val_soft_acc: 0.5443\n",
      "Epoch 430/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1720 - soft_acc: 0.9278 - val_loss: 0.5975 - val_soft_acc: 0.5686\n",
      "Epoch 431/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1795 - soft_acc: 0.9383 - val_loss: 0.6247 - val_soft_acc: 0.5257\n",
      "Epoch 432/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2072 - soft_acc: 0.9111 - val_loss: 0.5661 - val_soft_acc: 0.5379\n",
      "Epoch 433/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2097 - soft_acc: 0.9094 - val_loss: 0.5630 - val_soft_acc: 0.6050\n",
      "Epoch 434/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2125 - soft_acc: 0.8856 - val_loss: 0.5142 - val_soft_acc: 0.5629\n",
      "Epoch 435/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1859 - soft_acc: 0.9300 - val_loss: 0.5066 - val_soft_acc: 0.5779\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1915 - soft_acc: 0.9094 - val_loss: 0.4926 - val_soft_acc: 0.6364\n",
      "Epoch 437/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1760 - soft_acc: 0.9517 - val_loss: 0.5735 - val_soft_acc: 0.5400\n",
      "Epoch 438/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1678 - soft_acc: 0.9400best occur in epoch 437\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.1810 - soft_acc: 0.9533 - val_loss: 0.4853 - val_soft_acc: 0.6950\n",
      "Epoch 439/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1695 - soft_acc: 0.9278 - val_loss: 0.5296 - val_soft_acc: 0.5986\n",
      "Epoch 440/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1604 - soft_acc: 0.9361 - val_loss: 0.4964 - val_soft_acc: 0.6443\n",
      "Epoch 441/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1619 - soft_acc: 0.9461 - val_loss: 0.5040 - val_soft_acc: 0.6264\n",
      "Epoch 442/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1627 - soft_acc: 0.9583 - val_loss: 0.5670 - val_soft_acc: 0.5079\n",
      "Epoch 443/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1570 - soft_acc: 0.9517 - val_loss: 0.5212 - val_soft_acc: 0.5957\n",
      "Epoch 444/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1622 - soft_acc: 0.9383 - val_loss: 0.5165 - val_soft_acc: 0.5650\n",
      "Epoch 445/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1521 - soft_acc: 0.9567 - val_loss: 0.5944 - val_soft_acc: 0.6150\n",
      "Epoch 446/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1879 - soft_acc: 0.9350 - val_loss: 0.6291 - val_soft_acc: 0.4536\n",
      "Epoch 447/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2532 - soft_acc: 0.8528 - val_loss: 0.5594 - val_soft_acc: 0.4993\n",
      "Epoch 448/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1851 - soft_acc: 0.9400 - val_loss: 0.4835 - val_soft_acc: 0.6464\n",
      "Epoch 449/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1942 - soft_acc: 0.9400 - val_loss: 0.5532 - val_soft_acc: 0.5757\n",
      "Epoch 450/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1736 - soft_acc: 0.9328 - val_loss: 0.5107 - val_soft_acc: 0.6264\n",
      "Epoch 451/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1740 - soft_acc: 0.9378 - val_loss: 0.5347 - val_soft_acc: 0.6164\n",
      "Epoch 452/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1491 - soft_acc: 0.9461 - val_loss: 0.4993 - val_soft_acc: 0.6621\n",
      "Epoch 453/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1508 - soft_acc: 0.9483 - val_loss: 0.5359 - val_soft_acc: 0.6471\n",
      "Epoch 454/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1618 - soft_acc: 0.9550 - val_loss: 0.5174 - val_soft_acc: 0.5800\n",
      "Epoch 455/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1453 - soft_acc: 0.9583 - val_loss: 0.5668 - val_soft_acc: 0.5707\n",
      "Epoch 456/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1653 - soft_acc: 0.9272 - val_loss: 0.5112 - val_soft_acc: 0.6136\n",
      "Epoch 457/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1473 - soft_acc: 0.9600 - val_loss: 0.5268 - val_soft_acc: 0.6393\n",
      "Epoch 458/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1658 - soft_acc: 0.9350 - val_loss: 0.5876 - val_soft_acc: 0.5579\n",
      "Epoch 459/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1482 - soft_acc: 0.9461 - val_loss: 0.5143 - val_soft_acc: 0.6521\n",
      "Epoch 460/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1540 - soft_acc: 0.9306 - val_loss: 0.5507 - val_soft_acc: 0.6193\n",
      "Epoch 461/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1491 - soft_acc: 0.9633 - val_loss: 0.5625 - val_soft_acc: 0.5586\n",
      "Epoch 462/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1960 - soft_acc: 0.9367 - val_loss: 0.5128 - val_soft_acc: 0.6193\n",
      "Epoch 463/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1555 - soft_acc: 0.9633 - val_loss: 0.5719 - val_soft_acc: 0.4993\n",
      "Epoch 464/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1691 - soft_acc: 0.9450 - val_loss: 0.5077 - val_soft_acc: 0.6343\n",
      "Epoch 465/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1548 - soft_acc: 0.9617 - val_loss: 0.5115 - val_soft_acc: 0.6364\n",
      "Epoch 466/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1416 - soft_acc: 0.9633 - val_loss: 0.5170 - val_soft_acc: 0.5779\n",
      "Epoch 467/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1519 - soft_acc: 0.9600 - val_loss: 0.5277 - val_soft_acc: 0.6443\n",
      "Epoch 468/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1488 - soft_acc: 0.9583 - val_loss: 0.5245 - val_soft_acc: 0.6750\n",
      "Epoch 469/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1502 - soft_acc: 0.9433 - val_loss: 0.5559 - val_soft_acc: 0.5529\n",
      "Epoch 470/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1494 - soft_acc: 0.9567 - val_loss: 0.5376 - val_soft_acc: 0.6343\n",
      "Epoch 471/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1494 - soft_acc: 0.9683 - val_loss: 0.5220 - val_soft_acc: 0.6036\n",
      "Epoch 472/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1571 - soft_acc: 0.9461 - val_loss: 0.5944 - val_soft_acc: 0.5886\n",
      "Epoch 473/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1629 - soft_acc: 0.9372 - val_loss: 0.5981 - val_soft_acc: 0.5200\n",
      "Epoch 474/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1761 - soft_acc: 0.9433 - val_loss: 0.5147 - val_soft_acc: 0.6036\n",
      "Epoch 475/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1732 - soft_acc: 0.9328 - val_loss: 0.5967 - val_soft_acc: 0.5686\n",
      "Epoch 476/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1503 - soft_acc: 0.9550 - val_loss: 0.5343 - val_soft_acc: 0.6171\n",
      "Epoch 477/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1664 - soft_acc: 0.9378 - val_loss: 0.5366 - val_soft_acc: 0.6371\n",
      "Epoch 478/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1608 - soft_acc: 0.9467 - val_loss: 0.5300 - val_soft_acc: 0.5679\n",
      "Epoch 479/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1550 - soft_acc: 0.9617 - val_loss: 0.5057 - val_soft_acc: 0.5750\n",
      "Epoch 480/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1620 - soft_acc: 0.9567 - val_loss: 0.5991 - val_soft_acc: 0.5279\n",
      "Epoch 481/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1597 - soft_acc: 0.9533 - val_loss: 0.4812 - val_soft_acc: 0.6336\n",
      "Epoch 482/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1648 - soft_acc: 0.9444 - val_loss: 0.5889 - val_soft_acc: 0.5557\n",
      "Epoch 483/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1715 - soft_acc: 0.9517 - val_loss: 0.6061 - val_soft_acc: 0.5229\n",
      "Epoch 484/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1698 - soft_acc: 0.9033 - val_loss: 0.5034 - val_soft_acc: 0.6879\n",
      "Epoch 485/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1574 - soft_acc: 0.9478 - val_loss: 0.5447 - val_soft_acc: 0.6114\n",
      "Epoch 486/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1548 - soft_acc: 0.9461 - val_loss: 0.5558 - val_soft_acc: 0.6114\n",
      "Epoch 487/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1673 - soft_acc: 0.9461 - val_loss: 0.6788 - val_soft_acc: 0.5029\n",
      "Epoch 488/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1883 - soft_acc: 0.9106 - val_loss: 0.4996 - val_soft_acc: 0.6386\n",
      "Epoch 489/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1683 - soft_acc: 0.9378 - val_loss: 0.5371 - val_soft_acc: 0.6086\n",
      "Epoch 490/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1363 - soft_acc: 0.9583 - val_loss: 0.6061 - val_soft_acc: 0.5764\n",
      "Epoch 491/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1984 - soft_acc: 0.8922 - val_loss: 0.5507 - val_soft_acc: 0.5836\n",
      "Epoch 492/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1824 - soft_acc: 0.9294 - val_loss: 0.5877 - val_soft_acc: 0.5329\n",
      "Epoch 493/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1600 - soft_acc: 0.9378 - val_loss: 0.5470 - val_soft_acc: 0.6036\n",
      "Epoch 494/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1653 - soft_acc: 0.9239 - val_loss: 0.5957 - val_soft_acc: 0.5757\n",
      "Epoch 495/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1774 - soft_acc: 0.9417 - val_loss: 0.5323 - val_soft_acc: 0.6343\n",
      "Epoch 496/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1622 - soft_acc: 0.9500 - val_loss: 0.5711 - val_soft_acc: 0.5407\n",
      "Epoch 497/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2123 - soft_acc: 0.8972 - val_loss: 0.5550 - val_soft_acc: 0.5836\n",
      "Epoch 498/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1906 - soft_acc: 0.9194 - val_loss: 0.5734 - val_soft_acc: 0.5843\n",
      "Epoch 499/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1690 - soft_acc: 0.9450 - val_loss: 0.5430 - val_soft_acc: 0.5907\n",
      "Epoch 500/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1591 - soft_acc: 0.9583 - val_loss: 0.5519 - val_soft_acc: 0.6043\n",
      "Epoch 501/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1563 - soft_acc: 0.9478 - val_loss: 0.5753 - val_soft_acc: 0.4993\n",
      "Epoch 502/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1905 - soft_acc: 0.9328 - val_loss: 0.5724 - val_soft_acc: 0.4914\n",
      "Epoch 503/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1731 - soft_acc: 0.9361 - val_loss: 0.5836 - val_soft_acc: 0.5157\n",
      "Epoch 504/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1722 - soft_acc: 0.8911 - val_loss: 0.5089 - val_soft_acc: 0.6136\n",
      "Epoch 505/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1836 - soft_acc: 0.9261 - val_loss: 0.5807 - val_soft_acc: 0.5457\n",
      "Epoch 506/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1695 - soft_acc: 0.9444 - val_loss: 0.5324 - val_soft_acc: 0.6086\n",
      "Epoch 507/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1855 - soft_acc: 0.9500 - val_loss: 0.5811 - val_soft_acc: 0.5143\n",
      "Epoch 508/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1888 - soft_acc: 0.9278 - val_loss: 0.5321 - val_soft_acc: 0.5779\n",
      "Epoch 509/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1505 - soft_acc: 0.9733 - val_loss: 0.5309 - val_soft_acc: 0.6086\n",
      "Epoch 510/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1574 - soft_acc: 0.9567 - val_loss: 0.5154 - val_soft_acc: 0.5650\n",
      "Epoch 511/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1658 - soft_acc: 0.9528 - val_loss: 0.5642 - val_soft_acc: 0.5343\n",
      "Epoch 512/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1750 - soft_acc: 0.8950 - val_loss: 0.5221 - val_soft_acc: 0.5679\n",
      "Epoch 513/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1536 - soft_acc: 0.9567 - val_loss: 0.5220 - val_soft_acc: 0.6364\n",
      "Epoch 514/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1512 - soft_acc: 0.9411 - val_loss: 0.7431 - val_soft_acc: 0.4164\n",
      "Epoch 515/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1897 - soft_acc: 0.9250 - val_loss: 0.5079 - val_soft_acc: 0.6493\n",
      "Epoch 516/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1579 - soft_acc: 0.9494 - val_loss: 0.5533 - val_soft_acc: 0.5329\n",
      "Epoch 517/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1473 - soft_acc: 0.9561 - val_loss: 0.5418 - val_soft_acc: 0.5779\n",
      "Epoch 518/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1332 - soft_acc: 0.9683 - val_loss: 0.5273 - val_soft_acc: 0.5700\n",
      "Epoch 519/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1277 - soft_acc: 0.9528 - val_loss: 0.5597 - val_soft_acc: 0.5786\n",
      "Epoch 520/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1355 - soft_acc: 0.9528 - val_loss: 0.5731 - val_soft_acc: 0.5250\n",
      "Epoch 521/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1613 - soft_acc: 0.9461 - val_loss: 0.5371 - val_soft_acc: 0.5421\n",
      "Epoch 522/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1469 - soft_acc: 0.9528 - val_loss: 0.5598 - val_soft_acc: 0.5300\n",
      "Epoch 523/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1433 - soft_acc: 0.9544 - val_loss: 0.5372 - val_soft_acc: 0.5836\n",
      "Epoch 524/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1333 - soft_acc: 0.9717 - val_loss: 0.6042 - val_soft_acc: 0.5250\n",
      "Epoch 525/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1388 - soft_acc: 0.9733 - val_loss: 0.5632 - val_soft_acc: 0.5529\n",
      "Epoch 526/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1304 - soft_acc: 0.9456 - val_loss: 0.5634 - val_soft_acc: 0.5293\n",
      "Epoch 527/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1239 - soft_acc: 0.9683 - val_loss: 0.5446 - val_soft_acc: 0.5629\n",
      "Epoch 528/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1234 - soft_acc: 0.9717 - val_loss: 0.5843 - val_soft_acc: 0.5536\n",
      "Epoch 529/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1473 - soft_acc: 0.9528 - val_loss: 0.5607 - val_soft_acc: 0.6193\n",
      "Epoch 530/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1437 - soft_acc: 0.9544 - val_loss: 0.5632 - val_soft_acc: 0.5807\n",
      "Epoch 531/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1432 - soft_acc: 0.9717 - val_loss: 0.5148 - val_soft_acc: 0.6264\n",
      "Epoch 532/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1386 - soft_acc: 0.9683 - val_loss: 0.5599 - val_soft_acc: 0.5579\n",
      "Epoch 533/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1234 - soft_acc: 0.9733 - val_loss: 0.5371 - val_soft_acc: 0.5757\n",
      "Epoch 534/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1319 - soft_acc: 0.9717 - val_loss: 0.5419 - val_soft_acc: 0.6293\n",
      "Epoch 535/1000\n",
      "512/512 [==============================] - 0s 8us/sample - loss: 0.1288 - soft_acc: 0.9578 - val_loss: 0.5453 - val_soft_acc: 0.6136\n",
      "Epoch 536/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1397 - soft_acc: 0.9700 - val_loss: 0.6119 - val_soft_acc: 0.4507\n",
      "Epoch 537/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1462 - soft_acc: 0.9583 - val_loss: 0.5021 - val_soft_acc: 0.5929\n",
      "Epoch 538/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1305 - soft_acc: 0.9767 - val_loss: 0.6352 - val_soft_acc: 0.5514\n",
      "Epoch 539/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1861 - soft_acc: 0.9144 - val_loss: 0.6828 - val_soft_acc: 0.4521\n",
      "Epoch 540/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2359 - soft_acc: 0.8828 - val_loss: 0.5078 - val_soft_acc: 0.6343\n",
      "Epoch 541/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2079 - soft_acc: 0.9233 - val_loss: 0.6457 - val_soft_acc: 0.5000\n",
      "Epoch 542/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1907 - soft_acc: 0.9178 - val_loss: 0.5559 - val_soft_acc: 0.5321\n",
      "Epoch 543/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1528 - soft_acc: 0.9600 - val_loss: 0.5796 - val_soft_acc: 0.5507\n",
      "Epoch 544/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1482 - soft_acc: 0.9511 - val_loss: 0.5751 - val_soft_acc: 0.5450\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1474 - soft_acc: 0.9594 - val_loss: 0.5164 - val_soft_acc: 0.6371\n",
      "Epoch 546/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1464 - soft_acc: 0.9700 - val_loss: 0.5445 - val_soft_acc: 0.6271\n",
      "Epoch 547/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1430 - soft_acc: 0.9700 - val_loss: 0.6172 - val_soft_acc: 0.5150\n",
      "Epoch 548/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1773 - soft_acc: 0.9283 - val_loss: 0.7236 - val_soft_acc: 0.3807\n",
      "Epoch 549/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1914 - soft_acc: 0.9200 - val_loss: 0.6728 - val_soft_acc: 0.4679\n",
      "Epoch 550/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2181 - soft_acc: 0.8944 - val_loss: 0.5625 - val_soft_acc: 0.6093\n",
      "Epoch 551/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1973 - soft_acc: 0.9167 - val_loss: 0.5590 - val_soft_acc: 0.5736\n",
      "Epoch 552/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1611 - soft_acc: 0.9428 - val_loss: 0.5213 - val_soft_acc: 0.6264\n",
      "Epoch 553/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1404 - soft_acc: 0.9633 - val_loss: 0.5736 - val_soft_acc: 0.6221\n",
      "Epoch 554/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1495 - soft_acc: 0.9700 - val_loss: 0.5632 - val_soft_acc: 0.5679\n",
      "Epoch 555/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1390 - soft_acc: 0.9667 - val_loss: 0.5664 - val_soft_acc: 0.6164\n",
      "Epoch 556/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1382 - soft_acc: 0.9700 - val_loss: 0.5739 - val_soft_acc: 0.5457\n",
      "Epoch 557/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1579 - soft_acc: 0.9067 - val_loss: 0.5113 - val_soft_acc: 0.5671\n",
      "Epoch 558/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1593 - soft_acc: 0.9544 - val_loss: 0.7089 - val_soft_acc: 0.5229\n",
      "Epoch 559/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2290 - soft_acc: 0.9117 - val_loss: 0.5473 - val_soft_acc: 0.5429\n",
      "Epoch 560/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1859 - soft_acc: 0.9294 - val_loss: 0.5883 - val_soft_acc: 0.5550\n",
      "Epoch 561/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1612 - soft_acc: 0.9583 - val_loss: 0.6021 - val_soft_acc: 0.5129\n",
      "Epoch 562/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2395 - soft_acc: 0.9033 - val_loss: 0.5604 - val_soft_acc: 0.5786\n",
      "Epoch 563/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1928 - soft_acc: 0.8850 - val_loss: 0.5514 - val_soft_acc: 0.5171\n",
      "Epoch 564/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1496 - soft_acc: 0.9633 - val_loss: 0.5900 - val_soft_acc: 0.6093\n",
      "Epoch 565/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1451 - soft_acc: 0.9667 - val_loss: 0.5884 - val_soft_acc: 0.5200\n",
      "Epoch 566/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1477 - soft_acc: 0.9372 - val_loss: 0.5688 - val_soft_acc: 0.6221\n",
      "Epoch 567/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1580 - soft_acc: 0.9444 - val_loss: 0.5340 - val_soft_acc: 0.5986\n",
      "Epoch 568/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1424 - soft_acc: 0.9667 - val_loss: 0.6195 - val_soft_acc: 0.4714\n",
      "Epoch 569/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1625 - soft_acc: 0.9583 - val_loss: 0.5931 - val_soft_acc: 0.6014\n",
      "Epoch 570/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1376 - soft_acc: 0.9733 - val_loss: 0.5289 - val_soft_acc: 0.6086\n",
      "Epoch 571/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1517 - soft_acc: 0.9583 - val_loss: 0.4973 - val_soft_acc: 0.6314\n",
      "Epoch 572/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2161 - soft_acc: 0.9211 - val_loss: 0.4976 - val_soft_acc: 0.6771\n",
      "Epoch 573/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1878 - soft_acc: 0.9233 - val_loss: 0.6721 - val_soft_acc: 0.5050\n",
      "Epoch 574/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2011 - soft_acc: 0.9344 - val_loss: 0.5524 - val_soft_acc: 0.6214\n",
      "Epoch 575/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1566 - soft_acc: 0.9250 - val_loss: 0.5957 - val_soft_acc: 0.5121\n",
      "Epoch 576/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1678 - soft_acc: 0.9683 - val_loss: 0.5521 - val_soft_acc: 0.5964\n",
      "Epoch 577/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1748 - soft_acc: 0.9328 - val_loss: 0.5869 - val_soft_acc: 0.6143\n",
      "Epoch 578/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1683 - soft_acc: 0.9483 - val_loss: 0.6125 - val_soft_acc: 0.5300\n",
      "Epoch 579/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1656 - soft_acc: 0.9278 - val_loss: 0.5290 - val_soft_acc: 0.5500\n",
      "Epoch 580/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1567 - soft_acc: 0.9394 - val_loss: 0.6209 - val_soft_acc: 0.4971\n",
      "Epoch 581/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1767 - soft_acc: 0.9567 - val_loss: 0.7266 - val_soft_acc: 0.3936\n",
      "Epoch 582/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2146 - soft_acc: 0.8594 - val_loss: 0.4932 - val_soft_acc: 0.6314\n",
      "Epoch 583/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1777 - soft_acc: 0.9417 - val_loss: 0.5682 - val_soft_acc: 0.5957\n",
      "Epoch 584/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1573 - soft_acc: 0.9544 - val_loss: 0.6137 - val_soft_acc: 0.4843\n",
      "Epoch 585/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1936 - soft_acc: 0.9483 - val_loss: 0.5650 - val_soft_acc: 0.6300\n",
      "Epoch 586/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1532 - soft_acc: 0.9600 - val_loss: 0.5924 - val_soft_acc: 0.6221\n",
      "Epoch 587/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1556 - soft_acc: 0.9600 - val_loss: 0.5501 - val_soft_acc: 0.6143\n",
      "Epoch 588/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1679 - soft_acc: 0.9517 - val_loss: 0.5979 - val_soft_acc: 0.5529\n",
      "Epoch 589/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1575 - soft_acc: 0.9461 - val_loss: 0.5456 - val_soft_acc: 0.6421\n",
      "Epoch 590/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1500 - soft_acc: 0.9478 - val_loss: 0.5662 - val_soft_acc: 0.5757\n",
      "Epoch 591/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1574 - soft_acc: 0.9767 - val_loss: 0.6185 - val_soft_acc: 0.4793\n",
      "Epoch 592/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1586 - soft_acc: 0.9583 - val_loss: 0.6578 - val_soft_acc: 0.5071\n",
      "Epoch 593/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1484 - soft_acc: 0.9700 - val_loss: 0.6521 - val_soft_acc: 0.4357\n",
      "Epoch 594/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2087 - soft_acc: 0.9250 - val_loss: 0.5459 - val_soft_acc: 0.6064\n",
      "Epoch 595/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1630 - soft_acc: 0.9567 - val_loss: 0.5381 - val_soft_acc: 0.6064\n",
      "Epoch 596/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1349 - soft_acc: 0.9767 - val_loss: 0.5729 - val_soft_acc: 0.5579\n",
      "Epoch 597/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1334 - soft_acc: 0.9650 - val_loss: 0.5419 - val_soft_acc: 0.5757\n",
      "Epoch 598/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1242 - soft_acc: 0.9750 - val_loss: 0.5179 - val_soft_acc: 0.5686\n",
      "Epoch 599/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1173 - soft_acc: 0.9767 - val_loss: 0.5541 - val_soft_acc: 0.5650\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1097 - soft_acc: 0.9767 - val_loss: 0.5406 - val_soft_acc: 0.5807\n",
      "Epoch 601/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1186 - soft_acc: 0.9767 - val_loss: 0.5641 - val_soft_acc: 0.6064\n",
      "Epoch 602/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1527 - soft_acc: 0.9583 - val_loss: 0.6300 - val_soft_acc: 0.5050\n",
      "Epoch 603/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1615 - soft_acc: 0.9411 - val_loss: 0.6009 - val_soft_acc: 0.5786\n",
      "Epoch 604/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1424 - soft_acc: 0.9667 - val_loss: 0.5674 - val_soft_acc: 0.5986\n",
      "Epoch 605/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1350 - soft_acc: 0.9750 - val_loss: 0.6008 - val_soft_acc: 0.5021\n",
      "Epoch 606/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1757 - soft_acc: 0.9378 - val_loss: 0.5155 - val_soft_acc: 0.5957\n",
      "Epoch 607/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1643 - soft_acc: 0.9600 - val_loss: 0.5413 - val_soft_acc: 0.5679\n",
      "Epoch 608/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1440 - soft_acc: 0.9544 - val_loss: 0.5893 - val_soft_acc: 0.5579\n",
      "Epoch 609/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1366 - soft_acc: 0.9611 - val_loss: 0.5637 - val_soft_acc: 0.5114\n",
      "Epoch 610/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1402 - soft_acc: 0.9700 - val_loss: 0.5655 - val_soft_acc: 0.5936\n",
      "Epoch 611/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1456 - soft_acc: 0.9494 - val_loss: 0.5253 - val_soft_acc: 0.6036\n",
      "Epoch 612/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1424 - soft_acc: 0.9478 - val_loss: 0.5966 - val_soft_acc: 0.4814\n",
      "Epoch 613/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1354 - soft_acc: 0.9750 - val_loss: 0.5346 - val_soft_acc: 0.5450\n",
      "Epoch 614/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1466 - soft_acc: 0.9517 - val_loss: 0.6498 - val_soft_acc: 0.5050\n",
      "Epoch 615/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1665 - soft_acc: 0.9256 - val_loss: 0.5707 - val_soft_acc: 0.5193\n",
      "Epoch 616/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1634 - soft_acc: 0.9411 - val_loss: 0.5777 - val_soft_acc: 0.5607\n",
      "Epoch 617/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1587 - soft_acc: 0.9783 - val_loss: 0.5619 - val_soft_acc: 0.5607\n",
      "Epoch 618/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1441 - soft_acc: 0.9683 - val_loss: 0.6497 - val_soft_acc: 0.4900\n",
      "Epoch 619/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1556 - soft_acc: 0.9567 - val_loss: 0.5409 - val_soft_acc: 0.5943\n",
      "Epoch 620/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1440 - soft_acc: 0.9556 - val_loss: 0.6085 - val_soft_acc: 0.4693\n",
      "Epoch 621/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1240 - soft_acc: 0.9750 - val_loss: 0.5493 - val_soft_acc: 0.5450\n",
      "Epoch 622/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1159 - soft_acc: 0.9678 - val_loss: 0.5434 - val_soft_acc: 0.5707\n",
      "Epoch 623/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1115 - soft_acc: 0.9817 - val_loss: 0.5405 - val_soft_acc: 0.5964\n",
      "Epoch 624/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1195 - soft_acc: 0.9767 - val_loss: 0.5933 - val_soft_acc: 0.5686\n",
      "Epoch 625/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1321 - soft_acc: 0.9733 - val_loss: 0.5419 - val_soft_acc: 0.5200\n",
      "Epoch 626/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1624 - soft_acc: 0.9550 - val_loss: 0.5226 - val_soft_acc: 0.6143\n",
      "Epoch 627/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1220 - soft_acc: 0.9783 - val_loss: 0.5462 - val_soft_acc: 0.5600\n",
      "Epoch 628/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1217 - soft_acc: 0.9572 - val_loss: 0.5576 - val_soft_acc: 0.6393\n",
      "Epoch 629/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1351 - soft_acc: 0.9767 - val_loss: 0.5599 - val_soft_acc: 0.6264\n",
      "Epoch 630/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1239 - soft_acc: 0.9750 - val_loss: 0.5972 - val_soft_acc: 0.4793\n",
      "Epoch 631/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1600 - soft_acc: 0.9633 - val_loss: 0.5821 - val_soft_acc: 0.5714\n",
      "Epoch 632/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1340 - soft_acc: 0.9683 - val_loss: 0.5599 - val_soft_acc: 0.5279\n",
      "Epoch 633/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1233 - soft_acc: 0.9833 - val_loss: 0.5704 - val_soft_acc: 0.6550\n",
      "Epoch 634/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1421 - soft_acc: 0.9300 - val_loss: 0.6689 - val_soft_acc: 0.5050\n",
      "Epoch 635/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2074 - soft_acc: 0.9450 - val_loss: 0.5277 - val_soft_acc: 0.5700\n",
      "Epoch 636/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1862 - soft_acc: 0.9222 - val_loss: 0.5814 - val_soft_acc: 0.4714\n",
      "Epoch 637/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1406 - soft_acc: 0.9456 - val_loss: 0.5642 - val_soft_acc: 0.5507\n",
      "Epoch 638/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1215 - soft_acc: 0.9750 - val_loss: 0.5931 - val_soft_acc: 0.5207\n",
      "Epoch 639/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1745 - soft_acc: 0.9411 - val_loss: 0.6003 - val_soft_acc: 0.5157\n",
      "Epoch 640/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1463 - soft_acc: 0.9650 - val_loss: 0.5398 - val_soft_acc: 0.5836\n",
      "Epoch 641/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1421 - soft_acc: 0.9478 - val_loss: 0.5608 - val_soft_acc: 0.5936\n",
      "Epoch 642/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1230 - soft_acc: 0.9767 - val_loss: 0.5837 - val_soft_acc: 0.5357\n",
      "Epoch 643/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1351 - soft_acc: 0.9561 - val_loss: 0.6338 - val_soft_acc: 0.5100\n",
      "Epoch 644/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1574 - soft_acc: 0.9633 - val_loss: 0.5571 - val_soft_acc: 0.5814\n",
      "Epoch 645/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1214 - soft_acc: 0.9661 - val_loss: 0.5990 - val_soft_acc: 0.5357\n",
      "Epoch 646/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1196 - soft_acc: 0.9783 - val_loss: 0.5321 - val_soft_acc: 0.5857\n",
      "Epoch 647/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1081 - soft_acc: 0.9767 - val_loss: 0.6095 - val_soft_acc: 0.5229\n",
      "Epoch 648/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1187 - soft_acc: 0.9800 - val_loss: 0.5601 - val_soft_acc: 0.5350\n",
      "Epoch 649/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1189 - soft_acc: 0.9611 - val_loss: 0.5911 - val_soft_acc: 0.5043\n",
      "Epoch 650/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1143 - soft_acc: 0.9800 - val_loss: 0.5619 - val_soft_acc: 0.5707\n",
      "Epoch 651/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1296 - soft_acc: 0.9489 - val_loss: 0.5858 - val_soft_acc: 0.5679\n",
      "Epoch 652/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1274 - soft_acc: 0.9750 - val_loss: 0.7194 - val_soft_acc: 0.4086\n",
      "Epoch 653/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2027 - soft_acc: 0.9094 - val_loss: 0.6083 - val_soft_acc: 0.5121\n",
      "Epoch 654/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1672 - soft_acc: 0.9450 - val_loss: 0.5593 - val_soft_acc: 0.5971\n",
      "Epoch 655/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1385 - soft_acc: 0.9750 - val_loss: 0.5839 - val_soft_acc: 0.5043\n",
      "Epoch 656/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1188 - soft_acc: 0.9733 - val_loss: 0.5913 - val_soft_acc: 0.5686\n",
      "Epoch 657/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1243 - soft_acc: 0.9800 - val_loss: 0.5417 - val_soft_acc: 0.6121\n",
      "Epoch 658/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1087 - soft_acc: 0.9694 - val_loss: 0.5480 - val_soft_acc: 0.5786\n",
      "Epoch 659/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1097 - soft_acc: 0.9661 - val_loss: 0.5404 - val_soft_acc: 0.5321\n",
      "Epoch 660/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1117 - soft_acc: 0.9767 - val_loss: 0.5697 - val_soft_acc: 0.5529\n",
      "Epoch 661/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1314 - soft_acc: 0.9750 - val_loss: 0.5643 - val_soft_acc: 0.6279\n",
      "Epoch 662/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1312 - soft_acc: 0.9783 - val_loss: 0.5650 - val_soft_acc: 0.5964\n",
      "Epoch 663/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1314 - soft_acc: 0.9817 - val_loss: 0.5301 - val_soft_acc: 0.5500\n",
      "Epoch 664/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2006 - soft_acc: 0.8872 - val_loss: 0.5740 - val_soft_acc: 0.5507\n",
      "Epoch 665/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1684 - soft_acc: 0.9478 - val_loss: 0.5288 - val_soft_acc: 0.5907\n",
      "Epoch 666/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1309 - soft_acc: 0.9733 - val_loss: 0.6330 - val_soft_acc: 0.4843\n",
      "Epoch 667/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1334 - soft_acc: 0.9783 - val_loss: 0.5958 - val_soft_acc: 0.5429\n",
      "Epoch 668/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1463 - soft_acc: 0.9633 - val_loss: 0.6878 - val_soft_acc: 0.3979\n",
      "Epoch 669/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1339 - soft_acc: 0.9750 - val_loss: 0.5264 - val_soft_acc: 0.6400\n",
      "Epoch 670/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1326 - soft_acc: 0.9783 - val_loss: 0.5660 - val_soft_acc: 0.6321\n",
      "Epoch 671/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1325 - soft_acc: 0.9733 - val_loss: 0.5793 - val_soft_acc: 0.5607\n",
      "Epoch 672/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1176 - soft_acc: 0.9800 - val_loss: 0.5572 - val_soft_acc: 0.5707\n",
      "Epoch 673/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1139 - soft_acc: 0.9833 - val_loss: 0.5971 - val_soft_acc: 0.5664\n",
      "Epoch 674/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1043 - soft_acc: 0.9833 - val_loss: 0.5080 - val_soft_acc: 0.6143\n",
      "Epoch 675/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1052 - soft_acc: 0.9783 - val_loss: 0.6283 - val_soft_acc: 0.4900\n",
      "Epoch 676/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1700 - soft_acc: 0.9550 - val_loss: 0.5820 - val_soft_acc: 0.6271\n",
      "Epoch 677/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1387 - soft_acc: 0.9783 - val_loss: 0.5828 - val_soft_acc: 0.5607\n",
      "Epoch 678/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1641 - soft_acc: 0.9378 - val_loss: 0.5401 - val_soft_acc: 0.5886\n",
      "Epoch 679/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1455 - soft_acc: 0.9667 - val_loss: 0.5671 - val_soft_acc: 0.5529\n",
      "Epoch 680/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1595 - soft_acc: 0.9528 - val_loss: 0.5822 - val_soft_acc: 0.6143\n",
      "Epoch 681/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1317 - soft_acc: 0.9750 - val_loss: 0.5609 - val_soft_acc: 0.5807\n",
      "Epoch 682/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.0873 - soft_acc: 0.9900best occur in epoch 681\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.1151 - soft_acc: 0.9800 - val_loss: 0.5360 - val_soft_acc: 0.6850\n",
      "Epoch 683/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1217 - soft_acc: 0.9783 - val_loss: 0.5530 - val_soft_acc: 0.6014\n",
      "Epoch 684/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1132 - soft_acc: 0.9800 - val_loss: 0.6670 - val_soft_acc: 0.4829\n",
      "Epoch 685/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1748 - soft_acc: 0.9500 - val_loss: 0.5772 - val_soft_acc: 0.4971\n",
      "Epoch 686/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1256 - soft_acc: 0.9683 - val_loss: 0.5231 - val_soft_acc: 0.6164\n",
      "Epoch 687/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1273 - soft_acc: 0.9644 - val_loss: 0.5945 - val_soft_acc: 0.5250\n",
      "Epoch 688/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1439 - soft_acc: 0.9544 - val_loss: 0.5258 - val_soft_acc: 0.5836\n",
      "Epoch 689/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1500 - soft_acc: 0.9717 - val_loss: 0.5508 - val_soft_acc: 0.5557\n",
      "Epoch 690/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1212 - soft_acc: 0.9750 - val_loss: 0.6215 - val_soft_acc: 0.5486\n",
      "Epoch 691/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1130 - soft_acc: 0.9783 - val_loss: 0.5783 - val_soft_acc: 0.4507\n",
      "Epoch 692/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1236 - soft_acc: 0.9767 - val_loss: 0.5625 - val_soft_acc: 0.5250\n",
      "Epoch 693/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1158 - soft_acc: 0.9733 - val_loss: 0.5704 - val_soft_acc: 0.5636\n",
      "Epoch 694/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1089 - soft_acc: 0.9678 - val_loss: 0.5908 - val_soft_acc: 0.5843\n",
      "Epoch 695/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1624 - soft_acc: 0.9567 - val_loss: 0.6092 - val_soft_acc: 0.4671\n",
      "Epoch 696/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1837 - soft_acc: 0.9411 - val_loss: 0.5801 - val_soft_acc: 0.4793\n",
      "Epoch 697/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1735 - soft_acc: 0.9189 - val_loss: 0.6224 - val_soft_acc: 0.4514\n",
      "Epoch 698/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1573 - soft_acc: 0.9633 - val_loss: 0.5792 - val_soft_acc: 0.5143\n",
      "Epoch 699/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1352 - soft_acc: 0.9750 - val_loss: 0.5727 - val_soft_acc: 0.5121\n",
      "Epoch 700/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1477 - soft_acc: 0.9372 - val_loss: 0.5429 - val_soft_acc: 0.5400\n",
      "Epoch 701/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1320 - soft_acc: 0.9683 - val_loss: 0.5785 - val_soft_acc: 0.5764\n",
      "Epoch 702/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1351 - soft_acc: 0.9767 - val_loss: 0.5209 - val_soft_acc: 0.5907\n",
      "Epoch 703/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1327 - soft_acc: 0.9628 - val_loss: 0.5515 - val_soft_acc: 0.6193\n",
      "Epoch 704/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1239 - soft_acc: 0.9506 - val_loss: 0.5479 - val_soft_acc: 0.6036\n",
      "Epoch 705/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1053 - soft_acc: 0.9733 - val_loss: 0.6162 - val_soft_acc: 0.4307\n",
      "Epoch 706/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1459 - soft_acc: 0.9561 - val_loss: 0.5283 - val_soft_acc: 0.5193\n",
      "Epoch 707/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1316 - soft_acc: 0.9767 - val_loss: 0.5715 - val_soft_acc: 0.5221\n",
      "Epoch 708/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1457 - soft_acc: 0.9561 - val_loss: 0.6693 - val_soft_acc: 0.4500\n",
      "Epoch 709/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2043 - soft_acc: 0.9133 - val_loss: 0.6202 - val_soft_acc: 0.5286\n",
      "Epoch 710/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1829 - soft_acc: 0.9322 - val_loss: 0.5719 - val_soft_acc: 0.5857\n",
      "Epoch 711/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1666 - soft_acc: 0.9600 - val_loss: 0.6518 - val_soft_acc: 0.4136\n",
      "Epoch 712/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1591 - soft_acc: 0.9544 - val_loss: 0.6093 - val_soft_acc: 0.4357\n",
      "Epoch 713/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1758 - soft_acc: 0.9617 - val_loss: 0.6549 - val_soft_acc: 0.5414\n",
      "Epoch 714/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1467 - soft_acc: 0.9611 - val_loss: 0.5454 - val_soft_acc: 0.5171\n",
      "Epoch 715/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1432 - soft_acc: 0.9683 - val_loss: 0.5966 - val_soft_acc: 0.5071\n",
      "Epoch 716/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1298 - soft_acc: 0.9767 - val_loss: 0.5721 - val_soft_acc: 0.5836\n",
      "Epoch 717/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1234 - soft_acc: 0.9611 - val_loss: 0.5548 - val_soft_acc: 0.5936\n",
      "Epoch 718/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1108 - soft_acc: 0.9783 - val_loss: 0.6030 - val_soft_acc: 0.5307\n",
      "Epoch 719/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1165 - soft_acc: 0.9850 - val_loss: 0.5838 - val_soft_acc: 0.5607\n",
      "Epoch 720/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1138 - soft_acc: 0.9800 - val_loss: 0.5530 - val_soft_acc: 0.5579\n",
      "Epoch 721/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1054 - soft_acc: 0.9800 - val_loss: 0.5879 - val_soft_acc: 0.5664\n",
      "Epoch 722/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1007 - soft_acc: 0.9694 - val_loss: 0.6339 - val_soft_acc: 0.4929\n",
      "Epoch 723/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1461 - soft_acc: 0.9767 - val_loss: 0.7798 - val_soft_acc: 0.4021\n",
      "Epoch 724/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2455 - soft_acc: 0.8861 - val_loss: 0.7205 - val_soft_acc: 0.4743\n",
      "Epoch 725/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1959 - soft_acc: 0.9500 - val_loss: 0.5363 - val_soft_acc: 0.5650\n",
      "Epoch 726/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1435 - soft_acc: 0.9667 - val_loss: 0.5953 - val_soft_acc: 0.5557\n",
      "Epoch 727/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1483 - soft_acc: 0.9733 - val_loss: 0.5381 - val_soft_acc: 0.5421\n",
      "Epoch 728/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1407 - soft_acc: 0.9661 - val_loss: 0.6821 - val_soft_acc: 0.4679\n",
      "Epoch 729/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1361 - soft_acc: 0.9733 - val_loss: 0.5630 - val_soft_acc: 0.5279\n",
      "Epoch 730/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1534 - soft_acc: 0.9528 - val_loss: 0.5972 - val_soft_acc: 0.4564\n",
      "Epoch 731/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1397 - soft_acc: 0.9750 - val_loss: 0.5470 - val_soft_acc: 0.5607\n",
      "Epoch 732/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1381 - soft_acc: 0.9717 - val_loss: 0.6459 - val_soft_acc: 0.4564\n",
      "Epoch 733/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1384 - soft_acc: 0.9611 - val_loss: 0.5326 - val_soft_acc: 0.5886\n",
      "Epoch 734/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1311 - soft_acc: 0.9783 - val_loss: 0.6098 - val_soft_acc: 0.4893\n",
      "Epoch 735/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1155 - soft_acc: 0.9678 - val_loss: 0.5750 - val_soft_acc: 0.5507\n",
      "Epoch 736/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1107 - soft_acc: 0.9694 - val_loss: 0.5657 - val_soft_acc: 0.5071\n",
      "Epoch 737/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1276 - soft_acc: 0.9867 - val_loss: 0.6025 - val_soft_acc: 0.5664\n",
      "Epoch 738/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1186 - soft_acc: 0.9661 - val_loss: 0.6209 - val_soft_acc: 0.4436\n",
      "Epoch 739/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1183 - soft_acc: 0.9833 - val_loss: 0.6072 - val_soft_acc: 0.5436\n",
      "Epoch 740/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1317 - soft_acc: 0.9750 - val_loss: 0.6123 - val_soft_acc: 0.5386\n",
      "Epoch 741/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1293 - soft_acc: 0.9733 - val_loss: 0.6126 - val_soft_acc: 0.5079\n",
      "Epoch 742/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1238 - soft_acc: 0.9644 - val_loss: 0.6051 - val_soft_acc: 0.4871\n",
      "Epoch 743/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1179 - soft_acc: 0.9850 - val_loss: 0.5798 - val_soft_acc: 0.5379\n",
      "Epoch 744/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1160 - soft_acc: 0.9783 - val_loss: 0.5851 - val_soft_acc: 0.5171\n",
      "Epoch 745/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1206 - soft_acc: 0.9767 - val_loss: 0.6243 - val_soft_acc: 0.4486\n",
      "Epoch 746/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1136 - soft_acc: 0.9817 - val_loss: 0.5718 - val_soft_acc: 0.5864\n",
      "Epoch 747/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1130 - soft_acc: 0.9867 - val_loss: 0.5776 - val_soft_acc: 0.5529\n",
      "Epoch 748/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1220 - soft_acc: 0.9750 - val_loss: 0.6218 - val_soft_acc: 0.4664\n",
      "Epoch 749/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1206 - soft_acc: 0.9783 - val_loss: 0.5727 - val_soft_acc: 0.5093\n",
      "Epoch 750/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1180 - soft_acc: 0.9417 - val_loss: 0.6188 - val_soft_acc: 0.5129\n",
      "Epoch 751/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1437 - soft_acc: 0.9617 - val_loss: 0.5749 - val_soft_acc: 0.5757\n",
      "Epoch 752/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1224 - soft_acc: 0.9817 - val_loss: 0.6200 - val_soft_acc: 0.5357\n",
      "Epoch 753/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1130 - soft_acc: 0.9711 - val_loss: 0.5674 - val_soft_acc: 0.5650\n",
      "Epoch 754/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1068 - soft_acc: 0.9850 - val_loss: 0.6178 - val_soft_acc: 0.5664\n",
      "Epoch 755/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1106 - soft_acc: 0.9867 - val_loss: 0.5442 - val_soft_acc: 0.6064\n",
      "Epoch 756/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1221 - soft_acc: 0.9783 - val_loss: 0.6266 - val_soft_acc: 0.5257\n",
      "Epoch 757/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1134 - soft_acc: 0.9611 - val_loss: 0.5670 - val_soft_acc: 0.5507\n",
      "Epoch 758/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1032 - soft_acc: 0.9817 - val_loss: 0.5990 - val_soft_acc: 0.6043\n",
      "Epoch 759/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1625 - soft_acc: 0.9306 - val_loss: 0.5337 - val_soft_acc: 0.6193\n",
      "Epoch 760/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1369 - soft_acc: 0.9511 - val_loss: 0.6797 - val_soft_acc: 0.4543\n",
      "Epoch 761/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1238 - soft_acc: 0.9539 - val_loss: 0.5753 - val_soft_acc: 0.5886\n",
      "Epoch 762/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1241 - soft_acc: 0.9750 - val_loss: 0.5993 - val_soft_acc: 0.4757\n",
      "Epoch 763/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1150 - soft_acc: 0.9644 - val_loss: 0.5395 - val_soft_acc: 0.6143\n",
      "Epoch 764/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1128 - soft_acc: 0.9694 - val_loss: 0.5529 - val_soft_acc: 0.5764\n",
      "Epoch 765/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1057 - soft_acc: 0.9833 - val_loss: 0.5981 - val_soft_acc: 0.5757\n",
      "Epoch 766/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1201 - soft_acc: 0.9678 - val_loss: 0.5967 - val_soft_acc: 0.6021\n",
      "Epoch 767/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1069 - soft_acc: 0.9556 - val_loss: 0.5767 - val_soft_acc: 0.5171\n",
      "Epoch 768/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1114 - soft_acc: 0.9867 - val_loss: 0.5552 - val_soft_acc: 0.5400\n",
      "Epoch 769/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0977 - soft_acc: 0.9833 - val_loss: 0.6170 - val_soft_acc: 0.4207\n",
      "Epoch 770/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1247 - soft_acc: 0.9800 - val_loss: 0.5871 - val_soft_acc: 0.5407\n",
      "Epoch 771/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1121 - soft_acc: 0.9850 - val_loss: 0.6353 - val_soft_acc: 0.5129\n",
      "Epoch 772/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1209 - soft_acc: 0.9817 - val_loss: 0.5614 - val_soft_acc: 0.5964\n",
      "Epoch 773/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1359 - soft_acc: 0.9539 - val_loss: 0.6626 - val_soft_acc: 0.4750\n",
      "Epoch 774/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1535 - soft_acc: 0.9533 - val_loss: 0.5662 - val_soft_acc: 0.6093\n",
      "Epoch 775/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1392 - soft_acc: 0.9733 - val_loss: 0.5511 - val_soft_acc: 0.5350\n",
      "Epoch 776/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1277 - soft_acc: 0.9833 - val_loss: 0.5703 - val_soft_acc: 0.5479\n",
      "Epoch 777/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1084 - soft_acc: 0.9850 - val_loss: 0.5621 - val_soft_acc: 0.5629\n",
      "Epoch 778/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.0968 - soft_acc: 0.9711 - val_loss: 0.5718 - val_soft_acc: 0.5200\n",
      "Epoch 779/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0896 - soft_acc: 0.9728 - val_loss: 0.5656 - val_soft_acc: 0.5836\n",
      "Epoch 780/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.0897 - soft_acc: 0.9728 - val_loss: 0.5970 - val_soft_acc: 0.5450\n",
      "Epoch 781/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.0912 - soft_acc: 0.9867 - val_loss: 0.5490 - val_soft_acc: 0.6421\n",
      "Epoch 782/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0974 - soft_acc: 0.9661 - val_loss: 0.5753 - val_soft_acc: 0.5736\n",
      "Epoch 783/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1059 - soft_acc: 0.9833 - val_loss: 0.5933 - val_soft_acc: 0.5407\n",
      "Epoch 784/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1036 - soft_acc: 0.9728 - val_loss: 0.5447 - val_soft_acc: 0.5379\n",
      "Epoch 785/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1051 - soft_acc: 0.9883 - val_loss: 0.6229 - val_soft_acc: 0.4486\n",
      "Epoch 786/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1179 - soft_acc: 0.9817 - val_loss: 0.5560 - val_soft_acc: 0.6043\n",
      "Epoch 787/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1112 - soft_acc: 0.9867 - val_loss: 0.6025 - val_soft_acc: 0.5179\n",
      "Epoch 788/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1033 - soft_acc: 0.9833 - val_loss: 0.5655 - val_soft_acc: 0.5350\n",
      "Epoch 789/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0897 - soft_acc: 0.9850 - val_loss: 0.5983 - val_soft_acc: 0.5557\n",
      "Epoch 790/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.0929 - soft_acc: 0.9711 - val_loss: 0.5799 - val_soft_acc: 0.5371\n",
      "Epoch 791/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1011 - soft_acc: 0.9783 - val_loss: 0.5830 - val_soft_acc: 0.4764\n",
      "Epoch 792/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0977 - soft_acc: 0.9711 - val_loss: 0.6018 - val_soft_acc: 0.5050\n",
      "Epoch 793/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1248 - soft_acc: 0.9850 - val_loss: 0.5833 - val_soft_acc: 0.4736\n",
      "Epoch 794/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1183 - soft_acc: 0.9700 - val_loss: 0.6252 - val_soft_acc: 0.4486\n",
      "Epoch 795/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1224 - soft_acc: 0.9728 - val_loss: 0.6052 - val_soft_acc: 0.5200\n",
      "Epoch 796/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1249 - soft_acc: 0.9783 - val_loss: 0.5915 - val_soft_acc: 0.5250\n",
      "Epoch 797/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1096 - soft_acc: 0.9783 - val_loss: 0.6377 - val_soft_acc: 0.5407\n",
      "Epoch 798/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1173 - soft_acc: 0.9850 - val_loss: 0.5595 - val_soft_acc: 0.5736\n",
      "Epoch 799/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1178 - soft_acc: 0.9644 - val_loss: 0.6284 - val_soft_acc: 0.5179\n",
      "Epoch 800/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1071 - soft_acc: 0.9833 - val_loss: 0.5680 - val_soft_acc: 0.6093\n",
      "Epoch 801/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1095 - soft_acc: 0.9678 - val_loss: 0.5255 - val_soft_acc: 0.6014\n",
      "Epoch 802/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1140 - soft_acc: 0.9783 - val_loss: 0.6591 - val_soft_acc: 0.5000\n",
      "Epoch 803/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1299 - soft_acc: 0.9611 - val_loss: 0.5949 - val_soft_acc: 0.5407\n",
      "Epoch 804/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1199 - soft_acc: 0.9800 - val_loss: 0.5582 - val_soft_acc: 0.5779\n",
      "Epoch 805/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1265 - soft_acc: 0.9456 - val_loss: 0.5740 - val_soft_acc: 0.5657\n",
      "Epoch 806/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1103 - soft_acc: 0.9817 - val_loss: 0.5734 - val_soft_acc: 0.5221\n",
      "Epoch 807/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1025 - soft_acc: 0.9622 - val_loss: 0.6340 - val_soft_acc: 0.4621\n",
      "Epoch 808/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1214 - soft_acc: 0.9783 - val_loss: 0.5675 - val_soft_acc: 0.5714\n",
      "Epoch 809/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1195 - soft_acc: 0.9817 - val_loss: 0.5857 - val_soft_acc: 0.5279\n",
      "Epoch 810/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1009 - soft_acc: 0.9883 - val_loss: 0.6166 - val_soft_acc: 0.5279\n",
      "Epoch 811/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0970 - soft_acc: 0.9850 - val_loss: 0.5504 - val_soft_acc: 0.6300\n",
      "Epoch 812/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1049 - soft_acc: 0.9833 - val_loss: 0.6287 - val_soft_acc: 0.5336\n",
      "Epoch 813/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.0960 - soft_acc: 0.9883 - val_loss: 0.5892 - val_soft_acc: 0.5429\n",
      "Epoch 814/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.0958 - soft_acc: 0.9850 - val_loss: 0.5728 - val_soft_acc: 0.5629\n",
      "Epoch 815/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1034 - soft_acc: 0.9694 - val_loss: 0.5792 - val_soft_acc: 0.5021\n",
      "Epoch 816/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1153 - soft_acc: 0.9783 - val_loss: 0.5603 - val_soft_acc: 0.5550\n",
      "Epoch 817/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.0935 - soft_acc: 0.9694 - val_loss: 0.5828 - val_soft_acc: 0.4914\n",
      "Epoch 818/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1153 - soft_acc: 0.9717 - val_loss: 0.6038 - val_soft_acc: 0.5279\n",
      "Epoch 819/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1198 - soft_acc: 0.9750 - val_loss: 0.6066 - val_soft_acc: 0.5457\n",
      "Epoch 820/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0975 - soft_acc: 0.9883 - val_loss: 0.6282 - val_soft_acc: 0.5107\n",
      "Epoch 821/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1162 - soft_acc: 0.9817 - val_loss: 0.6189 - val_soft_acc: 0.4821\n",
      "Epoch 822/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1090 - soft_acc: 0.9833 - val_loss: 0.6299 - val_soft_acc: 0.5821\n",
      "Epoch 823/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1224 - soft_acc: 0.9850 - val_loss: 0.5767 - val_soft_acc: 0.5500\n",
      "Epoch 824/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1171 - soft_acc: 0.9750 - val_loss: 0.6204 - val_soft_acc: 0.4893\n",
      "Epoch 825/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1210 - soft_acc: 0.9556 - val_loss: 0.6331 - val_soft_acc: 0.5329\n",
      "Epoch 826/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1410 - soft_acc: 0.9700 - val_loss: 0.6375 - val_soft_acc: 0.4843\n",
      "Epoch 827/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1462 - soft_acc: 0.9733 - val_loss: 0.5653 - val_soft_acc: 0.6193\n",
      "Epoch 828/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1231 - soft_acc: 0.9783 - val_loss: 0.6188 - val_soft_acc: 0.5636\n",
      "Epoch 829/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1028 - soft_acc: 0.9800 - val_loss: 0.5473 - val_soft_acc: 0.5679\n",
      "Epoch 830/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1024 - soft_acc: 0.9867 - val_loss: 0.5713 - val_soft_acc: 0.5707\n",
      "Epoch 831/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0933 - soft_acc: 0.9867 - val_loss: 0.5610 - val_soft_acc: 0.5579\n",
      "Epoch 832/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.0896 - soft_acc: 0.9867 - val_loss: 0.5710 - val_soft_acc: 0.5321\n",
      "Epoch 833/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.0840 - soft_acc: 0.9867 - val_loss: 0.5975 - val_soft_acc: 0.5871\n",
      "Epoch 834/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1005 - soft_acc: 0.9761 - val_loss: 0.5856 - val_soft_acc: 0.5736\n",
      "Epoch 835/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.0976 - soft_acc: 0.9572 - val_loss: 0.5999 - val_soft_acc: 0.5071\n",
      "Epoch 836/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0974 - soft_acc: 0.9850 - val_loss: 0.5538 - val_soft_acc: 0.5836\n",
      "Epoch 837/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.0982 - soft_acc: 0.9800 - val_loss: 0.6842 - val_soft_acc: 0.4807\n",
      "Epoch 838/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1700 - soft_acc: 0.9289 - val_loss: 0.5482 - val_soft_acc: 0.5400\n",
      "Epoch 839/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1003 - soft_acc: 0.9589 - val_loss: 0.6012 - val_soft_acc: 0.5993\n",
      "Epoch 840/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.0895 - soft_acc: 0.9867 - val_loss: 0.5996 - val_soft_acc: 0.5736\n",
      "Epoch 841/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0945 - soft_acc: 0.9744 - val_loss: 0.5572 - val_soft_acc: 0.5886\n",
      "Epoch 842/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1093 - soft_acc: 0.9850 - val_loss: 0.6194 - val_soft_acc: 0.5643\n",
      "Epoch 843/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1250 - soft_acc: 0.9572 - val_loss: 0.6072 - val_soft_acc: 0.4614\n",
      "Epoch 844/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1208 - soft_acc: 0.9800 - val_loss: 0.6084 - val_soft_acc: 0.5029\n",
      "Epoch 845/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1021 - soft_acc: 0.9900 - val_loss: 0.5452 - val_soft_acc: 0.5964\n",
      "Epoch 846/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0967 - soft_acc: 0.9711 - val_loss: 0.6095 - val_soft_acc: 0.5357\n",
      "Epoch 847/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1161 - soft_acc: 0.9678 - val_loss: 0.5558 - val_soft_acc: 0.5321\n",
      "Epoch 848/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1009 - soft_acc: 0.9711 - val_loss: 0.6329 - val_soft_acc: 0.5207\n",
      "Epoch 849/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.0969 - soft_acc: 0.9661 - val_loss: 0.5456 - val_soft_acc: 0.5707\n",
      "Epoch 850/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1001 - soft_acc: 0.9817 - val_loss: 0.5963 - val_soft_acc: 0.5450\n",
      "Epoch 851/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.0931 - soft_acc: 0.9833 - val_loss: 0.5417 - val_soft_acc: 0.5936\n",
      "Epoch 852/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0986 - soft_acc: 0.9833 - val_loss: 0.6163 - val_soft_acc: 0.5257\n",
      "Epoch 853/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1040 - soft_acc: 0.9883 - val_loss: 0.5766 - val_soft_acc: 0.6479\n",
      "Epoch 854/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1194 - soft_acc: 0.9750 - val_loss: 0.5460 - val_soft_acc: 0.5171\n",
      "Epoch 855/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1039 - soft_acc: 0.9833 - val_loss: 0.6081 - val_soft_acc: 0.5307\n",
      "Epoch 856/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0990 - soft_acc: 0.9800 - val_loss: 0.5959 - val_soft_acc: 0.4457\n",
      "Epoch 857/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1081 - soft_acc: 0.9883 - val_loss: 0.5935 - val_soft_acc: 0.5121\n",
      "Epoch 858/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1050 - soft_acc: 0.9867 - val_loss: 0.5496 - val_soft_acc: 0.5400\n",
      "Epoch 859/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1010 - soft_acc: 0.9833 - val_loss: 0.6551 - val_soft_acc: 0.4921\n",
      "Epoch 860/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1223 - soft_acc: 0.9750 - val_loss: 0.5557 - val_soft_acc: 0.5786\n",
      "Epoch 861/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1006 - soft_acc: 0.9900 - val_loss: 0.5977 - val_soft_acc: 0.5307\n",
      "Epoch 862/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.0833 - soft_acc: 0.9744 - val_loss: 0.5674 - val_soft_acc: 0.5786\n",
      "Epoch 863/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.0950 - soft_acc: 0.9850 - val_loss: 0.5854 - val_soft_acc: 0.5786\n",
      "Epoch 864/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1073 - soft_acc: 0.9867 - val_loss: 0.6171 - val_soft_acc: 0.4793\n",
      "Epoch 865/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1198 - soft_acc: 0.9767 - val_loss: 0.6159 - val_soft_acc: 0.5350\n",
      "Epoch 866/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0990 - soft_acc: 0.9883 - val_loss: 0.6097 - val_soft_acc: 0.5200\n",
      "Epoch 867/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1055 - soft_acc: 0.9850 - val_loss: 0.5903 - val_soft_acc: 0.5379\n",
      "Epoch 868/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1286 - soft_acc: 0.9494 - val_loss: 0.6791 - val_soft_acc: 0.4343\n",
      "Epoch 869/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1516 - soft_acc: 0.9544 - val_loss: 0.5669 - val_soft_acc: 0.5400\n",
      "Epoch 870/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1043 - soft_acc: 0.9867 - val_loss: 0.5936 - val_soft_acc: 0.4271\n",
      "Epoch 871/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1085 - soft_acc: 0.9800 - val_loss: 0.5922 - val_soft_acc: 0.5021\n",
      "Epoch 872/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1003 - soft_acc: 0.9711 - val_loss: 0.6272 - val_soft_acc: 0.5279\n",
      "Epoch 873/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1224 - soft_acc: 0.9783 - val_loss: 0.6496 - val_soft_acc: 0.5386\n",
      "Epoch 874/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1096 - soft_acc: 0.9817 - val_loss: 0.5975 - val_soft_acc: 0.5229\n",
      "Epoch 875/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1421 - soft_acc: 0.9444 - val_loss: 0.6024 - val_soft_acc: 0.4864\n",
      "Epoch 876/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1102 - soft_acc: 0.9817 - val_loss: 0.6389 - val_soft_acc: 0.5643\n",
      "Epoch 877/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1328 - soft_acc: 0.9683 - val_loss: 0.5679 - val_soft_acc: 0.5943\n",
      "Epoch 878/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0928 - soft_acc: 0.9900 - val_loss: 0.5551 - val_soft_acc: 0.6271\n",
      "Epoch 879/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0992 - soft_acc: 0.9883 - val_loss: 0.5355 - val_soft_acc: 0.5471\n",
      "Epoch 880/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1000 - soft_acc: 0.9850 - val_loss: 0.6248 - val_soft_acc: 0.5150\n",
      "Epoch 881/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0967 - soft_acc: 0.9883 - val_loss: 0.5739 - val_soft_acc: 0.5557\n",
      "Epoch 882/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0984 - soft_acc: 0.9833 - val_loss: 0.6346 - val_soft_acc: 0.5664\n",
      "Epoch 883/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1095 - soft_acc: 0.9850 - val_loss: 0.5294 - val_soft_acc: 0.5557\n",
      "Epoch 884/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1132 - soft_acc: 0.9817 - val_loss: 0.6433 - val_soft_acc: 0.4414\n",
      "Epoch 885/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1185 - soft_acc: 0.9800 - val_loss: 0.5972 - val_soft_acc: 0.5336\n",
      "Epoch 886/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1186 - soft_acc: 0.9733 - val_loss: 0.5886 - val_soft_acc: 0.5121\n",
      "Epoch 887/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1154 - soft_acc: 0.9800 - val_loss: 0.5606 - val_soft_acc: 0.6014\n",
      "Epoch 888/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1187 - soft_acc: 0.9850 - val_loss: 0.6254 - val_soft_acc: 0.5179\n",
      "Epoch 889/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1199 - soft_acc: 0.9783 - val_loss: 0.5569 - val_soft_acc: 0.5607\n",
      "Epoch 890/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1114 - soft_acc: 0.9817 - val_loss: 0.6180 - val_soft_acc: 0.5407\n",
      "Epoch 891/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1041 - soft_acc: 0.9850 - val_loss: 0.5272 - val_soft_acc: 0.6036\n",
      "Epoch 892/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.0932 - soft_acc: 0.9867 - val_loss: 0.5967 - val_soft_acc: 0.6121\n",
      "Epoch 893/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1171 - soft_acc: 0.9800 - val_loss: 0.5900 - val_soft_acc: 0.6014\n",
      "Epoch 894/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1229 - soft_acc: 0.9733 - val_loss: 0.5712 - val_soft_acc: 0.5400\n",
      "Epoch 895/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1567 - soft_acc: 0.9667 - val_loss: 0.5792 - val_soft_acc: 0.4864\n",
      "Epoch 896/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1057 - soft_acc: 0.9867 - val_loss: 0.5939 - val_soft_acc: 0.5736\n",
      "Epoch 897/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1106 - soft_acc: 0.9833 - val_loss: 0.5403 - val_soft_acc: 0.5986\n",
      "Epoch 898/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1116 - soft_acc: 0.9833 - val_loss: 0.6328 - val_soft_acc: 0.5021\n",
      "Epoch 899/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0974 - soft_acc: 0.9867 - val_loss: 0.5324 - val_soft_acc: 0.5636\n",
      "Epoch 900/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0897 - soft_acc: 0.9850 - val_loss: 0.6104 - val_soft_acc: 0.5071\n",
      "Epoch 901/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1074 - soft_acc: 0.9644 - val_loss: 0.5680 - val_soft_acc: 0.5379\n",
      "Epoch 902/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.0846 - soft_acc: 0.9883 - val_loss: 0.6137 - val_soft_acc: 0.4743\n",
      "Epoch 903/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.0961 - soft_acc: 0.9817 - val_loss: 0.5695 - val_soft_acc: 0.5579\n",
      "Epoch 904/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.0901 - soft_acc: 0.9744 - val_loss: 0.6111 - val_soft_acc: 0.5379\n",
      "Epoch 905/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.0966 - soft_acc: 0.9867 - val_loss: 0.5770 - val_soft_acc: 0.5300\n",
      "Epoch 906/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0996 - soft_acc: 0.9883 - val_loss: 0.5772 - val_soft_acc: 0.5736\n",
      "Epoch 907/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1147 - soft_acc: 0.9850 - val_loss: 0.6307 - val_soft_acc: 0.5079\n",
      "Epoch 908/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1310 - soft_acc: 0.9767 - val_loss: 0.5929 - val_soft_acc: 0.5429\n",
      "Epoch 909/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1723 - soft_acc: 0.9633 - val_loss: 0.5665 - val_soft_acc: 0.5629\n",
      "Epoch 910/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1708 - soft_acc: 0.9494 - val_loss: 0.7076 - val_soft_acc: 0.4064\n",
      "Epoch 911/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1619 - soft_acc: 0.9600 - val_loss: 0.6441 - val_soft_acc: 0.5000\n",
      "Epoch 912/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1466 - soft_acc: 0.9700 - val_loss: 0.5910 - val_soft_acc: 0.5914\n",
      "Epoch 913/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1141 - soft_acc: 0.9817 - val_loss: 0.5768 - val_soft_acc: 0.4964\n",
      "Epoch 914/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.0984 - soft_acc: 0.9900 - val_loss: 0.6173 - val_soft_acc: 0.5071\n",
      "Epoch 915/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1011 - soft_acc: 0.9900 - val_loss: 0.5669 - val_soft_acc: 0.5679\n",
      "Epoch 916/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0838 - soft_acc: 0.9917 - val_loss: 0.5608 - val_soft_acc: 0.6164\n",
      "Epoch 917/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1074 - soft_acc: 0.9800 - val_loss: 0.6044 - val_soft_acc: 0.5021\n",
      "Epoch 918/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1047 - soft_acc: 0.9800 - val_loss: 0.5464 - val_soft_acc: 0.6171\n",
      "Epoch 919/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1143 - soft_acc: 0.9850 - val_loss: 0.5669 - val_soft_acc: 0.4971\n",
      "Epoch 920/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1065 - soft_acc: 0.9817 - val_loss: 0.5744 - val_soft_acc: 0.5329\n",
      "Epoch 921/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1029 - soft_acc: 0.9883 - val_loss: 0.6137 - val_soft_acc: 0.5150\n",
      "Epoch 922/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1116 - soft_acc: 0.9917 - val_loss: 0.5700 - val_soft_acc: 0.5579\n",
      "Epoch 923/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1035 - soft_acc: 0.9606 - val_loss: 0.6017 - val_soft_acc: 0.5379\n",
      "Epoch 924/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1081 - soft_acc: 0.9767 - val_loss: 0.5984 - val_soft_acc: 0.4993\n",
      "Epoch 925/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1197 - soft_acc: 0.9644 - val_loss: 0.5494 - val_soft_acc: 0.6450\n",
      "Epoch 926/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1054 - soft_acc: 0.9778 - val_loss: 0.6427 - val_soft_acc: 0.4464\n",
      "Epoch 927/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1152 - soft_acc: 0.9783 - val_loss: 0.5204 - val_soft_acc: 0.5450\n",
      "Epoch 928/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1100 - soft_acc: 0.9744 - val_loss: 0.6135 - val_soft_acc: 0.4693\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1114 - soft_acc: 0.9867 - val_loss: 0.5785 - val_soft_acc: 0.5379\n",
      "Epoch 930/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1350 - soft_acc: 0.9783 - val_loss: 0.5943 - val_soft_acc: 0.5536\n",
      "Epoch 931/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0980 - soft_acc: 0.9744 - val_loss: 0.6140 - val_soft_acc: 0.4879\n",
      "Epoch 932/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1139 - soft_acc: 0.9728 - val_loss: 0.6422 - val_soft_acc: 0.5029\n",
      "Epoch 933/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1081 - soft_acc: 0.9900 - val_loss: 0.5800 - val_soft_acc: 0.5507\n",
      "Epoch 934/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1054 - soft_acc: 0.9728 - val_loss: 0.6142 - val_soft_acc: 0.5250\n",
      "Epoch 935/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1031 - soft_acc: 0.9833 - val_loss: 0.5661 - val_soft_acc: 0.5586\n",
      "Epoch 936/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1132 - soft_acc: 0.9733 - val_loss: 0.5980 - val_soft_acc: 0.5657\n",
      "Epoch 937/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0895 - soft_acc: 0.9883 - val_loss: 0.5477 - val_soft_acc: 0.5679\n",
      "Epoch 938/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0916 - soft_acc: 0.9867 - val_loss: 0.5593 - val_soft_acc: 0.5886\n",
      "Epoch 939/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.0965 - soft_acc: 0.9850 - val_loss: 0.6329 - val_soft_acc: 0.4900\n",
      "Epoch 940/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0910 - soft_acc: 0.9867 - val_loss: 0.5823 - val_soft_acc: 0.4943\n",
      "Epoch 941/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.0894 - soft_acc: 0.9917 - val_loss: 0.5680 - val_soft_acc: 0.5579\n",
      "Epoch 942/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.0849 - soft_acc: 0.9778 - val_loss: 0.5892 - val_soft_acc: 0.5171\n",
      "Epoch 943/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.0973 - soft_acc: 0.9867 - val_loss: 0.5897 - val_soft_acc: 0.4843\n",
      "Epoch 944/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.0918 - soft_acc: 0.9811 - val_loss: 0.5931 - val_soft_acc: 0.5350\n",
      "Epoch 945/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1116 - soft_acc: 0.9883 - val_loss: 0.5778 - val_soft_acc: 0.5529\n",
      "Epoch 946/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1260 - soft_acc: 0.9817 - val_loss: 0.6459 - val_soft_acc: 0.4979\n",
      "Epoch 947/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1519 - soft_acc: 0.9783 - val_loss: 0.6773 - val_soft_acc: 0.3857\n",
      "Epoch 948/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1820 - soft_acc: 0.9278 - val_loss: 0.5925 - val_soft_acc: 0.4943\n",
      "Epoch 949/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1520 - soft_acc: 0.9600 - val_loss: 0.6766 - val_soft_acc: 0.4571\n",
      "Epoch 950/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1564 - soft_acc: 0.9533 - val_loss: 0.5980 - val_soft_acc: 0.5714\n",
      "Epoch 951/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1299 - soft_acc: 0.9783 - val_loss: 0.6618 - val_soft_acc: 0.4950\n",
      "Epoch 952/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1221 - soft_acc: 0.9817 - val_loss: 0.5618 - val_soft_acc: 0.5914\n",
      "Epoch 953/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1142 - soft_acc: 0.9833 - val_loss: 0.6043 - val_soft_acc: 0.5843\n",
      "Epoch 954/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0907 - soft_acc: 0.9917 - val_loss: 0.5680 - val_soft_acc: 0.5686\n",
      "Epoch 955/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0869 - soft_acc: 0.9900 - val_loss: 0.5716 - val_soft_acc: 0.5886\n",
      "Epoch 956/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0906 - soft_acc: 0.9883 - val_loss: 0.6225 - val_soft_acc: 0.4850\n",
      "Epoch 957/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1003 - soft_acc: 0.9850 - val_loss: 0.5404 - val_soft_acc: 0.6371\n",
      "Epoch 958/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1002 - soft_acc: 0.9867 - val_loss: 0.6312 - val_soft_acc: 0.4614\n",
      "Epoch 959/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1089 - soft_acc: 0.9850 - val_loss: 0.5920 - val_soft_acc: 0.4971\n",
      "Epoch 960/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1005 - soft_acc: 0.9744 - val_loss: 0.6038 - val_soft_acc: 0.4764\n",
      "Epoch 961/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1089 - soft_acc: 0.9883 - val_loss: 0.5734 - val_soft_acc: 0.5350\n",
      "Epoch 962/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.0964 - soft_acc: 0.9900 - val_loss: 0.5832 - val_soft_acc: 0.5657\n",
      "Epoch 963/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.0960 - soft_acc: 0.9917 - val_loss: 0.5913 - val_soft_acc: 0.5071\n",
      "Epoch 964/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.0863 - soft_acc: 0.9900 - val_loss: 0.6523 - val_soft_acc: 0.4514\n",
      "Epoch 965/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1402 - soft_acc: 0.9489 - val_loss: 0.6170 - val_soft_acc: 0.5407\n",
      "Epoch 966/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1149 - soft_acc: 0.9728 - val_loss: 0.5268 - val_soft_acc: 0.6043\n",
      "Epoch 967/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1046 - soft_acc: 0.9883 - val_loss: 0.6008 - val_soft_acc: 0.5300\n",
      "Epoch 968/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.0922 - soft_acc: 0.9917 - val_loss: 0.5656 - val_soft_acc: 0.5757\n",
      "Epoch 969/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1167 - soft_acc: 0.9628 - val_loss: 0.5719 - val_soft_acc: 0.5886\n",
      "Epoch 970/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.0923 - soft_acc: 0.9900 - val_loss: 0.6322 - val_soft_acc: 0.4671\n",
      "Epoch 971/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1237 - soft_acc: 0.9783 - val_loss: 0.6146 - val_soft_acc: 0.5336\n",
      "Epoch 972/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1611 - soft_acc: 0.9561 - val_loss: 0.5855 - val_soft_acc: 0.5300\n",
      "Epoch 973/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1403 - soft_acc: 0.9628 - val_loss: 0.6476 - val_soft_acc: 0.4514\n",
      "Epoch 974/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1120 - soft_acc: 0.9678 - val_loss: 0.5843 - val_soft_acc: 0.5536\n",
      "Epoch 975/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.0994 - soft_acc: 0.9900 - val_loss: 0.6022 - val_soft_acc: 0.5486\n",
      "Epoch 976/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1163 - soft_acc: 0.9817 - val_loss: 0.5419 - val_soft_acc: 0.6064\n",
      "Epoch 977/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.0975 - soft_acc: 0.9833 - val_loss: 0.5757 - val_soft_acc: 0.5764\n",
      "Epoch 978/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1002 - soft_acc: 0.9678 - val_loss: 0.5682 - val_soft_acc: 0.5507\n",
      "Epoch 979/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0836 - soft_acc: 0.9933 - val_loss: 0.6164 - val_soft_acc: 0.5893\n",
      "Epoch 980/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0880 - soft_acc: 0.9794 - val_loss: 0.5752 - val_soft_acc: 0.5707\n",
      "Epoch 981/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0944 - soft_acc: 0.9900 - val_loss: 0.6364 - val_soft_acc: 0.4971\n",
      "Epoch 982/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1300 - soft_acc: 0.9850 - val_loss: 0.5978 - val_soft_acc: 0.5943\n",
      "Epoch 983/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1573 - soft_acc: 0.9617 - val_loss: 0.6633 - val_soft_acc: 0.4550\n",
      "Epoch 984/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1243 - soft_acc: 0.9817 - val_loss: 0.6149 - val_soft_acc: 0.5157\n",
      "Epoch 985/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1210 - soft_acc: 0.9850 - val_loss: 0.6250 - val_soft_acc: 0.4743\n",
      "Epoch 986/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1123 - soft_acc: 0.9850 - val_loss: 0.6945 - val_soft_acc: 0.3957\n",
      "Epoch 987/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1434 - soft_acc: 0.9583 - val_loss: 0.6028 - val_soft_acc: 0.4229\n",
      "Epoch 988/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1477 - soft_acc: 0.9661 - val_loss: 0.5741 - val_soft_acc: 0.6300\n",
      "Epoch 989/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1095 - soft_acc: 0.9728 - val_loss: 0.6032 - val_soft_acc: 0.5479\n",
      "Epoch 990/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0885 - soft_acc: 0.9917 - val_loss: 0.6372 - val_soft_acc: 0.4979\n",
      "Epoch 991/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0964 - soft_acc: 0.9672 - val_loss: 0.5786 - val_soft_acc: 0.4764\n",
      "Epoch 992/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0874 - soft_acc: 0.9900 - val_loss: 0.6036 - val_soft_acc: 0.5279\n",
      "Epoch 993/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0929 - soft_acc: 0.9883 - val_loss: 0.5552 - val_soft_acc: 0.5957\n",
      "Epoch 994/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0871 - soft_acc: 0.9933 - val_loss: 0.7100 - val_soft_acc: 0.4550\n",
      "Epoch 995/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1325 - soft_acc: 0.9833 - val_loss: 0.6459 - val_soft_acc: 0.4493\n",
      "Epoch 996/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1301 - soft_acc: 0.9783 - val_loss: 0.6227 - val_soft_acc: 0.5000\n",
      "Epoch 997/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1208 - soft_acc: 0.9594 - val_loss: 0.5731 - val_soft_acc: 0.5786\n",
      "Epoch 998/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1358 - soft_acc: 0.9767 - val_loss: 0.5437 - val_soft_acc: 0.5607\n",
      "Epoch 999/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1694 - soft_acc: 0.9650 - val_loss: 0.5407 - val_soft_acc: 0.6143\n",
      "Epoch 1000/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1203 - soft_acc: 0.9767 - val_loss: 0.6709 - val_soft_acc: 0.4493\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.5360 - soft_acc: 0.6484\n",
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.4065 - soft_acc: 0.3100best occur in epoch 0\n",
      "512/512 [==============================] - 0s 442us/sample - loss: 9.6775 - soft_acc: 0.0767 - val_loss: 2.4686 - val_soft_acc: 0.2871\n",
      "Epoch 2/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.9345 - soft_acc: 0.1100best occur in epoch 1\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 2.2209 - soft_acc: 0.2706 - val_loss: 1.0983 - val_soft_acc: 0.1714\n",
      "Epoch 3/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3860 - soft_acc: 0.2400best occur in epoch 2\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 1.2518 - soft_acc: 0.2611 - val_loss: 1.1097 - val_soft_acc: 0.3029\n",
      "Epoch 4/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3200 - soft_acc: 0.2800best occur in epoch 3\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.4181 - soft_acc: 0.2872 - val_loss: 1.2126 - val_soft_acc: 0.2950\n",
      "Epoch 5/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.5094 - soft_acc: 0.2400best occur in epoch 4\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 1.3905 - soft_acc: 0.2594 - val_loss: 0.8703 - val_soft_acc: 0.3429\n",
      "Epoch 6/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0034 - soft_acc: 0.3200best occur in epoch 5\n",
      "512/512 [==============================] - 0s 58us/sample - loss: 1.0914 - soft_acc: 0.3167 - val_loss: 0.7818 - val_soft_acc: 0.3943\n",
      "Epoch 7/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 1.0169 - soft_acc: 0.3617 - val_loss: 0.9079 - val_soft_acc: 0.2957\n",
      "Epoch 8/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.1192 - soft_acc: 0.3100best occur in epoch 7\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.9890 - soft_acc: 0.3583 - val_loss: 0.6955 - val_soft_acc: 0.3964\n",
      "Epoch 9/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.8659 - soft_acc: 0.4083 - val_loss: 0.8231 - val_soft_acc: 0.3050\n",
      "Epoch 10/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0953 - soft_acc: 0.4200best occur in epoch 9\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.8283 - soft_acc: 0.4272 - val_loss: 0.7933 - val_soft_acc: 0.4114\n",
      "Epoch 11/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.9383 - soft_acc: 0.4000best occur in epoch 10\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.7579 - soft_acc: 0.4856 - val_loss: 0.6719 - val_soft_acc: 0.4364\n",
      "Epoch 12/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6858 - soft_acc: 0.5100best occur in epoch 11\n",
      "512/512 [==============================] - 0s 61us/sample - loss: 0.6675 - soft_acc: 0.4822 - val_loss: 0.6286 - val_soft_acc: 0.4871\n",
      "Epoch 13/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6474 - soft_acc: 0.5400best occur in epoch 12\n",
      "512/512 [==============================] - 0s 69us/sample - loss: 0.6157 - soft_acc: 0.5450 - val_loss: 0.6638 - val_soft_acc: 0.4950\n",
      "Epoch 14/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5516 - soft_acc: 0.5500best occur in epoch 13\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5982 - soft_acc: 0.5422 - val_loss: 0.6242 - val_soft_acc: 0.5229\n",
      "Epoch 15/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5498 - soft_acc: 0.5400best occur in epoch 14\n",
      "512/512 [==============================] - 0s 70us/sample - loss: 0.5853 - soft_acc: 0.5439 - val_loss: 0.5513 - val_soft_acc: 0.5757\n",
      "Epoch 16/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.5167 - soft_acc: 0.6167 - val_loss: 0.7119 - val_soft_acc: 0.3586\n",
      "Epoch 17/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.6579 - soft_acc: 0.5133 - val_loss: 0.6216 - val_soft_acc: 0.4643\n",
      "Epoch 18/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5329 - soft_acc: 0.5672 - val_loss: 0.6201 - val_soft_acc: 0.5457\n",
      "Epoch 19/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4994 - soft_acc: 0.5722 - val_loss: 0.6189 - val_soft_acc: 0.4821\n",
      "Epoch 20/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.6721 - soft_acc: 0.5217 - val_loss: 0.6103 - val_soft_acc: 0.5236\n",
      "Epoch 21/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.5438 - soft_acc: 0.5878 - val_loss: 0.5823 - val_soft_acc: 0.5079\n",
      "Epoch 22/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5028 - soft_acc: 0.6283 - val_loss: 0.7198 - val_soft_acc: 0.3636\n",
      "Epoch 23/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.7669 - soft_acc: 0.4456 - val_loss: 0.6122 - val_soft_acc: 0.4536\n",
      "Epoch 24/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.5994 - soft_acc: 0.5144 - val_loss: 0.6094 - val_soft_acc: 0.4564\n",
      "Epoch 25/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.5191 - soft_acc: 0.6194 - val_loss: 0.5760 - val_soft_acc: 0.4586\n",
      "Epoch 26/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5045 - soft_acc: 0.6572 - val_loss: 0.6963 - val_soft_acc: 0.4021\n",
      "Epoch 27/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.8209 - soft_acc: 0.4494 - val_loss: 0.6290 - val_soft_acc: 0.5071\n",
      "Epoch 28/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6571 - soft_acc: 0.5067 - val_loss: 0.8136 - val_soft_acc: 0.3536\n",
      "Epoch 29/1000\n",
      "512/512 [==============================] - 0s 0s/sample - loss: 0.7142 - soft_acc: 0.4794 - val_loss: 0.6213 - val_soft_acc: 0.5843\n",
      "Epoch 30/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4918 - soft_acc: 0.6200best occur in epoch 29\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.5143 - soft_acc: 0.6333 - val_loss: 0.6285 - val_soft_acc: 0.5764\n",
      "Epoch 31/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4578 - soft_acc: 0.6739 - val_loss: 0.5782 - val_soft_acc: 0.4871\n",
      "Epoch 32/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4857 - soft_acc: 0.5967 - val_loss: 0.6025 - val_soft_acc: 0.5229\n",
      "Epoch 33/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4220 - soft_acc: 0.6772 - val_loss: 0.5621 - val_soft_acc: 0.5014\n",
      "Epoch 34/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4231 - soft_acc: 0.6761 - val_loss: 0.6053 - val_soft_acc: 0.4664\n",
      "Epoch 35/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4160 - soft_acc: 0.7200best occur in epoch 34\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4431 - soft_acc: 0.7178 - val_loss: 0.5713 - val_soft_acc: 0.5179\n",
      "Epoch 36/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4238 - soft_acc: 0.6894 - val_loss: 0.5975 - val_soft_acc: 0.4893\n",
      "Epoch 37/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4044 - soft_acc: 0.6694 - val_loss: 0.6128 - val_soft_acc: 0.4764\n",
      "Epoch 38/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4185 - soft_acc: 0.7000 - val_loss: 0.5742 - val_soft_acc: 0.4950\n",
      "Epoch 39/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4563 - soft_acc: 0.6211 - val_loss: 0.5995 - val_soft_acc: 0.5279\n",
      "Epoch 40/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.5673 - soft_acc: 0.5478 - val_loss: 0.6001 - val_soft_acc: 0.4229\n",
      "Epoch 41/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4401 - soft_acc: 0.6556 - val_loss: 0.5787 - val_soft_acc: 0.5171\n",
      "Epoch 42/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.5566 - soft_acc: 0.5017 - val_loss: 0.6400 - val_soft_acc: 0.5307\n",
      "Epoch 43/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.5020 - soft_acc: 0.6156 - val_loss: 0.6145 - val_soft_acc: 0.4814\n",
      "Epoch 44/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5450 - soft_acc: 0.6100best occur in epoch 43\n",
      "512/512 [==============================] - 0s 57us/sample - loss: 0.4355 - soft_acc: 0.6706 - val_loss: 0.6041 - val_soft_acc: 0.5686\n",
      "Epoch 45/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.4030 - soft_acc: 0.6978 - val_loss: 0.5594 - val_soft_acc: 0.5171\n",
      "Epoch 46/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4328 - soft_acc: 0.6800best occur in epoch 45\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3960 - soft_acc: 0.7339 - val_loss: 0.5758 - val_soft_acc: 0.5171\n",
      "Epoch 47/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.4142 - soft_acc: 0.7289 - val_loss: 0.6048 - val_soft_acc: 0.5071\n",
      "Epoch 48/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3931 - soft_acc: 0.7178 - val_loss: 0.5951 - val_soft_acc: 0.5079\n",
      "Epoch 49/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4350 - soft_acc: 0.6467 - val_loss: 0.5447 - val_soft_acc: 0.5171\n",
      "Epoch 50/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4601 - soft_acc: 0.6806 - val_loss: 0.6063 - val_soft_acc: 0.5579\n",
      "Epoch 51/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3542 - soft_acc: 0.7100best occur in epoch 50\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3965 - soft_acc: 0.7167 - val_loss: 0.5447 - val_soft_acc: 0.5629\n",
      "Epoch 52/1000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.3882 - soft_acc: 0.6839 - val_loss: 0.6211 - val_soft_acc: 0.5200\n",
      "Epoch 53/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4175 - soft_acc: 0.5739 - val_loss: 0.6560 - val_soft_acc: 0.5329\n",
      "Epoch 54/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4621 - soft_acc: 0.6183 - val_loss: 0.5744 - val_soft_acc: 0.5586\n",
      "Epoch 55/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4094 - soft_acc: 0.6983 - val_loss: 0.5872 - val_soft_acc: 0.5071\n",
      "Epoch 56/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3787 - soft_acc: 0.7450 - val_loss: 0.6135 - val_soft_acc: 0.5200\n",
      "Epoch 57/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3701 - soft_acc: 0.7661 - val_loss: 0.5805 - val_soft_acc: 0.5121\n",
      "Epoch 58/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3441 - soft_acc: 0.7800best occur in epoch 57\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3816 - soft_acc: 0.7422 - val_loss: 0.5955 - val_soft_acc: 0.5407\n",
      "Epoch 59/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.3658 - soft_acc: 0.7217 - val_loss: 0.6150 - val_soft_acc: 0.5050\n",
      "Epoch 60/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3726 - soft_acc: 0.7228 - val_loss: 0.6933 - val_soft_acc: 0.4057\n",
      "Epoch 61/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4685 - soft_acc: 0.6478 - val_loss: 0.6007 - val_soft_acc: 0.6150\n",
      "Epoch 62/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4024 - soft_acc: 0.7267 - val_loss: 0.5590 - val_soft_acc: 0.5350\n",
      "Epoch 63/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3993 - soft_acc: 0.7283 - val_loss: 0.6013 - val_soft_acc: 0.4971\n",
      "Epoch 64/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4504 - soft_acc: 0.6694 - val_loss: 0.5804 - val_soft_acc: 0.5450\n",
      "Epoch 65/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4219 - soft_acc: 0.7144 - val_loss: 0.6256 - val_soft_acc: 0.4893\n",
      "Epoch 66/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4260 - soft_acc: 0.6467 - val_loss: 0.6689 - val_soft_acc: 0.4336\n",
      "Epoch 67/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4574 - soft_acc: 0.6544 - val_loss: 0.7437 - val_soft_acc: 0.4114\n",
      "Epoch 68/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.5220 - soft_acc: 0.6078 - val_loss: 0.5511 - val_soft_acc: 0.5864\n",
      "Epoch 69/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4433 - soft_acc: 0.7167 - val_loss: 0.5520 - val_soft_acc: 0.5579\n",
      "Epoch 70/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4110 - soft_acc: 0.7428 - val_loss: 0.5679 - val_soft_acc: 0.4643\n",
      "Epoch 71/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4415 - soft_acc: 0.6628 - val_loss: 0.5726 - val_soft_acc: 0.5350\n",
      "Epoch 72/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3561 - soft_acc: 0.7300best occur in epoch 71\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.3671 - soft_acc: 0.7556 - val_loss: 0.5973 - val_soft_acc: 0.5607\n",
      "Epoch 73/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3890 - soft_acc: 0.7228 - val_loss: 0.5933 - val_soft_acc: 0.5786\n",
      "Epoch 74/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3512 - soft_acc: 0.7600best occur in epoch 73\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3621 - soft_acc: 0.7344 - val_loss: 0.5454 - val_soft_acc: 0.6036\n",
      "Epoch 75/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3105 - soft_acc: 0.7800best occur in epoch 74\n",
      "512/512 [==============================] - 0s 59us/sample - loss: 0.3664 - soft_acc: 0.7461 - val_loss: 0.5673 - val_soft_acc: 0.6143\n",
      "Epoch 76/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3577 - soft_acc: 0.7222 - val_loss: 0.5458 - val_soft_acc: 0.4836\n",
      "Epoch 77/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3582 - soft_acc: 0.7622 - val_loss: 0.5677 - val_soft_acc: 0.5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3492 - soft_acc: 0.7439 - val_loss: 0.5947 - val_soft_acc: 0.4971\n",
      "Epoch 79/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3699 - soft_acc: 0.7689 - val_loss: 0.6805 - val_soft_acc: 0.5107\n",
      "Epoch 80/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4587 - soft_acc: 0.6611 - val_loss: 0.6291 - val_soft_acc: 0.5586\n",
      "Epoch 81/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4253 - soft_acc: 0.6906 - val_loss: 0.5452 - val_soft_acc: 0.5379\n",
      "Epoch 82/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5056 - soft_acc: 0.6322 - val_loss: 0.5512 - val_soft_acc: 0.5271\n",
      "Epoch 83/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3711 - soft_acc: 0.7211 - val_loss: 0.6574 - val_soft_acc: 0.4921\n",
      "Epoch 84/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3872 - soft_acc: 0.7061 - val_loss: 0.5386 - val_soft_acc: 0.5964\n",
      "Epoch 85/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3609 - soft_acc: 0.7572 - val_loss: 0.5421 - val_soft_acc: 0.5436\n",
      "Epoch 86/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3807 - soft_acc: 0.7300 - val_loss: 0.5573 - val_soft_acc: 0.5257\n",
      "Epoch 87/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3706 - soft_acc: 0.7439 - val_loss: 0.5850 - val_soft_acc: 0.4971\n",
      "Epoch 88/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3744 - soft_acc: 0.7522 - val_loss: 0.5664 - val_soft_acc: 0.5079\n",
      "Epoch 89/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3553 - soft_acc: 0.7750 - val_loss: 0.5546 - val_soft_acc: 0.5607\n",
      "Epoch 90/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3437 - soft_acc: 0.7672 - val_loss: 0.5321 - val_soft_acc: 0.5100\n",
      "Epoch 91/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3514 - soft_acc: 0.7478 - val_loss: 0.5500 - val_soft_acc: 0.5257\n",
      "Epoch 92/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3877 - soft_acc: 0.7356 - val_loss: 0.5509 - val_soft_acc: 0.5864\n",
      "Epoch 93/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3392 - soft_acc: 0.7822 - val_loss: 0.5447 - val_soft_acc: 0.4893\n",
      "Epoch 94/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3526 - soft_acc: 0.7794 - val_loss: 0.5426 - val_soft_acc: 0.5450\n",
      "Epoch 95/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3543 - soft_acc: 0.7428 - val_loss: 0.5497 - val_soft_acc: 0.5371\n",
      "Epoch 96/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3039 - soft_acc: 0.8500best occur in epoch 95\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3479 - soft_acc: 0.7839 - val_loss: 0.5298 - val_soft_acc: 0.6193\n",
      "Epoch 97/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3539 - soft_acc: 0.7761 - val_loss: 0.5824 - val_soft_acc: 0.5100\n",
      "Epoch 98/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3544 - soft_acc: 0.7550 - val_loss: 0.7112 - val_soft_acc: 0.4264\n",
      "Epoch 99/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4724 - soft_acc: 0.5528 - val_loss: 0.5380 - val_soft_acc: 0.6679\n",
      "Epoch 100/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5024 - soft_acc: 0.6322 - val_loss: 0.5620 - val_soft_acc: 0.5357\n",
      "Epoch 101/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4820 - soft_acc: 0.6533 - val_loss: 0.5259 - val_soft_acc: 0.5171\n",
      "Epoch 102/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3754 - soft_acc: 0.7761 - val_loss: 0.6980 - val_soft_acc: 0.4779\n",
      "Epoch 103/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4422 - soft_acc: 0.6567 - val_loss: 0.5548 - val_soft_acc: 0.5457\n",
      "Epoch 104/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3651 - soft_acc: 0.7211 - val_loss: 0.5537 - val_soft_acc: 0.5043\n",
      "Epoch 105/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3798 - soft_acc: 0.7217 - val_loss: 0.5568 - val_soft_acc: 0.5507\n",
      "Epoch 106/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3624 - soft_acc: 0.7456 - val_loss: 0.5896 - val_soft_acc: 0.5586\n",
      "Epoch 107/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3552 - soft_acc: 0.7411 - val_loss: 0.5467 - val_soft_acc: 0.5429\n",
      "Epoch 108/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3311 - soft_acc: 0.7922 - val_loss: 0.5563 - val_soft_acc: 0.5814\n",
      "Epoch 109/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3595 - soft_acc: 0.7417 - val_loss: 0.5628 - val_soft_acc: 0.6043\n",
      "Epoch 110/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3780 - soft_acc: 0.7322 - val_loss: 0.4996 - val_soft_acc: 0.5636\n",
      "Epoch 111/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3577 - soft_acc: 0.7817 - val_loss: 0.4686 - val_soft_acc: 0.5886\n",
      "Epoch 112/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3679 - soft_acc: 0.7378 - val_loss: 0.5499 - val_soft_acc: 0.5686\n",
      "Epoch 113/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3495 - soft_acc: 0.7667 - val_loss: 0.5402 - val_soft_acc: 0.5250\n",
      "Epoch 114/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3549 - soft_acc: 0.7639 - val_loss: 0.5319 - val_soft_acc: 0.5557\n",
      "Epoch 115/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3746 - soft_acc: 0.7600best occur in epoch 114\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.3811 - soft_acc: 0.7706 - val_loss: 0.4726 - val_soft_acc: 0.6800\n",
      "Epoch 116/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3713 - soft_acc: 0.7239 - val_loss: 0.5479 - val_soft_acc: 0.5121\n",
      "Epoch 117/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3408 - soft_acc: 0.7544 - val_loss: 0.4871 - val_soft_acc: 0.6093\n",
      "Epoch 118/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3544 - soft_acc: 0.8050 - val_loss: 0.5049 - val_soft_acc: 0.5886\n",
      "Epoch 119/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3723 - soft_acc: 0.7433 - val_loss: 0.5090 - val_soft_acc: 0.5907\n",
      "Epoch 120/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3369 - soft_acc: 0.7961 - val_loss: 0.5220 - val_soft_acc: 0.5729\n",
      "Epoch 121/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3239 - soft_acc: 0.8006 - val_loss: 0.4899 - val_soft_acc: 0.5857\n",
      "Epoch 122/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3186 - soft_acc: 0.8061 - val_loss: 0.5428 - val_soft_acc: 0.5014\n",
      "Epoch 123/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3287 - soft_acc: 0.8094 - val_loss: 0.4976 - val_soft_acc: 0.6057\n",
      "Epoch 124/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3184 - soft_acc: 0.7611 - val_loss: 0.4610 - val_soft_acc: 0.6207\n",
      "Epoch 125/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3237 - soft_acc: 0.7678 - val_loss: 0.5257 - val_soft_acc: 0.5764\n",
      "Epoch 126/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3899 - soft_acc: 0.6994 - val_loss: 0.5905 - val_soft_acc: 0.5921\n",
      "Epoch 127/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3645 - soft_acc: 0.7189 - val_loss: 0.5664 - val_soft_acc: 0.5279\n",
      "Epoch 128/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3448 - soft_acc: 0.7911 - val_loss: 0.6240 - val_soft_acc: 0.5307\n",
      "Epoch 129/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4038 - soft_acc: 0.6861 - val_loss: 0.4665 - val_soft_acc: 0.6186\n",
      "Epoch 130/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3623 - soft_acc: 0.7733 - val_loss: 0.4942 - val_soft_acc: 0.5479\n",
      "Epoch 131/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3913 - soft_acc: 0.6950 - val_loss: 0.5892 - val_soft_acc: 0.5271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3292 - soft_acc: 0.7756 - val_loss: 0.5402 - val_soft_acc: 0.5557\n",
      "Epoch 133/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3211 - soft_acc: 0.7883 - val_loss: 0.5194 - val_soft_acc: 0.5300\n",
      "Epoch 134/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3519 - soft_acc: 0.7672 - val_loss: 0.5104 - val_soft_acc: 0.5550\n",
      "Epoch 135/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3585 - soft_acc: 0.7867 - val_loss: 0.4658 - val_soft_acc: 0.6443\n",
      "Epoch 136/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3786 - soft_acc: 0.7317 - val_loss: 0.5256 - val_soft_acc: 0.5864\n",
      "Epoch 137/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3295 - soft_acc: 0.7694 - val_loss: 0.5801 - val_soft_acc: 0.5557\n",
      "Epoch 138/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3311 - soft_acc: 0.7817 - val_loss: 0.5733 - val_soft_acc: 0.5229\n",
      "Epoch 139/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3483 - soft_acc: 0.7256 - val_loss: 0.5849 - val_soft_acc: 0.5536\n",
      "Epoch 140/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3235 - soft_acc: 0.7672 - val_loss: 0.6091 - val_soft_acc: 0.5357\n",
      "Epoch 141/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.3171 - soft_acc: 0.7850 - val_loss: 0.5844 - val_soft_acc: 0.5557\n",
      "Epoch 142/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3081 - soft_acc: 0.8083 - val_loss: 0.6080 - val_soft_acc: 0.5586\n",
      "Epoch 143/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3766 - soft_acc: 0.7594 - val_loss: 0.5319 - val_soft_acc: 0.5964\n",
      "Epoch 144/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3159 - soft_acc: 0.7572 - val_loss: 0.5287 - val_soft_acc: 0.5429\n",
      "Epoch 145/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3556 - soft_acc: 0.7189 - val_loss: 0.5008 - val_soft_acc: 0.5914\n",
      "Epoch 146/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3212 - soft_acc: 0.8044 - val_loss: 0.4831 - val_soft_acc: 0.5986\n",
      "Epoch 147/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3276 - soft_acc: 0.7906 - val_loss: 0.5347 - val_soft_acc: 0.5707\n",
      "Epoch 148/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3076 - soft_acc: 0.8056 - val_loss: 0.5355 - val_soft_acc: 0.5250\n",
      "Epoch 149/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2951 - soft_acc: 0.8239 - val_loss: 0.5430 - val_soft_acc: 0.5507\n",
      "Epoch 150/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3182 - soft_acc: 0.8211 - val_loss: 0.6114 - val_soft_acc: 0.5407\n",
      "Epoch 151/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3867 - soft_acc: 0.7017 - val_loss: 0.4953 - val_soft_acc: 0.6243\n",
      "Epoch 152/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3726 - soft_acc: 0.7083 - val_loss: 0.5012 - val_soft_acc: 0.6500\n",
      "Epoch 153/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3576 - soft_acc: 0.7744 - val_loss: 0.5634 - val_soft_acc: 0.6121\n",
      "Epoch 154/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3135 - soft_acc: 0.8106 - val_loss: 0.5298 - val_soft_acc: 0.6043\n",
      "Epoch 155/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2925 - soft_acc: 0.8411 - val_loss: 0.4850 - val_soft_acc: 0.5886\n",
      "Epoch 156/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3008 - soft_acc: 0.7978 - val_loss: 0.4774 - val_soft_acc: 0.5829\n",
      "Epoch 157/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3073 - soft_acc: 0.8089 - val_loss: 0.4901 - val_soft_acc: 0.5986\n",
      "Epoch 158/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2951 - soft_acc: 0.8256 - val_loss: 0.5716 - val_soft_acc: 0.5814\n",
      "Epoch 159/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3344 - soft_acc: 0.7439 - val_loss: 0.5643 - val_soft_acc: 0.5350\n",
      "Epoch 160/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3514 - soft_acc: 0.7622 - val_loss: 0.4886 - val_soft_acc: 0.6729\n",
      "Epoch 161/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3146 - soft_acc: 0.8106 - val_loss: 0.4791 - val_soft_acc: 0.6214\n",
      "Epoch 162/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2820 - soft_acc: 0.8094 - val_loss: 0.5174 - val_soft_acc: 0.5757\n",
      "Epoch 163/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2917 - soft_acc: 0.8256 - val_loss: 0.5172 - val_soft_acc: 0.6093\n",
      "Epoch 164/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3178 - soft_acc: 0.7611 - val_loss: 0.5183 - val_soft_acc: 0.6014\n",
      "Epoch 165/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3141 - soft_acc: 0.7933 - val_loss: 0.5211 - val_soft_acc: 0.5557\n",
      "Epoch 166/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2756 - soft_acc: 0.8461 - val_loss: 0.5175 - val_soft_acc: 0.5757\n",
      "Epoch 167/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3017 - soft_acc: 0.8228 - val_loss: 0.4968 - val_soft_acc: 0.5350\n",
      "Epoch 168/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2837 - soft_acc: 0.8011 - val_loss: 0.5763 - val_soft_acc: 0.5579\n",
      "Epoch 169/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2757 - soft_acc: 0.8217 - val_loss: 0.5288 - val_soft_acc: 0.5786\n",
      "Epoch 170/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3005 - soft_acc: 0.8206 - val_loss: 0.5291 - val_soft_acc: 0.5943\n",
      "Epoch 171/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2924 - soft_acc: 0.8378 - val_loss: 0.5389 - val_soft_acc: 0.6121\n",
      "Epoch 172/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2785 - soft_acc: 0.7839 - val_loss: 0.5225 - val_soft_acc: 0.6321\n",
      "Epoch 173/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2915 - soft_acc: 0.8261 - val_loss: 0.5196 - val_soft_acc: 0.5686\n",
      "Epoch 174/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2699 - soft_acc: 0.8561 - val_loss: 0.5521 - val_soft_acc: 0.5664\n",
      "Epoch 175/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2833 - soft_acc: 0.8494 - val_loss: 0.5373 - val_soft_acc: 0.5507\n",
      "Epoch 176/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2960 - soft_acc: 0.8417 - val_loss: 0.5350 - val_soft_acc: 0.5379\n",
      "Epoch 177/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2998 - soft_acc: 0.8106 - val_loss: 0.5332 - val_soft_acc: 0.5529\n",
      "Epoch 178/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2882 - soft_acc: 0.8239 - val_loss: 0.5311 - val_soft_acc: 0.5786\n",
      "Epoch 179/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3276 - soft_acc: 0.7700best occur in epoch 178\n",
      "512/512 [==============================] - 0s 57us/sample - loss: 0.2925 - soft_acc: 0.8172 - val_loss: 0.4912 - val_soft_acc: 0.6729\n",
      "Epoch 180/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2804 - soft_acc: 0.8528 - val_loss: 0.5235 - val_soft_acc: 0.5300\n",
      "Epoch 181/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3072 - soft_acc: 0.7800 - val_loss: 0.5199 - val_soft_acc: 0.6400\n",
      "Epoch 182/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2976 - soft_acc: 0.8278 - val_loss: 0.5084 - val_soft_acc: 0.5707\n",
      "Epoch 183/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2911 - soft_acc: 0.8144 - val_loss: 0.5199 - val_soft_acc: 0.5400\n",
      "Epoch 184/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2837 - soft_acc: 0.8139 - val_loss: 0.5702 - val_soft_acc: 0.5100\n",
      "Epoch 185/1000\n",
      "512/512 [==============================] - 0s 8us/sample - loss: 0.2863 - soft_acc: 0.8206 - val_loss: 0.5802 - val_soft_acc: 0.4793\n",
      "Epoch 186/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2806 - soft_acc: 0.7878 - val_loss: 0.5767 - val_soft_acc: 0.5479\n",
      "Epoch 187/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2879 - soft_acc: 0.8483 - val_loss: 0.5404 - val_soft_acc: 0.5429\n",
      "Epoch 188/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2951 - soft_acc: 0.7944 - val_loss: 0.5322 - val_soft_acc: 0.5786\n",
      "Epoch 189/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2644 - soft_acc: 0.8061 - val_loss: 0.5371 - val_soft_acc: 0.5479\n",
      "Epoch 190/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2774 - soft_acc: 0.8344 - val_loss: 0.5184 - val_soft_acc: 0.6014\n",
      "Epoch 191/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2869 - soft_acc: 0.8372 - val_loss: 0.5051 - val_soft_acc: 0.5371\n",
      "Epoch 192/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2710 - soft_acc: 0.8411 - val_loss: 0.5321 - val_soft_acc: 0.5200\n",
      "Epoch 193/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2569 - soft_acc: 0.8433 - val_loss: 0.5130 - val_soft_acc: 0.6193\n",
      "Epoch 194/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2669 - soft_acc: 0.8472 - val_loss: 0.4957 - val_soft_acc: 0.5421\n",
      "Epoch 195/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2741 - soft_acc: 0.8528 - val_loss: 0.5198 - val_soft_acc: 0.5864\n",
      "Epoch 196/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3038 - soft_acc: 0.8156 - val_loss: 0.4998 - val_soft_acc: 0.5171\n",
      "Epoch 197/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2786 - soft_acc: 0.8650 - val_loss: 0.5324 - val_soft_acc: 0.5479\n",
      "Epoch 198/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2725 - soft_acc: 0.8333 - val_loss: 0.5147 - val_soft_acc: 0.5529\n",
      "Epoch 199/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2675 - soft_acc: 0.8667 - val_loss: 0.5087 - val_soft_acc: 0.5243\n",
      "Epoch 200/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2657 - soft_acc: 0.8461 - val_loss: 0.5479 - val_soft_acc: 0.4993\n",
      "Epoch 201/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2862 - soft_acc: 0.8222 - val_loss: 0.5425 - val_soft_acc: 0.5429\n",
      "Epoch 202/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2792 - soft_acc: 0.7889 - val_loss: 0.5300 - val_soft_acc: 0.5607\n",
      "Epoch 203/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2648 - soft_acc: 0.8544 - val_loss: 0.5306 - val_soft_acc: 0.5350\n",
      "Epoch 204/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2624 - soft_acc: 0.8561 - val_loss: 0.4991 - val_soft_acc: 0.5857\n",
      "Epoch 205/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2871 - soft_acc: 0.8450 - val_loss: 0.5462 - val_soft_acc: 0.6171\n",
      "Epoch 206/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2891 - soft_acc: 0.8156 - val_loss: 0.5227 - val_soft_acc: 0.5807\n",
      "Epoch 207/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3111 - soft_acc: 0.8161 - val_loss: 0.5192 - val_soft_acc: 0.5736\n",
      "Epoch 208/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4517 - soft_acc: 0.6306 - val_loss: 0.6802 - val_soft_acc: 0.5136\n",
      "Epoch 209/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3781 - soft_acc: 0.7183 - val_loss: 0.5888 - val_soft_acc: 0.5329\n",
      "Epoch 210/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3209 - soft_acc: 0.7806 - val_loss: 0.5659 - val_soft_acc: 0.5686\n",
      "Epoch 211/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3706 - soft_acc: 0.7267 - val_loss: 0.5595 - val_soft_acc: 0.4664\n",
      "Epoch 212/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3447 - soft_acc: 0.7828 - val_loss: 0.5268 - val_soft_acc: 0.5529\n",
      "Epoch 213/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2854 - soft_acc: 0.7839 - val_loss: 0.5505 - val_soft_acc: 0.5786\n",
      "Epoch 214/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3003 - soft_acc: 0.8089 - val_loss: 0.5375 - val_soft_acc: 0.5329\n",
      "Epoch 215/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3836 - soft_acc: 0.7133 - val_loss: 0.5031 - val_soft_acc: 0.6043\n",
      "Epoch 216/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3181 - soft_acc: 0.7922 - val_loss: 0.5390 - val_soft_acc: 0.5536\n",
      "Epoch 217/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4219 - soft_acc: 0.7094 - val_loss: 0.5155 - val_soft_acc: 0.6221\n",
      "Epoch 218/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2786 - soft_acc: 0.8306 - val_loss: 0.5591 - val_soft_acc: 0.5300\n",
      "Epoch 219/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2777 - soft_acc: 0.8233 - val_loss: 0.5779 - val_soft_acc: 0.5121\n",
      "Epoch 220/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2773 - soft_acc: 0.8422 - val_loss: 0.5112 - val_soft_acc: 0.5450\n",
      "Epoch 221/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2978 - soft_acc: 0.8444 - val_loss: 0.5087 - val_soft_acc: 0.6421\n",
      "Epoch 222/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2604 - soft_acc: 0.8733 - val_loss: 0.4909 - val_soft_acc: 0.6121\n",
      "Epoch 223/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2701 - soft_acc: 0.8406 - val_loss: 0.5209 - val_soft_acc: 0.5371\n",
      "Epoch 224/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2788 - soft_acc: 0.8344 - val_loss: 0.5599 - val_soft_acc: 0.5200\n",
      "Epoch 225/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3131 - soft_acc: 0.7750 - val_loss: 0.5068 - val_soft_acc: 0.5936\n",
      "Epoch 226/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2749 - soft_acc: 0.8650 - val_loss: 0.4889 - val_soft_acc: 0.5600\n",
      "Epoch 227/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2555 - soft_acc: 0.8594 - val_loss: 0.5079 - val_soft_acc: 0.5479\n",
      "Epoch 228/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2570 - soft_acc: 0.8294 - val_loss: 0.5457 - val_soft_acc: 0.5171\n",
      "Epoch 229/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2485 - soft_acc: 0.8678 - val_loss: 0.5334 - val_soft_acc: 0.5893\n",
      "Epoch 230/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2607 - soft_acc: 0.8561 - val_loss: 0.5893 - val_soft_acc: 0.5179\n",
      "Epoch 231/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2969 - soft_acc: 0.8517 - val_loss: 0.5396 - val_soft_acc: 0.5507\n",
      "Epoch 232/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2690 - soft_acc: 0.8289 - val_loss: 0.5535 - val_soft_acc: 0.5250\n",
      "Epoch 233/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2657 - soft_acc: 0.8344 - val_loss: 0.6081 - val_soft_acc: 0.5486\n",
      "Epoch 234/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3891 - soft_acc: 0.6617 - val_loss: 0.5422 - val_soft_acc: 0.5557\n",
      "Epoch 235/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3969 - soft_acc: 0.7089 - val_loss: 0.5148 - val_soft_acc: 0.6093\n",
      "Epoch 236/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3920 - soft_acc: 0.7017 - val_loss: 0.4933 - val_soft_acc: 0.5786\n",
      "Epoch 237/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3636 - soft_acc: 0.6950 - val_loss: 0.6836 - val_soft_acc: 0.3800\n",
      "Epoch 238/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3993 - soft_acc: 0.6900 - val_loss: 0.5504 - val_soft_acc: 0.5657\n",
      "Epoch 239/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3189 - soft_acc: 0.7750 - val_loss: 0.4996 - val_soft_acc: 0.5914\n",
      "Epoch 240/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3274 - soft_acc: 0.7456 - val_loss: 0.4990 - val_soft_acc: 0.5243\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2823 - soft_acc: 0.8306 - val_loss: 0.5467 - val_soft_acc: 0.5943\n",
      "Epoch 242/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2768 - soft_acc: 0.8444 - val_loss: 0.5254 - val_soft_acc: 0.5736\n",
      "Epoch 243/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2820 - soft_acc: 0.8394 - val_loss: 0.5489 - val_soft_acc: 0.5171\n",
      "Epoch 244/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2550 - soft_acc: 0.8456 - val_loss: 0.5004 - val_soft_acc: 0.5886\n",
      "Epoch 245/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2758 - soft_acc: 0.8267 - val_loss: 0.5070 - val_soft_acc: 0.5907\n",
      "Epoch 246/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2718 - soft_acc: 0.8406 - val_loss: 0.5114 - val_soft_acc: 0.4864\n",
      "Epoch 247/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3002 - soft_acc: 0.7822 - val_loss: 0.5177 - val_soft_acc: 0.5457\n",
      "Epoch 248/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3156 - soft_acc: 0.7783 - val_loss: 0.5239 - val_soft_acc: 0.5221\n",
      "Epoch 249/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2792 - soft_acc: 0.8289 - val_loss: 0.4971 - val_soft_acc: 0.6164\n",
      "Epoch 250/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2506 - soft_acc: 0.8644 - val_loss: 0.4966 - val_soft_acc: 0.6164\n",
      "Epoch 251/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2617 - soft_acc: 0.8350 - val_loss: 0.4878 - val_soft_acc: 0.5757\n",
      "Epoch 252/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2653 - soft_acc: 0.8272 - val_loss: 0.4823 - val_soft_acc: 0.5886\n",
      "Epoch 253/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3195 - soft_acc: 0.8011 - val_loss: 0.5206 - val_soft_acc: 0.5936\n",
      "Epoch 254/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2675 - soft_acc: 0.8494 - val_loss: 0.5393 - val_soft_acc: 0.4864\n",
      "Epoch 255/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2404 - soft_acc: 0.8533 - val_loss: 0.5690 - val_soft_acc: 0.4943\n",
      "Epoch 256/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2531 - soft_acc: 0.8472 - val_loss: 0.5661 - val_soft_acc: 0.5457\n",
      "Epoch 257/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2719 - soft_acc: 0.8272 - val_loss: 0.5367 - val_soft_acc: 0.4964\n",
      "Epoch 258/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3013 - soft_acc: 0.8467 - val_loss: 0.5261 - val_soft_acc: 0.6221\n",
      "Epoch 259/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2724 - soft_acc: 0.8272 - val_loss: 0.5195 - val_soft_acc: 0.5864\n",
      "Epoch 260/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2680 - soft_acc: 0.8244 - val_loss: 0.5283 - val_soft_acc: 0.5686\n",
      "Epoch 261/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2806 - soft_acc: 0.8378 - val_loss: 0.5358 - val_soft_acc: 0.5121\n",
      "Epoch 262/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2768 - soft_acc: 0.8261 - val_loss: 0.5218 - val_soft_acc: 0.5507\n",
      "Epoch 263/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2759 - soft_acc: 0.8011 - val_loss: 0.4973 - val_soft_acc: 0.5350\n",
      "Epoch 264/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2600 - soft_acc: 0.8139 - val_loss: 0.5400 - val_soft_acc: 0.4736\n",
      "Epoch 265/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2431 - soft_acc: 0.8606 - val_loss: 0.5159 - val_soft_acc: 0.5936\n",
      "Epoch 266/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2491 - soft_acc: 0.8539 - val_loss: 0.5120 - val_soft_acc: 0.5707\n",
      "Epoch 267/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2717 - soft_acc: 0.8339 - val_loss: 0.5108 - val_soft_acc: 0.6093\n",
      "Epoch 268/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2804 - soft_acc: 0.8156 - val_loss: 0.4697 - val_soft_acc: 0.5500\n",
      "Epoch 269/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2614 - soft_acc: 0.8700 - val_loss: 0.5051 - val_soft_acc: 0.5193\n",
      "Epoch 270/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3119 - soft_acc: 0.8300 - val_loss: 0.5669 - val_soft_acc: 0.5329\n",
      "Epoch 271/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2485 - soft_acc: 0.8850 - val_loss: 0.5658 - val_soft_acc: 0.5893\n",
      "Epoch 272/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2518 - soft_acc: 0.8400 - val_loss: 0.5495 - val_soft_acc: 0.5507\n",
      "Epoch 273/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2457 - soft_acc: 0.8572 - val_loss: 0.5863 - val_soft_acc: 0.5279\n",
      "Epoch 274/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.2543 - soft_acc: 0.8644 - val_loss: 0.5376 - val_soft_acc: 0.5221\n",
      "Epoch 275/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2553 - soft_acc: 0.8578 - val_loss: 0.5369 - val_soft_acc: 0.5071\n",
      "Epoch 276/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2656 - soft_acc: 0.8717 - val_loss: 0.5315 - val_soft_acc: 0.5429\n",
      "Epoch 277/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2537 - soft_acc: 0.8644 - val_loss: 0.5825 - val_soft_acc: 0.6071\n",
      "Epoch 278/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2748 - soft_acc: 0.8583 - val_loss: 0.5443 - val_soft_acc: 0.5586\n",
      "Epoch 279/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2547 - soft_acc: 0.8800 - val_loss: 0.5511 - val_soft_acc: 0.5507\n",
      "Epoch 280/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2525 - soft_acc: 0.8750 - val_loss: 0.5073 - val_soft_acc: 0.5964\n",
      "Epoch 281/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3090 - soft_acc: 0.7661 - val_loss: 0.6067 - val_soft_acc: 0.5229\n",
      "Epoch 282/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3114 - soft_acc: 0.7817 - val_loss: 0.5093 - val_soft_acc: 0.5550\n",
      "Epoch 283/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2927 - soft_acc: 0.8100 - val_loss: 0.5572 - val_soft_acc: 0.5050\n",
      "Epoch 284/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3054 - soft_acc: 0.8078 - val_loss: 0.5080 - val_soft_acc: 0.6214\n",
      "Epoch 285/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2383 - soft_acc: 0.8767 - val_loss: 0.5288 - val_soft_acc: 0.5864\n",
      "Epoch 286/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2506 - soft_acc: 0.8778 - val_loss: 0.5213 - val_soft_acc: 0.5814\n",
      "Epoch 287/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2629 - soft_acc: 0.8339 - val_loss: 0.5112 - val_soft_acc: 0.5400\n",
      "Epoch 288/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2515 - soft_acc: 0.8678 - val_loss: 0.5111 - val_soft_acc: 0.5707\n",
      "Epoch 289/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2943 - soft_acc: 0.7922 - val_loss: 0.5303 - val_soft_acc: 0.6300\n",
      "Epoch 290/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2448 - soft_acc: 0.8467 - val_loss: 0.5189 - val_soft_acc: 0.5300\n",
      "Epoch 291/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2884 - soft_acc: 0.8122 - val_loss: 0.5054 - val_soft_acc: 0.5579\n",
      "Epoch 292/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2740 - soft_acc: 0.8217 - val_loss: 0.5290 - val_soft_acc: 0.5093\n",
      "Epoch 293/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2925 - soft_acc: 0.8067 - val_loss: 0.5613 - val_soft_acc: 0.5357\n",
      "Epoch 294/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2375 - soft_acc: 0.8844 - val_loss: 0.5870 - val_soft_acc: 0.5414\n",
      "Epoch 295/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2665 - soft_acc: 0.8478 - val_loss: 0.6099 - val_soft_acc: 0.4900\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3193 - soft_acc: 0.7789 - val_loss: 0.5942 - val_soft_acc: 0.5407\n",
      "Epoch 297/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3103 - soft_acc: 0.8039 - val_loss: 0.5088 - val_soft_acc: 0.5607\n",
      "Epoch 298/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2656 - soft_acc: 0.8367 - val_loss: 0.5067 - val_soft_acc: 0.5679\n",
      "Epoch 299/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2595 - soft_acc: 0.8733 - val_loss: 0.5446 - val_soft_acc: 0.5407\n",
      "Epoch 300/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2617 - soft_acc: 0.8539 - val_loss: 0.5626 - val_soft_acc: 0.5914\n",
      "Epoch 301/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2467 - soft_acc: 0.8350 - val_loss: 0.5216 - val_soft_acc: 0.5864\n",
      "Epoch 302/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2867 - soft_acc: 0.8256 - val_loss: 0.5206 - val_soft_acc: 0.5450\n",
      "Epoch 303/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.2680 - soft_acc: 0.8650 - val_loss: 0.5236 - val_soft_acc: 0.5886\n",
      "Epoch 304/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2308 - soft_acc: 0.8844 - val_loss: 0.5200 - val_soft_acc: 0.5757\n",
      "Epoch 305/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2984 - soft_acc: 0.8189 - val_loss: 0.5323 - val_soft_acc: 0.5707\n",
      "Epoch 306/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3690 - soft_acc: 0.7528 - val_loss: 0.5686 - val_soft_acc: 0.5014\n",
      "Epoch 307/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2738 - soft_acc: 0.8439 - val_loss: 0.5335 - val_soft_acc: 0.6221\n",
      "Epoch 308/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2707 - soft_acc: 0.8650 - val_loss: 0.5693 - val_soft_acc: 0.4843\n",
      "Epoch 309/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2547 - soft_acc: 0.8572 - val_loss: 0.5117 - val_soft_acc: 0.5964\n",
      "Epoch 310/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2422 - soft_acc: 0.8900 - val_loss: 0.4897 - val_soft_acc: 0.5579\n",
      "Epoch 311/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2390 - soft_acc: 0.8817 - val_loss: 0.4965 - val_soft_acc: 0.5143\n",
      "Epoch 312/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2410 - soft_acc: 0.8783 - val_loss: 0.5057 - val_soft_acc: 0.5814\n",
      "Epoch 313/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2479 - soft_acc: 0.8500best occur in epoch 312\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2422 - soft_acc: 0.8828 - val_loss: 0.4892 - val_soft_acc: 0.6086\n",
      "Epoch 314/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2606 - soft_acc: 0.8333 - val_loss: 0.5269 - val_soft_acc: 0.5764\n",
      "Epoch 315/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2283 - soft_acc: 0.8667 - val_loss: 0.5129 - val_soft_acc: 0.5786\n",
      "Epoch 316/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2630 - soft_acc: 0.8683 - val_loss: 0.4994 - val_soft_acc: 0.6043\n",
      "Epoch 317/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2251 - soft_acc: 0.8689 - val_loss: 0.5096 - val_soft_acc: 0.5271\n",
      "Epoch 318/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2296 - soft_acc: 0.8844 - val_loss: 0.5096 - val_soft_acc: 0.5736\n",
      "Epoch 319/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2825 - soft_acc: 0.8189 - val_loss: 0.5008 - val_soft_acc: 0.5736\n",
      "Epoch 320/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2642 - soft_acc: 0.8389 - val_loss: 0.5701 - val_soft_acc: 0.5250\n",
      "Epoch 321/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2609 - soft_acc: 0.8356 - val_loss: 0.5192 - val_soft_acc: 0.5429\n",
      "Epoch 322/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2284 - soft_acc: 0.8844 - val_loss: 0.5208 - val_soft_acc: 0.5686\n",
      "Epoch 323/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2177 - soft_acc: 0.8561 - val_loss: 0.5239 - val_soft_acc: 0.5300\n",
      "Epoch 324/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2330 - soft_acc: 0.8467 - val_loss: 0.5494 - val_soft_acc: 0.5407\n",
      "Epoch 325/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2804 - soft_acc: 0.8294 - val_loss: 0.5154 - val_soft_acc: 0.5607\n",
      "Epoch 326/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2436 - soft_acc: 0.8622 - val_loss: 0.5070 - val_soft_acc: 0.5271\n",
      "Epoch 327/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2475 - soft_acc: 0.8644 - val_loss: 0.5167 - val_soft_acc: 0.5607\n",
      "Epoch 328/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2508 - soft_acc: 0.8817 - val_loss: 0.5214 - val_soft_acc: 0.5657\n",
      "Epoch 329/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2502 - soft_acc: 0.8661 - val_loss: 0.5196 - val_soft_acc: 0.4886\n",
      "Epoch 330/1000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.2910 - soft_acc: 0.81 - 0s 31us/sample - loss: 0.2785 - soft_acc: 0.8306 - val_loss: 0.5142 - val_soft_acc: 0.5707\n",
      "Epoch 331/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2589 - soft_acc: 0.8406 - val_loss: 0.5172 - val_soft_acc: 0.6221\n",
      "Epoch 332/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2320 - soft_acc: 0.8811 - val_loss: 0.5249 - val_soft_acc: 0.5914\n",
      "Epoch 333/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2306 - soft_acc: 0.8761 - val_loss: 0.5311 - val_soft_acc: 0.5579\n",
      "Epoch 334/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2366 - soft_acc: 0.8744 - val_loss: 0.5327 - val_soft_acc: 0.5300\n",
      "Epoch 335/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2367 - soft_acc: 0.8589 - val_loss: 0.5137 - val_soft_acc: 0.5786\n",
      "Epoch 336/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2532 - soft_acc: 0.8711 - val_loss: 0.5281 - val_soft_acc: 0.5807\n",
      "Epoch 337/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2657 - soft_acc: 0.8356 - val_loss: 0.5163 - val_soft_acc: 0.6014\n",
      "Epoch 338/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2531 - soft_acc: 0.8472 - val_loss: 0.5713 - val_soft_acc: 0.5307\n",
      "Epoch 339/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2524 - soft_acc: 0.8628 - val_loss: 0.5388 - val_soft_acc: 0.5636\n",
      "Epoch 340/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2261 - soft_acc: 0.8928 - val_loss: 0.5142 - val_soft_acc: 0.5657\n",
      "Epoch 341/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2571 - soft_acc: 0.8611 - val_loss: 0.5589 - val_soft_acc: 0.5229\n",
      "Epoch 342/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2625 - soft_acc: 0.8183 - val_loss: 0.5010 - val_soft_acc: 0.5429\n",
      "Epoch 343/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2540 - soft_acc: 0.8506 - val_loss: 0.5667 - val_soft_acc: 0.4971\n",
      "Epoch 344/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3258 - soft_acc: 0.7822 - val_loss: 0.5628 - val_soft_acc: 0.5457\n",
      "Epoch 345/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2450 - soft_acc: 0.8689 - val_loss: 0.5448 - val_soft_acc: 0.5943\n",
      "Epoch 346/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2213 - soft_acc: 0.8611 - val_loss: 0.5477 - val_soft_acc: 0.5279\n",
      "Epoch 347/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2285 - soft_acc: 0.8917 - val_loss: 0.5314 - val_soft_acc: 0.5964\n",
      "Epoch 348/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2227 - soft_acc: 0.8789 - val_loss: 0.5280 - val_soft_acc: 0.5657\n",
      "Epoch 349/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2176 - soft_acc: 0.8511 - val_loss: 0.5100 - val_soft_acc: 0.5936\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2121 - soft_acc: 0.8944 - val_loss: 0.5304 - val_soft_acc: 0.5350\n",
      "Epoch 351/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2521 - soft_acc: 0.8983 - val_loss: 0.5303 - val_soft_acc: 0.4793\n",
      "Epoch 352/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2301 - soft_acc: 0.8778 - val_loss: 0.5122 - val_soft_acc: 0.5857\n",
      "Epoch 353/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2082 - soft_acc: 0.8633 - val_loss: 0.5345 - val_soft_acc: 0.5350\n",
      "Epoch 354/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2073 - soft_acc: 0.8961 - val_loss: 0.5185 - val_soft_acc: 0.5629\n",
      "Epoch 355/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2033 - soft_acc: 0.9028 - val_loss: 0.5350 - val_soft_acc: 0.5507\n",
      "Epoch 356/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2193 - soft_acc: 0.8900best occur in epoch 355\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2107 - soft_acc: 0.9061 - val_loss: 0.5393 - val_soft_acc: 0.6243\n",
      "Epoch 357/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2230 - soft_acc: 0.8889 - val_loss: 0.5681 - val_soft_acc: 0.5436\n",
      "Epoch 358/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2214 - soft_acc: 0.8906 - val_loss: 0.5720 - val_soft_acc: 0.5021\n",
      "Epoch 359/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2607 - soft_acc: 0.8489 - val_loss: 0.5417 - val_soft_acc: 0.5307\n",
      "Epoch 360/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2888 - soft_acc: 0.8139 - val_loss: 0.5410 - val_soft_acc: 0.5407\n",
      "Epoch 361/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2454 - soft_acc: 0.8678 - val_loss: 0.5042 - val_soft_acc: 0.6021\n",
      "Epoch 362/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2536 - soft_acc: 0.8389 - val_loss: 0.4791 - val_soft_acc: 0.5957\n",
      "Epoch 363/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2376 - soft_acc: 0.8828 - val_loss: 0.5281 - val_soft_acc: 0.5843\n",
      "Epoch 364/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2235 - soft_acc: 0.8967 - val_loss: 0.5810 - val_soft_acc: 0.4843\n",
      "Epoch 365/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2354 - soft_acc: 0.8639 - val_loss: 0.5180 - val_soft_acc: 0.5764\n",
      "Epoch 366/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2407 - soft_acc: 0.8278 - val_loss: 0.4805 - val_soft_acc: 0.5421\n",
      "Epoch 367/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2284 - soft_acc: 0.8800best occur in epoch 366\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2276 - soft_acc: 0.8967 - val_loss: 0.4709 - val_soft_acc: 0.7107\n",
      "Epoch 368/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2277 - soft_acc: 0.8861 - val_loss: 0.5127 - val_soft_acc: 0.5914\n",
      "Epoch 369/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2559 - soft_acc: 0.8594 - val_loss: 0.5685 - val_soft_acc: 0.5279\n",
      "Epoch 370/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2328 - soft_acc: 0.8622 - val_loss: 0.5471 - val_soft_acc: 0.5171\n",
      "Epoch 371/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2131 - soft_acc: 0.9000 - val_loss: 0.5288 - val_soft_acc: 0.5171\n",
      "Epoch 372/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2183 - soft_acc: 0.8772 - val_loss: 0.5407 - val_soft_acc: 0.6071\n",
      "Epoch 373/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2154 - soft_acc: 0.8733 - val_loss: 0.5254 - val_soft_acc: 0.5557\n",
      "Epoch 374/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2221 - soft_acc: 0.8894 - val_loss: 0.5427 - val_soft_acc: 0.5200\n",
      "Epoch 375/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2403 - soft_acc: 0.8656 - val_loss: 0.5464 - val_soft_acc: 0.5171\n",
      "Epoch 376/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2757 - soft_acc: 0.8306 - val_loss: 0.5283 - val_soft_acc: 0.6093\n",
      "Epoch 377/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2817 - soft_acc: 0.8117 - val_loss: 0.5276 - val_soft_acc: 0.5764\n",
      "Epoch 378/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2309 - soft_acc: 0.8878 - val_loss: 0.5592 - val_soft_acc: 0.5379\n",
      "Epoch 379/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2211 - soft_acc: 0.8861 - val_loss: 0.5499 - val_soft_acc: 0.5071\n",
      "Epoch 380/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2354 - soft_acc: 0.8517 - val_loss: 0.5375 - val_soft_acc: 0.4993\n",
      "Epoch 381/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2300 - soft_acc: 0.8672 - val_loss: 0.5521 - val_soft_acc: 0.5150\n",
      "Epoch 382/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2146 - soft_acc: 0.8806 - val_loss: 0.5835 - val_soft_acc: 0.4486\n",
      "Epoch 383/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2659 - soft_acc: 0.8511 - val_loss: 0.5293 - val_soft_acc: 0.5271\n",
      "Epoch 384/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2510 - soft_acc: 0.8539 - val_loss: 0.5578 - val_soft_acc: 0.5614\n",
      "Epoch 385/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2582 - soft_acc: 0.8694 - val_loss: 0.5188 - val_soft_acc: 0.6064\n",
      "Epoch 386/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2260 - soft_acc: 0.9017 - val_loss: 0.5172 - val_soft_acc: 0.5807\n",
      "Epoch 387/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2261 - soft_acc: 0.9133 - val_loss: 0.5453 - val_soft_acc: 0.5071\n",
      "Epoch 388/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2190 - soft_acc: 0.8978 - val_loss: 0.5097 - val_soft_acc: 0.5857\n",
      "Epoch 389/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2244 - soft_acc: 0.8561 - val_loss: 0.5130 - val_soft_acc: 0.5114\n",
      "Epoch 390/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2376 - soft_acc: 0.8778 - val_loss: 0.5390 - val_soft_acc: 0.5764\n",
      "Epoch 391/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2204 - soft_acc: 0.9150 - val_loss: 0.5530 - val_soft_acc: 0.4686\n",
      "Epoch 392/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2206 - soft_acc: 0.8911 - val_loss: 0.5336 - val_soft_acc: 0.5429\n",
      "Epoch 393/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2024 - soft_acc: 0.9128 - val_loss: 0.5187 - val_soft_acc: 0.5729\n",
      "Epoch 394/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2412 - soft_acc: 0.8711 - val_loss: 0.5313 - val_soft_acc: 0.6193\n",
      "Epoch 395/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2413 - soft_acc: 0.8917 - val_loss: 0.5172 - val_soft_acc: 0.5500\n",
      "Epoch 396/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2223 - soft_acc: 0.9017 - val_loss: 0.5734 - val_soft_acc: 0.4586\n",
      "Epoch 397/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2068 - soft_acc: 0.8889 - val_loss: 0.5289 - val_soft_acc: 0.5836\n",
      "Epoch 398/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2060 - soft_acc: 0.8700 - val_loss: 0.5055 - val_soft_acc: 0.5164\n",
      "Epoch 399/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2019 - soft_acc: 0.9028 - val_loss: 0.5354 - val_soft_acc: 0.5200\n",
      "Epoch 400/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1909 - soft_acc: 0.8972 - val_loss: 0.5548 - val_soft_acc: 0.5050\n",
      "Epoch 401/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1876 - soft_acc: 0.9022 - val_loss: 0.5419 - val_soft_acc: 0.5686\n",
      "Epoch 402/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2092 - soft_acc: 0.8828 - val_loss: 0.5524 - val_soft_acc: 0.5121\n",
      "Epoch 403/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1933 - soft_acc: 0.9128 - val_loss: 0.5702 - val_soft_acc: 0.4379\n",
      "Epoch 404/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2068 - soft_acc: 0.9200 - val_loss: 0.5484 - val_soft_acc: 0.5329\n",
      "Epoch 405/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2268 - soft_acc: 0.8961 - val_loss: 0.6020 - val_soft_acc: 0.5257\n",
      "Epoch 406/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2500 - soft_acc: 0.8828 - val_loss: 0.5449 - val_soft_acc: 0.5457\n",
      "Epoch 407/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2358 - soft_acc: 0.8644 - val_loss: 0.5560 - val_soft_acc: 0.5150\n",
      "Epoch 408/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2089 - soft_acc: 0.8839 - val_loss: 0.5456 - val_soft_acc: 0.4814\n",
      "Epoch 409/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1889 - soft_acc: 0.9200 - val_loss: 0.5388 - val_soft_acc: 0.5893\n",
      "Epoch 410/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2001 - soft_acc: 0.8872 - val_loss: 0.5686 - val_soft_acc: 0.5536\n",
      "Epoch 411/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2318 - soft_acc: 0.8667 - val_loss: 0.5607 - val_soft_acc: 0.4971\n",
      "Epoch 412/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2344 - soft_acc: 0.8933 - val_loss: 0.5621 - val_soft_acc: 0.5586\n",
      "Epoch 413/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2517 - soft_acc: 0.8633 - val_loss: 0.5567 - val_soft_acc: 0.4871\n",
      "Epoch 414/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2577 - soft_acc: 0.8339 - val_loss: 0.5181 - val_soft_acc: 0.5536\n",
      "Epoch 415/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2181 - soft_acc: 0.8872 - val_loss: 0.4617 - val_soft_acc: 0.6314\n",
      "Epoch 416/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2292 - soft_acc: 0.9100 - val_loss: 0.5199 - val_soft_acc: 0.4764\n",
      "Epoch 417/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2161 - soft_acc: 0.9133 - val_loss: 0.5443 - val_soft_acc: 0.4871\n",
      "Epoch 418/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2334 - soft_acc: 0.8728 - val_loss: 0.5328 - val_soft_acc: 0.5657\n",
      "Epoch 419/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2070 - soft_acc: 0.9150 - val_loss: 0.5341 - val_soft_acc: 0.5714\n",
      "Epoch 420/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1906 - soft_acc: 0.9144 - val_loss: 0.5327 - val_soft_acc: 0.5657\n",
      "Epoch 421/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2019 - soft_acc: 0.8822 - val_loss: 0.5534 - val_soft_acc: 0.5150\n",
      "Epoch 422/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2188 - soft_acc: 0.8911 - val_loss: 0.5588 - val_soft_acc: 0.5050\n",
      "Epoch 423/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2240 - soft_acc: 0.9067 - val_loss: 0.4919 - val_soft_acc: 0.6621\n",
      "Epoch 424/1000\n",
      "512/512 [==============================] - 0s 8us/sample - loss: 0.2284 - soft_acc: 0.8861 - val_loss: 0.5479 - val_soft_acc: 0.5457\n",
      "Epoch 425/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.2105 - soft_acc: 0.9044 - val_loss: 0.5378 - val_soft_acc: 0.5836\n",
      "Epoch 426/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2022 - soft_acc: 0.9083 - val_loss: 0.5600 - val_soft_acc: 0.5636\n",
      "Epoch 427/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2177 - soft_acc: 0.8856 - val_loss: 0.5001 - val_soft_acc: 0.5757\n",
      "Epoch 428/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2369 - soft_acc: 0.8761 - val_loss: 0.5108 - val_soft_acc: 0.5836\n",
      "Epoch 429/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2098 - soft_acc: 0.8978 - val_loss: 0.5334 - val_soft_acc: 0.5400\n",
      "Epoch 430/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2177 - soft_acc: 0.8978 - val_loss: 0.5210 - val_soft_acc: 0.5379\n",
      "Epoch 431/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2083 - soft_acc: 0.9167 - val_loss: 0.4948 - val_soft_acc: 0.6421\n",
      "Epoch 432/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2230 - soft_acc: 0.9000 - val_loss: 0.5578 - val_soft_acc: 0.5329\n",
      "Epoch 433/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2026 - soft_acc: 0.8622 - val_loss: 0.5295 - val_soft_acc: 0.5171\n",
      "Epoch 434/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2038 - soft_acc: 0.9044 - val_loss: 0.5138 - val_soft_acc: 0.5479\n",
      "Epoch 435/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2083 - soft_acc: 0.8594 - val_loss: 0.5792 - val_soft_acc: 0.5436\n",
      "Epoch 436/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1980 - soft_acc: 0.9022 - val_loss: 0.5303 - val_soft_acc: 0.5814\n",
      "Epoch 437/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2646 - soft_acc: 0.8628 - val_loss: 0.5016 - val_soft_acc: 0.6264\n",
      "Epoch 438/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2420 - soft_acc: 0.8794 - val_loss: 0.5317 - val_soft_acc: 0.5150\n",
      "Epoch 439/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2466 - soft_acc: 0.8778 - val_loss: 0.5211 - val_soft_acc: 0.5814\n",
      "Epoch 440/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2787 - soft_acc: 0.8083 - val_loss: 0.5463 - val_soft_acc: 0.5200\n",
      "Epoch 441/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2541 - soft_acc: 0.8850 - val_loss: 0.5601 - val_soft_acc: 0.5357\n",
      "Epoch 442/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2335 - soft_acc: 0.8894 - val_loss: 0.5424 - val_soft_acc: 0.5586\n",
      "Epoch 443/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2137 - soft_acc: 0.9011 - val_loss: 0.5877 - val_soft_acc: 0.5279\n",
      "Epoch 444/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3019 - soft_acc: 0.8122 - val_loss: 0.5531 - val_soft_acc: 0.5229\n",
      "Epoch 445/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2154 - soft_acc: 0.8928 - val_loss: 0.5174 - val_soft_acc: 0.5171\n",
      "Epoch 446/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2033 - soft_acc: 0.9133 - val_loss: 0.5216 - val_soft_acc: 0.4943\n",
      "Epoch 447/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2144 - soft_acc: 0.8906 - val_loss: 0.4896 - val_soft_acc: 0.5707\n",
      "Epoch 448/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2178 - soft_acc: 0.8961 - val_loss: 0.4963 - val_soft_acc: 0.5471\n",
      "Epoch 449/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2038 - soft_acc: 0.8611 - val_loss: 0.5179 - val_soft_acc: 0.6250\n",
      "Epoch 450/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2095 - soft_acc: 0.9133 - val_loss: 0.5297 - val_soft_acc: 0.5407\n",
      "Epoch 451/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1925 - soft_acc: 0.9128 - val_loss: 0.5289 - val_soft_acc: 0.4893\n",
      "Epoch 452/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2191 - soft_acc: 0.9050 - val_loss: 0.5416 - val_soft_acc: 0.4943\n",
      "Epoch 453/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1997 - soft_acc: 0.9028 - val_loss: 0.5152 - val_soft_acc: 0.6121\n",
      "Epoch 454/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2146 - soft_acc: 0.8722 - val_loss: 0.5343 - val_soft_acc: 0.5457\n",
      "Epoch 455/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2050 - soft_acc: 0.9039 - val_loss: 0.5261 - val_soft_acc: 0.5736\n",
      "Epoch 456/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1928 - soft_acc: 0.9250 - val_loss: 0.5374 - val_soft_acc: 0.4457\n",
      "Epoch 457/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1885 - soft_acc: 0.9022 - val_loss: 0.5402 - val_soft_acc: 0.5250\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1861 - soft_acc: 0.9056 - val_loss: 0.5302 - val_soft_acc: 0.5457\n",
      "Epoch 459/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1821 - soft_acc: 0.9367 - val_loss: 0.5201 - val_soft_acc: 0.5043\n",
      "Epoch 460/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1740 - soft_acc: 0.9072 - val_loss: 0.5231 - val_soft_acc: 0.5629\n",
      "Epoch 461/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1739 - soft_acc: 0.9194 - val_loss: 0.5429 - val_soft_acc: 0.5179\n",
      "Epoch 462/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1867 - soft_acc: 0.8867 - val_loss: 0.5388 - val_soft_acc: 0.4814\n",
      "Epoch 463/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2285 - soft_acc: 0.8844 - val_loss: 0.5257 - val_soft_acc: 0.5714\n",
      "Epoch 464/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2268 - soft_acc: 0.8772 - val_loss: 0.5214 - val_soft_acc: 0.5043\n",
      "Epoch 465/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2291 - soft_acc: 0.8722 - val_loss: 0.5343 - val_soft_acc: 0.5736\n",
      "Epoch 466/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2807 - soft_acc: 0.8089 - val_loss: 0.5129 - val_soft_acc: 0.6271\n",
      "Epoch 467/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2251 - soft_acc: 0.8978 - val_loss: 0.5734 - val_soft_acc: 0.5050\n",
      "Epoch 468/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2731 - soft_acc: 0.8256 - val_loss: 0.5891 - val_soft_acc: 0.5921\n",
      "Epoch 469/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2217 - soft_acc: 0.9133 - val_loss: 0.5643 - val_soft_acc: 0.5486\n",
      "Epoch 470/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2385 - soft_acc: 0.8744 - val_loss: 0.5298 - val_soft_acc: 0.5043\n",
      "Epoch 471/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2002 - soft_acc: 0.9044 - val_loss: 0.5590 - val_soft_acc: 0.5043\n",
      "Epoch 472/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1868 - soft_acc: 0.9211 - val_loss: 0.5514 - val_soft_acc: 0.5193\n",
      "Epoch 473/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1852 - soft_acc: 0.9061 - val_loss: 0.5291 - val_soft_acc: 0.5736\n",
      "Epoch 474/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2116 - soft_acc: 0.9044 - val_loss: 0.5580 - val_soft_acc: 0.5229\n",
      "Epoch 475/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2390 - soft_acc: 0.8967 - val_loss: 0.5845 - val_soft_acc: 0.5000\n",
      "Epoch 476/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2161 - soft_acc: 0.8922 - val_loss: 0.5539 - val_soft_acc: 0.5329\n",
      "Epoch 477/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1792 - soft_acc: 0.9194 - val_loss: 0.5802 - val_soft_acc: 0.5000\n",
      "Epoch 478/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2333 - soft_acc: 0.8978 - val_loss: 0.5672 - val_soft_acc: 0.5386\n",
      "Epoch 479/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1974 - soft_acc: 0.9094 - val_loss: 0.5669 - val_soft_acc: 0.4486\n",
      "Epoch 480/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1941 - soft_acc: 0.8889 - val_loss: 0.5551 - val_soft_acc: 0.5557\n",
      "Epoch 481/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2013 - soft_acc: 0.9233 - val_loss: 0.5586 - val_soft_acc: 0.4764\n",
      "Epoch 482/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1884 - soft_acc: 0.9350 - val_loss: 0.5406 - val_soft_acc: 0.5479\n",
      "Epoch 483/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2123 - soft_acc: 0.8756 - val_loss: 0.5817 - val_soft_acc: 0.4900\n",
      "Epoch 484/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1990 - soft_acc: 0.9161 - val_loss: 0.5737 - val_soft_acc: 0.4950\n",
      "Epoch 485/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2042 - soft_acc: 0.9161 - val_loss: 0.5157 - val_soft_acc: 0.5271\n",
      "Epoch 486/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2376 - soft_acc: 0.8900 - val_loss: 0.5075 - val_soft_acc: 0.5343\n",
      "Epoch 487/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2335 - soft_acc: 0.8739 - val_loss: 0.5408 - val_soft_acc: 0.4714\n",
      "Epoch 488/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2223 - soft_acc: 0.9028 - val_loss: 0.5204 - val_soft_acc: 0.5021\n",
      "Epoch 489/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2076 - soft_acc: 0.9217 - val_loss: 0.5079 - val_soft_acc: 0.5421\n",
      "Epoch 490/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2246 - soft_acc: 0.8956 - val_loss: 0.5354 - val_soft_acc: 0.5021\n",
      "Epoch 491/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2047 - soft_acc: 0.8883 - val_loss: 0.5369 - val_soft_acc: 0.5250\n",
      "Epoch 492/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1842 - soft_acc: 0.9194 - val_loss: 0.5009 - val_soft_acc: 0.5607\n",
      "Epoch 493/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2026 - soft_acc: 0.9128 - val_loss: 0.5073 - val_soft_acc: 0.6014\n",
      "Epoch 494/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1963 - soft_acc: 0.9200 - val_loss: 0.5296 - val_soft_acc: 0.5100\n",
      "Epoch 495/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2018 - soft_acc: 0.9267 - val_loss: 0.5233 - val_soft_acc: 0.5864\n",
      "Epoch 496/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2497 - soft_acc: 0.8678 - val_loss: 0.5111 - val_soft_acc: 0.5964\n",
      "Epoch 497/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2779 - soft_acc: 0.8667 - val_loss: 0.5310 - val_soft_acc: 0.5221\n",
      "Epoch 498/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2106 - soft_acc: 0.9061 - val_loss: 0.5038 - val_soft_acc: 0.6371\n",
      "Epoch 499/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2223 - soft_acc: 0.9167 - val_loss: 0.5214 - val_soft_acc: 0.5736\n",
      "Epoch 500/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2327 - soft_acc: 0.8933 - val_loss: 0.5684 - val_soft_acc: 0.5021\n",
      "Epoch 501/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1985 - soft_acc: 0.9211 - val_loss: 0.4822 - val_soft_acc: 0.5450\n",
      "Epoch 502/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2215 - soft_acc: 0.8756 - val_loss: 0.5239 - val_soft_acc: 0.5914\n",
      "Epoch 503/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1978 - soft_acc: 0.9161 - val_loss: 0.5435 - val_soft_acc: 0.5943\n",
      "Epoch 504/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1770 - soft_acc: 0.9417 - val_loss: 0.5094 - val_soft_acc: 0.5729\n",
      "Epoch 505/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1828 - soft_acc: 0.9317 - val_loss: 0.5296 - val_soft_acc: 0.5943\n",
      "Epoch 506/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1705 - soft_acc: 0.9311 - val_loss: 0.5423 - val_soft_acc: 0.5279\n",
      "Epoch 507/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1969 - soft_acc: 0.9078 - val_loss: 0.5209 - val_soft_acc: 0.5379\n",
      "Epoch 508/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1805 - soft_acc: 0.9211 - val_loss: 0.5223 - val_soft_acc: 0.5764\n",
      "Epoch 509/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2045 - soft_acc: 0.9044 - val_loss: 0.5373 - val_soft_acc: 0.5279\n",
      "Epoch 510/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1895 - soft_acc: 0.9039 - val_loss: 0.5157 - val_soft_acc: 0.6243\n",
      "Epoch 511/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1920 - soft_acc: 0.9250 - val_loss: 0.5536 - val_soft_acc: 0.5307\n",
      "Epoch 512/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1818 - soft_acc: 0.9367 - val_loss: 0.5076 - val_soft_acc: 0.5600\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1705 - soft_acc: 0.9156 - val_loss: 0.4988 - val_soft_acc: 0.6164\n",
      "Epoch 514/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1558 - soft_acc: 0.9361 - val_loss: 0.5210 - val_soft_acc: 0.6243\n",
      "Epoch 515/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1850 - soft_acc: 0.9483 - val_loss: 0.5019 - val_soft_acc: 0.5657\n",
      "Epoch 516/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1680 - soft_acc: 0.9344 - val_loss: 0.5234 - val_soft_acc: 0.5786\n",
      "Epoch 517/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2129 - soft_acc: 0.9083 - val_loss: 0.5674 - val_soft_acc: 0.5000\n",
      "Epoch 518/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2262 - soft_acc: 0.9011 - val_loss: 0.5215 - val_soft_acc: 0.4764\n",
      "Epoch 519/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1877 - soft_acc: 0.9072 - val_loss: 0.5315 - val_soft_acc: 0.5171\n",
      "Epoch 520/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1920 - soft_acc: 0.9283 - val_loss: 0.5466 - val_soft_acc: 0.5171\n",
      "Epoch 521/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1734 - soft_acc: 0.9383 - val_loss: 0.4949 - val_soft_acc: 0.6471\n",
      "Epoch 522/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1700 - soft_acc: 0.9311 - val_loss: 0.5387 - val_soft_acc: 0.5614\n",
      "Epoch 523/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1924 - soft_acc: 0.9194 - val_loss: 0.5833 - val_soft_acc: 0.5179\n",
      "Epoch 524/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1655 - soft_acc: 0.9417 - val_loss: 0.5635 - val_soft_acc: 0.5100\n",
      "Epoch 525/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1699 - soft_acc: 0.9400 - val_loss: 0.5729 - val_soft_acc: 0.5179\n",
      "Epoch 526/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2547 - soft_acc: 0.8783 - val_loss: 0.5482 - val_soft_acc: 0.4736\n",
      "Epoch 527/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2292 - soft_acc: 0.8878 - val_loss: 0.5735 - val_soft_acc: 0.5150\n",
      "Epoch 528/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2258 - soft_acc: 0.9167 - val_loss: 0.5160 - val_soft_acc: 0.5864\n",
      "Epoch 529/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2254 - soft_acc: 0.8944 - val_loss: 0.5704 - val_soft_acc: 0.5021\n",
      "Epoch 530/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2024 - soft_acc: 0.9111 - val_loss: 0.5333 - val_soft_acc: 0.5350\n",
      "Epoch 531/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1699 - soft_acc: 0.9328 - val_loss: 0.5101 - val_soft_acc: 0.5450\n",
      "Epoch 532/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1725 - soft_acc: 0.9467 - val_loss: 0.5271 - val_soft_acc: 0.5071\n",
      "Epoch 533/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1778 - soft_acc: 0.9333 - val_loss: 0.5087 - val_soft_acc: 0.5321\n",
      "Epoch 534/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1807 - soft_acc: 0.9072 - val_loss: 0.5138 - val_soft_acc: 0.5964\n",
      "Epoch 535/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1999 - soft_acc: 0.9039 - val_loss: 0.5136 - val_soft_acc: 0.6193\n",
      "Epoch 536/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1743 - soft_acc: 0.9500 - val_loss: 0.5397 - val_soft_acc: 0.5350\n",
      "Epoch 537/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1757 - soft_acc: 0.9350 - val_loss: 0.5104 - val_soft_acc: 0.5407\n",
      "Epoch 538/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1678 - soft_acc: 0.9261 - val_loss: 0.4967 - val_soft_acc: 0.6321\n",
      "Epoch 539/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1720 - soft_acc: 0.9450 - val_loss: 0.5188 - val_soft_acc: 0.5507\n",
      "Epoch 540/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1761 - soft_acc: 0.9344 - val_loss: 0.5552 - val_soft_acc: 0.5257\n",
      "Epoch 541/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1656 - soft_acc: 0.9400 - val_loss: 0.5369 - val_soft_acc: 0.5964\n",
      "Epoch 542/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1701 - soft_acc: 0.9294 - val_loss: 0.5192 - val_soft_acc: 0.5350\n",
      "Epoch 543/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1576 - soft_acc: 0.9483 - val_loss: 0.4812 - val_soft_acc: 0.5786\n",
      "Epoch 544/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1793 - soft_acc: 0.9122 - val_loss: 0.4943 - val_soft_acc: 0.5600\n",
      "Epoch 545/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2288 - soft_acc: 0.8511 - val_loss: 0.4953 - val_soft_acc: 0.6093\n",
      "Epoch 546/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1643 - soft_acc: 0.9567 - val_loss: 0.5450 - val_soft_acc: 0.5407\n",
      "Epoch 547/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1691 - soft_acc: 0.9383 - val_loss: 0.5366 - val_soft_acc: 0.5964\n",
      "Epoch 548/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2207 - soft_acc: 0.8739 - val_loss: 0.5231 - val_soft_acc: 0.4686\n",
      "Epoch 549/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1975 - soft_acc: 0.9183 - val_loss: 0.5147 - val_soft_acc: 0.6071\n",
      "Epoch 550/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2205 - soft_acc: 0.8783 - val_loss: 0.5177 - val_soft_acc: 0.5557\n",
      "Epoch 551/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2166 - soft_acc: 0.9150 - val_loss: 0.4917 - val_soft_acc: 0.6579\n",
      "Epoch 552/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1913 - soft_acc: 0.9367 - val_loss: 0.5072 - val_soft_acc: 0.6136\n",
      "Epoch 553/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2493 - soft_acc: 0.8717 - val_loss: 0.5103 - val_soft_acc: 0.5964\n",
      "Epoch 554/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1979 - soft_acc: 0.9061 - val_loss: 0.5761 - val_soft_acc: 0.5464\n",
      "Epoch 555/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1877 - soft_acc: 0.9211 - val_loss: 0.5787 - val_soft_acc: 0.5279\n",
      "Epoch 556/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2178 - soft_acc: 0.9200 - val_loss: 0.5786 - val_soft_acc: 0.5307\n",
      "Epoch 557/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2673 - soft_acc: 0.8611 - val_loss: 0.5157 - val_soft_acc: 0.5707\n",
      "Epoch 558/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2383 - soft_acc: 0.8844 - val_loss: 0.5252 - val_soft_acc: 0.5379\n",
      "Epoch 559/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2118 - soft_acc: 0.8961 - val_loss: 0.5311 - val_soft_acc: 0.5450\n",
      "Epoch 560/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1854 - soft_acc: 0.9194 - val_loss: 0.5045 - val_soft_acc: 0.5143\n",
      "Epoch 561/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1557 - soft_acc: 0.9411 - val_loss: 0.5311 - val_soft_acc: 0.5171\n",
      "Epoch 562/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1912 - soft_acc: 0.9267 - val_loss: 0.5404 - val_soft_acc: 0.4914\n",
      "Epoch 563/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1620 - soft_acc: 0.9500 - val_loss: 0.5210 - val_soft_acc: 0.5814\n",
      "Epoch 564/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1836 - soft_acc: 0.9333 - val_loss: 0.5231 - val_soft_acc: 0.5757\n",
      "Epoch 565/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1783 - soft_acc: 0.9333 - val_loss: 0.5182 - val_soft_acc: 0.5843\n",
      "Epoch 566/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1809 - soft_acc: 0.8672 - val_loss: 0.4859 - val_soft_acc: 0.5371\n",
      "Epoch 567/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1648 - soft_acc: 0.9467 - val_loss: 0.5180 - val_soft_acc: 0.5479\n",
      "Epoch 568/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1690 - soft_acc: 0.9361 - val_loss: 0.5093 - val_soft_acc: 0.5679\n",
      "Epoch 569/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1555 - soft_acc: 0.9428 - val_loss: 0.5290 - val_soft_acc: 0.5686\n",
      "Epoch 570/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1498 - soft_acc: 0.9361 - val_loss: 0.5246 - val_soft_acc: 0.5457\n",
      "Epoch 571/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1365 - soft_acc: 0.9528 - val_loss: 0.5150 - val_soft_acc: 0.5736\n",
      "Epoch 572/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2112 - soft_acc: 0.9178 - val_loss: 0.5175 - val_soft_acc: 0.5379\n",
      "Epoch 573/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2339 - soft_acc: 0.9000 - val_loss: 0.5295 - val_soft_acc: 0.5657\n",
      "Epoch 574/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2081 - soft_acc: 0.9094 - val_loss: 0.6128 - val_soft_acc: 0.4364\n",
      "Epoch 575/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2418 - soft_acc: 0.8878 - val_loss: 0.5078 - val_soft_acc: 0.5271\n",
      "Epoch 576/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1708 - soft_acc: 0.9450 - val_loss: 0.5325 - val_soft_acc: 0.5121\n",
      "Epoch 577/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1725 - soft_acc: 0.9222 - val_loss: 0.5533 - val_soft_acc: 0.5457\n",
      "Epoch 578/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2429 - soft_acc: 0.8811 - val_loss: 0.5345 - val_soft_acc: 0.5279\n",
      "Epoch 579/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1893 - soft_acc: 0.9194 - val_loss: 0.5088 - val_soft_acc: 0.6521\n",
      "Epoch 580/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1849 - soft_acc: 0.9417 - val_loss: 0.5523 - val_soft_acc: 0.4714\n",
      "Epoch 581/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1682 - soft_acc: 0.9583 - val_loss: 0.5213 - val_soft_acc: 0.5657\n",
      "Epoch 582/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1579 - soft_acc: 0.9600 - val_loss: 0.5251 - val_soft_acc: 0.5764\n",
      "Epoch 583/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1696 - soft_acc: 0.9378 - val_loss: 0.5348 - val_soft_acc: 0.5200\n",
      "Epoch 584/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1635 - soft_acc: 0.9344 - val_loss: 0.4796 - val_soft_acc: 0.6114\n",
      "Epoch 585/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1632 - soft_acc: 0.9500 - val_loss: 0.5234 - val_soft_acc: 0.5429\n",
      "Epoch 586/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1509 - soft_acc: 0.9428 - val_loss: 0.5181 - val_soft_acc: 0.5043\n",
      "Epoch 587/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1560 - soft_acc: 0.9617 - val_loss: 0.5240 - val_soft_acc: 0.5200\n",
      "Epoch 588/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1570 - soft_acc: 0.9461 - val_loss: 0.5436 - val_soft_acc: 0.6171\n",
      "Epoch 589/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1990 - soft_acc: 0.9217 - val_loss: 0.5423 - val_soft_acc: 0.5586\n",
      "Epoch 590/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2174 - soft_acc: 0.9217 - val_loss: 0.5268 - val_soft_acc: 0.5450\n",
      "Epoch 591/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2023 - soft_acc: 0.9267 - val_loss: 0.5404 - val_soft_acc: 0.5307\n",
      "Epoch 592/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1925 - soft_acc: 0.9250 - val_loss: 0.5254 - val_soft_acc: 0.5986\n",
      "Epoch 593/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2223 - soft_acc: 0.9133 - val_loss: 0.5382 - val_soft_acc: 0.5486\n",
      "Epoch 594/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1663 - soft_acc: 0.9478 - val_loss: 0.5481 - val_soft_acc: 0.5686\n",
      "Epoch 595/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1899 - soft_acc: 0.9467 - val_loss: 0.5157 - val_soft_acc: 0.5350\n",
      "Epoch 596/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2089 - soft_acc: 0.9167 - val_loss: 0.5009 - val_soft_acc: 0.4886\n",
      "Epoch 597/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1540 - soft_acc: 0.9444 - val_loss: 0.5034 - val_soft_acc: 0.5350\n",
      "Epoch 598/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1907 - soft_acc: 0.8983 - val_loss: 0.4974 - val_soft_acc: 0.5657\n",
      "Epoch 599/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1743 - soft_acc: 0.9428 - val_loss: 0.5823 - val_soft_acc: 0.4771\n",
      "Epoch 600/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1800 - soft_acc: 0.9500 - val_loss: 0.5753 - val_soft_acc: 0.4257\n",
      "Epoch 601/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.1685 - soft_acc: 0.9222 - val_loss: 0.5556 - val_soft_acc: 0.4943\n",
      "Epoch 602/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2318 - soft_acc: 0.8761 - val_loss: 0.5373 - val_soft_acc: 0.5764\n",
      "Epoch 603/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1968 - soft_acc: 0.9350 - val_loss: 0.5686 - val_soft_acc: 0.5121\n",
      "Epoch 604/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1966 - soft_acc: 0.9311 - val_loss: 0.5488 - val_soft_acc: 0.5429\n",
      "Epoch 605/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2393 - soft_acc: 0.8600 - val_loss: 0.5511 - val_soft_acc: 0.5100\n",
      "Epoch 606/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1582 - soft_acc: 0.9500 - val_loss: 0.5730 - val_soft_acc: 0.4564\n",
      "Epoch 607/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1601 - soft_acc: 0.9617 - val_loss: 0.5781 - val_soft_acc: 0.4536\n",
      "Epoch 608/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1591 - soft_acc: 0.9500 - val_loss: 0.5577 - val_soft_acc: 0.4536\n",
      "Epoch 609/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1493 - soft_acc: 0.9544 - val_loss: 0.5446 - val_soft_acc: 0.5179\n",
      "Epoch 610/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1900 - soft_acc: 0.9261 - val_loss: 0.5635 - val_soft_acc: 0.5000\n",
      "Epoch 611/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1662 - soft_acc: 0.9467 - val_loss: 0.5271 - val_soft_acc: 0.5736\n",
      "Epoch 612/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1575 - soft_acc: 0.9378 - val_loss: 0.5632 - val_soft_acc: 0.5021\n",
      "Epoch 613/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2014 - soft_acc: 0.8800 - val_loss: 0.5642 - val_soft_acc: 0.5100\n",
      "Epoch 614/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1713 - soft_acc: 0.9533 - val_loss: 0.5656 - val_soft_acc: 0.4921\n",
      "Epoch 615/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1407 - soft_acc: 0.9667 - val_loss: 0.5380 - val_soft_acc: 0.5043\n",
      "Epoch 616/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1514 - soft_acc: 0.9633 - val_loss: 0.5053 - val_soft_acc: 0.5550\n",
      "Epoch 617/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1440 - soft_acc: 0.9617 - val_loss: 0.5430 - val_soft_acc: 0.5071\n",
      "Epoch 618/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1412 - soft_acc: 0.9667 - val_loss: 0.5703 - val_soft_acc: 0.4843\n",
      "Epoch 619/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1535 - soft_acc: 0.9478 - val_loss: 0.5676 - val_soft_acc: 0.5664\n",
      "Epoch 620/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1464 - soft_acc: 0.9494 - val_loss: 0.5609 - val_soft_acc: 0.4614\n",
      "Epoch 621/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1470 - soft_acc: 0.9550 - val_loss: 0.5634 - val_soft_acc: 0.4843\n",
      "Epoch 622/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1820 - soft_acc: 0.9417 - val_loss: 0.5687 - val_soft_acc: 0.4950\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1909 - soft_acc: 0.9283 - val_loss: 0.5611 - val_soft_acc: 0.5221\n",
      "Epoch 624/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1819 - soft_acc: 0.9378 - val_loss: 0.5351 - val_soft_acc: 0.5529\n",
      "Epoch 625/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1861 - soft_acc: 0.9333 - val_loss: 0.5500 - val_soft_acc: 0.4793\n",
      "Epoch 626/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.2029 - soft_acc: 0.8922 - val_loss: 0.5642 - val_soft_acc: 0.5357\n",
      "Epoch 627/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1699 - soft_acc: 0.9533 - val_loss: 0.5397 - val_soft_acc: 0.5021\n",
      "Epoch 628/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1662 - soft_acc: 0.9239 - val_loss: 0.5321 - val_soft_acc: 0.5021\n",
      "Epoch 629/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1589 - soft_acc: 0.9483 - val_loss: 0.5107 - val_soft_acc: 0.5607\n",
      "Epoch 630/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1532 - soft_acc: 0.9461 - val_loss: 0.5448 - val_soft_acc: 0.5786\n",
      "Epoch 631/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1334 - soft_acc: 0.9683 - val_loss: 0.5585 - val_soft_acc: 0.5586\n",
      "Epoch 632/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1474 - soft_acc: 0.9550 - val_loss: 0.5740 - val_soft_acc: 0.5514\n",
      "Epoch 633/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1556 - soft_acc: 0.9600 - val_loss: 0.5687 - val_soft_acc: 0.5279\n",
      "Epoch 634/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1378 - soft_acc: 0.9783 - val_loss: 0.5588 - val_soft_acc: 0.6179\n",
      "Epoch 635/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1468 - soft_acc: 0.9544 - val_loss: 0.5669 - val_soft_acc: 0.4636\n",
      "Epoch 636/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2107 - soft_acc: 0.9250 - val_loss: 0.5635 - val_soft_acc: 0.5050\n",
      "Epoch 637/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2195 - soft_acc: 0.8806 - val_loss: 0.5737 - val_soft_acc: 0.5357\n",
      "Epoch 638/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2032 - soft_acc: 0.9183 - val_loss: 0.5613 - val_soft_acc: 0.5436\n",
      "Epoch 639/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1918 - soft_acc: 0.9267 - val_loss: 0.5682 - val_soft_acc: 0.5743\n",
      "Epoch 640/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2355 - soft_acc: 0.8500 - val_loss: 0.5556 - val_soft_acc: 0.5614\n",
      "Epoch 641/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2233 - soft_acc: 0.8928 - val_loss: 0.5398 - val_soft_acc: 0.5607\n",
      "Epoch 642/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1718 - soft_acc: 0.9261 - val_loss: 0.5156 - val_soft_acc: 0.5300\n",
      "Epoch 643/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1601 - soft_acc: 0.9444 - val_loss: 0.5527 - val_soft_acc: 0.4971\n",
      "Epoch 644/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1645 - soft_acc: 0.9344 - val_loss: 0.5448 - val_soft_acc: 0.5764\n",
      "Epoch 645/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1615 - soft_acc: 0.9517 - val_loss: 0.5456 - val_soft_acc: 0.5993\n",
      "Epoch 646/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1761 - soft_acc: 0.9433 - val_loss: 0.5491 - val_soft_acc: 0.4943\n",
      "Epoch 647/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2088 - soft_acc: 0.9150 - val_loss: 0.5604 - val_soft_acc: 0.4793\n",
      "Epoch 648/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1734 - soft_acc: 0.9583 - val_loss: 0.5376 - val_soft_acc: 0.5079\n",
      "Epoch 649/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1646 - soft_acc: 0.9361 - val_loss: 0.5340 - val_soft_acc: 0.5586\n",
      "Epoch 650/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1735 - soft_acc: 0.9244 - val_loss: 0.5329 - val_soft_acc: 0.5714\n",
      "Epoch 651/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1687 - soft_acc: 0.9517 - val_loss: 0.5329 - val_soft_acc: 0.5100\n",
      "Epoch 652/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1418 - soft_acc: 0.9633 - val_loss: 0.5422 - val_soft_acc: 0.5250\n",
      "Epoch 653/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1619 - soft_acc: 0.9256 - val_loss: 0.5515 - val_soft_acc: 0.4764\n",
      "Epoch 654/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1725 - soft_acc: 0.9533 - val_loss: 0.5536 - val_soft_acc: 0.5229\n",
      "Epoch 655/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1485 - soft_acc: 0.9600 - val_loss: 0.5339 - val_soft_acc: 0.5043\n",
      "Epoch 656/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1393 - soft_acc: 0.9650 - val_loss: 0.5618 - val_soft_acc: 0.5436\n",
      "Epoch 657/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1575 - soft_acc: 0.9550 - val_loss: 0.5150 - val_soft_acc: 0.5479\n",
      "Epoch 658/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1409 - soft_acc: 0.9617 - val_loss: 0.5391 - val_soft_acc: 0.4893\n",
      "Epoch 659/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1347 - soft_acc: 0.9650 - val_loss: 0.5331 - val_soft_acc: 0.5757\n",
      "Epoch 660/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1375 - soft_acc: 0.9489 - val_loss: 0.5416 - val_soft_acc: 0.5279\n",
      "Epoch 661/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1610 - soft_acc: 0.9167 - val_loss: 0.5358 - val_soft_acc: 0.5457\n",
      "Epoch 662/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1625 - soft_acc: 0.9483 - val_loss: 0.5627 - val_soft_acc: 0.5100\n",
      "Epoch 663/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1476 - soft_acc: 0.9717 - val_loss: 0.5688 - val_soft_acc: 0.5407\n",
      "Epoch 664/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1388 - soft_acc: 0.9667 - val_loss: 0.5427 - val_soft_acc: 0.5379\n",
      "Epoch 665/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1514 - soft_acc: 0.9633 - val_loss: 0.5110 - val_soft_acc: 0.6350\n",
      "Epoch 666/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1575 - soft_acc: 0.9394 - val_loss: 0.5144 - val_soft_acc: 0.5457\n",
      "Epoch 667/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1529 - soft_acc: 0.9533 - val_loss: 0.5211 - val_soft_acc: 0.5957\n",
      "Epoch 668/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1782 - soft_acc: 0.9361 - val_loss: 0.5388 - val_soft_acc: 0.5943\n",
      "Epoch 669/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1414 - soft_acc: 0.9683 - val_loss: 0.5672 - val_soft_acc: 0.5200\n",
      "Epoch 670/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1740 - soft_acc: 0.9483 - val_loss: 0.5722 - val_soft_acc: 0.5586\n",
      "Epoch 671/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1697 - soft_acc: 0.9428 - val_loss: 0.5937 - val_soft_acc: 0.5436\n",
      "Epoch 672/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1410 - soft_acc: 0.9717 - val_loss: 0.5826 - val_soft_acc: 0.5129\n",
      "Epoch 673/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1375 - soft_acc: 0.9700 - val_loss: 0.5529 - val_soft_acc: 0.5250\n",
      "Epoch 674/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1613 - soft_acc: 0.9478 - val_loss: 0.5865 - val_soft_acc: 0.5179\n",
      "Epoch 675/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1530 - soft_acc: 0.9478 - val_loss: 0.5638 - val_soft_acc: 0.5229\n",
      "Epoch 676/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1446 - soft_acc: 0.9633 - val_loss: 0.5647 - val_soft_acc: 0.5921\n",
      "Epoch 677/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1675 - soft_acc: 0.9550 - val_loss: 0.5747 - val_soft_acc: 0.4436\n",
      "Epoch 678/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1285 - soft_acc: 0.9628 - val_loss: 0.5309 - val_soft_acc: 0.5171\n",
      "Epoch 679/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1341 - soft_acc: 0.9750 - val_loss: 0.5336 - val_soft_acc: 0.5100\n",
      "Epoch 680/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1290 - soft_acc: 0.9628 - val_loss: 0.5059 - val_soft_acc: 0.6221\n",
      "Epoch 681/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1367 - soft_acc: 0.9506 - val_loss: 0.5304 - val_soft_acc: 0.5664\n",
      "Epoch 682/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1733 - soft_acc: 0.9483 - val_loss: 0.5345 - val_soft_acc: 0.5564\n",
      "Epoch 683/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1554 - soft_acc: 0.9683 - val_loss: 0.5322 - val_soft_acc: 0.5479\n",
      "Epoch 684/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1324 - soft_acc: 0.9628 - val_loss: 0.5443 - val_soft_acc: 0.5664\n",
      "Epoch 685/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1232 - soft_acc: 0.9833 - val_loss: 0.5601 - val_soft_acc: 0.4743\n",
      "Epoch 686/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1319 - soft_acc: 0.9733 - val_loss: 0.5298 - val_soft_acc: 0.5557\n",
      "Epoch 687/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1194 - soft_acc: 0.9783 - val_loss: 0.5014 - val_soft_acc: 0.5629\n",
      "Epoch 688/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1142 - soft_acc: 0.9800 - val_loss: 0.5376 - val_soft_acc: 0.5200\n",
      "Epoch 689/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1279 - soft_acc: 0.9717 - val_loss: 0.5387 - val_soft_acc: 0.5686\n",
      "Epoch 690/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1305 - soft_acc: 0.9800 - val_loss: 0.5376 - val_soft_acc: 0.5993\n",
      "Epoch 691/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1364 - soft_acc: 0.9667 - val_loss: 0.5286 - val_soft_acc: 0.5557\n",
      "Epoch 692/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1591 - soft_acc: 0.9478 - val_loss: 0.5096 - val_soft_acc: 0.5686\n",
      "Epoch 693/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1521 - soft_acc: 0.9650 - val_loss: 0.5419 - val_soft_acc: 0.5636\n",
      "Epoch 694/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1420 - soft_acc: 0.9700 - val_loss: 0.5561 - val_soft_acc: 0.4950\n",
      "Epoch 695/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1503 - soft_acc: 0.9667 - val_loss: 0.5675 - val_soft_acc: 0.4714\n",
      "Epoch 696/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1766 - soft_acc: 0.9411 - val_loss: 0.5601 - val_soft_acc: 0.5000\n",
      "Epoch 697/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2305 - soft_acc: 0.8983 - val_loss: 0.5317 - val_soft_acc: 0.4971\n",
      "Epoch 698/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1955 - soft_acc: 0.9161 - val_loss: 0.5156 - val_soft_acc: 0.5093\n",
      "Epoch 699/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1398 - soft_acc: 0.9733 - val_loss: 0.5348 - val_soft_acc: 0.5050\n",
      "Epoch 700/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1927 - soft_acc: 0.9417 - val_loss: 0.4936 - val_soft_acc: 0.5550\n",
      "Epoch 701/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1549 - soft_acc: 0.9617 - val_loss: 0.5266 - val_soft_acc: 0.5221\n",
      "Epoch 702/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2159 - soft_acc: 0.9283 - val_loss: 0.4718 - val_soft_acc: 0.5164\n",
      "Epoch 703/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1727 - soft_acc: 0.9517 - val_loss: 0.4903 - val_soft_acc: 0.5629\n",
      "Epoch 704/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1559 - soft_acc: 0.9667 - val_loss: 0.5045 - val_soft_acc: 0.5757\n",
      "Epoch 705/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1651 - soft_acc: 0.9417 - val_loss: 0.5158 - val_soft_acc: 0.5457\n",
      "Epoch 706/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1583 - soft_acc: 0.9583 - val_loss: 0.5329 - val_soft_acc: 0.5686\n",
      "Epoch 707/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1204 - soft_acc: 0.9817 - val_loss: 0.5305 - val_soft_acc: 0.5557\n",
      "Epoch 708/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1259 - soft_acc: 0.9644 - val_loss: 0.5402 - val_soft_acc: 0.5557\n",
      "Epoch 709/1000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.1193 - soft_acc: 0.9800 - val_loss: 0.5234 - val_soft_acc: 0.5764\n",
      "Epoch 710/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1163 - soft_acc: 0.9661 - val_loss: 0.5469 - val_soft_acc: 0.5714\n",
      "Epoch 711/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1127 - soft_acc: 0.9800 - val_loss: 0.5445 - val_soft_acc: 0.5021\n",
      "Epoch 712/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1098 - soft_acc: 0.9711 - val_loss: 0.5330 - val_soft_acc: 0.5586\n",
      "Epoch 713/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1144 - soft_acc: 0.9817 - val_loss: 0.4922 - val_soft_acc: 0.5707\n",
      "Epoch 714/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1059 - soft_acc: 0.9711 - val_loss: 0.5254 - val_soft_acc: 0.5636\n",
      "Epoch 715/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1271 - soft_acc: 0.9800 - val_loss: 0.5256 - val_soft_acc: 0.5379\n",
      "Epoch 716/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1409 - soft_acc: 0.9422 - val_loss: 0.5068 - val_soft_acc: 0.5786\n",
      "Epoch 717/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1425 - soft_acc: 0.9594 - val_loss: 0.5445 - val_soft_acc: 0.5457\n",
      "Epoch 718/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1414 - soft_acc: 0.9750 - val_loss: 0.5061 - val_soft_acc: 0.5093\n",
      "Epoch 719/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1277 - soft_acc: 0.9817 - val_loss: 0.5233 - val_soft_acc: 0.5457\n",
      "Epoch 720/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1226 - soft_acc: 0.9800 - val_loss: 0.5136 - val_soft_acc: 0.5686\n",
      "Epoch 721/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1194 - soft_acc: 0.9817 - val_loss: 0.5083 - val_soft_acc: 0.5429\n",
      "Epoch 722/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1163 - soft_acc: 0.9817 - val_loss: 0.5183 - val_soft_acc: 0.5536\n",
      "Epoch 723/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1163 - soft_acc: 0.9628 - val_loss: 0.5352 - val_soft_acc: 0.4407\n",
      "Epoch 724/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1136 - soft_acc: 0.9833 - val_loss: 0.5399 - val_soft_acc: 0.5200\n",
      "Epoch 725/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1146 - soft_acc: 0.9817 - val_loss: 0.5469 - val_soft_acc: 0.5129\n",
      "Epoch 726/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1216 - soft_acc: 0.9800 - val_loss: 0.5758 - val_soft_acc: 0.5129\n",
      "Epoch 727/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1277 - soft_acc: 0.9783 - val_loss: 0.5672 - val_soft_acc: 0.4664\n",
      "Epoch 728/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1345 - soft_acc: 0.9644 - val_loss: 0.5485 - val_soft_acc: 0.5793\n",
      "Epoch 729/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1414 - soft_acc: 0.9683 - val_loss: 0.5223 - val_soft_acc: 0.5429\n",
      "Epoch 730/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1240 - soft_acc: 0.9700best occur in epoch 729\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1552 - soft_acc: 0.9633 - val_loss: 0.5060 - val_soft_acc: 0.6557\n",
      "Epoch 731/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1944 - soft_acc: 0.9111 - val_loss: 0.5184 - val_soft_acc: 0.4714\n",
      "Epoch 732/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1730 - soft_acc: 0.9467 - val_loss: 0.5652 - val_soft_acc: 0.4871\n",
      "Epoch 733/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1518 - soft_acc: 0.9444 - val_loss: 0.5433 - val_soft_acc: 0.5279\n",
      "Epoch 734/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1472 - soft_acc: 0.9650 - val_loss: 0.5484 - val_soft_acc: 0.4743\n",
      "Epoch 735/1000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.1455 - soft_acc: 0.9767 - val_loss: 0.5436 - val_soft_acc: 0.5507\n",
      "Epoch 736/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1313 - soft_acc: 0.9611 - val_loss: 0.5376 - val_soft_acc: 0.5893\n",
      "Epoch 737/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1434 - soft_acc: 0.9750 - val_loss: 0.5757 - val_soft_acc: 0.5050\n",
      "Epoch 738/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1310 - soft_acc: 0.9717 - val_loss: 0.4913 - val_soft_acc: 0.6014\n",
      "Epoch 739/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1219 - soft_acc: 0.9800 - val_loss: 0.5099 - val_soft_acc: 0.5707\n",
      "Epoch 740/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1224 - soft_acc: 0.9600best occur in epoch 739\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1385 - soft_acc: 0.9700 - val_loss: 0.4997 - val_soft_acc: 0.6529\n",
      "Epoch 741/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.1284 - soft_acc: 0.9750 - val_loss: 0.5249 - val_soft_acc: 0.5121\n",
      "Epoch 742/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1194 - soft_acc: 0.9717 - val_loss: 0.5238 - val_soft_acc: 0.5536\n",
      "Epoch 743/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1135 - soft_acc: 0.9711 - val_loss: 0.5420 - val_soft_acc: 0.5379\n",
      "Epoch 744/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1232 - soft_acc: 0.9783 - val_loss: 0.5517 - val_soft_acc: 0.5486\n",
      "Epoch 745/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1331 - soft_acc: 0.9750 - val_loss: 0.4991 - val_soft_acc: 0.5329\n",
      "Epoch 746/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1209 - soft_acc: 0.9850 - val_loss: 0.4823 - val_soft_acc: 0.6164\n",
      "Epoch 747/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1219 - soft_acc: 0.9850 - val_loss: 0.5177 - val_soft_acc: 0.5321\n",
      "Epoch 748/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1206 - soft_acc: 0.9678 - val_loss: 0.5647 - val_soft_acc: 0.5279\n",
      "Epoch 749/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1361 - soft_acc: 0.9733 - val_loss: 0.5542 - val_soft_acc: 0.5536\n",
      "Epoch 750/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1386 - soft_acc: 0.9767 - val_loss: 0.5298 - val_soft_acc: 0.5429\n",
      "Epoch 751/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1484 - soft_acc: 0.9561 - val_loss: 0.5566 - val_soft_acc: 0.5436\n",
      "Epoch 752/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1546 - soft_acc: 0.9700 - val_loss: 0.5737 - val_soft_acc: 0.5107\n",
      "Epoch 753/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1632 - soft_acc: 0.9411 - val_loss: 0.5741 - val_soft_acc: 0.4771\n",
      "Epoch 754/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1411 - soft_acc: 0.9733 - val_loss: 0.5474 - val_soft_acc: 0.5357\n",
      "Epoch 755/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1120 - soft_acc: 0.9767 - val_loss: 0.5340 - val_soft_acc: 0.5000\n",
      "Epoch 756/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1259 - soft_acc: 0.9817 - val_loss: 0.5665 - val_soft_acc: 0.4486\n",
      "Epoch 757/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1459 - soft_acc: 0.9700 - val_loss: 0.5420 - val_soft_acc: 0.5229\n",
      "Epoch 758/1000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1222 - soft_acc: 0.9661 - val_loss: 0.5388 - val_soft_acc: 0.5514\n",
      "Epoch 759/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1291 - soft_acc: 0.9817 - val_loss: 0.5489 - val_soft_acc: 0.6021\n",
      "Epoch 760/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1294 - soft_acc: 0.9578 - val_loss: 0.5327 - val_soft_acc: 0.5050\n",
      "Epoch 761/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1255 - soft_acc: 0.9767 - val_loss: 0.5303 - val_soft_acc: 0.5400\n",
      "Epoch 762/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1140 - soft_acc: 0.9800 - val_loss: 0.5445 - val_soft_acc: 0.4971\n",
      "Epoch 763/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1050 - soft_acc: 0.9644 - val_loss: 0.5213 - val_soft_acc: 0.5557\n",
      "Epoch 764/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1023 - soft_acc: 0.9850 - val_loss: 0.5212 - val_soft_acc: 0.5050\n",
      "Epoch 765/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1235 - soft_acc: 0.9800 - val_loss: 0.5579 - val_soft_acc: 0.5336\n",
      "Epoch 766/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1370 - soft_acc: 0.9767 - val_loss: 0.5381 - val_soft_acc: 0.5536\n",
      "Epoch 767/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1325 - soft_acc: 0.9767 - val_loss: 0.5357 - val_soft_acc: 0.5300\n",
      "Epoch 768/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1417 - soft_acc: 0.9644 - val_loss: 0.5296 - val_soft_acc: 0.5836\n",
      "Epoch 769/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1296 - soft_acc: 0.9733 - val_loss: 0.5172 - val_soft_acc: 0.6093\n",
      "Epoch 770/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1369 - soft_acc: 0.9783 - val_loss: 0.5169 - val_soft_acc: 0.5993\n",
      "Epoch 771/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1836 - soft_acc: 0.9383 - val_loss: 0.5551 - val_soft_acc: 0.5407\n",
      "Epoch 772/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2238 - soft_acc: 0.9000 - val_loss: 0.5489 - val_soft_acc: 0.5357\n",
      "Epoch 773/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1995 - soft_acc: 0.9317 - val_loss: 0.5054 - val_soft_acc: 0.5907\n",
      "Epoch 774/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1980 - soft_acc: 0.8844 - val_loss: 0.5389 - val_soft_acc: 0.5407\n",
      "Epoch 775/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1574 - soft_acc: 0.9478 - val_loss: 0.5698 - val_soft_acc: 0.5336\n",
      "Epoch 776/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2025 - soft_acc: 0.9250 - val_loss: 0.5052 - val_soft_acc: 0.5321\n",
      "Epoch 777/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1951 - soft_acc: 0.9267 - val_loss: 0.5054 - val_soft_acc: 0.6043\n",
      "Epoch 778/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.1369 - soft_acc: 0.9594 - val_loss: 0.5211 - val_soft_acc: 0.5557\n",
      "Epoch 779/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1248 - soft_acc: 0.9800 - val_loss: 0.5018 - val_soft_acc: 0.5400\n",
      "Epoch 780/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1370 - soft_acc: 0.9522 - val_loss: 0.4963 - val_soft_acc: 0.5550\n",
      "Epoch 781/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1460 - soft_acc: 0.9267 - val_loss: 0.5406 - val_soft_acc: 0.5636\n",
      "Epoch 782/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1426 - soft_acc: 0.9506 - val_loss: 0.5542 - val_soft_acc: 0.5843\n",
      "Epoch 783/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1440 - soft_acc: 0.9628 - val_loss: 0.5161 - val_soft_acc: 0.5764\n",
      "Epoch 784/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1236 - soft_acc: 0.9817 - val_loss: 0.5350 - val_soft_acc: 0.5486\n",
      "Epoch 785/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1926 - soft_acc: 0.9500 - val_loss: 0.5698 - val_soft_acc: 0.4364\n",
      "Epoch 786/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1728 - soft_acc: 0.9333 - val_loss: 0.5192 - val_soft_acc: 0.5529\n",
      "Epoch 787/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1359 - soft_acc: 0.9783 - val_loss: 0.5606 - val_soft_acc: 0.5486\n",
      "Epoch 788/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1131 - soft_acc: 0.9678 - val_loss: 0.5579 - val_soft_acc: 0.5279\n",
      "Epoch 789/1000\n",
      "512/512 [==============================] - 0s 52us/sample - loss: 0.1064 - soft_acc: 0.9850 - val_loss: 0.5377 - val_soft_acc: 0.5100\n",
      "Epoch 790/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1284 - soft_acc: 0.9678 - val_loss: 0.4992 - val_soft_acc: 0.5764\n",
      "Epoch 791/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1339 - soft_acc: 0.9733 - val_loss: 0.5227 - val_soft_acc: 0.5429\n",
      "Epoch 792/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1215 - soft_acc: 0.9783 - val_loss: 0.5157 - val_soft_acc: 0.5964\n",
      "Epoch 793/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1372 - soft_acc: 0.9750 - val_loss: 0.5134 - val_soft_acc: 0.5479\n",
      "Epoch 794/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1287 - soft_acc: 0.9767 - val_loss: 0.5324 - val_soft_acc: 0.5636\n",
      "Epoch 795/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1240 - soft_acc: 0.9800 - val_loss: 0.5366 - val_soft_acc: 0.5507\n",
      "Epoch 796/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1209 - soft_acc: 0.9700 - val_loss: 0.5150 - val_soft_acc: 0.5657\n",
      "Epoch 797/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1038 - soft_acc: 0.9883 - val_loss: 0.5215 - val_soft_acc: 0.5836\n",
      "Epoch 798/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1052 - soft_acc: 0.9867 - val_loss: 0.5435 - val_soft_acc: 0.5379\n",
      "Epoch 799/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1392 - soft_acc: 0.9683 - val_loss: 0.5374 - val_soft_acc: 0.5686\n",
      "Epoch 800/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1197 - soft_acc: 0.9783 - val_loss: 0.5176 - val_soft_acc: 0.5171\n",
      "Epoch 801/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1346 - soft_acc: 0.9733 - val_loss: 0.5635 - val_soft_acc: 0.5486\n",
      "Epoch 802/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1312 - soft_acc: 0.9750 - val_loss: 0.5444 - val_soft_acc: 0.5479\n",
      "Epoch 803/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1320 - soft_acc: 0.9767 - val_loss: 0.5021 - val_soft_acc: 0.5529\n",
      "Epoch 804/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1329 - soft_acc: 0.9800 - val_loss: 0.5593 - val_soft_acc: 0.4943\n",
      "Epoch 805/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1283 - soft_acc: 0.9833 - val_loss: 0.5257 - val_soft_acc: 0.5429\n",
      "Epoch 806/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1597 - soft_acc: 0.9583 - val_loss: 0.5347 - val_soft_acc: 0.5400\n",
      "Epoch 807/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1359 - soft_acc: 0.9683 - val_loss: 0.5537 - val_soft_acc: 0.5100\n",
      "Epoch 808/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1175 - soft_acc: 0.9694 - val_loss: 0.5437 - val_soft_acc: 0.5586\n",
      "Epoch 809/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1250 - soft_acc: 0.9767 - val_loss: 0.5708 - val_soft_acc: 0.5207\n",
      "Epoch 810/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1117 - soft_acc: 0.9644 - val_loss: 0.5517 - val_soft_acc: 0.5407\n",
      "Epoch 811/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1243 - soft_acc: 0.9733 - val_loss: 0.4807 - val_soft_acc: 0.5093\n",
      "Epoch 812/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1026 - soft_acc: 0.9900 - val_loss: 0.5092 - val_soft_acc: 0.5736\n",
      "Epoch 813/1000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.1064 - soft_acc: 0.9883 - val_loss: 0.5299 - val_soft_acc: 0.5329\n",
      "Epoch 814/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1162 - soft_acc: 0.9767 - val_loss: 0.5522 - val_soft_acc: 0.4814\n",
      "Epoch 815/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2093 - soft_acc: 0.8906 - val_loss: 0.5227 - val_soft_acc: 0.5993\n",
      "Epoch 816/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1831 - soft_acc: 0.9533 - val_loss: 0.5366 - val_soft_acc: 0.5786\n",
      "Epoch 817/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2023 - soft_acc: 0.9233 - val_loss: 0.5508 - val_soft_acc: 0.5021\n",
      "Epoch 818/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1758 - soft_acc: 0.9483 - val_loss: 0.5859 - val_soft_acc: 0.5386\n",
      "Epoch 819/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1508 - soft_acc: 0.9617 - val_loss: 0.5739 - val_soft_acc: 0.4950\n",
      "Epoch 820/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1238 - soft_acc: 0.9783 - val_loss: 0.5739 - val_soft_acc: 0.4614\n",
      "Epoch 821/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1290 - soft_acc: 0.9817 - val_loss: 0.5871 - val_soft_acc: 0.4514\n",
      "Epoch 822/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1262 - soft_acc: 0.9833 - val_loss: 0.5695 - val_soft_acc: 0.5050\n",
      "Epoch 823/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1230 - soft_acc: 0.9644 - val_loss: 0.5349 - val_soft_acc: 0.5557\n",
      "Epoch 824/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1164 - soft_acc: 0.9883 - val_loss: 0.5211 - val_soft_acc: 0.5143\n",
      "Epoch 825/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1000 - soft_acc: 0.9867 - val_loss: 0.5400 - val_soft_acc: 0.4864\n",
      "Epoch 826/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1008 - soft_acc: 0.9850 - val_loss: 0.5553 - val_soft_acc: 0.5586\n",
      "Epoch 827/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0957 - soft_acc: 0.9833 - val_loss: 0.5532 - val_soft_acc: 0.5200\n",
      "Epoch 828/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1001 - soft_acc: 0.9850 - val_loss: 0.5381 - val_soft_acc: 0.5943\n",
      "Epoch 829/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1098 - soft_acc: 0.9833 - val_loss: 0.5180 - val_soft_acc: 0.5457\n",
      "Epoch 830/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1048 - soft_acc: 0.9850 - val_loss: 0.5124 - val_soft_acc: 0.5171\n",
      "Epoch 831/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1194 - soft_acc: 0.9800 - val_loss: 0.5183 - val_soft_acc: 0.5507\n",
      "Epoch 832/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1366 - soft_acc: 0.9783 - val_loss: 0.5593 - val_soft_acc: 0.5050\n",
      "Epoch 833/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1599 - soft_acc: 0.9361 - val_loss: 0.5751 - val_soft_acc: 0.5179\n",
      "Epoch 834/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1758 - soft_acc: 0.9533 - val_loss: 0.5846 - val_soft_acc: 0.5000\n",
      "Epoch 835/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2237 - soft_acc: 0.8772 - val_loss: 0.5258 - val_soft_acc: 0.5279\n",
      "Epoch 836/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1619 - soft_acc: 0.9617 - val_loss: 0.5379 - val_soft_acc: 0.5121\n",
      "Epoch 837/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1746 - soft_acc: 0.9333 - val_loss: 0.5095 - val_soft_acc: 0.5221\n",
      "Epoch 838/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1438 - soft_acc: 0.9700 - val_loss: 0.5739 - val_soft_acc: 0.4943\n",
      "Epoch 839/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1436 - soft_acc: 0.9556 - val_loss: 0.5819 - val_soft_acc: 0.4514\n",
      "Epoch 840/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1427 - soft_acc: 0.9717 - val_loss: 0.5533 - val_soft_acc: 0.4664\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1398 - soft_acc: 0.9717 - val_loss: 0.5555 - val_soft_acc: 0.4714\n",
      "Epoch 842/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1249 - soft_acc: 0.9750 - val_loss: 0.5245 - val_soft_acc: 0.5171\n",
      "Epoch 843/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1631 - soft_acc: 0.9428 - val_loss: 0.5726 - val_soft_acc: 0.5614\n",
      "Epoch 844/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1343 - soft_acc: 0.9683 - val_loss: 0.5599 - val_soft_acc: 0.4486\n",
      "Epoch 845/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1479 - soft_acc: 0.9733 - val_loss: 0.5589 - val_soft_acc: 0.4486\n",
      "Epoch 846/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1599 - soft_acc: 0.9583 - val_loss: 0.5753 - val_soft_acc: 0.4943\n",
      "Epoch 847/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1492 - soft_acc: 0.9633 - val_loss: 0.5142 - val_soft_acc: 0.6250\n",
      "Epoch 848/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1326 - soft_acc: 0.9750 - val_loss: 0.5397 - val_soft_acc: 0.5171\n",
      "Epoch 849/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1241 - soft_acc: 0.9750 - val_loss: 0.5231 - val_soft_acc: 0.5064\n",
      "Epoch 850/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1179 - soft_acc: 0.9817 - val_loss: 0.5221 - val_soft_acc: 0.5529\n",
      "Epoch 851/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1088 - soft_acc: 0.9833 - val_loss: 0.5562 - val_soft_acc: 0.5357\n",
      "Epoch 852/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1072 - soft_acc: 0.9850 - val_loss: 0.5678 - val_soft_acc: 0.5150\n",
      "Epoch 853/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0987 - soft_acc: 0.9867 - val_loss: 0.5170 - val_soft_acc: 0.5529\n",
      "Epoch 854/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1002 - soft_acc: 0.9867 - val_loss: 0.5236 - val_soft_acc: 0.4486\n",
      "Epoch 855/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1143 - soft_acc: 0.9800 - val_loss: 0.5285 - val_soft_acc: 0.5071\n",
      "Epoch 856/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1051 - soft_acc: 0.9694 - val_loss: 0.5350 - val_soft_acc: 0.5736\n",
      "Epoch 857/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.0926 - soft_acc: 0.9883 - val_loss: 0.5528 - val_soft_acc: 0.5257\n",
      "Epoch 858/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1276 - soft_acc: 0.9750 - val_loss: 0.5538 - val_soft_acc: 0.5357\n",
      "Epoch 859/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1522 - soft_acc: 0.9578 - val_loss: 0.5347 - val_soft_acc: 0.5121\n",
      "Epoch 860/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.1451 - soft_acc: 0.9533 - val_loss: 0.5506 - val_soft_acc: 0.4793\n",
      "Epoch 861/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.1223 - soft_acc: 0.9800 - val_loss: 0.5043 - val_soft_acc: 0.5529\n",
      "Epoch 862/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1305 - soft_acc: 0.9700 - val_loss: 0.5194 - val_soft_acc: 0.5586\n",
      "Epoch 863/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1147 - soft_acc: 0.9767 - val_loss: 0.5414 - val_soft_acc: 0.5486\n",
      "Epoch 864/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1447 - soft_acc: 0.9544 - val_loss: 0.5261 - val_soft_acc: 0.5379\n",
      "Epoch 865/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1325 - soft_acc: 0.9733 - val_loss: 0.5280 - val_soft_acc: 0.5329\n",
      "Epoch 866/1000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.1202 - soft_acc: 0.9750 - val_loss: 0.5027 - val_soft_acc: 0.5864\n",
      "Epoch 867/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1305 - soft_acc: 0.9733 - val_loss: 0.5182 - val_soft_acc: 0.5279\n",
      "Epoch 868/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1213 - soft_acc: 0.9800 - val_loss: 0.5648 - val_soft_acc: 0.4921\n",
      "Epoch 869/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1451 - soft_acc: 0.9478 - val_loss: 0.5759 - val_soft_acc: 0.5357\n",
      "Epoch 870/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1123 - soft_acc: 0.9489 - val_loss: 0.5430 - val_soft_acc: 0.5300\n",
      "Epoch 871/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.1182 - soft_acc: 0.9800 - val_loss: 0.5714 - val_soft_acc: 0.4971\n",
      "Epoch 872/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1066 - soft_acc: 0.9800 - val_loss: 0.5525 - val_soft_acc: 0.5207\n",
      "Epoch 873/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0965 - soft_acc: 0.9744 - val_loss: 0.5192 - val_soft_acc: 0.5736\n",
      "Epoch 874/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1134 - soft_acc: 0.9867 - val_loss: 0.5621 - val_soft_acc: 0.4893\n",
      "Epoch 875/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1040 - soft_acc: 0.9833 - val_loss: 0.5795 - val_soft_acc: 0.5050\n",
      "Epoch 876/1000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.1003 - soft_acc: 0.9900 - val_loss: 0.5579 - val_soft_acc: 0.5050\n",
      "Epoch 877/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0872 - soft_acc: 0.9867 - val_loss: 0.5482 - val_soft_acc: 0.4893\n",
      "Epoch 878/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1078 - soft_acc: 0.9867 - val_loss: 0.5995 - val_soft_acc: 0.4771\n",
      "Epoch 879/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1529 - soft_acc: 0.9700 - val_loss: 0.5471 - val_soft_acc: 0.5200\n",
      "Epoch 880/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1430 - soft_acc: 0.9544 - val_loss: 0.5501 - val_soft_acc: 0.5557\n",
      "Epoch 881/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1660 - soft_acc: 0.9483 - val_loss: 0.5855 - val_soft_acc: 0.4843\n",
      "Epoch 882/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2319 - soft_acc: 0.9250 - val_loss: 0.5376 - val_soft_acc: 0.5636\n",
      "Epoch 883/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1945 - soft_acc: 0.9056 - val_loss: 0.5020 - val_soft_acc: 0.6343\n",
      "Epoch 884/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1629 - soft_acc: 0.9683 - val_loss: 0.5285 - val_soft_acc: 0.5071\n",
      "Epoch 885/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1031 - soft_acc: 0.9883 - val_loss: 0.5294 - val_soft_acc: 0.5250\n",
      "Epoch 886/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1180 - soft_acc: 0.9817 - val_loss: 0.5161 - val_soft_acc: 0.5121\n",
      "Epoch 887/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1528 - soft_acc: 0.9767 - val_loss: 0.5409 - val_soft_acc: 0.5507\n",
      "Epoch 888/1000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.1257 - soft_acc: 0.9733 - val_loss: 0.5411 - val_soft_acc: 0.4921\n",
      "Epoch 889/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1559 - soft_acc: 0.9306 - val_loss: 0.5725 - val_soft_acc: 0.4407\n",
      "Epoch 890/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1343 - soft_acc: 0.9644 - val_loss: 0.5294 - val_soft_acc: 0.5586\n",
      "Epoch 891/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.1270 - soft_acc: 0.9628 - val_loss: 0.5470 - val_soft_acc: 0.5329\n",
      "Epoch 892/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1084 - soft_acc: 0.9833 - val_loss: 0.5390 - val_soft_acc: 0.5714\n",
      "Epoch 893/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.0961 - soft_acc: 0.9744 - val_loss: 0.5473 - val_soft_acc: 0.5121\n",
      "Epoch 894/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1026 - soft_acc: 0.9917 - val_loss: 0.5439 - val_soft_acc: 0.5457\n",
      "Epoch 895/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1188 - soft_acc: 0.9661 - val_loss: 0.5456 - val_soft_acc: 0.4586\n",
      "Epoch 896/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1341 - soft_acc: 0.9628 - val_loss: 0.5440 - val_soft_acc: 0.5400\n",
      "Epoch 897/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1567 - soft_acc: 0.9428 - val_loss: 0.5679 - val_soft_acc: 0.5179\n",
      "Epoch 898/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1144 - soft_acc: 0.9678 - val_loss: 0.5794 - val_soft_acc: 0.4564\n",
      "Epoch 899/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1129 - soft_acc: 0.9833 - val_loss: 0.5382 - val_soft_acc: 0.5150\n",
      "Epoch 900/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0991 - soft_acc: 0.9694 - val_loss: 0.5228 - val_soft_acc: 0.4943\n",
      "Epoch 901/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1356 - soft_acc: 0.9628 - val_loss: 0.5124 - val_soft_acc: 0.6143\n",
      "Epoch 902/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1054 - soft_acc: 0.9728 - val_loss: 0.5053 - val_soft_acc: 0.5657\n",
      "Epoch 903/1000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1087 - soft_acc: 0.9850 - val_loss: 0.5248 - val_soft_acc: 0.5071\n",
      "Epoch 904/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.0850 - soft_acc: 0.9900 - val_loss: 0.5400 - val_soft_acc: 0.5971\n",
      "Epoch 905/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.0859 - soft_acc: 0.9900 - val_loss: 0.5378 - val_soft_acc: 0.5279\n",
      "Epoch 906/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0915 - soft_acc: 0.9867 - val_loss: 0.5467 - val_soft_acc: 0.5714\n",
      "Epoch 907/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0846 - soft_acc: 0.9778 - val_loss: 0.5571 - val_soft_acc: 0.4921\n",
      "Epoch 908/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1486 - soft_acc: 0.9700 - val_loss: 0.5233 - val_soft_acc: 0.5329\n",
      "Epoch 909/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.0928 - soft_acc: 0.9900 - val_loss: 0.5173 - val_soft_acc: 0.5329\n",
      "Epoch 910/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.0812 - soft_acc: 0.9728 - val_loss: 0.5153 - val_soft_acc: 0.5786\n",
      "Epoch 911/1000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.0891 - soft_acc: 0.9850 - val_loss: 0.5203 - val_soft_acc: 0.5429\n",
      "Epoch 912/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0930 - soft_acc: 0.9850 - val_loss: 0.5316 - val_soft_acc: 0.5557\n",
      "Epoch 913/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0917 - soft_acc: 0.9883 - val_loss: 0.5739 - val_soft_acc: 0.5179\n",
      "Epoch 914/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1020 - soft_acc: 0.9694 - val_loss: 0.5247 - val_soft_acc: 0.5171\n",
      "Epoch 915/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.0952 - soft_acc: 0.9761 - val_loss: 0.5080 - val_soft_acc: 0.5507\n",
      "Epoch 916/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0937 - soft_acc: 0.9900 - val_loss: 0.5226 - val_soft_acc: 0.6043\n",
      "Epoch 917/1000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.0866 - soft_acc: 0.9900 - val_loss: 0.5521 - val_soft_acc: 0.4971\n",
      "Epoch 918/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1003 - soft_acc: 0.9867 - val_loss: 0.5908 - val_soft_acc: 0.4464\n",
      "Epoch 919/1000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.0992 - soft_acc: 0.9867 - val_loss: 0.5940 - val_soft_acc: 0.4414\n",
      "Epoch 920/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1013 - soft_acc: 0.9694 - val_loss: 0.5628 - val_soft_acc: 0.5714\n",
      "Epoch 921/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0884 - soft_acc: 0.9883 - val_loss: 0.5404 - val_soft_acc: 0.5379\n",
      "Epoch 922/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0863 - soft_acc: 0.9917 - val_loss: 0.5164 - val_soft_acc: 0.5507\n",
      "Epoch 923/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1288 - soft_acc: 0.9767 - val_loss: 0.5080 - val_soft_acc: 0.5479\n",
      "Epoch 924/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.0826 - soft_acc: 0.9883 - val_loss: 0.5018 - val_soft_acc: 0.5607\n",
      "Epoch 925/1000\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.0928 - soft_acc: 0.9900 - val_loss: 0.5168 - val_soft_acc: 0.5300\n",
      "Epoch 926/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1028 - soft_acc: 0.9850 - val_loss: 0.5482 - val_soft_acc: 0.4664\n",
      "Epoch 927/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1674 - soft_acc: 0.9717 - val_loss: 0.5364 - val_soft_acc: 0.4714\n",
      "Epoch 928/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1623 - soft_acc: 0.9633 - val_loss: 0.5518 - val_soft_acc: 0.4586\n",
      "Epoch 929/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1209 - soft_acc: 0.9800 - val_loss: 0.5770 - val_soft_acc: 0.4664\n",
      "Epoch 930/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1052 - soft_acc: 0.9833 - val_loss: 0.5166 - val_soft_acc: 0.5886\n",
      "Epoch 931/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1043 - soft_acc: 0.9917 - val_loss: 0.4998 - val_soft_acc: 0.5707\n",
      "Epoch 932/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1104 - soft_acc: 0.9850 - val_loss: 0.5232 - val_soft_acc: 0.5793\n",
      "Epoch 933/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1004 - soft_acc: 0.9761 - val_loss: 0.5384 - val_soft_acc: 0.5379\n",
      "Epoch 934/1000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1047 - soft_acc: 0.9867 - val_loss: 0.5516 - val_soft_acc: 0.4486\n",
      "Epoch 935/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1118 - soft_acc: 0.9678 - val_loss: 0.5491 - val_soft_acc: 0.4614\n",
      "Epoch 936/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1180 - soft_acc: 0.9750 - val_loss: 0.5359 - val_soft_acc: 0.5714\n",
      "Epoch 937/1000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.1089 - soft_acc: 0.9833 - val_loss: 0.5517 - val_soft_acc: 0.5100\n",
      "Epoch 938/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1285 - soft_acc: 0.9733 - val_loss: 0.5187 - val_soft_acc: 0.5914\n",
      "Epoch 939/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1357 - soft_acc: 0.9700 - val_loss: 0.5144 - val_soft_acc: 0.5479\n",
      "Epoch 940/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1125 - soft_acc: 0.9867 - val_loss: 0.5237 - val_soft_acc: 0.5329\n",
      "Epoch 941/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1153 - soft_acc: 0.9850 - val_loss: 0.5330 - val_soft_acc: 0.5379\n",
      "Epoch 942/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1443 - soft_acc: 0.9733 - val_loss: 0.5015 - val_soft_acc: 0.6221\n",
      "Epoch 943/1000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.1754 - soft_acc: 0.9428 - val_loss: 0.4994 - val_soft_acc: 0.5221\n",
      "Epoch 944/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1555 - soft_acc: 0.9633 - val_loss: 0.5146 - val_soft_acc: 0.5271\n",
      "Epoch 945/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1491 - soft_acc: 0.9633 - val_loss: 0.5543 - val_soft_acc: 0.5914\n",
      "Epoch 946/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1443 - soft_acc: 0.9700 - val_loss: 0.5606 - val_soft_acc: 0.5536\n",
      "Epoch 947/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1252 - soft_acc: 0.9817 - val_loss: 0.5561 - val_soft_acc: 0.5457\n",
      "Epoch 948/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1094 - soft_acc: 0.9817 - val_loss: 0.5460 - val_soft_acc: 0.5100\n",
      "Epoch 949/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.0998 - soft_acc: 0.9711 - val_loss: 0.5625 - val_soft_acc: 0.5129\n",
      "Epoch 950/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.0981 - soft_acc: 0.9867 - val_loss: 0.5322 - val_soft_acc: 0.5893\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 0.0906 - soft_acc: 0.9817 - val_loss: 0.5134 - val_soft_acc: 0.6371\n",
      "Epoch 952/1000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.0872 - soft_acc: 0.9761 - val_loss: 0.5096 - val_soft_acc: 0.5529\n",
      "Epoch 953/1000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.0833 - soft_acc: 0.9900 - val_loss: 0.5133 - val_soft_acc: 0.5529\n",
      "Epoch 954/1000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.0857 - soft_acc: 0.9778 - val_loss: 0.5206 - val_soft_acc: 0.5221\n",
      "Epoch 955/1000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.0745 - soft_acc: 0.9900 - val_loss: 0.5139 - val_soft_acc: 0.5500\n",
      "Epoch 956/1000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.0740 - soft_acc: 0.9917 - val_loss: 0.5065 - val_soft_acc: 0.6093\n",
      "Epoch 957/1000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.0742 - soft_acc: 0.9900 - val_loss: 0.5298 - val_soft_acc: 0.5686\n",
      "Epoch 958/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.0924 - soft_acc: 0.9917 - val_loss: 0.5086 - val_soft_acc: 0.5557\n",
      "Epoch 959/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0792 - soft_acc: 0.9883 - val_loss: 0.5345 - val_soft_acc: 0.5536\n",
      "Epoch 960/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.0782 - soft_acc: 0.9933 - val_loss: 0.5394 - val_soft_acc: 0.5507\n",
      "Epoch 961/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1143 - soft_acc: 0.9783 - val_loss: 0.5361 - val_soft_acc: 0.5300\n",
      "Epoch 962/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0976 - soft_acc: 0.9867 - val_loss: 0.5467 - val_soft_acc: 0.5636\n",
      "Epoch 963/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1008 - soft_acc: 0.9850 - val_loss: 0.5549 - val_soft_acc: 0.5200\n",
      "Epoch 964/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0869 - soft_acc: 0.9900 - val_loss: 0.4964 - val_soft_acc: 0.5936\n",
      "Epoch 965/1000\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.1066 - soft_acc: 0.9783 - val_loss: 0.5277 - val_soft_acc: 0.5636\n",
      "Epoch 966/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.1003 - soft_acc: 0.9867 - val_loss: 0.5258 - val_soft_acc: 0.5379\n",
      "Epoch 967/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1027 - soft_acc: 0.9850 - val_loss: 0.5326 - val_soft_acc: 0.5429\n",
      "Epoch 968/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.0812 - soft_acc: 0.9917 - val_loss: 0.4965 - val_soft_acc: 0.5886\n",
      "Epoch 969/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.0760 - soft_acc: 0.9794 - val_loss: 0.4932 - val_soft_acc: 0.6243\n",
      "Epoch 970/1000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.0870 - soft_acc: 0.9917 - val_loss: 0.5353 - val_soft_acc: 0.5664\n",
      "Epoch 971/1000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.0770 - soft_acc: 0.9900 - val_loss: 0.5240 - val_soft_acc: 0.5071\n",
      "Epoch 972/1000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.0822 - soft_acc: 0.9883 - val_loss: 0.4975 - val_soft_acc: 0.5657\n",
      "Epoch 973/1000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.0977 - soft_acc: 0.9900 - val_loss: 0.5078 - val_soft_acc: 0.5757\n",
      "Epoch 974/1000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.0935 - soft_acc: 0.9900 - val_loss: 0.5058 - val_soft_acc: 0.5886\n",
      "Epoch 975/1000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.0858 - soft_acc: 0.9917 - val_loss: 0.5065 - val_soft_acc: 0.5836\n",
      "Epoch 976/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0869 - soft_acc: 0.9917 - val_loss: 0.5004 - val_soft_acc: 0.5371\n",
      "Epoch 977/1000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.0860 - soft_acc: 0.9778 - val_loss: 0.5258 - val_soft_acc: 0.5321\n",
      "Epoch 978/1000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.0823 - soft_acc: 0.9794 - val_loss: 0.4960 - val_soft_acc: 0.5421\n",
      "Epoch 979/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1011 - soft_acc: 0.9833 - val_loss: 0.5082 - val_soft_acc: 0.5550\n",
      "Epoch 980/1000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.0834 - soft_acc: 0.9900 - val_loss: 0.5231 - val_soft_acc: 0.5529\n",
      "Epoch 981/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0974 - soft_acc: 0.9883 - val_loss: 0.4978 - val_soft_acc: 0.6114\n",
      "Epoch 982/1000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.1107 - soft_acc: 0.9833 - val_loss: 0.5174 - val_soft_acc: 0.5736\n",
      "Epoch 983/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1021 - soft_acc: 0.9850 - val_loss: 0.5194 - val_soft_acc: 0.5657\n",
      "Epoch 984/1000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.1036 - soft_acc: 0.9900 - val_loss: 0.5346 - val_soft_acc: 0.5400\n",
      "Epoch 985/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1112 - soft_acc: 0.9883 - val_loss: 0.5006 - val_soft_acc: 0.5550\n",
      "Epoch 986/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1210 - soft_acc: 0.9750 - val_loss: 0.5073 - val_soft_acc: 0.5400\n",
      "Epoch 987/1000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.1042 - soft_acc: 0.9817 - val_loss: 0.5131 - val_soft_acc: 0.5764\n",
      "Epoch 988/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0906 - soft_acc: 0.9867 - val_loss: 0.5020 - val_soft_acc: 0.5914\n",
      "Epoch 989/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0845 - soft_acc: 0.9883 - val_loss: 0.5177 - val_soft_acc: 0.5607\n",
      "Epoch 990/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.0763 - soft_acc: 0.9950 - val_loss: 0.5246 - val_soft_acc: 0.5043\n",
      "Epoch 991/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.0768 - soft_acc: 0.9900 - val_loss: 0.5214 - val_soft_acc: 0.6121\n",
      "Epoch 992/1000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.0737 - soft_acc: 0.9900 - val_loss: 0.5639 - val_soft_acc: 0.5436\n",
      "Epoch 993/1000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.0907 - soft_acc: 0.9867 - val_loss: 0.5565 - val_soft_acc: 0.4771\n",
      "Epoch 994/1000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1553 - soft_acc: 0.9389 - val_loss: 0.5665 - val_soft_acc: 0.5436\n",
      "Epoch 995/1000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1381 - soft_acc: 0.9750 - val_loss: 0.5395 - val_soft_acc: 0.5043\n",
      "Epoch 996/1000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1276 - soft_acc: 0.9800 - val_loss: 0.5368 - val_soft_acc: 0.5507\n",
      "Epoch 997/1000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1213 - soft_acc: 0.9711 - val_loss: 0.5630 - val_soft_acc: 0.5050\n",
      "Epoch 998/1000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.1610 - soft_acc: 0.9683 - val_loss: 0.5143 - val_soft_acc: 0.5936\n",
      "Epoch 999/1000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.1250 - soft_acc: 0.9717 - val_loss: 0.5278 - val_soft_acc: 0.5821\n",
      "Epoch 1000/1000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.1088 - soft_acc: 0.9900best occur in epoch 999\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.1149 - soft_acc: 0.9900 - val_loss: 0.5407 - val_soft_acc: 0.6479\n",
      "128/128 [==============================] - 0s 264us/sample - loss: 0.5407 - soft_acc: 0.5703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "    \n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = './saved_models/'\n",
    "fold_var = 1\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return KB.mean(KB.equal(KB.round(y_true),KB.round(y_pred)))\n",
    "    \n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    training_data = X[train_index]\n",
    "    training_label = Y[train_index]\n",
    "    validation_data = X[val_index]\n",
    "    validation_label = Y[val_index]\n",
    "\n",
    "    # CREATE NEW MODEL\n",
    "    model = create_new_model()\n",
    "    # COMPILE NEW MODEL\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[soft_acc])\n",
    "\n",
    "    # CREATE CALLBACK\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+'model_'+str(fold_var)+'.h5', \n",
    "                                                    monitor='val_soft_acc', \n",
    "                                                    verbose=1, \n",
    "                                                    save_best_only=True, \n",
    "                                                    mode='max')\n",
    "    best_acc = 0\n",
    "    def saveModel(epoch,logs):\n",
    "        global best_acc\n",
    "        val_acc = logs['val_soft_acc']\n",
    "        acc = logs['soft_acc']\n",
    "        tmp = (val_acc + acc)/2\n",
    "        if tmp >= best_acc:\n",
    "            best_acc = tmp\n",
    "            model.save_weights(save_dir+'no_lead_model_'+str(fold_var)+'.h5')\n",
    "            print('best occur in epoch',epoch)\n",
    "    callbacks_list = [LambdaCallback(on_epoch_end=saveModel)]\n",
    "    # There can be other callbacks, but just showing one because it involves the model name\n",
    "    # This saves the best model\n",
    "    # FIT THE MODEL\n",
    "    train_history = model.fit(training_data,\n",
    "                              training_label,\n",
    "                              epochs=1000,\n",
    "                              batch_size=100,\n",
    "                              callbacks=callbacks_list,\n",
    "                              validation_data=(validation_data,validation_label))\n",
    "    #PLOT HISTORY\n",
    "    #:\n",
    "    #:\n",
    "    # LOAD BEST MODEL to evaluate the performance of the model\n",
    "    model = create_new_model()\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[soft_acc])\n",
    "    model.load_weights(\"./saved_models/no_lead_model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "    results = model.evaluate(validation_data,validation_label)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "\n",
    "    VALIDATION_ACCURACY.append(results['soft_acc'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "\n",
    "    KB.clear_session()\n",
    "\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.546875, 0.734375, 0.6328125, 0.6484375, 0.5703125]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265625"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(VALIDATION_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153,)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(test_X.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = np.zeros(test_X.shape[0])\n",
    "for i in range(1,6):\n",
    "    model = create_new_model()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[soft_acc])\n",
    "    model.load_weights('./saved_models/model_'+str(i)+'.h5')\n",
    "    tmp = model.predict(test_X)\n",
    "    tmp = np.reshape(tmp,(tmp.shape[0],))\n",
    "    summ = summ + tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.73631964, 2.49472818, 3.93170099, 1.79970911, 3.55367069,\n",
       "       3.06418829, 2.33471632, 4.86184483, 6.72277145, 3.97450237,\n",
       "       2.48029528, 2.38672314, 4.95522089, 4.36203704, 5.1185111 ,\n",
       "       4.28741097, 3.67200813, 1.87076192, 2.35977125, 2.5438942 ,\n",
       "       4.06308093, 5.44544964, 3.87988091, 2.48753858, 1.61020267,\n",
       "       3.59030175, 3.10793815, 5.24760113, 7.09634132, 3.72044268,\n",
       "       4.35947118, 2.86961265, 3.26758666, 4.34690561, 4.66148725,\n",
       "       4.75734882, 3.35362558, 4.71649766, 3.04578819, 2.43603666,\n",
       "       3.60302048, 2.85845852, 3.91990733, 4.29871101, 5.65649242,\n",
       "       2.52693729, 2.61276178, 3.59199967, 4.57206192, 4.959268  ,\n",
       "       4.07904692, 4.10608926, 2.1300348 , 4.0978446 , 6.05771437,\n",
       "       3.42136006, 2.86060157, 5.66359282, 3.43872037, 2.88215861,\n",
       "       2.91032519, 3.54267836, 4.35055084, 5.37072983, 3.49372659,\n",
       "       3.93339367, 2.17477393, 1.80286648, 5.03306065, 3.70685525,\n",
       "       3.37496815, 5.40513592, 3.49084978, 2.16902635, 2.78846793,\n",
       "       3.99088645, 3.3687315 , 5.59477224, 3.66941185, 4.0846262 ,\n",
       "       2.82011142, 2.88498859, 3.12306714, 3.48156004, 4.12128406,\n",
       "       4.64913969, 4.0737494 , 3.16400352, 2.97978325, 2.90785923,\n",
       "       3.31781421, 5.06948671, 3.98313313, 4.89467907, 4.18342252,\n",
       "       2.63410068, 3.66447711, 3.36860256, 3.6267375 , 5.23138924,\n",
       "       4.42827559, 3.37152662, 3.14910502, 3.76965618, 3.29037123,\n",
       "       6.29286861, 4.4453661 , 5.18775883, 2.95509582, 1.92512684,\n",
       "       3.04366832, 3.18092875, 5.12942314, 4.44120779, 5.39619198,\n",
       "       2.898983  , 3.43610964, 3.23324022, 3.34466105, 5.64113894,\n",
       "       3.88294439, 4.97565956, 3.8611517 , 3.79385576, 4.15605807,\n",
       "       3.61493373, 4.38316307, 4.7273838 , 5.70304394, 3.02087154,\n",
       "       2.87939148, 3.21506481, 3.01697807, 5.39928789, 4.51195612,\n",
       "       4.28738799, 3.01668448, 3.953304  , 4.63499775, 4.0680294 ,\n",
       "       4.67279396, 4.78042965, 4.12833085, 1.86905465, 2.64536858,\n",
       "       3.33934641, 4.064358  , 4.76079187, 4.14661179, 5.41560926,\n",
       "       2.41702042, 1.74588416, 2.89484859])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = summ/5\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = transfer_label(Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  label\n",
       "0     2017-04-01      3\n",
       "1     2017-04-02      2\n",
       "2     2017-04-03      4\n",
       "3     2017-04-04      2\n",
       "4     2017-04-05      4\n",
       "..           ...    ...\n",
       "148   2017-08-27      4\n",
       "149   2017-08-28      5\n",
       "150   2017-08-29      2\n",
       "151   2017-08-30      2\n",
       "152   2017-08-31      3\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nolabel = pd.read_csv('./test_nolabel.csv')\n",
    "test_label = pd.DataFrame()\n",
    "test_label['arrival_date'] = test_nolabel['arrival_date']\n",
    "test_label['label'] = test_Y.astype('int64')\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label.to_csv('./test_label_regular_5_dnn_mean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict adr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "X,Y,test,X_booking,test_booking = pre_adr_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56365 samples, validate on 14092 samples\n",
      "Epoch 1/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 2223.8335 - mean_squared_error: 2223.8330 - acc: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 780.09221, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 3s 58us/sample - loss: 2206.4517 - mean_squared_error: 2206.4514 - acc: 0.0000e+00 - val_loss: 780.0922 - val_mean_squared_error: 780.0922 - val_acc: 0.0000e+00\n",
      "Epoch 2/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 1503.7778 - mean_squared_error: 1503.7776 - acc: 0.0000e+00\n",
      "Epoch 00002: val_loss did not improve from 780.09221\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1485.3832 - mean_squared_error: 1485.3829 - acc: 0.0000e+00 - val_loss: 794.6991 - val_mean_squared_error: 794.6993 - val_acc: 1.4192e-04\n",
      "Epoch 3/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 1384.1809 - mean_squared_error: 1384.1808 - acc: 0.0000e+00\n",
      "Epoch 00003: val_loss improved from 780.09221 to 717.23791, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1375.4863 - mean_squared_error: 1375.4863 - acc: 0.0000e+00 - val_loss: 717.2379 - val_mean_squared_error: 717.2377 - val_acc: 0.0000e+00\n",
      "Epoch 4/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1336.0095 - mean_squared_error: 1336.0095 - acc: 0.0000e+00 ETA: 0s - loss: 1398.8886 - mean_squared_error: 1398.8887 - acc: 0.00\n",
      "Epoch 00004: val_loss did not improve from 717.23791\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1332.4615 - mean_squared_error: 1332.4615 - acc: 0.0000e+00 - val_loss: 930.4447 - val_mean_squared_error: 930.4443 - val_acc: 0.0000e+00\n",
      "Epoch 5/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1282.2577 - mean_squared_error: 1282.2572 - acc: 0.0000e+00\n",
      "Epoch 00005: val_loss improved from 717.23791 to 705.02206, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 1279.9924 - mean_squared_error: 1279.9921 - acc: 0.0000e+00 - val_loss: 705.0221 - val_mean_squared_error: 705.0223 - val_acc: 0.0000e+00\n",
      "Epoch 6/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 1263.8822 - mean_squared_error: 1263.8822 - acc: 0.0000e+00\n",
      "Epoch 00006: val_loss improved from 705.02206 to 694.85938, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 1260.5408 - mean_squared_error: 1260.5406 - acc: 0.0000e+00 - val_loss: 694.8594 - val_mean_squared_error: 694.8594 - val_acc: 0.0000e+00\n",
      "Epoch 7/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 1247.3420 - mean_squared_error: 1247.3414 - acc: 1.7953e-05\n",
      "Epoch 00007: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 1241.9034 - mean_squared_error: 1241.9027 - acc: 1.7742e-05 - val_loss: 738.9690 - val_mean_squared_error: 738.9692 - val_acc: 1.4192e-04\n",
      "Epoch 8/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 1237.4220 - mean_squared_error: 1237.4216 - acc: 0.0000e+00\n",
      "Epoch 00008: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1236.7149 - mean_squared_error: 1236.7146 - acc: 0.0000e+00 - val_loss: 804.9474 - val_mean_squared_error: 804.9476 - val_acc: 2.1289e-04\n",
      "Epoch 9/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 1228.1638 - mean_squared_error: 1228.1642 - acc: 3.6563e-05\n",
      "Epoch 00009: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1213.2648 - mean_squared_error: 1213.2651 - acc: 3.5483e-05 - val_loss: 823.3779 - val_mean_squared_error: 823.3780 - val_acc: 1.4192e-04\n",
      "Epoch 10/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 1203.0041 - mean_squared_error: 1203.0039 - acc: 1.8083e-05\n",
      "Epoch 00010: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1193.5984 - mean_squared_error: 1193.5981 - acc: 1.7742e-05 - val_loss: 799.6382 - val_mean_squared_error: 799.6382 - val_acc: 1.4192e-04\n",
      "Epoch 11/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 1185.3520 - mean_squared_error: 1185.3519 - acc: 9.0580e-05\n",
      "Epoch 00011: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1177.1041 - mean_squared_error: 1177.1041 - acc: 8.8708e-05 - val_loss: 868.4670 - val_mean_squared_error: 868.4670 - val_acc: 7.0962e-05\n",
      "Epoch 12/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 1184.2422 - mean_squared_error: 1184.2428 - acc: 7.2072e-05\n",
      "Epoch 00012: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1178.7336 - mean_squared_error: 1178.7341 - acc: 7.0966e-05 - val_loss: 716.8024 - val_mean_squared_error: 716.8022 - val_acc: 7.0962e-05\n",
      "Epoch 13/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1162.2142 - mean_squared_error: 1162.2147 - acc: 3.5651e-05\n",
      "Epoch 00013: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1159.8248 - mean_squared_error: 1159.8253 - acc: 3.5483e-05 - val_loss: 794.1825 - val_mean_squared_error: 794.1824 - val_acc: 7.0962e-05\n",
      "Epoch 14/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 1166.4932 - mean_squared_error: 1166.4929 - acc: 7.2072e-05TA: 0s - loss: 653.5581 - mean_squared_error: 653.5580 - a\n",
      "Epoch 00014: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1158.1586 - mean_squared_error: 1158.1583 - acc: 7.0966e-05 - val_loss: 748.5624 - val_mean_squared_error: 748.5624 - val_acc: 7.0962e-05\n",
      "Epoch 15/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 1157.1034 - mean_squared_error: 1157.1031 - acc: 9.1743e-05TA: 1s - loss: 631.4202 - mean_squ\n",
      "Epoch 00015: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1139.7287 - mean_squared_error: 1139.7286 - acc: 8.8708e-05 - val_loss: 763.2168 - val_mean_squared_error: 763.2168 - val_acc: 1.4192e-04\n",
      "Epoch 16/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 1135.2116 - mean_squared_error: 1135.2120 - acc: 1.7953e-04\n",
      "Epoch 00016: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 1129.4185 - mean_squared_error: 1129.4189 - acc: 1.7742e-04 - val_loss: 773.6514 - val_mean_squared_error: 773.6514 - val_acc: 2.1289e-04\n",
      "Epoch 17/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1127.7868 - mean_squared_error: 1127.7859 - acc: 2.1661e-04\n",
      "Epoch 00017: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1120.0405 - mean_squared_error: 1120.0397 - acc: 2.1290e-04 - val_loss: 828.8169 - val_mean_squared_error: 828.8167 - val_acc: 7.0962e-05\n",
      "Epoch 18/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 1117.8141 - mean_squared_error: 1117.8149 - acc: 2.1544e-04 ETA: 0s - loss: 1430.0163 - mean_squared_error: 1430.01\n",
      "Epoch 00018: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1111.8032 - mean_squared_error: 1111.8041 - acc: 2.1290e-04 - val_loss: 872.2919 - val_mean_squared_error: 872.2921 - val_acc: 2.8385e-04\n",
      "Epoch 19/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 1129.9767 - mean_squared_error: 1129.9763 - acc: 2.5783e-04\n",
      "Epoch 00019: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1110.1196 - mean_squared_error: 1110.1191 - acc: 2.4838e-04 - val_loss: 817.4791 - val_mean_squared_error: 817.4791 - val_acc: 2.1289e-04\n",
      "Epoch 20/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 1107.0510 - mean_squared_error: 1107.0507 - acc: 3.2609e-04\n",
      "Epoch 00020: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1097.3184 - mean_squared_error: 1097.3180 - acc: 3.3709e-04 - val_loss: 860.3342 - val_mean_squared_error: 860.3343 - val_acc: 3.5481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 1093.4997 - mean_squared_error: 1093.4996 - acc: 2.9144e-04\n",
      "Epoch 00021: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1078.7408 - mean_squared_error: 1078.7408 - acc: 2.8386e-04 - val_loss: 829.8098 - val_mean_squared_error: 829.8098 - val_acc: 4.9674e-04\n",
      "Epoch 22/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 1094.1781 - mean_squared_error: 1094.1776 - acc: 3.8113e-04\n",
      "Epoch 00022: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1084.8080 - mean_squared_error: 1084.8076 - acc: 3.9031e-04 - val_loss: 812.0736 - val_mean_squared_error: 812.0736 - val_acc: 1.4192e-04\n",
      "Epoch 23/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 1086.7840 - mean_squared_error: 1086.7839 - acc: 3.8182e-04\n",
      "Epoch 00023: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1076.1068 - mean_squared_error: 1076.1069 - acc: 3.7257e-04 - val_loss: 792.1533 - val_mean_squared_error: 792.1534 - val_acc: 4.2577e-04\n",
      "Epoch 24/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 1078.7605 - mean_squared_error: 1078.7603 - acc: 4.5208e-04\n",
      "Epoch 00024: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1069.4033 - mean_squared_error: 1069.4031 - acc: 4.4354e-04 - val_loss: 862.1190 - val_mean_squared_error: 862.1194 - val_acc: 1.4192e-04\n",
      "Epoch 25/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 1071.2307 - mean_squared_error: 1071.2310 - acc: 4.8301e-04\n",
      "Epoch 00025: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1067.5768 - mean_squared_error: 1067.5770 - acc: 4.7902e-04 - val_loss: 968.7861 - val_mean_squared_error: 968.7858 - val_acc: 7.0962e-05\n",
      "Epoch 26/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 1043.1019 - mean_squared_error: 1043.1017 - acc: 4.0367e-04\n",
      "Epoch 00026: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1028.2855 - mean_squared_error: 1028.2854 - acc: 3.9031e-04 - val_loss: 955.3947 - val_mean_squared_error: 955.3948 - val_acc: 2.1289e-04\n",
      "Epoch 27/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 1076.7311 - mean_squared_error: 1076.7314 - acc: 4.4643e-04\n",
      "Epoch 00027: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1074.0818 - mean_squared_error: 1074.0822 - acc: 4.4354e-04 - val_loss: 857.9652 - val_mean_squared_error: 857.9650 - val_acc: 2.1289e-04\n",
      "Epoch 28/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 952.1652 - mean_squared_error: 952.1652 - acc: 5.3957e-04\n",
      "Epoch 00028: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 947.2812 - mean_squared_error: 947.2812 - acc: 5.4999e-04 - val_loss: 790.4596 - val_mean_squared_error: 790.4596 - val_acc: 3.5481e-04\n",
      "Epoch 29/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 1068.4259 - mean_squared_error: 1068.4258 - acc: 4.2934e-04TA: 0s - loss: 571.7973 - mean_squared_error: 571.7972 - acc: 4.82\n",
      "Epoch 00029: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1065.0856 - mean_squared_error: 1065.0854 - acc: 4.4354e-04 - val_loss: 776.1353 - val_mean_squared_error: 776.1356 - val_acc: 0.0000e+00\n",
      "Epoch 30/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 1008.9235 - mean_squared_error: 1008.9236 - acc: 4.5620e-04\n",
      "Epoch 00030: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 996.8123 - mean_squared_error: 996.8124 - acc: 4.6128e-04 - val_loss: 858.3178 - val_mean_squared_error: 858.3179 - val_acc: 7.0962e-04\n",
      "Epoch 31/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 854.1985 - mean_squared_error: 854.1982 - acc: 5.1376e-04\n",
      "Epoch 00031: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 849.0122 - mean_squared_error: 849.0120 - acc: 4.9676e-04 - val_loss: 828.3238 - val_mean_squared_error: 828.3237 - val_acc: 4.9674e-04\n",
      "Epoch 32/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1081.3031 - mean_squared_error: 1081.3037 - acc: 6.4982e-04\n",
      "Epoch 00032: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1071.0053 - mean_squared_error: 1071.0059 - acc: 6.3869e-04 - val_loss: 822.0632 - val_mean_squared_error: 822.0630 - val_acc: 3.5481e-04\n",
      "Epoch 33/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 876.7048 - mean_squared_error: 876.7048 - acc: 4.9091e-04\n",
      "Epoch 00033: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 871.9806 - mean_squared_error: 871.9807 - acc: 5.1450e-04 - val_loss: 890.6231 - val_mean_squared_error: 890.6230 - val_acc: 5.6770e-04\n",
      "Epoch 34/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1064.4287 - mean_squared_error: 1064.4287 - acc: 5.5258e-04\n",
      "Epoch 00034: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1062.3019 - mean_squared_error: 1062.3019 - acc: 5.4999e-04 - val_loss: 886.2410 - val_mean_squared_error: 886.2411 - val_acc: 4.2577e-04\n",
      "Epoch 35/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 992.6833 - mean_squared_error: 992.6831 - acc: 4.3557e-04  \n",
      "Epoch 00035: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 983.7378 - mean_squared_error: 983.7375 - acc: 4.2580e-04 - val_loss: 1192.2194 - val_mean_squared_error: 1192.2192 - val_acc: 2.8385e-04\n",
      "Epoch 36/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 691.3262 - mean_squared_error: 691.3265 - acc: 5.7554e-04\n",
      "Epoch 00036: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 690.9260 - mean_squared_error: 690.9265 - acc: 5.8547e-04 - val_loss: 22374.2791 - val_mean_squared_error: 22374.2793 - val_acc: 2.8385e-04\n",
      "Epoch 37/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 1102.2030 - mean_squared_error: 1102.2030 - acc: 3.6364e-04\n",
      "Epoch 00037: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1090.6167 - mean_squared_error: 1090.6167 - acc: 3.5483e-04 - val_loss: 772.7304 - val_mean_squared_error: 772.7304 - val_acc: 2.1289e-04\n",
      "Epoch 38/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 1105.1054 - mean_squared_error: 1105.1056 - acc: 4.6296e-04\n",
      "Epoch 00038: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1080.3084 - mean_squared_error: 1080.3085 - acc: 4.9676e-04 - val_loss: 800.2811 - val_mean_squared_error: 800.2812 - val_acc: 2.8385e-04\n",
      "Epoch 39/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 881.1140 - mean_squared_error: 881.1142 - acc: 3.9711e-04\n",
      "Epoch 00039: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 875.6308 - mean_squared_error: 875.6310 - acc: 3.9031e-04 - val_loss: 905.2882 - val_mean_squared_error: 905.2880 - val_acc: 2.1289e-04\n",
      "Epoch 40/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 663.1803 - mean_squared_error: 663.1807 - acc: 4.6847e-04\n",
      "Epoch 00040: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 661.9993 - mean_squared_error: 661.9996 - acc: 4.7902e-04 - val_loss: 789.0790 - val_mean_squared_error: 789.0788 - val_acc: 7.0962e-05\n",
      "Epoch 41/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 1071.3035 - mean_squared_error: 1071.3033 - acc: 3.9927e-04\n",
      "Epoch 00041: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 1060.1252 - mean_squared_error: 1060.1250 - acc: 3.9031e-04 - val_loss: 906.0064 - val_mean_squared_error: 906.0065 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 582.6385 - mean_squared_error: 582.6382 - acc: 4.3478e-04\n",
      "Epoch 00042: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 581.6623 - mean_squared_error: 581.6621 - acc: 4.2580e-04 - val_loss: 2827.8950 - val_mean_squared_error: 2827.8948 - val_acc: 2.8385e-04\n",
      "Epoch 43/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1081.3033 - mean_squared_error: 1081.3035 - acc: 5.5258e-04\n",
      "Epoch 00043: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1078.4606 - mean_squared_error: 1078.4607 - acc: 5.4999e-04 - val_loss: 867.0731 - val_mean_squared_error: 867.0730 - val_acc: 4.2577e-04\n",
      "Epoch 44/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 1082.2746 - mean_squared_error: 1082.2747 - acc: 5.7196e-04\n",
      "Epoch 00044: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 1060.4066 - mean_squared_error: 1060.4067 - acc: 5.8547e-04 - val_loss: 844.0712 - val_mean_squared_error: 844.0713 - val_acc: 8.5155e-04\n",
      "Epoch 45/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 1054.8636 - mean_squared_error: 1054.8635 - acc: 4.3011e-04\n",
      "Epoch 00045: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1050.4768 - mean_squared_error: 1050.4767 - acc: 4.2580e-04 - val_loss: 956.4452 - val_mean_squared_error: 956.4452 - val_acc: 2.1289e-04\n",
      "Epoch 46/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1045.7809 - mean_squared_error: 1045.7805 - acc: 4.3321e-04\n",
      "Epoch 00046: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 1037.6651 - mean_squared_error: 1037.6647 - acc: 4.4354e-04 - val_loss: 950.3464 - val_mean_squared_error: 950.3463 - val_acc: 3.5481e-04\n",
      "Epoch 47/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 1041.3895 - mean_squared_error: 1041.3894 - acc: 5.0725e-04\n",
      "Epoch 00047: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1030.3026 - mean_squared_error: 1030.3025 - acc: 5.1450e-04 - val_loss: 904.7726 - val_mean_squared_error: 904.7725 - val_acc: 1.4192e-04\n",
      "Epoch 48/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 1034.1448 - mean_squared_error: 1034.1447 - acc: 5.2632e-04\n",
      "Epoch 00048: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1021.3039 - mean_squared_error: 1021.3038 - acc: 5.1450e-04 - val_loss: 925.2664 - val_mean_squared_error: 925.2665 - val_acc: 0.0000e+00\n",
      "Epoch 49/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 1017.8188 - mean_squared_error: 1017.8188 - acc: 4.7532e-04\n",
      "Epoch 00049: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1005.1512 - mean_squared_error: 1005.1513 - acc: 4.7902e-04 - val_loss: 836.9532 - val_mean_squared_error: 836.9533 - val_acc: 0.0000e+00\n",
      "Epoch 50/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 628.1341 - mean_squared_error: 628.1341 - acc: 4.5372e-04 ETA: 0s - loss: 539.3764 - mean_squared_error: 539.3764 - acc\n",
      "Epoch 00050: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 633.1866 - mean_squared_error: 633.1865 - acc: 4.4354e-04 - val_loss: 2323.4030 - val_mean_squared_error: 2323.4028 - val_acc: 6.3866e-04\n",
      "Epoch 51/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 957.4072 - mean_squared_error: 957.4074 - acc: 4.3011e-04\n",
      "Epoch 00051: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 953.8075 - mean_squared_error: 953.8078 - acc: 4.2580e-04 - val_loss: 773.5705 - val_mean_squared_error: 773.5703 - val_acc: 2.1289e-04\n",
      "Epoch 52/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 1086.7657 - mean_squared_error: 1086.7654 - acc: 5.3571e-04 ETA: 0s - loss: 1214.6829 - mean_squared_error: 1214.6829 - acc: \n",
      "Epoch 00052: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 1083.4219 - mean_squared_error: 1083.4216 - acc: 5.3225e-04 - val_loss: 822.2752 - val_mean_squared_error: 822.2754 - val_acc: 2.1289e-04\n",
      "Epoch 53/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 1219.1396 - mean_squared_error: 1219.1400 - acc: 4.1367e-04\n",
      "Epoch 00053: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1212.1661 - mean_squared_error: 1212.1667 - acc: 4.0805e-04 - val_loss: 873.7764 - val_mean_squared_error: 873.7763 - val_acc: 5.6770e-04\n",
      "Epoch 54/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 1105.2328 - mean_squared_error: 1105.2328 - acc: 4.0925e-04\n",
      "Epoch 00054: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 1104.0935 - mean_squared_error: 1104.0935 - acc: 4.0805e-04 - val_loss: 862.3893 - val_mean_squared_error: 862.3893 - val_acc: 0.0000e+00\n",
      "Epoch 55/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 771.9901 - mean_squared_error: 771.9901 - acc: 4.7882e-04\n",
      "Epoch 00055: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 765.6439 - mean_squared_error: 765.6439 - acc: 4.9676e-04 - val_loss: 929.5171 - val_mean_squared_error: 929.5173 - val_acc: 2.1289e-04\n",
      "Epoch 56/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 1145.9876 - mean_squared_error: 1145.9874 - acc: 4.9451e-04\n",
      "Epoch 00056: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1136.2481 - mean_squared_error: 1136.2480 - acc: 4.7902e-04 - val_loss: 787.1419 - val_mean_squared_error: 787.1418 - val_acc: 2.1289e-04\n",
      "Epoch 57/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 886.8468 - mean_squared_error: 886.8464 - acc: 3.1423e-04\n",
      "Epoch 00057: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 874.1216 - mean_squared_error: 874.1212 - acc: 3.7257e-04 - val_loss: 986.7674 - val_mean_squared_error: 986.7678 - val_acc: 3.5481e-04\n",
      "Epoch 58/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 600.0349 - mean_squared_error: 600.0348 - acc: 4.4803e-04\n",
      "Epoch 00058: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 599.0361 - mean_squared_error: 599.0360 - acc: 4.4354e-04 - val_loss: 918.1966 - val_mean_squared_error: 918.1965 - val_acc: 4.9674e-04\n",
      "Epoch 59/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 691.8984 - mean_squared_error: 691.8984 - acc: 5.3667e-04\n",
      "Epoch 00059: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 691.7673 - mean_squared_error: 691.7673 - acc: 5.4999e-04 - val_loss: 929.4361 - val_mean_squared_error: 929.4362 - val_acc: 1.4192e-04\n",
      "Epoch 60/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1192.0622 - mean_squared_error: 1192.0624 - acc: 4.6931e-04\n",
      "Epoch 00060: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1181.1265 - mean_squared_error: 1181.1267 - acc: 4.7902e-04 - val_loss: 1056.0514 - val_mean_squared_error: 1056.0513 - val_acc: 3.5481e-04\n",
      "Epoch 61/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 983.6471 - mean_squared_error: 983.6475 - acc: 3.9497e-04  \n",
      "Epoch 00061: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 979.2558 - mean_squared_error: 979.2562 - acc: 3.9031e-04 - val_loss: 1207.2414 - val_mean_squared_error: 1207.2416 - val_acc: 7.0962e-04\n",
      "Epoch 62/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 661.8323 - mean_squared_error: 661.8327 - acc: 6.0823e-04\n",
      "Epoch 00062: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 660.6336 - mean_squared_error: 660.6339 - acc: 6.0321e-04 - val_loss: 943.9265 - val_mean_squared_error: 943.9265 - val_acc: 3.5481e-04\n",
      "Epoch 63/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 1007.5193 - mean_squared_error: 1007.5189 - acc: 3.9497e-04\n",
      "Epoch 00063: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1001.9291 - mean_squared_error: 1001.9288 - acc: 4.0805e-04 - val_loss: 884.8763 - val_mean_squared_error: 884.8765 - val_acc: 5.6770e-04\n",
      "Epoch 64/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 905.9571 - mean_squared_error: 905.9570 - acc: 5.6159e-04\n",
      "Epoch 00064: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 899.2051 - mean_squared_error: 899.2050 - acc: 5.4999e-04 - val_loss: 1388.2136 - val_mean_squared_error: 1388.2136 - val_acc: 7.0962e-04\n",
      "Epoch 65/3000\n",
      "53800/56365 [===========================>..] - ETA: 0s - loss: 850.3038 - mean_squared_error: 850.3030 - acc: 5.3903e-04\n",
      "Epoch 00065: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 837.7116 - mean_squared_error: 837.7111 - acc: 5.4999e-04 - val_loss: 1365.0429 - val_mean_squared_error: 1365.0428 - val_acc: 0.0011\n",
      "Epoch 66/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 639.4122 - mean_squared_error: 639.4118 - acc: 6.0773e-04\n",
      "Epoch 00066: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 635.1306 - mean_squared_error: 635.1302 - acc: 6.2095e-04 - val_loss: 903.5631 - val_mean_squared_error: 903.5629 - val_acc: 2.1289e-04\n",
      "Epoch 67/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 778.4761 - mean_squared_error: 778.4761 - acc: 5.1282e-04\n",
      "Epoch 00067: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 770.0718 - mean_squared_error: 770.0719 - acc: 5.1450e-04 - val_loss: 1190.0614 - val_mean_squared_error: 1190.0614 - val_acc: 9.9347e-04\n",
      "Epoch 68/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 693.0577 - mean_squared_error: 693.0576 - acc: 4.9360e-04\n",
      "Epoch 00068: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 687.0643 - mean_squared_error: 687.0643 - acc: 4.9676e-04 - val_loss: 1025.2080 - val_mean_squared_error: 1025.2080 - val_acc: 6.3866e-04\n",
      "Epoch 69/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 1057.9721 - mean_squared_error: 1057.9722 - acc: 5.4545e-04\n",
      "Epoch 00069: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 1045.7575 - mean_squared_error: 1045.7576 - acc: 5.4999e-04 - val_loss: 869.1486 - val_mean_squared_error: 869.1489 - val_acc: 2.8385e-04\n",
      "Epoch 70/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1033.1940 - mean_squared_error: 1033.1938 - acc: 6.1372e-04\n",
      "Epoch 00070: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 1025.8163 - mean_squared_error: 1025.8160 - acc: 6.2095e-04 - val_loss: 915.3612 - val_mean_squared_error: 915.3613 - val_acc: 0.0011\n",
      "Epoch 71/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 1026.5917 - mean_squared_error: 1026.5918 - acc: 6.4982e-04\n",
      "Epoch 00071: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1017.6536 - mean_squared_error: 1017.6538 - acc: 6.3869e-04 - val_loss: 992.6454 - val_mean_squared_error: 992.6454 - val_acc: 2.1289e-04\n",
      "Epoch 72/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 1011.4525 - mean_squared_error: 1011.4523 - acc: 4.9002e-04\n",
      "Epoch 00072: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1001.8948 - mean_squared_error: 1001.8947 - acc: 4.7902e-04 - val_loss: 866.6890 - val_mean_squared_error: 866.6891 - val_acc: 0.0011\n",
      "Epoch 73/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 1026.5400 - mean_squared_error: 1026.5394 - acc: 5.7196e-04\n",
      "Epoch 00073: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1005.9917 - mean_squared_error: 1005.9910 - acc: 5.8547e-04 - val_loss: 886.6279 - val_mean_squared_error: 886.6280 - val_acc: 5.6770e-04\n",
      "Epoch 74/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 805.3661 - mean_squared_error: 805.3663 - acc: 5.7971e-04\n",
      "Epoch 00074: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 800.0911 - mean_squared_error: 800.0912 - acc: 5.6773e-04 - val_loss: 876.2328 - val_mean_squared_error: 876.2324 - val_acc: 4.9674e-04\n",
      "Epoch 75/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 559.4691 - mean_squared_error: 559.4695 - acc: 6.8223e-04\n",
      "Epoch 00075: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 30us/sample - loss: 562.3959 - mean_squared_error: 562.3963 - acc: 6.7418e-04 - val_loss: 31226.9958 - val_mean_squared_error: 31227.0000 - val_acc: 2.1289e-04\n",
      "Epoch 76/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 626.1193 - mean_squared_error: 626.1194 - acc: 6.8100e-04\n",
      "Epoch 00076: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 625.4707 - mean_squared_error: 625.4708 - acc: 6.7418e-04 - val_loss: 822.4167 - val_mean_squared_error: 822.4167 - val_acc: 2.1289e-04\n",
      "Epoch 77/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 1024.4171 - mean_squared_error: 1024.4167 - acc: 6.4695e-04\n",
      "Epoch 00077: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 1004.0960 - mean_squared_error: 1004.0956 - acc: 6.2095e-04 - val_loss: 859.9535 - val_mean_squared_error: 859.9537 - val_acc: 3.5481e-04\n",
      "Epoch 78/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 513.3835 - mean_squared_error: 513.3833 - acc: 6.4286e-04\n",
      "Epoch 00078: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 513.1864 - mean_squared_error: 513.1862 - acc: 6.3869e-04 - val_loss: 1012.9900 - val_mean_squared_error: 1012.9900 - val_acc: 9.9347e-04\n",
      "Epoch 79/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 511.9715 - mean_squared_error: 511.9714 - acc: 7.0144e-04\n",
      "Epoch 00079: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 513.2619 - mean_squared_error: 513.2619 - acc: 6.9192e-04 - val_loss: 874.8526 - val_mean_squared_error: 874.8525 - val_acc: 4.2577e-04\n",
      "Epoch 80/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 1014.0026 - mean_squared_error: 1014.0030 - acc: 6.0219e-04\n",
      "Epoch 00080: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 999.4591 - mean_squared_error: 999.4595 - acc: 6.2095e-04 - val_loss: 840.4516 - val_mean_squared_error: 840.4516 - val_acc: 6.3866e-04\n",
      "Epoch 81/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 934.6493 - mean_squared_error: 934.6489 - acc: 4.9002e-04\n",
      "Epoch 00081: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 925.7079 - mean_squared_error: 925.7075 - acc: 4.9676e-04 - val_loss: 890.0096 - val_mean_squared_error: 890.0097 - val_acc: 7.0962e-04\n",
      "Epoch 82/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 734.1253 - mean_squared_error: 734.1258 - acc: 5.8608e-04\n",
      "Epoch 00082: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 729.0875 - mean_squared_error: 729.0880 - acc: 5.8547e-04 - val_loss: 801.1000 - val_mean_squared_error: 801.0999 - val_acc: 2.8385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 943.3172 - mean_squared_error: 943.3170 - acc: 5.7658e-04\n",
      "Epoch 00083: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 936.1014 - mean_squared_error: 936.1013 - acc: 5.8547e-04 - val_loss: 1230.8107 - val_mean_squared_error: 1230.8107 - val_acc: 4.2577e-04\n",
      "Epoch 84/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 660.6430 - mean_squared_error: 660.6431 - acc: 6.3291e-04\n",
      "Epoch 00084: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 657.8082 - mean_squared_error: 657.8083 - acc: 6.2095e-04 - val_loss: 1595.6588 - val_mean_squared_error: 1595.6586 - val_acc: 7.0962e-05\n",
      "Epoch 85/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 803.4728 - mean_squared_error: 803.4724 - acc: 6.0773e-04\n",
      "Epoch 00085: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 793.2785 - mean_squared_error: 793.2780 - acc: 5.8547e-04 - val_loss: 885.7038 - val_mean_squared_error: 885.7037 - val_acc: 7.8058e-04\n",
      "Epoch 86/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 1029.4766 - mean_squared_error: 1029.4764 - acc: 4.8387e-04\n",
      "Epoch 00086: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1027.6260 - mean_squared_error: 1027.6259 - acc: 4.7902e-04 - val_loss: 794.6080 - val_mean_squared_error: 794.6082 - val_acc: 4.9674e-04\n",
      "Epoch 87/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 1016.7691 - mean_squared_error: 1016.7686 - acc: 6.1151e-04\n",
      "Epoch 00087: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1010.7315 - mean_squared_error: 1010.7310 - acc: 6.0321e-04 - val_loss: 940.9445 - val_mean_squared_error: 940.9445 - val_acc: 4.2577e-04\n",
      "Epoch 88/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 1006.6387 - mean_squared_error: 1006.6388 - acc: 4.6847e-04\n",
      "Epoch 00088: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 999.7455 - mean_squared_error: 999.7455 - acc: 4.6128e-04 - val_loss: 858.8173 - val_mean_squared_error: 858.8172 - val_acc: 0.0011\n",
      "Epoch 89/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 999.7194 - mean_squared_error: 999.7196 - acc: 6.5934e-04  \n",
      "Epoch 00089: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 984.6829 - mean_squared_error: 984.6833 - acc: 6.5644e-04 - val_loss: 809.3034 - val_mean_squared_error: 809.3036 - val_acc: 6.3866e-04\n",
      "Epoch 90/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 1020.2335 - mean_squared_error: 1020.2336 - acc: 7.5646e-04\n",
      "Epoch 00090: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 999.0415 - mean_squared_error: 999.0419 - acc: 7.2740e-04 - val_loss: 816.6346 - val_mean_squared_error: 816.6348 - val_acc: 0.0015\n",
      "Epoch 91/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 991.5414 - mean_squared_error: 991.5413 - acc: 6.6055e-04  \n",
      "Epoch 00091: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 974.8284 - mean_squared_error: 974.8284 - acc: 6.9192e-04 - val_loss: 813.4142 - val_mean_squared_error: 813.4138 - val_acc: 9.2251e-04\n",
      "Epoch 92/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 885.2653 - mean_squared_error: 885.2650 - acc: 5.3763e-04\n",
      "Epoch 00092: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 881.2206 - mean_squared_error: 881.2203 - acc: 5.4999e-04 - val_loss: 875.1280 - val_mean_squared_error: 875.1279 - val_acc: 0.0012\n",
      "Epoch 93/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 960.3691 - mean_squared_error: 960.3695 - acc: 6.4748e-04\n",
      "Epoch 00093: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 953.0264 - mean_squared_error: 953.0268 - acc: 6.7418e-04 - val_loss: 854.3602 - val_mean_squared_error: 854.3603 - val_acc: 0.0011\n",
      "Epoch 94/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 931.0301 - mean_squared_error: 931.0299 - acc: 5.5456e-04\n",
      "Epoch 00094: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 926.7144 - mean_squared_error: 926.7142 - acc: 5.4999e-04 - val_loss: 906.8948 - val_mean_squared_error: 906.8947 - val_acc: 8.5155e-04\n",
      "Epoch 95/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 560.9714 - mean_squared_error: 560.9716 - acc: 4.4037e-04\n",
      "Epoch 00095: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 559.9857 - mean_squared_error: 559.9859 - acc: 4.4354e-04 - val_loss: 888.0908 - val_mean_squared_error: 888.0908 - val_acc: 7.0962e-04\n",
      "Epoch 96/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 984.6249 - mean_squared_error: 984.6251 - acc: 4.6429e-04  \n",
      "Epoch 00096: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 981.7706 - mean_squared_error: 981.7708 - acc: 4.6128e-04 - val_loss: 842.9821 - val_mean_squared_error: 842.9822 - val_acc: 8.5155e-04\n",
      "Epoch 97/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 978.2662 - mean_squared_error: 978.2658 - acc: 7.0144e-04  \n",
      "Epoch 00097: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 970.6713 - mean_squared_error: 970.6710 - acc: 6.9192e-04 - val_loss: 904.7350 - val_mean_squared_error: 904.7352 - val_acc: 8.5155e-04\n",
      "Epoch 98/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 962.0859 - mean_squared_error: 962.0858 - acc: 7.3937e-04\n",
      "Epoch 00098: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 942.1472 - mean_squared_error: 942.1471 - acc: 7.4514e-04 - val_loss: 907.5793 - val_mean_squared_error: 907.5792 - val_acc: 4.2577e-04\n",
      "Epoch 99/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 648.2433 - mean_squared_error: 648.2432 - acc: 5.9675e-04\n",
      "Epoch 00099: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 646.0866 - mean_squared_error: 646.0864 - acc: 5.8547e-04 - val_loss: 979.3070 - val_mean_squared_error: 979.3073 - val_acc: 7.0962e-05\n",
      "Epoch 100/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 789.5636 - mean_squared_error: 789.5634 - acc: 5.5456e-04\n",
      "Epoch 00100: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 786.5395 - mean_squared_error: 786.5393 - acc: 5.4999e-04 - val_loss: 886.2319 - val_mean_squared_error: 886.2320 - val_acc: 2.8385e-04\n",
      "Epoch 101/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 808.9189 - mean_squared_error: 808.9189 - acc: 7.5368e-04\n",
      "Epoch 00101: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 834.9417 - mean_squared_error: 834.9417 - acc: 7.2740e-04 - val_loss: 2925.9714 - val_mean_squared_error: 2925.9714 - val_acc: 9.2251e-04\n",
      "Epoch 102/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 512.5138 - mean_squared_error: 512.5139 - acc: 6.0219e-04\n",
      "Epoch 00102: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 511.4470 - mean_squared_error: 511.4471 - acc: 5.8547e-04 - val_loss: 881.9306 - val_mean_squared_error: 881.9307 - val_acc: 2.8385e-04\n",
      "Epoch 103/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 583.7255 - mean_squared_error: 583.7255 - acc: 4.4563e-04\n",
      "Epoch 00103: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 583.2639 - mean_squared_error: 583.2639 - acc: 4.4354e-04 - val_loss: 836.7191 - val_mean_squared_error: 836.7192 - val_acc: 3.5481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 485.5091 - mean_squared_error: 485.5091 - acc: 6.0773e-04\n",
      "Epoch 00104: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 486.9505 - mean_squared_error: 486.9505 - acc: 6.5644e-04 - val_loss: 1955.1306 - val_mean_squared_error: 1955.1307 - val_acc: 2.8385e-04\n",
      "Epoch 105/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 499.1923 - mean_squared_error: 499.1927 - acc: 4.9911e-04\n",
      "Epoch 00105: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 499.2668 - mean_squared_error: 499.2673 - acc: 4.9676e-04 - val_loss: 849.5689 - val_mean_squared_error: 849.5688 - val_acc: 7.0962e-05\n",
      "Epoch 106/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 811.7919 - mean_squared_error: 811.7918 - acc: 4.5045e-04\n",
      "Epoch 00106: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 806.6649 - mean_squared_error: 806.6649 - acc: 4.4354e-04 - val_loss: 851.1772 - val_mean_squared_error: 851.1772 - val_acc: 7.0962e-05\n",
      "Epoch 107/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 1000.5116 - mean_squared_error: 1000.5114 - acc: 6.0440e-04\n",
      "Epoch 00107: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 983.8341 - mean_squared_error: 983.8339 - acc: 6.2095e-04 - val_loss: 810.5873 - val_mean_squared_error: 810.5873 - val_acc: 9.9347e-04\n",
      "Epoch 108/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 608.9309 - mean_squared_error: 608.9310 - acc: 6.1372e-04 ETA: 0s - loss: 469.8939 - mean_squared_error: 469.8939 - acc: 6.31\n",
      "Epoch 00108: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 607.7308 - mean_squared_error: 607.7308 - acc: 6.2095e-04 - val_loss: 982.7598 - val_mean_squared_error: 982.7601 - val_acc: 4.2577e-04\n",
      "Epoch 109/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 688.5710 - mean_squared_error: 688.5712 - acc: 8.0357e-04\n",
      "Epoch 00109: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 687.6990 - mean_squared_error: 687.6991 - acc: 7.9837e-04 - val_loss: 991.3428 - val_mean_squared_error: 991.3431 - val_acc: 2.8385e-04\n",
      "Epoch 110/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 1008.5568 - mean_squared_error: 1008.5569 - acc: 5.8182e-04\n",
      "Epoch 00110: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 995.8874 - mean_squared_error: 995.8875 - acc: 5.8547e-04 - val_loss: 818.3902 - val_mean_squared_error: 818.3902 - val_acc: 0.0016\n",
      "Epoch 111/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 986.8239 - mean_squared_error: 986.8239 - acc: 5.3860e-04  \n",
      "Epoch 00111: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 980.9785 - mean_squared_error: 980.9785 - acc: 5.3225e-04 - val_loss: 886.6338 - val_mean_squared_error: 886.6338 - val_acc: 4.9674e-04\n",
      "Epoch 112/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 985.0625 - mean_squared_error: 985.0627 - acc: 5.0633e-04  \n",
      "Epoch 00112: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 975.0215 - mean_squared_error: 975.0218 - acc: 5.1450e-04 - val_loss: 817.9613 - val_mean_squared_error: 817.9612 - val_acc: 9.9347e-04\n",
      "Epoch 113/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 960.7812 - mean_squared_error: 960.7809 - acc: 6.2950e-04\n",
      "Epoch 00113: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 953.4177 - mean_squared_error: 953.4175 - acc: 6.3869e-04 - val_loss: 803.3294 - val_mean_squared_error: 803.3292 - val_acc: 0.0015\n",
      "Epoch 114/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 942.4818 - mean_squared_error: 942.4816 - acc: 6.7766e-04\n",
      "Epoch 00114: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 927.1364 - mean_squared_error: 927.1362 - acc: 6.7418e-04 - val_loss: 806.2177 - val_mean_squared_error: 806.2176 - val_acc: 4.9674e-04\n",
      "Epoch 115/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 901.9961 - mean_squared_error: 901.9964 - acc: 6.9272e-04\n",
      "Epoch 00115: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 901.7102 - mean_squared_error: 901.7105 - acc: 6.9192e-04 - val_loss: 976.8347 - val_mean_squared_error: 976.8345 - val_acc: 0.0011\n",
      "Epoch 116/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 564.2731 - mean_squared_error: 564.2730 - acc: 6.0329e-04\n",
      "Epoch 00116: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 561.8728 - mean_squared_error: 561.8727 - acc: 6.0321e-04 - val_loss: 4524.5543 - val_mean_squared_error: 4524.5547 - val_acc: 4.9674e-04\n",
      "Epoch 117/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 1261.0212 - mean_squared_error: 1261.0203 - acc: 5.6673e-04\n",
      "Epoch 00117: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1236.6493 - mean_squared_error: 1236.6484 - acc: 5.4999e-04 - val_loss: 944.6929 - val_mean_squared_error: 944.6930 - val_acc: 4.2577e-04\n",
      "Epoch 118/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 980.3079 - mean_squared_error: 980.3071 - acc: 5.6364e-04\n",
      "Epoch 00118: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 967.6250 - mean_squared_error: 967.6241 - acc: 6.0321e-04 - val_loss: 917.5309 - val_mean_squared_error: 917.5310 - val_acc: 7.0962e-04\n",
      "Epoch 119/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 970.9105 - mean_squared_error: 970.9108 - acc: 6.3063e-04\n",
      "Epoch 00119: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 963.3988 - mean_squared_error: 963.3991 - acc: 6.2095e-04 - val_loss: 885.5886 - val_mean_squared_error: 885.5884 - val_acc: 4.9674e-04\n",
      "Epoch 120/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 945.2133 - mean_squared_error: 945.2130 - acc: 5.4945e-04\n",
      "Epoch 00120: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 929.0822 - mean_squared_error: 929.0820 - acc: 5.4999e-04 - val_loss: 824.1308 - val_mean_squared_error: 824.1308 - val_acc: 9.2251e-04\n",
      "Epoch 121/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 902.5360 - mean_squared_error: 902.5359 - acc: 5.3016e-04\n",
      "Epoch 00121: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 889.7440 - mean_squared_error: 889.7438 - acc: 5.3225e-04 - val_loss: 898.6350 - val_mean_squared_error: 898.6349 - val_acc: 9.9347e-04\n",
      "Epoch 122/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 912.2523 - mean_squared_error: 912.2524 - acc: 5.7090e-04\n",
      "Epoch 00122: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 895.1329 - mean_squared_error: 895.1329 - acc: 5.6773e-04 - val_loss: 865.3985 - val_mean_squared_error: 865.3984 - val_acc: 0.0013\n",
      "Epoch 123/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 811.3790 - mean_squared_error: 811.3795 - acc: 4.8128e-04\n",
      "Epoch 00123: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 809.7141 - mean_squared_error: 809.7146 - acc: 4.7902e-04 - val_loss: 1152.7556 - val_mean_squared_error: 1152.7557 - val_acc: 2.1289e-04\n",
      "Epoch 124/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 737.9367 - mean_squared_error: 737.9365 - acc: 7.0652e-04\n",
      "Epoch 00124: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 732.4453 - mean_squared_error: 732.4450 - acc: 6.9192e-04 - val_loss: 1609.5909 - val_mean_squared_error: 1609.5909 - val_acc: 5.6770e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 451.4756 - mean_squared_error: 451.4756 - acc: 7.3084e-04\n",
      "Epoch 00125: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 450.9453 - mean_squared_error: 450.9452 - acc: 7.4514e-04 - val_loss: 1389.4150 - val_mean_squared_error: 1389.4147 - val_acc: 9.9347e-04\n",
      "Epoch 126/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 480.1145 - mean_squared_error: 480.1144 - acc: 6.4695e-04\n",
      "Epoch 00126: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 479.5566 - mean_squared_error: 479.5564 - acc: 6.3869e-04 - val_loss: 1374.5402 - val_mean_squared_error: 1374.5402 - val_acc: 7.8058e-04\n",
      "Epoch 127/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 483.7275 - mean_squared_error: 483.7275 - acc: 6.5934e-04\n",
      "Epoch 00127: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 482.3430 - mean_squared_error: 482.3431 - acc: 6.7418e-04 - val_loss: 853.4182 - val_mean_squared_error: 853.4180 - val_acc: 0.0011\n",
      "Epoch 128/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 942.2824 - mean_squared_error: 942.2825 - acc: 6.4982e-04\n",
      "Epoch 00128: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 933.3809 - mean_squared_error: 933.3810 - acc: 6.5644e-04 - val_loss: 877.1256 - val_mean_squared_error: 877.1257 - val_acc: 6.3866e-04\n",
      "Epoch 129/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 725.3815 - mean_squared_error: 725.3814 - acc: 5.4250e-04\n",
      "Epoch 00129: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 719.9040 - mean_squared_error: 719.9040 - acc: 5.4999e-04 - val_loss: 1036.0130 - val_mean_squared_error: 1036.0133 - val_acc: 0.0013\n",
      "Epoch 130/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 837.8041 - mean_squared_error: 837.8038 - acc: 6.3636e-04\n",
      "Epoch 00130: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 832.5370 - mean_squared_error: 832.5367 - acc: 6.5644e-04 - val_loss: 1281.6084 - val_mean_squared_error: 1281.6082 - val_acc: 7.0962e-04\n",
      "Epoch 131/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 541.3184 - mean_squared_error: 541.3184 - acc: 4.8913e-04\n",
      "Epoch 00131: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 540.3055 - mean_squared_error: 540.3055 - acc: 4.7902e-04 - val_loss: 788.9164 - val_mean_squared_error: 788.9163 - val_acc: 2.8385e-04\n",
      "Epoch 132/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 972.3788 - mean_squared_error: 972.3789 - acc: 5.2252e-04\n",
      "Epoch 00132: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 964.8617 - mean_squared_error: 964.8617 - acc: 5.1450e-04 - val_loss: 819.8072 - val_mean_squared_error: 819.8073 - val_acc: 2.8385e-04\n",
      "Epoch 133/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 893.5661 - mean_squared_error: 893.5659 - acc: 5.2823e-04\n",
      "Epoch 00133: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 881.8122 - mean_squared_error: 881.8121 - acc: 5.1450e-04 - val_loss: 949.9104 - val_mean_squared_error: 949.9105 - val_acc: 4.2577e-04\n",
      "Epoch 134/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 712.4608 - mean_squared_error: 712.4609 - acc: 6.6071e-04\n",
      "Epoch 00134: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 711.2124 - mean_squared_error: 711.2126 - acc: 6.9192e-04 - val_loss: 804.1190 - val_mean_squared_error: 804.1191 - val_acc: 4.2577e-04\n",
      "Epoch 135/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 489.3128 - mean_squared_error: 489.3127 - acc: 5.3211e-04\n",
      "Epoch 00135: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 489.0117 - mean_squared_error: 489.0116 - acc: 5.3225e-04 - val_loss: 811.1143 - val_mean_squared_error: 811.1143 - val_acc: 3.5481e-04\n",
      "Epoch 136/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 942.1987 - mean_squared_error: 942.1993 - acc: 6.1041e-04\n",
      "Epoch 00136: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 936.0634 - mean_squared_error: 936.0640 - acc: 6.0321e-04 - val_loss: 868.5100 - val_mean_squared_error: 868.5101 - val_acc: 4.9674e-04\n",
      "Epoch 137/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 734.7684 - mean_squared_error: 734.7686 - acc: 6.2278e-04\n",
      "Epoch 00137: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 733.9522 - mean_squared_error: 733.9525 - acc: 6.2095e-04 - val_loss: 1179.0668 - val_mean_squared_error: 1179.0667 - val_acc: 3.5481e-04\n",
      "Epoch 138/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 453.2853 - mean_squared_error: 453.2850 - acc: 6.3063e-04\n",
      "Epoch 00138: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 483.2917 - mean_squared_error: 483.2915 - acc: 6.3869e-04 - val_loss: 911.8431 - val_mean_squared_error: 911.8433 - val_acc: 0.0011\n",
      "Epoch 139/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 958.0191 - mean_squared_error: 958.0191 - acc: 7.2222e-04\n",
      "Epoch 00139: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 938.5031 - mean_squared_error: 938.5030 - acc: 7.4514e-04 - val_loss: 871.5700 - val_mean_squared_error: 871.5701 - val_acc: 0.0013\n",
      "Epoch 140/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 820.6132 - mean_squared_error: 820.6134 - acc: 6.0219e-04\n",
      "Epoch 00140: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 810.8889 - mean_squared_error: 810.8890 - acc: 6.0321e-04 - val_loss: 1161.8814 - val_mean_squared_error: 1161.8813 - val_acc: 0.0016\n",
      "Epoch 141/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 637.6905 - mean_squared_error: 637.6905 - acc: 6.3636e-04\n",
      "Epoch 00141: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 633.5655 - mean_squared_error: 633.5654 - acc: 6.2095e-04 - val_loss: 1549.8504 - val_mean_squared_error: 1549.8502 - val_acc: 6.3866e-04\n",
      "Epoch 142/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 662.2904 - mean_squared_error: 662.2903 - acc: 5.8615e-04   ETA: 0s - loss: 1010.2883 - mean_squared_erro\n",
      "Epoch 00142: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 661.9661 - mean_squared_error: 661.9659 - acc: 5.8547e-04 - val_loss: 1121.2676 - val_mean_squared_error: 1121.2676 - val_acc: 0.0013\n",
      "Epoch 143/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 659.0036 - mean_squared_error: 659.0034 - acc: 6.4516e-04 ETA: 0s - loss: 758.9494 - mean_squared_error: 758.94\n",
      "Epoch 00143: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 656.9436 - mean_squared_error: 656.9434 - acc: 6.3869e-04 - val_loss: 1529.6766 - val_mean_squared_error: 1529.6766 - val_acc: 7.0962e-05\n",
      "Epoch 144/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 499.4123 - mean_squared_error: 499.4123 - acc: 6.8468e-04\n",
      "Epoch 00144: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 499.2870 - mean_squared_error: 499.2870 - acc: 6.9192e-04 - val_loss: 4336.5492 - val_mean_squared_error: 4336.5488 - val_acc: 0.0014\n",
      "Epoch 145/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 542.2118 - mean_squared_error: 542.2115 - acc: 5.8716e-04\n",
      "Epoch 00145: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 539.8965 - mean_squared_error: 539.8962 - acc: 5.8547e-04 - val_loss: 3327.5782 - val_mean_squared_error: 3327.5781 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 449.2556 - mean_squared_error: 449.2556 - acc: 6.0606e-04\n",
      "Epoch 00146: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 448.8706 - mean_squared_error: 448.8706 - acc: 6.0321e-04 - val_loss: 831.7393 - val_mean_squared_error: 831.7391 - val_acc: 2.1289e-04\n",
      "Epoch 147/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 582.8603 - mean_squared_error: 582.8600 - acc: 7.8853e-04\n",
      "Epoch 00147: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 581.2345 - mean_squared_error: 581.2342 - acc: 7.8063e-04 - val_loss: 4137.5285 - val_mean_squared_error: 4137.5278 - val_acc: 0.0000e+00\n",
      "Epoch 148/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 443.8479 - mean_squared_error: 443.8480 - acc: 5.3763e-04\n",
      "Epoch 00148: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 443.6973 - mean_squared_error: 443.6973 - acc: 5.6773e-04 - val_loss: 7296.6887 - val_mean_squared_error: 7296.6875 - val_acc: 0.0015\n",
      "Epoch 149/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 450.6712 - mean_squared_error: 450.6711 - acc: 6.2389e-04\n",
      "Epoch 00149: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 450.5315 - mean_squared_error: 450.5313 - acc: 6.2095e-04 - val_loss: 8152.7723 - val_mean_squared_error: 8152.7720 - val_acc: 1.4192e-04\n",
      "Epoch 150/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 1783.4298 - mean_squared_error: 1783.4302 - acc: 5.7041e-04\n",
      "Epoch 00150: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1777.6622 - mean_squared_error: 1777.6626 - acc: 6.0321e-04 - val_loss: 827.4621 - val_mean_squared_error: 827.4620 - val_acc: 0.0012\n",
      "Epoch 151/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 645.1876 - mean_squared_error: 645.1874 - acc: 5.4845e-04\n",
      "Epoch 00151: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 639.2173 - mean_squared_error: 639.2170 - acc: 5.8547e-04 - val_loss: 948.1010 - val_mean_squared_error: 948.1012 - val_acc: 5.6770e-04\n",
      "Epoch 152/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 606.0937 - mean_squared_error: 606.0942 - acc: 6.5836e-04\n",
      "Epoch 00152: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 605.4110 - mean_squared_error: 605.4115 - acc: 6.5644e-04 - val_loss: 878.4296 - val_mean_squared_error: 878.4297 - val_acc: 0.0016\n",
      "Epoch 153/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 515.3123 - mean_squared_error: 515.3123 - acc: 5.1565e-04\n",
      "Epoch 00153: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 513.3110 - mean_squared_error: 513.3111 - acc: 5.1450e-04 - val_loss: 2145.4025 - val_mean_squared_error: 2145.4021 - val_acc: 5.6770e-04\n",
      "Epoch 154/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 435.4893 - mean_squared_error: 435.4892 - acc: 7.1823e-04\n",
      "Epoch 00154: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 599.4461 - mean_squared_error: 599.4460 - acc: 7.2740e-04 - val_loss: 9670.6733 - val_mean_squared_error: 9670.6738 - val_acc: 2.1289e-04\n",
      "Epoch 155/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 535.4961 - mean_squared_error: 535.4962 - acc: 5.9034e-04\n",
      "Epoch 00155: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 534.5745 - mean_squared_error: 534.5745 - acc: 5.8547e-04 - val_loss: 877.3967 - val_mean_squared_error: 877.3967 - val_acc: 7.8058e-04\n",
      "Epoch 156/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 631.2234 - mean_squared_error: 631.2234 - acc: 5.6058e-04\n",
      "Epoch 00156: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 628.9155 - mean_squared_error: 628.9156 - acc: 5.4999e-04 - val_loss: 7161.0268 - val_mean_squared_error: 7161.0273 - val_acc: 4.2577e-04\n",
      "Epoch 157/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 446.0153 - mean_squared_error: 446.0155 - acc: 6.2271e-04\n",
      "Epoch 00157: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 447.0793 - mean_squared_error: 447.0794 - acc: 6.5644e-04 - val_loss: 5596.2178 - val_mean_squared_error: 5596.2178 - val_acc: 0.0012\n",
      "Epoch 158/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 1515.8719 - mean_squared_error: 1515.8723 - acc: 6.9217e-04\n",
      "Epoch 00158: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 1488.1649 - mean_squared_error: 1488.1654 - acc: 6.7418e-04 - val_loss: 828.7141 - val_mean_squared_error: 828.7142 - val_acc: 1.4192e-04\n",
      "Epoch 159/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 947.9513 - mean_squared_error: 947.9517 - acc: 6.0000e-04\n",
      "Epoch 00159: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 935.7946 - mean_squared_error: 935.7950 - acc: 6.0321e-04 - val_loss: 855.7620 - val_mean_squared_error: 855.7617 - val_acc: 2.8385e-04\n",
      "Epoch 160/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 762.1539 - mean_squared_error: 762.1537 - acc: 4.4964e-04\n",
      "Epoch 00160: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 757.3724 - mean_squared_error: 757.3723 - acc: 4.4354e-04 - val_loss: 952.6260 - val_mean_squared_error: 952.6260 - val_acc: 7.0962e-04\n",
      "Epoch 161/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 493.5250 - mean_squared_error: 493.5247 - acc: 6.6908e-04\n",
      "Epoch 00161: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 491.5093 - mean_squared_error: 491.5091 - acc: 6.7418e-04 - val_loss: 1895.5541 - val_mean_squared_error: 1895.5538 - val_acc: 2.8385e-04\n",
      "Epoch 162/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 496.9741 - mean_squared_error: 496.9742 - acc: 6.1594e-04\n",
      "Epoch 00162: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 496.0817 - mean_squared_error: 496.0818 - acc: 6.0321e-04 - val_loss: 2807.1629 - val_mean_squared_error: 2807.1626 - val_acc: 2.8385e-04\n",
      "Epoch 163/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 469.0863 - mean_squared_error: 469.0864 - acc: 5.6940e-04\n",
      "Epoch 00163: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 468.8541 - mean_squared_error: 468.8542 - acc: 5.6773e-04 - val_loss: 935.5949 - val_mean_squared_error: 935.5954 - val_acc: 0.0015\n",
      "Epoch 164/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 617.7973 - mean_squared_error: 617.7974 - acc: 6.4457e-04\n",
      "Epoch 00164: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 610.5317 - mean_squared_error: 610.5317 - acc: 6.5644e-04 - val_loss: 2765.9721 - val_mean_squared_error: 2765.9722 - val_acc: 0.0015\n",
      "Epoch 165/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 589.7935 - mean_squared_error: 589.7937 - acc: 6.0662e-04\n",
      "Epoch 00165: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 583.7104 - mean_squared_error: 583.7107 - acc: 6.2095e-04 - val_loss: 837.4820 - val_mean_squared_error: 837.4821 - val_acc: 5.6770e-04\n",
      "Epoch 166/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 756.0595 - mean_squared_error: 756.0592 - acc: 6.2385e-04\n",
      "Epoch 00166: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 744.7084 - mean_squared_error: 744.7082 - acc: 6.0321e-04 - val_loss: 1284.2848 - val_mean_squared_error: 1284.2850 - val_acc: 6.3866e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 470.0476 - mean_squared_error: 470.0476 - acc: 7.5000e-04\n",
      "Epoch 00167: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 469.9693 - mean_squared_error: 469.9693 - acc: 7.4514e-04 - val_loss: 1786.3526 - val_mean_squared_error: 1786.3524 - val_acc: 0.0011\n",
      "Epoch 168/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 442.5201 - mean_squared_error: 442.5204 - acc: 6.6071e-04\n",
      "Epoch 00168: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 442.4112 - mean_squared_error: 442.4115 - acc: 6.7418e-04 - val_loss: 2160.4672 - val_mean_squared_error: 2160.4670 - val_acc: 4.2577e-04\n",
      "Epoch 169/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 473.5464 - mean_squared_error: 473.5467 - acc: 6.1111e-04\n",
      "Epoch 00169: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 472.0945 - mean_squared_error: 472.0948 - acc: 6.0321e-04 - val_loss: 9030.5047 - val_mean_squared_error: 9030.5049 - val_acc: 2.1289e-04\n",
      "Epoch 170/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 505.8199 - mean_squared_error: 505.8197 - acc: 3.7975e-04\n",
      "Epoch 00170: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 503.7434 - mean_squared_error: 503.7434 - acc: 3.7257e-04 - val_loss: 925.0327 - val_mean_squared_error: 925.0328 - val_acc: 1.4192e-04\n",
      "Epoch 171/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 424.2118 - mean_squared_error: 424.2119 - acc: 5.3476e-04\n",
      "Epoch 00171: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 424.1772 - mean_squared_error: 424.1773 - acc: 5.3225e-04 - val_loss: 818.5707 - val_mean_squared_error: 818.5707 - val_acc: 1.4192e-04\n",
      "Epoch 172/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 569.3694 - mean_squared_error: 569.3692 - acc: 5.2632e-04\n",
      "Epoch 00172: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 565.9173 - mean_squared_error: 565.9171 - acc: 5.1450e-04 - val_loss: 2948.1443 - val_mean_squared_error: 2948.1443 - val_acc: 0.0000e+00\n",
      "Epoch 173/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 474.9078 - mean_squared_error: 474.9077 - acc: 5.6159e-04\n",
      "Epoch 00173: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 473.5562 - mean_squared_error: 473.5560 - acc: 5.4999e-04 - val_loss: 9917.3727 - val_mean_squared_error: 9917.3730 - val_acc: 0.0013\n",
      "Epoch 174/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 466.3678 - mean_squared_error: 466.3682 - acc: 6.5217e-04\n",
      "Epoch 00174: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 466.6060 - mean_squared_error: 466.6063 - acc: 6.7418e-04 - val_loss: 859.8639 - val_mean_squared_error: 859.8639 - val_acc: 0.0012\n",
      "Epoch 175/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 458.8812 - mean_squared_error: 458.8808 - acc: 5.7143e-04\n",
      "Epoch 00175: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 458.2539 - mean_squared_error: 458.2536 - acc: 5.6773e-04 - val_loss: 858.5758 - val_mean_squared_error: 858.5756 - val_acc: 3.5481e-04\n",
      "Epoch 176/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 511.7596 - mean_squared_error: 511.7593 - acc: 4.4037e-04\n",
      "Epoch 00176: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 510.7561 - mean_squared_error: 510.7558 - acc: 4.7902e-04 - val_loss: 1734.7422 - val_mean_squared_error: 1734.7424 - val_acc: 4.9674e-04\n",
      "Epoch 177/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 460.4518 - mean_squared_error: 460.4518 - acc: 5.5755e-04\n",
      "Epoch 00177: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 460.7017 - mean_squared_error: 460.7018 - acc: 5.4999e-04 - val_loss: 813.5246 - val_mean_squared_error: 813.5245 - val_acc: 0.0000e+00\n",
      "Epoch 178/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 730.3156 - mean_squared_error: 730.3157 - acc: 5.0633e-04\n",
      "Epoch 00178: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 724.8110 - mean_squared_error: 724.8112 - acc: 5.1450e-04 - val_loss: 1764.6023 - val_mean_squared_error: 1764.6024 - val_acc: 6.3866e-04\n",
      "Epoch 179/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 675.9698 - mean_squared_error: 675.9697 - acc: 6.1261e-04\n",
      "Epoch 00179: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 672.2322 - mean_squared_error: 672.2319 - acc: 6.2095e-04 - val_loss: 775.0840 - val_mean_squared_error: 775.0839 - val_acc: 0.0013\n",
      "Epoch 180/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 952.1237 - mean_squared_error: 952.1240 - acc: 7.7206e-04\n",
      "Epoch 00180: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 934.8219 - mean_squared_error: 934.8223 - acc: 7.4514e-04 - val_loss: 831.6802 - val_mean_squared_error: 831.6803 - val_acc: 1.4192e-04\n",
      "Epoch 181/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 817.4584 - mean_squared_error: 817.4576 - acc: 5.7301e-04\n",
      "Epoch 00181: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 802.7622 - mean_squared_error: 802.7617 - acc: 5.4999e-04 - val_loss: 1127.4222 - val_mean_squared_error: 1127.4222 - val_acc: 2.1289e-04\n",
      "Epoch 182/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 601.0237 - mean_squared_error: 601.0236 - acc: 5.0725e-04\n",
      "Epoch 00182: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 598.6123 - mean_squared_error: 598.6121 - acc: 4.9676e-04 - val_loss: 7279.0872 - val_mean_squared_error: 7279.0854 - val_acc: 3.5481e-04\n",
      "Epoch 183/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 629.4553 - mean_squared_error: 629.4553 - acc: 6.8223e-04\n",
      "Epoch 00183: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 627.9982 - mean_squared_error: 627.9982 - acc: 6.7418e-04 - val_loss: 734.4175 - val_mean_squared_error: 734.4177 - val_acc: 7.0962e-05\n",
      "Epoch 184/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 525.9621 - mean_squared_error: 525.9621 - acc: 5.2158e-04\n",
      "Epoch 00184: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 525.4781 - mean_squared_error: 525.4781 - acc: 5.1450e-04 - val_loss: 1809.8713 - val_mean_squared_error: 1809.8707 - val_acc: 9.9347e-04\n",
      "Epoch 185/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 423.5877 - mean_squared_error: 423.5878 - acc: 6.4865e-04\n",
      "Epoch 00185: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 423.9859 - mean_squared_error: 423.9860 - acc: 6.3869e-04 - val_loss: 4041.9925 - val_mean_squared_error: 4041.9924 - val_acc: 6.3866e-04\n",
      "Epoch 186/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 435.5196 - mean_squared_error: 435.5196 - acc: 7.4818e-04\n",
      "Epoch 00186: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 435.7168 - mean_squared_error: 435.7169 - acc: 7.4514e-04 - val_loss: 859.6485 - val_mean_squared_error: 859.6486 - val_acc: 0.0011\n",
      "Epoch 187/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 689.7501 - mean_squared_error: 689.7502 - acc: 6.1483e-04\n",
      "Epoch 00187: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 685.0531 - mean_squared_error: 685.0533 - acc: 6.0321e-04 - val_loss: 979.4432 - val_mean_squared_error: 979.4432 - val_acc: 6.3866e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 669.3776 - mean_squared_error: 669.3774 - acc: 6.9982e-04\n",
      "Epoch 00188: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 659.0106 - mean_squared_error: 659.0105 - acc: 6.9192e-04 - val_loss: 5101.1076 - val_mean_squared_error: 5101.1074 - val_acc: 7.8058e-04\n",
      "Epoch 189/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 627.8070 - mean_squared_error: 627.8069 - acc: 5.0450e-04\n",
      "Epoch 00189: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 624.9650 - mean_squared_error: 624.9648 - acc: 5.3225e-04 - val_loss: 778.1047 - val_mean_squared_error: 778.1048 - val_acc: 9.2251e-04\n",
      "Epoch 190/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 549.6220 - mean_squared_error: 549.6218 - acc: 4.4883e-04\n",
      "Epoch 00190: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 548.3814 - mean_squared_error: 548.3812 - acc: 4.7902e-04 - val_loss: 1192.2982 - val_mean_squared_error: 1192.2982 - val_acc: 0.0012\n",
      "Epoch 191/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 425.6586 - mean_squared_error: 425.6586 - acc: 5.3211e-04\n",
      "Epoch 00191: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 424.2522 - mean_squared_error: 424.2523 - acc: 5.3225e-04 - val_loss: 760.4017 - val_mean_squared_error: 760.4017 - val_acc: 2.1289e-04\n",
      "Epoch 192/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 452.3419 - mean_squared_error: 452.3420 - acc: 7.0144e-04\n",
      "Epoch 00192: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 452.3488 - mean_squared_error: 452.3489 - acc: 6.9192e-04 - val_loss: 4087.0616 - val_mean_squared_error: 4087.0618 - val_acc: 1.4192e-04\n",
      "Epoch 193/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 544.7771 - mean_squared_error: 544.7770 - acc: 5.8929e-04\n",
      "Epoch 00193: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 543.4124 - mean_squared_error: 543.4124 - acc: 5.8547e-04 - val_loss: 815.6995 - val_mean_squared_error: 815.6995 - val_acc: 0.0012\n",
      "Epoch 194/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 582.3040 - mean_squared_error: 582.3040 - acc: 5.4152e-04\n",
      "Epoch 00194: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 579.7745 - mean_squared_error: 579.7745 - acc: 5.3225e-04 - val_loss: 956.4523 - val_mean_squared_error: 956.4524 - val_acc: 7.0962e-05\n",
      "Epoch 195/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 415.3076 - mean_squared_error: 415.3078 - acc: 5.4152e-04\n",
      "Epoch 00195: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 415.3194 - mean_squared_error: 415.3195 - acc: 5.4999e-04 - val_loss: 1219.2171 - val_mean_squared_error: 1219.2172 - val_acc: 8.5155e-04\n",
      "Epoch 196/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 414.1472 - mean_squared_error: 414.1474 - acc: 6.7151e-04\n",
      "Epoch 00196: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 414.1961 - mean_squared_error: 414.1963 - acc: 6.5644e-04 - val_loss: 724.0423 - val_mean_squared_error: 724.0423 - val_acc: 9.2251e-04\n",
      "Epoch 197/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 487.9837 - mean_squared_error: 487.9839 - acc: 5.6777e-04\n",
      "Epoch 00197: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 484.2131 - mean_squared_error: 484.2133 - acc: 5.6773e-04 - val_loss: 1553.8359 - val_mean_squared_error: 1553.8359 - val_acc: 4.2577e-04\n",
      "Epoch 198/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 597.5712 - mean_squared_error: 597.5711 - acc: 5.2065e-04\n",
      "Epoch 00198: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 595.3473 - mean_squared_error: 595.3472 - acc: 5.1450e-04 - val_loss: 771.2993 - val_mean_squared_error: 771.2993 - val_acc: 0.0011\n",
      "Epoch 199/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 403.8257 - mean_squared_error: 403.8256 - acc: 4.7882e-04\n",
      "Epoch 00199: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 678.8545 - mean_squared_error: 678.8545 - acc: 4.7902e-04 - val_loss: 756.6705 - val_mean_squared_error: 756.6705 - val_acc: 7.8058e-04\n",
      "Epoch 200/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 415.3281 - mean_squared_error: 415.3278 - acc: 5.9353e-04\n",
      "Epoch 00200: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 414.8569 - mean_squared_error: 414.8566 - acc: 6.0321e-04 - val_loss: 2861.4698 - val_mean_squared_error: 2861.4705 - val_acc: 4.2577e-04\n",
      "Epoch 201/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 512.7317 - mean_squared_error: 512.7315 - acc: 5.3667e-04\n",
      "Epoch 00201: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 511.7743 - mean_squared_error: 511.7741 - acc: 5.3225e-04 - val_loss: 7309.0208 - val_mean_squared_error: 7309.0186 - val_acc: 4.2577e-04\n",
      "Epoch 202/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 560.1315 - mean_squared_error: 560.1317 - acc: 6.1041e-04\n",
      "Epoch 00202: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 559.8224 - mean_squared_error: 559.8226 - acc: 6.0321e-04 - val_loss: 819.4650 - val_mean_squared_error: 819.4647 - val_acc: 6.3866e-04\n",
      "Epoch 203/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 887.5285 - mean_squared_error: 887.5283 - acc: 5.0269e-04\n",
      "Epoch 00203: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 881.4790 - mean_squared_error: 881.4789 - acc: 5.1450e-04 - val_loss: 817.8231 - val_mean_squared_error: 817.8229 - val_acc: 0.0015\n",
      "Epoch 204/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 655.3363 - mean_squared_error: 655.3364 - acc: 5.8719e-04\n",
      "Epoch 00204: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 654.5263 - mean_squared_error: 654.5265 - acc: 6.0321e-04 - val_loss: 1202.1458 - val_mean_squared_error: 1202.1464 - val_acc: 0.0011\n",
      "Epoch 205/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 437.8854 - mean_squared_error: 437.8852 - acc: 6.2500e-04\n",
      "Epoch 00205: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 437.5270 - mean_squared_error: 437.5268 - acc: 6.2095e-04 - val_loss: 3047.8748 - val_mean_squared_error: 3047.8743 - val_acc: 0.0013\n",
      "Epoch 206/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 415.6537 - mean_squared_error: 415.6535 - acc: 5.7554e-04\n",
      "Epoch 00206: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 415.0273 - mean_squared_error: 415.0271 - acc: 5.6773e-04 - val_loss: 5966.1744 - val_mean_squared_error: 5966.1738 - val_acc: 7.0962e-04\n",
      "Epoch 207/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 401.6989 - mean_squared_error: 401.6989 - acc: 6.0773e-04\n",
      "Epoch 00207: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 401.6666 - mean_squared_error: 401.6665 - acc: 6.0321e-04 - val_loss: 2090.0077 - val_mean_squared_error: 2090.0076 - val_acc: 2.1289e-04\n",
      "Epoch 208/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 396.6429 - mean_squared_error: 396.6428 - acc: 7.0397e-04\n",
      "Epoch 00208: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 395.8313 - mean_squared_error: 395.8313 - acc: 6.9192e-04 - val_loss: 3107.6708 - val_mean_squared_error: 3107.6707 - val_acc: 2.8385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 457.7135 - mean_squared_error: 457.7134 - acc: 5.3016e-04\n",
      "Epoch 00209: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 455.8194 - mean_squared_error: 455.8194 - acc: 5.3225e-04 - val_loss: 772.1847 - val_mean_squared_error: 772.1848 - val_acc: 5.6770e-04\n",
      "Epoch 210/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 721.7885 - mean_squared_error: 721.7886 - acc: 5.2158e-04\n",
      "Epoch 00210: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 717.9804 - mean_squared_error: 717.9805 - acc: 5.1450e-04 - val_loss: 3454.1302 - val_mean_squared_error: 3454.1306 - val_acc: 9.2251e-04\n",
      "Epoch 211/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 406.7626 - mean_squared_error: 406.7624 - acc: 6.0714e-04\n",
      "Epoch 00211: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 406.4335 - mean_squared_error: 406.4333 - acc: 6.0321e-04 - val_loss: 6196.0433 - val_mean_squared_error: 6196.0430 - val_acc: 6.3866e-04\n",
      "Epoch 212/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 424.1504 - mean_squared_error: 424.1505 - acc: 4.7445e-04\n",
      "Epoch 00212: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 423.2177 - mean_squared_error: 423.2178 - acc: 4.7902e-04 - val_loss: 2117.9939 - val_mean_squared_error: 2117.9939 - val_acc: 6.3866e-04\n",
      "Epoch 213/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 452.1411 - mean_squared_error: 452.1410 - acc: 6.4695e-04\n",
      "Epoch 00213: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 450.5883 - mean_squared_error: 450.5882 - acc: 6.3869e-04 - val_loss: 20022.1470 - val_mean_squared_error: 20022.1426 - val_acc: 0.0013\n",
      "Epoch 214/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 940.3008 - mean_squared_error: 940.3000 - acc: 5.3407e-04\n",
      "Epoch 00214: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 921.3197 - mean_squared_error: 921.3190 - acc: 5.3225e-04 - val_loss: 861.2498 - val_mean_squared_error: 861.2499 - val_acc: 2.8385e-04\n",
      "Epoch 215/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 597.5102 - mean_squared_error: 597.5100 - acc: 4.9724e-04\n",
      "Epoch 00215: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 590.2083 - mean_squared_error: 590.2080 - acc: 4.7902e-04 - val_loss: 3445.1753 - val_mean_squared_error: 3445.1760 - val_acc: 0.0011\n",
      "Epoch 216/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 402.7352 - mean_squared_error: 402.7349 - acc: 6.7273e-04\n",
      "Epoch 00216: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 402.5141 - mean_squared_error: 402.5138 - acc: 6.7418e-04 - val_loss: 2007.4540 - val_mean_squared_error: 2007.4540 - val_acc: 7.0962e-04\n",
      "Epoch 217/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 409.2799 - mean_squared_error: 409.2800 - acc: 6.0606e-04\n",
      "Epoch 00217: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 408.8166 - mean_squared_error: 408.8167 - acc: 6.0321e-04 - val_loss: 906.6403 - val_mean_squared_error: 906.6402 - val_acc: 2.1289e-04\n",
      "Epoch 218/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 568.3204 - mean_squared_error: 568.3201 - acc: 5.5258e-04\n",
      "Epoch 00218: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 567.7741 - mean_squared_error: 567.7739 - acc: 5.4999e-04 - val_loss: 11849.0232 - val_mean_squared_error: 11849.0234 - val_acc: 3.5481e-04\n",
      "Epoch 219/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 617.2419 - mean_squared_error: 617.2419 - acc: 4.6679e-04\n",
      "Epoch 00219: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 614.4574 - mean_squared_error: 614.4576 - acc: 4.6128e-04 - val_loss: 2183.6182 - val_mean_squared_error: 2183.6182 - val_acc: 5.6770e-04\n",
      "Epoch 220/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 398.1679 - mean_squared_error: 398.1680 - acc: 5.3763e-04 ETA: 1s - loss: 384.2583 - mean_squ\n",
      "Epoch 00220: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 397.6095 - mean_squared_error: 397.6095 - acc: 5.3225e-04 - val_loss: 2013.3319 - val_mean_squared_error: 2013.3318 - val_acc: 0.0011\n",
      "Epoch 221/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 671.4922 - mean_squared_error: 671.4924 - acc: 4.1742e-04\n",
      "Epoch 00221: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 666.8575 - mean_squared_error: 666.8577 - acc: 4.4354e-04 - val_loss: 897.8310 - val_mean_squared_error: 897.8311 - val_acc: 3.5481e-04\n",
      "Epoch 222/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 676.9484 - mean_squared_error: 676.9485 - acc: 6.3063e-04\n",
      "Epoch 00222: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 672.1642 - mean_squared_error: 672.1644 - acc: 6.2095e-04 - val_loss: 793.7631 - val_mean_squared_error: 793.7630 - val_acc: 8.5155e-04\n",
      "Epoch 223/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 820.1411 - mean_squared_error: 820.1410 - acc: 5.4348e-04\n",
      "Epoch 00223: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 811.8163 - mean_squared_error: 811.8161 - acc: 5.3225e-04 - val_loss: 1604.8917 - val_mean_squared_error: 1604.8918 - val_acc: 2.1289e-04\n",
      "Epoch 224/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 424.0194 - mean_squared_error: 424.0196 - acc: 6.3063e-04\n",
      "Epoch 00224: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 423.9869 - mean_squared_error: 423.9872 - acc: 6.7418e-04 - val_loss: 5153.3513 - val_mean_squared_error: 5153.3516 - val_acc: 0.0015\n",
      "Epoch 225/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 479.7085 - mean_squared_error: 479.7085 - acc: 6.4865e-04\n",
      "Epoch 00225: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 478.1163 - mean_squared_error: 478.1164 - acc: 6.3869e-04 - val_loss: 776.6070 - val_mean_squared_error: 776.6070 - val_acc: 7.0962e-04\n",
      "Epoch 226/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 485.2922 - mean_squared_error: 485.2921 - acc: 5.9034e-04 ETA: 0s - loss: 509.0543 - mean_squared_error: 509.0543 - acc: \n",
      "Epoch 00226: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 484.7901 - mean_squared_error: 484.7901 - acc: 5.8547e-04 - val_loss: 2392.5959 - val_mean_squared_error: 2392.5964 - val_acc: 9.2251e-04\n",
      "Epoch 227/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 483.9746 - mean_squared_error: 483.9746 - acc: 6.3291e-04\n",
      "Epoch 00227: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 481.9576 - mean_squared_error: 481.9576 - acc: 6.3869e-04 - val_loss: 798.6522 - val_mean_squared_error: 798.6522 - val_acc: 0.0013\n",
      "Epoch 228/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 493.3613 - mean_squared_error: 493.3615 - acc: 5.2347e-04\n",
      "Epoch 00228: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 492.0149 - mean_squared_error: 492.0150 - acc: 5.1450e-04 - val_loss: 1510.4402 - val_mean_squared_error: 1510.4401 - val_acc: 6.3866e-04\n",
      "Epoch 229/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 409.4544 - mean_squared_error: 409.4544 - acc: 4.9541e-04\n",
      "Epoch 00229: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 408.0748 - mean_squared_error: 408.0748 - acc: 5.3225e-04 - val_loss: 2406.6745 - val_mean_squared_error: 2406.6750 - val_acc: 4.9674e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 421.7415 - mean_squared_error: 421.7414 - acc: 6.0109e-04\n",
      "Epoch 00230: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 420.5575 - mean_squared_error: 420.5575 - acc: 6.2095e-04 - val_loss: 785.6365 - val_mean_squared_error: 785.6366 - val_acc: 5.6770e-04\n",
      "Epoch 231/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 461.7426 - mean_squared_error: 461.7427 - acc: 6.4748e-04\n",
      "Epoch 00231: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 462.0025 - mean_squared_error: 462.0026 - acc: 6.5644e-04 - val_loss: 3247.8926 - val_mean_squared_error: 3247.8918 - val_acc: 0.0000e+00\n",
      "Epoch 232/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 397.0791 - mean_squared_error: 397.0792 - acc: 6.3521e-04\n",
      "Epoch 00232: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 396.4905 - mean_squared_error: 396.4906 - acc: 6.2095e-04 - val_loss: 1317.3408 - val_mean_squared_error: 1317.3411 - val_acc: 7.0962e-04\n",
      "Epoch 233/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 449.0319 - mean_squared_error: 449.0320 - acc: 5.3016e-04\n",
      "Epoch 00233: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 446.9213 - mean_squared_error: 446.9214 - acc: 5.6773e-04 - val_loss: 8971.6018 - val_mean_squared_error: 8971.6016 - val_acc: 1.4192e-04\n",
      "Epoch 234/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 403.1638 - mean_squared_error: 403.1638 - acc: 6.4220e-04\n",
      "Epoch 00234: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 402.8866 - mean_squared_error: 402.8866 - acc: 6.2095e-04 - val_loss: 6207.9376 - val_mean_squared_error: 6207.9375 - val_acc: 7.0962e-05\n",
      "Epoch 235/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 688.6881 - mean_squared_error: 688.6880 - acc: 5.0269e-04\n",
      "Epoch 00235: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 684.4890 - mean_squared_error: 684.4888 - acc: 4.9676e-04 - val_loss: 786.2758 - val_mean_squared_error: 786.2760 - val_acc: 7.0962e-04\n",
      "Epoch 236/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 511.4180 - mean_squared_error: 511.4177 - acc: 5.5147e-04\n",
      "Epoch 00236: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 505.5079 - mean_squared_error: 505.5076 - acc: 5.3225e-04 - val_loss: 1701.2751 - val_mean_squared_error: 1701.2756 - val_acc: 0.0000e+00\n",
      "Epoch 237/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 443.7446 - mean_squared_error: 443.7444 - acc: 6.7736e-04\n",
      "Epoch 00237: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 443.7602 - mean_squared_error: 443.7601 - acc: 6.9192e-04 - val_loss: 6444.7882 - val_mean_squared_error: 6444.7886 - val_acc: 4.2577e-04\n",
      "Epoch 238/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 405.0083 - mean_squared_error: 405.0081 - acc: 5.0633e-04\n",
      "Epoch 00238: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 405.4346 - mean_squared_error: 405.4344 - acc: 4.9676e-04 - val_loss: 1224.1793 - val_mean_squared_error: 1224.1794 - val_acc: 4.9674e-04\n",
      "Epoch 239/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 474.8901 - mean_squared_error: 474.8900 - acc: 5.8288e-04\n",
      "Epoch 00239: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 471.4189 - mean_squared_error: 471.4189 - acc: 5.8547e-04 - val_loss: 9562.8604 - val_mean_squared_error: 9562.8594 - val_acc: 4.2577e-04\n",
      "Epoch 240/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 474.3993 - mean_squared_error: 474.3993 - acc: 5.2347e-04\n",
      "Epoch 00240: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 473.5497 - mean_squared_error: 473.5496 - acc: 5.4999e-04 - val_loss: 2176.9963 - val_mean_squared_error: 2176.9961 - val_acc: 1.4192e-04\n",
      "Epoch 241/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 408.6435 - mean_squared_error: 408.6434 - acc: 3.1250e-04\n",
      "Epoch 00241: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 408.1223 - mean_squared_error: 408.1222 - acc: 3.0161e-04 - val_loss: 853.6582 - val_mean_squared_error: 853.6583 - val_acc: 5.6770e-04\n",
      "Epoch 242/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 445.9035 - mean_squared_error: 445.9037 - acc: 5.6838e-04\n",
      "Epoch 00242: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 445.6902 - mean_squared_error: 445.6905 - acc: 5.6773e-04 - val_loss: 16079.3507 - val_mean_squared_error: 16079.3486 - val_acc: 3.5481e-04\n",
      "Epoch 243/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 770.4050 - mean_squared_error: 770.4053 - acc: 4.9091e-04\n",
      "Epoch 00243: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 761.3204 - mean_squared_error: 761.3207 - acc: 4.7902e-04 - val_loss: 800.3712 - val_mean_squared_error: 800.3713 - val_acc: 2.1289e-04\n",
      "Epoch 244/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 563.9588 - mean_squared_error: 563.9587 - acc: 5.4545e-04   ETA: 0s - loss: 1067.5669 - mean_square\n",
      "Epoch 00244: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 559.7383 - mean_squared_error: 559.7382 - acc: 5.3225e-04 - val_loss: 801.3620 - val_mean_squared_error: 801.3621 - val_acc: 3.5481e-04\n",
      "Epoch 245/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 484.7603 - mean_squared_error: 484.7604 - acc: 6.0498e-04\n",
      "Epoch 00245: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 484.5144 - mean_squared_error: 484.5145 - acc: 6.2095e-04 - val_loss: 806.9481 - val_mean_squared_error: 806.9482 - val_acc: 2.1289e-04\n",
      "Epoch 246/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 492.2589 - mean_squared_error: 492.2591 - acc: 5.2347e-04\n",
      "Epoch 00246: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 490.4180 - mean_squared_error: 490.4181 - acc: 5.1450e-04 - val_loss: 1397.2226 - val_mean_squared_error: 1397.2228 - val_acc: 0.0000e+00\n",
      "Epoch 247/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 427.0378 - mean_squared_error: 427.0379 - acc: 5.8719e-04\n",
      "Epoch 00247: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 426.7837 - mean_squared_error: 426.7838 - acc: 5.8547e-04 - val_loss: 717.9125 - val_mean_squared_error: 717.9123 - val_acc: 3.5481e-04\n",
      "Epoch 248/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 781.4614 - mean_squared_error: 781.4617 - acc: 5.0725e-04\n",
      "Epoch 00248: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 773.4433 - mean_squared_error: 773.4435 - acc: 5.1450e-04 - val_loss: 4226.9094 - val_mean_squared_error: 4226.9097 - val_acc: 2.8385e-04\n",
      "Epoch 249/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 380.2840 - mean_squared_error: 380.2840 - acc: 6.9853e-04\n",
      "Epoch 00249: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 399.3083 - mean_squared_error: 399.3082 - acc: 6.9192e-04 - val_loss: 1939.1852 - val_mean_squared_error: 1939.1853 - val_acc: 7.8058e-04\n",
      "Epoch 250/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 621.4149 - mean_squared_error: 621.4149 - acc: 5.1661e-04\n",
      "Epoch 00250: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 611.2715 - mean_squared_error: 611.2714 - acc: 5.1450e-04 - val_loss: 2793.8774 - val_mean_squared_error: 2793.8779 - val_acc: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 400.9874 - mean_squared_error: 400.9873 - acc: 3.7567e-04\n",
      "Epoch 00251: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 400.8989 - mean_squared_error: 400.8988 - acc: 3.7257e-04 - val_loss: 1124.6833 - val_mean_squared_error: 1124.6835 - val_acc: 7.0962e-05\n",
      "Epoch 252/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 581.4693 - mean_squared_error: 581.4693 - acc: 5.0269e-04\n",
      "Epoch 00252: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 579.2673 - mean_squared_error: 579.2673 - acc: 4.9676e-04 - val_loss: 798.6120 - val_mean_squared_error: 798.6120 - val_acc: 7.0962e-05\n",
      "Epoch 253/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 900.3908 - mean_squared_error: 900.3912 - acc: 5.6261e-04\n",
      "Epoch 00253: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 888.9106 - mean_squared_error: 888.9110 - acc: 5.4999e-04 - val_loss: 765.9217 - val_mean_squared_error: 765.9216 - val_acc: 7.0962e-05\n",
      "Epoch 254/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 584.2901 - mean_squared_error: 584.2906 - acc: 5.6673e-04\n",
      "Epoch 00254: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 578.0787 - mean_squared_error: 578.0793 - acc: 5.4999e-04 - val_loss: 758.1992 - val_mean_squared_error: 758.1994 - val_acc: 7.0962e-05\n",
      "Epoch 255/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 415.7347 - mean_squared_error: 415.7346 - acc: 6.0662e-04\n",
      "Epoch 00255: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 414.1238 - mean_squared_error: 414.1236 - acc: 6.0321e-04 - val_loss: 1686.4316 - val_mean_squared_error: 1686.4316 - val_acc: 3.5481e-04\n",
      "Epoch 256/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 382.3748 - mean_squared_error: 382.3748 - acc: 5.6466e-04\n",
      "Epoch 00256: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 422.3623 - mean_squared_error: 422.3623 - acc: 5.6773e-04 - val_loss: 2997.7488 - val_mean_squared_error: 2997.7490 - val_acc: 4.9674e-04\n",
      "Epoch 257/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 406.9706 - mean_squared_error: 406.9704 - acc: 6.6421e-04\n",
      "Epoch 00257: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 405.3413 - mean_squared_error: 405.3411 - acc: 7.0966e-04 - val_loss: 780.4888 - val_mean_squared_error: 780.4888 - val_acc: 6.3866e-04\n",
      "Epoch 258/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 405.4594 - mean_squared_error: 405.4596 - acc: 5.8608e-04\n",
      "Epoch 00258: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 404.1654 - mean_squared_error: 404.1656 - acc: 5.8547e-04 - val_loss: 5326.1739 - val_mean_squared_error: 5326.1743 - val_acc: 2.1289e-04\n",
      "Epoch 259/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 496.7980 - mean_squared_error: 496.7982 - acc: 4.8128e-04\n",
      "Epoch 00259: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 496.5721 - mean_squared_error: 496.5723 - acc: 4.7902e-04 - val_loss: 771.5119 - val_mean_squared_error: 771.5120 - val_acc: 0.0000e+00\n",
      "Epoch 260/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 896.2793 - mean_squared_error: 896.2794 - acc: 5.5856e-04\n",
      "Epoch 00260: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 888.3092 - mean_squared_error: 888.3093 - acc: 5.4999e-04 - val_loss: 806.9243 - val_mean_squared_error: 806.9243 - val_acc: 5.6770e-04\n",
      "Epoch 261/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 421.4029 - mean_squared_error: 421.4028 - acc: 3.7838e-04\n",
      "Epoch 00261: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 421.2423 - mean_squared_error: 421.2422 - acc: 4.0805e-04 - val_loss: 778.5581 - val_mean_squared_error: 778.5582 - val_acc: 7.8058e-04\n",
      "Epoch 262/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 396.4265 - mean_squared_error: 396.4264 - acc: 6.5574e-04\n",
      "Epoch 00262: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 396.8109 - mean_squared_error: 396.8108 - acc: 6.3869e-04 - val_loss: 829.4450 - val_mean_squared_error: 829.4450 - val_acc: 3.5481e-04\n",
      "Epoch 263/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 742.6126 - mean_squared_error: 742.6124 - acc: 5.0179e-04\n",
      "Epoch 00263: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 738.1473 - mean_squared_error: 738.1471 - acc: 5.1450e-04 - val_loss: 734.1450 - val_mean_squared_error: 734.1453 - val_acc: 1.4192e-04\n",
      "Epoch 264/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 379.6554 - mean_squared_error: 379.6556 - acc: 5.6261e-04\n",
      "Epoch 00264: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 378.8821 - mean_squared_error: 378.8823 - acc: 5.4999e-04 - val_loss: 1414.3755 - val_mean_squared_error: 1414.3755 - val_acc: 4.2577e-04\n",
      "Epoch 265/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 440.9041 - mean_squared_error: 440.9040 - acc: 6.6308e-04\n",
      "Epoch 00265: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 440.3065 - mean_squared_error: 440.3065 - acc: 6.5644e-04 - val_loss: 794.0952 - val_mean_squared_error: 794.0953 - val_acc: 9.2251e-04\n",
      "Epoch 266/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 566.3764 - mean_squared_error: 566.3765 - acc: 6.2837e-04 ETA: 0s - loss: 373.7434 - mean_squared_error: 373.\n",
      "Epoch 00266: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 563.7122 - mean_squared_error: 563.7123 - acc: 6.2095e-04 - val_loss: 3943.2255 - val_mean_squared_error: 3943.2241 - val_acc: 7.0962e-04\n",
      "Epoch 267/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 592.7177 - mean_squared_error: 592.7178 - acc: 5.0360e-04\n",
      "Epoch 00267: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 589.6655 - mean_squared_error: 589.6655 - acc: 4.9676e-04 - val_loss: 782.2381 - val_mean_squared_error: 782.2381 - val_acc: 2.1289e-04\n",
      "Epoch 268/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 843.7052 - mean_squared_error: 843.7054 - acc: 5.4446e-04\n",
      "Epoch 00268: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 833.1897 - mean_squared_error: 833.1899 - acc: 5.3225e-04 - val_loss: 1007.4749 - val_mean_squared_error: 1007.4755 - val_acc: 2.8385e-04\n",
      "Epoch 269/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 469.3551 - mean_squared_error: 469.3551 - acc: 5.2441e-04\n",
      "Epoch 00269: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 468.6112 - mean_squared_error: 468.6113 - acc: 5.4999e-04 - val_loss: 3445.2600 - val_mean_squared_error: 3445.2603 - val_acc: 2.8385e-04\n",
      "Epoch 270/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 778.6072 - mean_squared_error: 778.6069 - acc: 6.0932e-04\n",
      "Epoch 00270: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 774.3860 - mean_squared_error: 774.3859 - acc: 6.0321e-04 - val_loss: 3754.0055 - val_mean_squared_error: 3754.0056 - val_acc: 2.1289e-04\n",
      "Epoch 271/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 505.4333 - mean_squared_error: 505.4333 - acc: 7.1301e-04\n",
      "Epoch 00271: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 504.6030 - mean_squared_error: 504.6030 - acc: 7.0966e-04 - val_loss: 732.7048 - val_mean_squared_error: 732.7047 - val_acc: 4.9674e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 592.3200 - mean_squared_error: 592.3199 - acc: 5.7143e-04\n",
      "Epoch 00272: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 591.1179 - mean_squared_error: 591.1177 - acc: 5.6773e-04 - val_loss: 2333.1073 - val_mean_squared_error: 2333.1072 - val_acc: 0.0000e+00\n",
      "Epoch 273/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 445.9136 - mean_squared_error: 445.9134 - acc: 6.7395e-04\n",
      "Epoch 00273: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 444.2237 - mean_squared_error: 444.2235 - acc: 6.7418e-04 - val_loss: 721.3530 - val_mean_squared_error: 721.3530 - val_acc: 2.1289e-04\n",
      "Epoch 274/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 598.3757 - mean_squared_error: 598.3755 - acc: 7.2595e-04\n",
      "Epoch 00274: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 593.1580 - mean_squared_error: 593.1578 - acc: 7.0966e-04 - val_loss: 830.7668 - val_mean_squared_error: 830.7670 - val_acc: 7.0962e-05\n",
      "Epoch 275/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 442.2384 - mean_squared_error: 442.2383 - acc: 4.4037e-04\n",
      "Epoch 00275: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 440.1800 - mean_squared_error: 440.1799 - acc: 4.2580e-04 - val_loss: 1006.0943 - val_mean_squared_error: 1006.0944 - val_acc: 3.5481e-04\n",
      "Epoch 276/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 385.1563 - mean_squared_error: 385.1562 - acc: 6.1931e-04\n",
      "Epoch 00276: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 385.6866 - mean_squared_error: 385.6865 - acc: 6.0321e-04 - val_loss: 772.7124 - val_mean_squared_error: 772.7125 - val_acc: 2.8385e-04\n",
      "Epoch 277/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 387.7799 - mean_squared_error: 387.7798 - acc: 4.5620e-04\n",
      "Epoch 00277: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 388.9018 - mean_squared_error: 388.9018 - acc: 4.4354e-04 - val_loss: 925.5904 - val_mean_squared_error: 925.5904 - val_acc: 2.8385e-04\n",
      "Epoch 278/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 422.6771 - mean_squared_error: 422.6771 - acc: 4.5704e-04\n",
      "Epoch 00278: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 420.9687 - mean_squared_error: 420.9687 - acc: 4.6128e-04 - val_loss: 2291.3522 - val_mean_squared_error: 2291.3528 - val_acc: 4.2577e-04\n",
      "Epoch 279/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 383.7840 - mean_squared_error: 383.7837 - acc: 6.2837e-04\n",
      "Epoch 00279: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 383.4955 - mean_squared_error: 383.4952 - acc: 6.2095e-04 - val_loss: 742.5931 - val_mean_squared_error: 742.5933 - val_acc: 0.0000e+00\n",
      "Epoch 280/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 542.2688 - mean_squared_error: 542.2688 - acc: 6.4401e-04\n",
      "Epoch 00280: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 540.8170 - mean_squared_error: 540.8171 - acc: 6.3869e-04 - val_loss: 754.1253 - val_mean_squared_error: 754.1254 - val_acc: 6.3866e-04\n",
      "Epoch 281/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 412.4836 - mean_squared_error: 412.4836 - acc: 4.2279e-04\n",
      "Epoch 00281: val_loss did not improve from 694.85938\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 411.0679 - mean_squared_error: 411.0679 - acc: 4.4354e-04 - val_loss: 4154.9127 - val_mean_squared_error: 4154.9136 - val_acc: 7.0962e-05\n",
      "Epoch 282/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 1018.7621 - mean_squared_error: 1018.7624 - acc: 6.3521e-04\n",
      "Epoch 00282: val_loss improved from 694.85938 to 663.52857, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 1004.8708 - mean_squared_error: 1004.8711 - acc: 6.2095e-04 - val_loss: 663.5286 - val_mean_squared_error: 663.5286 - val_acc: 3.5481e-04\n",
      "Epoch 283/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 416.3877 - mean_squared_error: 416.3877 - acc: 4.8649e-04\n",
      "Epoch 00283: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 416.1167 - mean_squared_error: 416.1167 - acc: 5.1450e-04 - val_loss: 732.7527 - val_mean_squared_error: 732.7526 - val_acc: 7.0962e-04\n",
      "Epoch 284/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 413.1288 - mean_squared_error: 413.1288 - acc: 6.3869e-04\n",
      "Epoch 00284: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 414.2273 - mean_squared_error: 414.2273 - acc: 6.3869e-04 - val_loss: 692.7186 - val_mean_squared_error: 692.7185 - val_acc: 7.0962e-04\n",
      "Epoch 285/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 374.5806 - mean_squared_error: 374.5807 - acc: 6.7766e-04\n",
      "Epoch 00285: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 373.6029 - mean_squared_error: 373.6029 - acc: 6.9192e-04 - val_loss: 759.6102 - val_mean_squared_error: 759.6103 - val_acc: 7.8058e-04\n",
      "Epoch 286/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 376.0378 - mean_squared_error: 376.0376 - acc: 5.9246e-04\n",
      "Epoch 00286: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 375.6082 - mean_squared_error: 375.6080 - acc: 6.2095e-04 - val_loss: 704.6944 - val_mean_squared_error: 704.6943 - val_acc: 3.5481e-04\n",
      "Epoch 287/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 380.5880 - mean_squared_error: 380.5883 - acc: 6.1706e-04\n",
      "Epoch 00287: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 381.2388 - mean_squared_error: 381.2390 - acc: 6.2095e-04 - val_loss: 764.5607 - val_mean_squared_error: 764.5608 - val_acc: 7.0962e-05\n",
      "Epoch 288/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 520.2299 - mean_squared_error: 520.2298 - acc: 5.1471e-04\n",
      "Epoch 00288: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 515.2078 - mean_squared_error: 515.2078 - acc: 4.9676e-04 - val_loss: 1907.5892 - val_mean_squared_error: 1907.5890 - val_acc: 6.3866e-04\n",
      "Epoch 289/3000\n",
      "53600/56365 [===========================>..] - ETA: 0s - loss: 375.4342 - mean_squared_error: 375.4343 - acc: 7.0896e-04\n",
      "Epoch 00289: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 374.4287 - mean_squared_error: 374.4288 - acc: 7.2740e-04 - val_loss: 892.0746 - val_mean_squared_error: 892.0748 - val_acc: 2.1289e-04\n",
      "Epoch 290/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 480.1782 - mean_squared_error: 480.1782 - acc: 4.4362e-04\n",
      "Epoch 00290: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 474.7760 - mean_squared_error: 474.7759 - acc: 4.6128e-04 - val_loss: 1215.4695 - val_mean_squared_error: 1215.4697 - val_acc: 0.0000e+00\n",
      "Epoch 291/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 410.8739 - mean_squared_error: 410.8738 - acc: 6.5934e-04\n",
      "Epoch 00291: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 410.7465 - mean_squared_error: 410.7465 - acc: 6.9192e-04 - val_loss: 759.1573 - val_mean_squared_error: 759.1574 - val_acc: 7.0962e-05\n",
      "Epoch 292/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 509.9163 - mean_squared_error: 509.9163 - acc: 6.3943e-04\n",
      "Epoch 00292: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 509.6974 - mean_squared_error: 509.6973 - acc: 6.3869e-04 - val_loss: 726.5168 - val_mean_squared_error: 726.5168 - val_acc: 8.5155e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 374.8888 - mean_squared_error: 374.8887 - acc: 5.7090e-04\n",
      "Epoch 00293: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 373.9396 - mean_squared_error: 373.9395 - acc: 5.6773e-04 - val_loss: 1132.4694 - val_mean_squared_error: 1132.4692 - val_acc: 1.4192e-04\n",
      "Epoch 294/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 459.6500 - mean_squared_error: 459.6499 - acc: 6.0329e-04\n",
      "Epoch 00294: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 457.0576 - mean_squared_error: 457.0575 - acc: 5.8547e-04 - val_loss: 756.4697 - val_mean_squared_error: 756.4695 - val_acc: 2.1289e-04\n",
      "Epoch 295/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 407.6966 - mean_squared_error: 407.6965 - acc: 5.3604e-04\n",
      "Epoch 00295: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 406.3410 - mean_squared_error: 406.3409 - acc: 5.6773e-04 - val_loss: 804.4898 - val_mean_squared_error: 804.4898 - val_acc: 2.8385e-04\n",
      "Epoch 296/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 359.6262 - mean_squared_error: 359.6262 - acc: 5.9353e-04\n",
      "Epoch 00296: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 360.2218 - mean_squared_error: 360.2218 - acc: 5.8547e-04 - val_loss: 1190.5773 - val_mean_squared_error: 1190.5771 - val_acc: 2.8385e-04\n",
      "Epoch 297/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 414.0030 - mean_squared_error: 414.0031 - acc: 5.3667e-04\n",
      "Epoch 00297: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 413.4965 - mean_squared_error: 413.4966 - acc: 5.4999e-04 - val_loss: 3877.8175 - val_mean_squared_error: 3877.8169 - val_acc: 2.1289e-04\n",
      "Epoch 298/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 373.4078 - mean_squared_error: 373.4079 - acc: 5.9891e-04\n",
      "Epoch 00298: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 511.5421 - mean_squared_error: 511.5421 - acc: 5.8547e-04 - val_loss: 990.4895 - val_mean_squared_error: 990.4899 - val_acc: 0.0013\n",
      "Epoch 299/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 561.0449 - mean_squared_error: 561.0450 - acc: 5.8824e-04\n",
      "Epoch 00299: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 560.0145 - mean_squared_error: 560.0147 - acc: 5.8547e-04 - val_loss: 1193.8522 - val_mean_squared_error: 1193.8522 - val_acc: 2.8385e-04\n",
      "Epoch 300/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 380.8613 - mean_squared_error: 380.8613 - acc: 6.8841e-04\n",
      "Epoch 00300: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 380.3727 - mean_squared_error: 380.3728 - acc: 6.7418e-04 - val_loss: 985.6142 - val_mean_squared_error: 985.6142 - val_acc: 6.3866e-04\n",
      "Epoch 301/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 365.1699 - mean_squared_error: 365.1702 - acc: 5.9459e-04\n",
      "Epoch 00301: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 365.4591 - mean_squared_error: 365.4594 - acc: 5.8547e-04 - val_loss: 1645.3871 - val_mean_squared_error: 1645.3873 - val_acc: 1.4192e-04\n",
      "Epoch 302/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 382.0522 - mean_squared_error: 382.0522 - acc: 6.5954e-04\n",
      "Epoch 00302: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 382.0917 - mean_squared_error: 382.0917 - acc: 6.5644e-04 - val_loss: 778.2080 - val_mean_squared_error: 778.2081 - val_acc: 7.0962e-04\n",
      "Epoch 303/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 574.0710 - mean_squared_error: 574.0712 - acc: 6.0109e-04\n",
      "Epoch 00303: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 569.6409 - mean_squared_error: 569.6411 - acc: 6.3869e-04 - val_loss: 683.6436 - val_mean_squared_error: 683.6435 - val_acc: 4.9674e-04\n",
      "Epoch 304/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 540.4808 - mean_squared_error: 540.4804 - acc: 6.2724e-04 ETA: 0s - loss: 686.3659 - mean_squared_error: 686.\n",
      "Epoch 00304: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 538.5290 - mean_squared_error: 538.5286 - acc: 6.2095e-04 - val_loss: 1004.6320 - val_mean_squared_error: 1004.6317 - val_acc: 4.2577e-04\n",
      "Epoch 305/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 365.0499 - mean_squared_error: 365.0500 - acc: 6.8468e-04\n",
      "Epoch 00305: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 364.8236 - mean_squared_error: 364.8236 - acc: 7.2740e-04 - val_loss: 2308.6832 - val_mean_squared_error: 2308.6836 - val_acc: 3.5481e-04\n",
      "Epoch 306/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 468.7521 - mean_squared_error: 468.7521 - acc: 4.1441e-04\n",
      "Epoch 00306: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 468.5308 - mean_squared_error: 468.5309 - acc: 4.2580e-04 - val_loss: 784.5225 - val_mean_squared_error: 784.5225 - val_acc: 0.0000e+00\n",
      "Epoch 307/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 776.8129 - mean_squared_error: 776.8137 - acc: 5.8929e-04\n",
      "Epoch 00307: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 773.8693 - mean_squared_error: 773.8701 - acc: 5.8547e-04 - val_loss: 722.4470 - val_mean_squared_error: 722.4471 - val_acc: 7.0962e-05\n",
      "Epoch 308/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 368.9499 - mean_squared_error: 368.9500 - acc: 6.7395e-04\n",
      "Epoch 00308: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 368.9035 - mean_squared_error: 368.9035 - acc: 7.0966e-04 - val_loss: 780.6920 - val_mean_squared_error: 780.6920 - val_acc: 3.5481e-04\n",
      "Epoch 309/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 387.4708 - mean_squared_error: 387.4707 - acc: 5.8182e-04\n",
      "Epoch 00309: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 386.9710 - mean_squared_error: 386.9710 - acc: 6.0321e-04 - val_loss: 722.3958 - val_mean_squared_error: 722.3958 - val_acc: 4.9674e-04\n",
      "Epoch 310/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 418.4644 - mean_squared_error: 418.4644 - acc: 5.8824e-04\n",
      "Epoch 00310: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 418.8221 - mean_squared_error: 418.8221 - acc: 5.8547e-04 - val_loss: 1191.9502 - val_mean_squared_error: 1191.9503 - val_acc: 1.4192e-04\n",
      "Epoch 311/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 386.1416 - mean_squared_error: 386.1416 - acc: 5.9783e-04\n",
      "Epoch 00311: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 384.9269 - mean_squared_error: 384.9268 - acc: 5.8547e-04 - val_loss: 740.6931 - val_mean_squared_error: 740.6932 - val_acc: 7.0962e-05\n",
      "Epoch 312/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 571.9694 - mean_squared_error: 571.9699 - acc: 6.9395e-04\n",
      "Epoch 00312: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 571.2685 - mean_squared_error: 571.2690 - acc: 7.0966e-04 - val_loss: 991.4134 - val_mean_squared_error: 991.4135 - val_acc: 5.6770e-04\n",
      "Epoch 313/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 365.5054 - mean_squared_error: 365.5055 - acc: 4.7359e-04\n",
      "Epoch 00313: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 365.6221 - mean_squared_error: 365.6222 - acc: 4.9676e-04 - val_loss: 1501.9813 - val_mean_squared_error: 1501.9808 - val_acc: 2.1289e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 914.1598 - mean_squared_error: 914.1595 - acc: 6.4057e-04\n",
      "Epoch 00314: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 912.4320 - mean_squared_error: 912.4318 - acc: 6.3869e-04 - val_loss: 743.0251 - val_mean_squared_error: 743.0252 - val_acc: 2.1289e-04\n",
      "Epoch 315/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 568.9265 - mean_squared_error: 568.9263 - acc: 5.6881e-04\n",
      "Epoch 00315: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 562.3105 - mean_squared_error: 562.3102 - acc: 5.4999e-04 - val_loss: 722.3037 - val_mean_squared_error: 722.3033 - val_acc: 0.0000e+00\n",
      "Epoch 316/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 362.3673 - mean_squared_error: 362.3672 - acc: 7.2202e-04\n",
      "Epoch 00316: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 362.5532 - mean_squared_error: 362.5531 - acc: 7.4514e-04 - val_loss: 808.1471 - val_mean_squared_error: 808.1472 - val_acc: 0.0000e+00\n",
      "Epoch 317/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 357.8616 - mean_squared_error: 357.8615 - acc: 6.3063e-04\n",
      "Epoch 00317: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 357.2460 - mean_squared_error: 357.2459 - acc: 6.2095e-04 - val_loss: 765.4047 - val_mean_squared_error: 765.4045 - val_acc: 7.0962e-05\n",
      "Epoch 318/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 563.8402 - mean_squared_error: 563.8403 - acc: 4.3165e-04\n",
      "Epoch 00318: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 560.7661 - mean_squared_error: 560.7661 - acc: 4.4354e-04 - val_loss: 1148.3503 - val_mean_squared_error: 1148.3501 - val_acc: 1.4192e-04\n",
      "Epoch 319/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 455.6966 - mean_squared_error: 455.6968 - acc: 5.8824e-04\n",
      "Epoch 00319: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 452.4429 - mean_squared_error: 452.4430 - acc: 6.2095e-04 - val_loss: 3287.2861 - val_mean_squared_error: 3287.2852 - val_acc: 2.1289e-04\n",
      "Epoch 320/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 377.4187 - mean_squared_error: 377.4187 - acc: 6.3177e-04\n",
      "Epoch 00320: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 378.6215 - mean_squared_error: 378.6216 - acc: 6.2095e-04 - val_loss: 742.1132 - val_mean_squared_error: 742.1129 - val_acc: 8.5155e-04\n",
      "Epoch 321/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 373.6515 - mean_squared_error: 373.6517 - acc: 5.1002e-04\n",
      "Epoch 00321: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 374.3523 - mean_squared_error: 374.3526 - acc: 4.9676e-04 - val_loss: 670.4902 - val_mean_squared_error: 670.4904 - val_acc: 0.0000e+00\n",
      "Epoch 322/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 474.2228 - mean_squared_error: 474.2227 - acc: 6.2157e-04\n",
      "Epoch 00322: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 470.2879 - mean_squared_error: 470.2878 - acc: 6.0321e-04 - val_loss: 1494.7731 - val_mean_squared_error: 1494.7726 - val_acc: 1.4192e-04\n",
      "Epoch 323/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 592.5285 - mean_squared_error: 592.5284 - acc: 6.9091e-04\n",
      "Epoch 00323: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 588.0293 - mean_squared_error: 588.0293 - acc: 6.9192e-04 - val_loss: 1960.9192 - val_mean_squared_error: 1960.9191 - val_acc: 1.4192e-04\n",
      "Epoch 324/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 797.0870 - mean_squared_error: 797.0875 - acc: 5.5160e-04\n",
      "Epoch 00324: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 795.6757 - mean_squared_error: 795.6762 - acc: 5.4999e-04 - val_loss: 706.6112 - val_mean_squared_error: 706.6113 - val_acc: 2.8385e-04\n",
      "Epoch 325/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 397.0127 - mean_squared_error: 397.0126 - acc: 5.6838e-04\n",
      "Epoch 00325: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 396.9820 - mean_squared_error: 396.9819 - acc: 5.6773e-04 - val_loss: 729.2892 - val_mean_squared_error: 729.2892 - val_acc: 7.0962e-05\n",
      "Epoch 326/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 392.0077 - mean_squared_error: 392.0076 - acc: 4.6595e-04\n",
      "Epoch 00326: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 391.3535 - mean_squared_error: 391.3534 - acc: 4.6128e-04 - val_loss: 1038.8057 - val_mean_squared_error: 1038.8059 - val_acc: 6.3866e-04\n",
      "Epoch 327/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 359.6242 - mean_squared_error: 359.6243 - acc: 6.4576e-04\n",
      "Epoch 00327: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 360.8082 - mean_squared_error: 360.8083 - acc: 6.2095e-04 - val_loss: 763.4479 - val_mean_squared_error: 763.4479 - val_acc: 6.3866e-04\n",
      "Epoch 328/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 400.2665 - mean_squared_error: 400.2665 - acc: 4.6512e-04\n",
      "Epoch 00328: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 400.4949 - mean_squared_error: 400.4949 - acc: 4.7902e-04 - val_loss: 753.3792 - val_mean_squared_error: 753.3792 - val_acc: 4.2577e-04\n",
      "Epoch 329/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 515.4035 - mean_squared_error: 515.4036 - acc: 5.5655e-04\n",
      "Epoch 00329: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 513.5452 - mean_squared_error: 513.5454 - acc: 5.4999e-04 - val_loss: 949.7136 - val_mean_squared_error: 949.7134 - val_acc: 5.6770e-04\n",
      "Epoch 330/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 633.5639 - mean_squared_error: 633.5635 - acc: 5.6364e-04\n",
      "Epoch 00330: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 627.3146 - mean_squared_error: 627.3142 - acc: 5.6773e-04 - val_loss: 775.0127 - val_mean_squared_error: 775.0127 - val_acc: 7.8058e-04\n",
      "Epoch 331/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 858.5252 - mean_squared_error: 858.5256 - acc: 7.4007e-04\n",
      "Epoch 00331: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 850.0526 - mean_squared_error: 850.0529 - acc: 7.4514e-04 - val_loss: 755.1322 - val_mean_squared_error: 755.1322 - val_acc: 9.9347e-04\n",
      "Epoch 332/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 499.9476 - mean_squared_error: 499.9473 - acc: 5.7658e-04\n",
      "Epoch 00332: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 498.0745 - mean_squared_error: 498.0743 - acc: 5.6773e-04 - val_loss: 736.7774 - val_mean_squared_error: 736.7775 - val_acc: 6.3866e-04\n",
      "Epoch 333/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 388.8686 - mean_squared_error: 388.8685 - acc: 6.2271e-04\n",
      "Epoch 00333: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 388.4256 - mean_squared_error: 388.4255 - acc: 6.0321e-04 - val_loss: 902.0810 - val_mean_squared_error: 902.0810 - val_acc: 7.0962e-05\n",
      "Epoch 334/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 368.3340 - mean_squared_error: 368.3340 - acc: 5.3286e-04\n",
      "Epoch 00334: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 368.2060 - mean_squared_error: 368.2060 - acc: 5.3225e-04 - val_loss: 770.4917 - val_mean_squared_error: 770.4918 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 443.3496 - mean_squared_error: 443.3496 - acc: 4.8474e-04\n",
      "Epoch 00335: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 443.3916 - mean_squared_error: 443.3916 - acc: 4.7902e-04 - val_loss: 4404.0403 - val_mean_squared_error: 4404.0400 - val_acc: 2.1289e-04\n",
      "Epoch 336/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 383.5916 - mean_squared_error: 383.5916 - acc: 6.6071e-04\n",
      "Epoch 00336: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 383.1905 - mean_squared_error: 383.1905 - acc: 6.5644e-04 - val_loss: 2176.5639 - val_mean_squared_error: 2176.5632 - val_acc: 7.0962e-05\n",
      "Epoch 337/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 385.2763 - mean_squared_error: 385.2762 - acc: 6.9519e-04\n",
      "Epoch 00337: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 385.2407 - mean_squared_error: 385.2407 - acc: 6.9192e-04 - val_loss: 837.4844 - val_mean_squared_error: 837.4843 - val_acc: 2.1289e-04\n",
      "Epoch 338/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 384.4141 - mean_squared_error: 384.4140 - acc: 5.6058e-04\n",
      "Epoch 00338: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 384.1650 - mean_squared_error: 384.1649 - acc: 5.6773e-04 - val_loss: 2134.5670 - val_mean_squared_error: 2134.5669 - val_acc: 4.2577e-04\n",
      "Epoch 339/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 488.5062 - mean_squared_error: 488.5061 - acc: 4.6763e-04\n",
      "Epoch 00339: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 488.1890 - mean_squared_error: 488.1888 - acc: 4.7902e-04 - val_loss: 788.0236 - val_mean_squared_error: 788.0236 - val_acc: 0.0000e+00\n",
      "Epoch 340/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 830.7563 - mean_squared_error: 830.7560 - acc: 7.0909e-04\n",
      "Epoch 00340: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 819.1989 - mean_squared_error: 819.1986 - acc: 6.9192e-04 - val_loss: 715.7764 - val_mean_squared_error: 715.7763 - val_acc: 7.8058e-04\n",
      "Epoch 341/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 380.4545 - mean_squared_error: 380.4546 - acc: 6.5814e-04\n",
      "Epoch 00341: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 379.1813 - mean_squared_error: 379.1813 - acc: 6.3869e-04 - val_loss: 725.9908 - val_mean_squared_error: 725.9908 - val_acc: 7.0962e-04\n",
      "Epoch 342/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 397.5735 - mean_squared_error: 397.5733 - acc: 5.8929e-04\n",
      "Epoch 00342: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 398.3049 - mean_squared_error: 398.3046 - acc: 5.8547e-04 - val_loss: 761.3857 - val_mean_squared_error: 761.3853 - val_acc: 7.0962e-04\n",
      "Epoch 343/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 504.3060 - mean_squared_error: 504.3058 - acc: 5.7658e-04\n",
      "Epoch 00343: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 501.8857 - mean_squared_error: 501.8856 - acc: 5.6773e-04 - val_loss: 946.3086 - val_mean_squared_error: 946.3086 - val_acc: 0.0000e+00\n",
      "Epoch 344/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 348.5425 - mean_squared_error: 348.5424 - acc: 5.1693e-04\n",
      "Epoch 00344: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 348.7628 - mean_squared_error: 348.7628 - acc: 5.4999e-04 - val_loss: 773.1308 - val_mean_squared_error: 773.1309 - val_acc: 1.4192e-04\n",
      "Epoch 345/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 409.7232 - mean_squared_error: 409.7234 - acc: 6.6787e-04\n",
      "Epoch 00345: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 409.5100 - mean_squared_error: 409.5101 - acc: 6.5644e-04 - val_loss: 1637.2408 - val_mean_squared_error: 1637.2411 - val_acc: 2.1289e-04\n",
      "Epoch 346/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 488.1941 - mean_squared_error: 488.1943 - acc: 5.5456e-04\n",
      "Epoch 00346: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 487.4660 - mean_squared_error: 487.4662 - acc: 5.4999e-04 - val_loss: 698.0296 - val_mean_squared_error: 698.0297 - val_acc: 0.0000e+00\n",
      "Epoch 347/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 388.7074 - mean_squared_error: 388.7073 - acc: 5.3286e-04\n",
      "Epoch 00347: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 388.5590 - mean_squared_error: 388.5590 - acc: 5.3225e-04 - val_loss: 779.1588 - val_mean_squared_error: 779.1588 - val_acc: 2.1289e-04\n",
      "Epoch 348/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 417.3701 - mean_squared_error: 417.3699 - acc: 6.2612e-04\n",
      "Epoch 00348: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 417.3039 - mean_squared_error: 417.3038 - acc: 6.2095e-04 - val_loss: 741.8987 - val_mean_squared_error: 741.8988 - val_acc: 1.4192e-04\n",
      "Epoch 349/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 442.0556 - mean_squared_error: 442.0556 - acc: 6.6667e-04\n",
      "Epoch 00349: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 437.3135 - mean_squared_error: 437.3135 - acc: 6.7418e-04 - val_loss: 745.0369 - val_mean_squared_error: 745.0370 - val_acc: 7.0962e-05\n",
      "Epoch 350/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 466.7148 - mean_squared_error: 466.7148 - acc: 5.5856e-04\n",
      "Epoch 00350: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 465.2308 - mean_squared_error: 465.2308 - acc: 5.6773e-04 - val_loss: 1145.4613 - val_mean_squared_error: 1145.4612 - val_acc: 1.4192e-04\n",
      "Epoch 351/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 449.9137 - mean_squared_error: 449.9136 - acc: 6.0329e-04\n",
      "Epoch 00351: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 447.5292 - mean_squared_error: 447.5291 - acc: 5.8547e-04 - val_loss: 759.7918 - val_mean_squared_error: 759.7916 - val_acc: 2.1289e-04\n",
      "Epoch 352/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 551.0092 - mean_squared_error: 551.0090 - acc: 5.3957e-04\n",
      "Epoch 00352: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 548.0820 - mean_squared_error: 548.0817 - acc: 5.3225e-04 - val_loss: 792.8941 - val_mean_squared_error: 792.8940 - val_acc: 0.0014\n",
      "Epoch 353/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 412.7948 - mean_squared_error: 412.7949 - acc: 5.9459e-04\n",
      "Epoch 00353: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 412.4050 - mean_squared_error: 412.4050 - acc: 5.8547e-04 - val_loss: 763.6193 - val_mean_squared_error: 763.6193 - val_acc: 3.5481e-04\n",
      "Epoch 354/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 408.2786 - mean_squared_error: 408.2783 - acc: 6.9395e-04\n",
      "Epoch 00354: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 408.2840 - mean_squared_error: 408.2837 - acc: 6.9192e-04 - val_loss: 735.3286 - val_mean_squared_error: 735.3286 - val_acc: 1.4192e-04\n",
      "Epoch 355/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 707.7011 - mean_squared_error: 707.7013 - acc: 5.0089e-04\n",
      "Epoch 00355: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 704.6541 - mean_squared_error: 704.6543 - acc: 4.9676e-04 - val_loss: 948.1058 - val_mean_squared_error: 948.1052 - val_acc: 7.0962e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 472.0350 - mean_squared_error: 472.0350 - acc: 6.7979e-04\n",
      "Epoch 00356: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 471.1838 - mean_squared_error: 471.1839 - acc: 6.7418e-04 - val_loss: 771.3970 - val_mean_squared_error: 771.3971 - val_acc: 1.4192e-04\n",
      "Epoch 357/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 519.6859 - mean_squared_error: 519.6856 - acc: 5.0817e-04\n",
      "Epoch 00357: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 515.4254 - mean_squared_error: 515.4251 - acc: 4.9676e-04 - val_loss: 708.6330 - val_mean_squared_error: 708.6328 - val_acc: 4.9674e-04\n",
      "Epoch 358/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 350.9891 - mean_squared_error: 350.9889 - acc: 6.5336e-04\n",
      "Epoch 00358: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 351.0788 - mean_squared_error: 351.0786 - acc: 6.3869e-04 - val_loss: 773.0408 - val_mean_squared_error: 773.0406 - val_acc: 1.4192e-04\n",
      "Epoch 359/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 439.6445 - mean_squared_error: 439.6443 - acc: 6.5954e-04\n",
      "Epoch 00359: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 439.1325 - mean_squared_error: 439.1324 - acc: 6.7418e-04 - val_loss: 816.0525 - val_mean_squared_error: 816.0524 - val_acc: 9.2251e-04\n",
      "Epoch 360/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 382.5514 - mean_squared_error: 382.5513 - acc: 5.8182e-04\n",
      "Epoch 00360: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 380.6356 - mean_squared_error: 380.6355 - acc: 6.2095e-04 - val_loss: 724.7453 - val_mean_squared_error: 724.7451 - val_acc: 2.8385e-04\n",
      "Epoch 361/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 401.9895 - mean_squared_error: 401.9895 - acc: 5.2536e-04\n",
      "Epoch 00361: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 401.6873 - mean_squared_error: 401.6873 - acc: 5.1450e-04 - val_loss: 1053.9901 - val_mean_squared_error: 1053.9902 - val_acc: 7.0962e-04\n",
      "Epoch 362/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 344.9973 - mean_squared_error: 344.9973 - acc: 6.6421e-04\n",
      "Epoch 00362: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 405.3350 - mean_squared_error: 405.3351 - acc: 6.5644e-04 - val_loss: 744.4770 - val_mean_squared_error: 744.4771 - val_acc: 7.0962e-04\n",
      "Epoch 363/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 395.8315 - mean_squared_error: 395.8317 - acc: 5.7762e-04\n",
      "Epoch 00363: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 395.5423 - mean_squared_error: 395.5425 - acc: 5.6773e-04 - val_loss: 808.4023 - val_mean_squared_error: 808.4022 - val_acc: 7.0962e-05\n",
      "Epoch 364/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 346.9638 - mean_squared_error: 346.9636 - acc: 5.1693e-04\n",
      "Epoch 00364: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 346.7587 - mean_squared_error: 346.7585 - acc: 5.1450e-04 - val_loss: 765.3306 - val_mean_squared_error: 765.3304 - val_acc: 2.1289e-04\n",
      "Epoch 365/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 412.3276 - mean_squared_error: 412.3274 - acc: 5.5957e-04\n",
      "Epoch 00365: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 412.2063 - mean_squared_error: 412.2062 - acc: 5.8547e-04 - val_loss: 1389.5696 - val_mean_squared_error: 1389.5697 - val_acc: 9.2251e-04\n",
      "Epoch 366/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 575.6503 - mean_squared_error: 575.6505 - acc: 6.4057e-04\n",
      "Epoch 00366: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 574.7599 - mean_squared_error: 574.7601 - acc: 6.3869e-04 - val_loss: 752.2371 - val_mean_squared_error: 752.2372 - val_acc: 3.5481e-04\n",
      "Epoch 367/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 771.0064 - mean_squared_error: 771.0067 - acc: 6.8966e-04\n",
      "Epoch 00367: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 761.5186 - mean_squared_error: 761.5187 - acc: 6.7418e-04 - val_loss: 804.1038 - val_mean_squared_error: 804.1039 - val_acc: 7.0962e-04\n",
      "Epoch 368/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 345.3052 - mean_squared_error: 345.3050 - acc: 5.9353e-04\n",
      "Epoch 00368: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 379.0582 - mean_squared_error: 379.0580 - acc: 6.0321e-04 - val_loss: 847.2953 - val_mean_squared_error: 847.2953 - val_acc: 5.6770e-04\n",
      "Epoch 369/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 501.0440 - mean_squared_error: 501.0439 - acc: 5.2920e-04\n",
      "Epoch 00369: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 496.0033 - mean_squared_error: 496.0032 - acc: 5.4999e-04 - val_loss: 704.7739 - val_mean_squared_error: 704.7737 - val_acc: 1.4192e-04\n",
      "Epoch 370/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 405.9165 - mean_squared_error: 405.9167 - acc: 7.3801e-04\n",
      "Epoch 00370: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 405.9725 - mean_squared_error: 405.9727 - acc: 7.2740e-04 - val_loss: 914.5462 - val_mean_squared_error: 914.5461 - val_acc: 7.0962e-05\n",
      "Epoch 371/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 352.6864 - mean_squared_error: 352.6864 - acc: 6.0998e-04\n",
      "Epoch 00371: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 351.3271 - mean_squared_error: 351.3270 - acc: 5.8547e-04 - val_loss: 749.6310 - val_mean_squared_error: 749.6308 - val_acc: 0.0000e+00\n",
      "Epoch 372/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 416.3060 - mean_squared_error: 416.3061 - acc: 6.3063e-04\n",
      "Epoch 00372: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 414.9823 - mean_squared_error: 414.9824 - acc: 6.3869e-04 - val_loss: 1597.0489 - val_mean_squared_error: 1597.0487 - val_acc: 8.5155e-04\n",
      "Epoch 373/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 355.1936 - mean_squared_error: 355.1935 - acc: 5.1601e-04\n",
      "Epoch 00373: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 354.9784 - mean_squared_error: 354.9783 - acc: 5.1450e-04 - val_loss: 4644.3942 - val_mean_squared_error: 4644.3926 - val_acc: 3.5481e-04\n",
      "Epoch 374/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 536.2234 - mean_squared_error: 536.2232 - acc: 6.4057e-04\n",
      "Epoch 00374: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 535.5043 - mean_squared_error: 535.5040 - acc: 6.3869e-04 - val_loss: 730.1361 - val_mean_squared_error: 730.1360 - val_acc: 3.5481e-04\n",
      "Epoch 375/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 481.0272 - mean_squared_error: 481.0273 - acc: 5.8824e-04\n",
      "Epoch 00375: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 480.5756 - mean_squared_error: 480.5756 - acc: 5.8547e-04 - val_loss: 889.2953 - val_mean_squared_error: 889.2952 - val_acc: 2.1289e-04\n",
      "Epoch 376/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 349.9480 - mean_squared_error: 349.9479 - acc: 6.4286e-04\n",
      "Epoch 00376: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 349.4841 - mean_squared_error: 349.4840 - acc: 6.3869e-04 - val_loss: 1346.7801 - val_mean_squared_error: 1346.7802 - val_acc: 1.4192e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 383.1930 - mean_squared_error: 383.1929 - acc: 6.7766e-04\n",
      "Epoch 00377: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 381.1105 - mean_squared_error: 381.1103 - acc: 6.7418e-04 - val_loss: 715.7972 - val_mean_squared_error: 715.7971 - val_acc: 6.3866e-04\n",
      "Epoch 378/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 468.0829 - mean_squared_error: 468.0830 - acc: 8.9606e-04\n",
      "Epoch 00378: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 466.8357 - mean_squared_error: 466.8359 - acc: 8.8708e-04 - val_loss: 1138.6308 - val_mean_squared_error: 1138.6307 - val_acc: 2.8385e-04\n",
      "Epoch 379/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 355.0963 - mean_squared_error: 355.0963 - acc: 4.7016e-04\n",
      "Epoch 00379: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 354.8113 - mean_squared_error: 354.8112 - acc: 4.7902e-04 - val_loss: 789.9643 - val_mean_squared_error: 789.9641 - val_acc: 7.0962e-05\n",
      "Epoch 380/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 340.5681 - mean_squared_error: 340.5682 - acc: 6.2167e-04\n",
      "Epoch 00380: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.5013 - mean_squared_error: 340.5014 - acc: 6.2095e-04 - val_loss: 782.4242 - val_mean_squared_error: 782.4244 - val_acc: 1.4192e-04\n",
      "Epoch 381/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 375.6235 - mean_squared_error: 375.6235 - acc: 5.5258e-04\n",
      "Epoch 00381: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 375.4148 - mean_squared_error: 375.4147 - acc: 5.4999e-04 - val_loss: 1506.0122 - val_mean_squared_error: 1506.0123 - val_acc: 3.5481e-04\n",
      "Epoch 382/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 378.2795 - mean_squared_error: 378.2795 - acc: 7.1942e-04\n",
      "Epoch 00382: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 377.9116 - mean_squared_error: 377.9115 - acc: 7.0966e-04 - val_loss: 748.4565 - val_mean_squared_error: 748.4564 - val_acc: 7.0962e-05\n",
      "Epoch 383/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 407.1660 - mean_squared_error: 407.1661 - acc: 6.3869e-04\n",
      "Epoch 00383: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 404.1739 - mean_squared_error: 404.1740 - acc: 6.3869e-04 - val_loss: 1083.6844 - val_mean_squared_error: 1083.6843 - val_acc: 2.8385e-04\n",
      "Epoch 384/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 405.4294 - mean_squared_error: 405.4296 - acc: 7.0397e-04\n",
      "Epoch 00384: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 403.8662 - mean_squared_error: 403.8663 - acc: 7.0966e-04 - val_loss: 1818.5958 - val_mean_squared_error: 1818.5955 - val_acc: 7.0962e-04\n",
      "Epoch 385/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 555.2117 - mean_squared_error: 555.2117 - acc: 5.4545e-04\n",
      "Epoch 00385: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 550.3652 - mean_squared_error: 550.3653 - acc: 5.4999e-04 - val_loss: 728.6142 - val_mean_squared_error: 728.6143 - val_acc: 2.8385e-04\n",
      "Epoch 386/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 696.7117 - mean_squared_error: 696.7117 - acc: 5.0450e-04\n",
      "Epoch 00386: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 691.0424 - mean_squared_error: 691.0425 - acc: 5.1450e-04 - val_loss: 863.4817 - val_mean_squared_error: 863.4816 - val_acc: 0.0000e+00\n",
      "Epoch 387/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 386.0326 - mean_squared_error: 386.0329 - acc: 6.1372e-04\n",
      "Epoch 00387: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 385.1004 - mean_squared_error: 385.1006 - acc: 6.2095e-04 - val_loss: 1313.7499 - val_mean_squared_error: 1313.7501 - val_acc: 6.3866e-04\n",
      "Epoch 388/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 342.8132 - mean_squared_error: 342.8134 - acc: 5.8932e-04\n",
      "Epoch 00388: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 342.7740 - mean_squared_error: 342.7741 - acc: 5.6773e-04 - val_loss: 1294.8996 - val_mean_squared_error: 1294.8998 - val_acc: 2.8385e-04\n",
      "Epoch 389/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 358.4712 - mean_squared_error: 358.4709 - acc: 7.1298e-04\n",
      "Epoch 00389: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 357.8575 - mean_squared_error: 357.8572 - acc: 6.9192e-04 - val_loss: 1648.6016 - val_mean_squared_error: 1648.6013 - val_acc: 2.1289e-04\n",
      "Epoch 390/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 336.8638 - mean_squared_error: 336.8643 - acc: 5.7348e-04\n",
      "Epoch 00390: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.4533 - mean_squared_error: 337.4537 - acc: 5.6773e-04 - val_loss: 892.5417 - val_mean_squared_error: 892.5417 - val_acc: 7.0962e-04\n",
      "Epoch 391/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 401.3528 - mean_squared_error: 401.3524 - acc: 5.9459e-04\n",
      "Epoch 00391: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 400.8428 - mean_squared_error: 400.8424 - acc: 5.8547e-04 - val_loss: 770.8564 - val_mean_squared_error: 770.8563 - val_acc: 0.0014\n",
      "Epoch 392/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 447.6545 - mean_squared_error: 447.6543 - acc: 7.4733e-04\n",
      "Epoch 00392: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 447.6505 - mean_squared_error: 447.6503 - acc: 7.4514e-04 - val_loss: 851.6565 - val_mean_squared_error: 851.6566 - val_acc: 1.4192e-04\n",
      "Epoch 393/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 333.7250 - mean_squared_error: 333.7251 - acc: 6.2271e-04\n",
      "Epoch 00393: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 334.3670 - mean_squared_error: 334.3670 - acc: 6.2095e-04 - val_loss: 839.6190 - val_mean_squared_error: 839.6191 - val_acc: 1.4192e-04\n",
      "Epoch 394/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 341.8165 - mean_squared_error: 341.8167 - acc: 6.8345e-04\n",
      "Epoch 00394: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 341.1399 - mean_squared_error: 341.1400 - acc: 6.9192e-04 - val_loss: 778.9256 - val_mean_squared_error: 778.9254 - val_acc: 7.8058e-04\n",
      "Epoch 395/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 394.3084 - mean_squared_error: 394.3083 - acc: 6.4338e-04\n",
      "Epoch 00395: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 392.0019 - mean_squared_error: 392.0019 - acc: 6.7418e-04 - val_loss: 774.3767 - val_mean_squared_error: 774.3766 - val_acc: 1.4192e-04\n",
      "Epoch 396/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 344.9840 - mean_squared_error: 344.9842 - acc: 5.1471e-04\n",
      "Epoch 00396: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 346.0551 - mean_squared_error: 346.0552 - acc: 5.1450e-04 - val_loss: 730.0447 - val_mean_squared_error: 730.0449 - val_acc: 7.0962e-05\n",
      "Epoch 397/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 477.3968 - mean_squared_error: 477.3969 - acc: 6.2724e-04\n",
      "Epoch 00397: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 476.2121 - mean_squared_error: 476.2122 - acc: 6.2095e-04 - val_loss: 790.2845 - val_mean_squared_error: 790.2845 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 401.2759 - mean_squared_error: 401.2760 - acc: 5.9459e-04\n",
      "Epoch 00398: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 401.3542 - mean_squared_error: 401.3543 - acc: 5.8547e-04 - val_loss: 782.3740 - val_mean_squared_error: 782.3738 - val_acc: 7.0962e-04\n",
      "Epoch 399/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 362.5671 - mean_squared_error: 362.5672 - acc: 5.1002e-04\n",
      "Epoch 00399: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 362.2192 - mean_squared_error: 362.2194 - acc: 5.1450e-04 - val_loss: 722.5928 - val_mean_squared_error: 722.5927 - val_acc: 7.0962e-05\n",
      "Epoch 400/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 395.5316 - mean_squared_error: 395.5318 - acc: 6.4516e-04\n",
      "Epoch 00400: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 395.2326 - mean_squared_error: 395.2327 - acc: 6.3869e-04 - val_loss: 780.5772 - val_mean_squared_error: 780.5776 - val_acc: 7.0962e-04\n",
      "Epoch 401/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 363.4172 - mean_squared_error: 363.4173 - acc: 6.2500e-04\n",
      "Epoch 00401: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 363.4555 - mean_squared_error: 363.4555 - acc: 6.5644e-04 - val_loss: 790.9900 - val_mean_squared_error: 790.9900 - val_acc: 4.9674e-04\n",
      "Epoch 402/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 607.6562 - mean_squared_error: 607.6567 - acc: 7.1823e-04\n",
      "Epoch 00402: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 598.0988 - mean_squared_error: 598.0992 - acc: 6.9192e-04 - val_loss: 763.4199 - val_mean_squared_error: 763.4201 - val_acc: 7.0962e-05\n",
      "Epoch 403/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 334.9942 - mean_squared_error: 334.9944 - acc: 6.6667e-04\n",
      "Epoch 00403: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 334.7365 - mean_squared_error: 334.7367 - acc: 6.7418e-04 - val_loss: 882.8360 - val_mean_squared_error: 882.8359 - val_acc: 0.0000e+00\n",
      "Epoch 404/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 402.4066 - mean_squared_error: 402.4066 - acc: 5.1693e-04 ETA: 0s - loss: 346.0039 - mean_squar\n",
      "Epoch 00404: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 31us/sample - loss: 402.3446 - mean_squared_error: 402.3447 - acc: 5.3225e-04 - val_loss: 1014.1838 - val_mean_squared_error: 1014.1838 - val_acc: 5.6770e-04\n",
      "Epoch 405/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 623.5614 - mean_squared_error: 623.5615 - acc: 5.5249e-04\n",
      "Epoch 00405: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 614.2357 - mean_squared_error: 614.2357 - acc: 5.4999e-04 - val_loss: 697.9103 - val_mean_squared_error: 697.9103 - val_acc: 7.0962e-05\n",
      "Epoch 406/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 396.0594 - mean_squared_error: 396.0593 - acc: 6.7151e-04\n",
      "Epoch 00406: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 394.9504 - mean_squared_error: 394.9503 - acc: 7.4514e-04 - val_loss: 704.5878 - val_mean_squared_error: 704.5880 - val_acc: 6.3866e-04\n",
      "Epoch 407/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 333.2241 - mean_squared_error: 333.2242 - acc: 6.3869e-04\n",
      "Epoch 00407: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 333.3225 - mean_squared_error: 333.3226 - acc: 6.3869e-04 - val_loss: 726.4578 - val_mean_squared_error: 726.4580 - val_acc: 5.6770e-04\n",
      "Epoch 408/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 477.9186 - mean_squared_error: 477.9189 - acc: 5.4545e-04\n",
      "Epoch 00408: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 474.7894 - mean_squared_error: 474.7897 - acc: 5.3225e-04 - val_loss: 872.8706 - val_mean_squared_error: 872.8705 - val_acc: 7.0962e-04\n",
      "Epoch 409/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 438.1350 - mean_squared_error: 438.1350 - acc: 7.1429e-04\n",
      "Epoch 00409: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 435.1263 - mean_squared_error: 435.1262 - acc: 6.9192e-04 - val_loss: 696.1218 - val_mean_squared_error: 696.1216 - val_acc: 1.4192e-04\n",
      "Epoch 410/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 386.6320 - mean_squared_error: 386.6322 - acc: 7.2860e-04\n",
      "Epoch 00410: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 385.1274 - mean_squared_error: 385.1275 - acc: 7.0966e-04 - val_loss: 735.0776 - val_mean_squared_error: 735.0777 - val_acc: 7.8058e-04\n",
      "Epoch 411/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 394.7765 - mean_squared_error: 394.7764 - acc: 6.4103e-04\n",
      "Epoch 00411: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 392.8563 - mean_squared_error: 392.8562 - acc: 6.2095e-04 - val_loss: 1075.1344 - val_mean_squared_error: 1075.1346 - val_acc: 2.8385e-04\n",
      "Epoch 412/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 339.9786 - mean_squared_error: 339.9786 - acc: 5.4545e-04 ETA: 1s - loss: 395.0903 - me\n",
      "Epoch 00412: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.8399 - mean_squared_error: 340.8399 - acc: 5.6773e-04 - val_loss: 1844.4227 - val_mean_squared_error: 1844.4224 - val_acc: 7.0962e-05\n",
      "Epoch 413/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 386.2786 - mean_squared_error: 386.2787 - acc: 7.4007e-04\n",
      "Epoch 00413: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 386.3918 - mean_squared_error: 386.3919 - acc: 7.2740e-04 - val_loss: 676.6137 - val_mean_squared_error: 676.6136 - val_acc: 1.4192e-04\n",
      "Epoch 414/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 655.8736 - mean_squared_error: 655.8738 - acc: 5.6673e-04\n",
      "Epoch 00414: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 645.4518 - mean_squared_error: 645.4521 - acc: 5.4999e-04 - val_loss: 775.5751 - val_mean_squared_error: 775.5751 - val_acc: 5.6770e-04\n",
      "Epoch 415/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 358.0521 - mean_squared_error: 358.0519 - acc: 5.9034e-04\n",
      "Epoch 00415: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 357.8644 - mean_squared_error: 357.8642 - acc: 6.0321e-04 - val_loss: 715.1788 - val_mean_squared_error: 715.1787 - val_acc: 0.0000e+00\n",
      "Epoch 416/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 342.0101 - mean_squared_error: 342.0100 - acc: 5.4054e-04\n",
      "Epoch 00416: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 342.2230 - mean_squared_error: 342.2230 - acc: 5.3225e-04 - val_loss: 786.0178 - val_mean_squared_error: 786.0176 - val_acc: 7.0962e-04\n",
      "Epoch 417/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 362.2962 - mean_squared_error: 362.2963 - acc: 6.4865e-04\n",
      "Epoch 00417: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 362.5339 - mean_squared_error: 362.5341 - acc: 6.3869e-04 - val_loss: 710.8458 - val_mean_squared_error: 710.8457 - val_acc: 0.0000e+00\n",
      "Epoch 418/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 412.7581 - mean_squared_error: 412.7582 - acc: 5.3571e-04\n",
      "Epoch 00418: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 412.6480 - mean_squared_error: 412.6481 - acc: 5.4999e-04 - val_loss: 732.6648 - val_mean_squared_error: 732.6650 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 363.4563 - mean_squared_error: 363.4563 - acc: 7.5404e-04 ETA: 0s - loss: 335.4117 - mean_squ\n",
      "Epoch 00419: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 362.8941 - mean_squared_error: 362.8941 - acc: 7.6288e-04 - val_loss: 713.2513 - val_mean_squared_error: 713.2512 - val_acc: 0.0000e+00\n",
      "Epoch 420/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 478.6786 - mean_squared_error: 478.6784 - acc: 6.6427e-04 ETA: 1s - loss: 323.6207 - mean\n",
      "Epoch 00420: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 476.6284 - mean_squared_error: 476.6282 - acc: 6.5644e-04 - val_loss: 699.6512 - val_mean_squared_error: 699.6512 - val_acc: 7.8058e-04\n",
      "Epoch 421/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 340.6109 - mean_squared_error: 340.6109 - acc: 7.3084e-04\n",
      "Epoch 00421: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 340.6109 - mean_squared_error: 340.6110 - acc: 7.2740e-04 - val_loss: 1288.8610 - val_mean_squared_error: 1288.8611 - val_acc: 7.0962e-05\n",
      "Epoch 422/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 356.7049 - mean_squared_error: 356.7051 - acc: 4.1591e-04\n",
      "Epoch 00422: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 356.7056 - mean_squared_error: 356.7058 - acc: 4.2580e-04 - val_loss: 703.1882 - val_mean_squared_error: 703.1881 - val_acc: 7.8058e-04\n",
      "Epoch 423/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 328.5658 - mean_squared_error: 328.5660 - acc: 5.3407e-04\n",
      "Epoch 00423: val_loss did not improve from 663.52857\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 329.4712 - mean_squared_error: 329.4714 - acc: 5.1450e-04 - val_loss: 721.6699 - val_mean_squared_error: 721.6701 - val_acc: 2.8385e-04\n",
      "Epoch 424/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 396.7895 - mean_squared_error: 396.7895 - acc: 6.2612e-04\n",
      "Epoch 00424: val_loss improved from 663.52857 to 663.47691, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 396.1211 - mean_squared_error: 396.1211 - acc: 6.2095e-04 - val_loss: 663.4769 - val_mean_squared_error: 663.4768 - val_acc: 7.0962e-04\n",
      "Epoch 425/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 371.1802 - mean_squared_error: 371.1800 - acc: 5.6159e-04\n",
      "Epoch 00425: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 370.1128 - mean_squared_error: 370.1128 - acc: 5.8547e-04 - val_loss: 694.4023 - val_mean_squared_error: 694.4022 - val_acc: 1.4192e-04\n",
      "Epoch 426/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 433.5996 - mean_squared_error: 433.5996 - acc: 5.4152e-04 ETA: 0s - loss: 443.6469 - mean_squared_error: 443.6468 - acc: 5.2734\n",
      "Epoch 00426: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 431.8314 - mean_squared_error: 431.8314 - acc: 5.3225e-04 - val_loss: 712.7610 - val_mean_squared_error: 712.7609 - val_acc: 0.0000e+00\n",
      "Epoch 427/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 436.3116 - mean_squared_error: 436.3117 - acc: 6.2950e-04\n",
      "Epoch 00427: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 434.7687 - mean_squared_error: 434.7688 - acc: 6.2095e-04 - val_loss: 730.8177 - val_mean_squared_error: 730.8177 - val_acc: 4.2577e-04\n",
      "Epoch 428/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 492.2879 - mean_squared_error: 492.2882 - acc: 5.7143e-04\n",
      "Epoch 00428: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 491.1005 - mean_squared_error: 491.1007 - acc: 5.6773e-04 - val_loss: 696.7796 - val_mean_squared_error: 696.7798 - val_acc: 5.6770e-04\n",
      "Epoch 429/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 439.1834 - mean_squared_error: 439.1833 - acc: 5.8288e-04\n",
      "Epoch 00429: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 436.4336 - mean_squared_error: 436.4336 - acc: 6.0321e-04 - val_loss: 737.0659 - val_mean_squared_error: 737.0658 - val_acc: 8.5155e-04\n",
      "Epoch 430/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 346.9605 - mean_squared_error: 346.9606 - acc: 6.4516e-04\n",
      "Epoch 00430: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 347.0622 - mean_squared_error: 347.0623 - acc: 6.3869e-04 - val_loss: 901.2060 - val_mean_squared_error: 901.2059 - val_acc: 2.8385e-04\n",
      "Epoch 431/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 330.2854 - mean_squared_error: 330.2853 - acc: 5.8824e-04\n",
      "Epoch 00431: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 330.0782 - mean_squared_error: 330.0781 - acc: 6.3869e-04 - val_loss: 707.0908 - val_mean_squared_error: 707.0907 - val_acc: 7.0962e-05\n",
      "Epoch 432/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 406.8524 - mean_squared_error: 406.8524 - acc: 7.0397e-04\n",
      "Epoch 00432: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 405.6351 - mean_squared_error: 405.6351 - acc: 6.9192e-04 - val_loss: 714.6055 - val_mean_squared_error: 714.6055 - val_acc: 6.3866e-04\n",
      "Epoch 433/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 448.2880 - mean_squared_error: 448.2878 - acc: 5.0542e-04\n",
      "Epoch 00433: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 445.9223 - mean_squared_error: 445.9220 - acc: 5.1450e-04 - val_loss: 722.1936 - val_mean_squared_error: 722.1937 - val_acc: 7.0962e-05\n",
      "Epoch 434/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 501.1443 - mean_squared_error: 501.1443 - acc: 6.2612e-04 ETA: 0s - loss: 561.6518 - mean_squared_error: 561.6515 - a\n",
      "Epoch 00434: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 499.5636 - mean_squared_error: 499.5636 - acc: 6.3869e-04 - val_loss: 795.3215 - val_mean_squared_error: 795.3212 - val_acc: 2.1289e-04\n",
      "Epoch 435/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 360.2848 - mean_squared_error: 360.2847 - acc: 5.7451e-04 ETA: 0s - loss: 335.5374 - mean_squared\n",
      "Epoch 00435: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 359.5969 - mean_squared_error: 359.5969 - acc: 5.6773e-04 - val_loss: 716.3888 - val_mean_squared_error: 716.3887 - val_acc: 2.1289e-04\n",
      "Epoch 436/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 339.3753 - mean_squared_error: 339.3753 - acc: 5.7762e-04\n",
      "Epoch 00436: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 338.8905 - mean_squared_error: 338.8905 - acc: 5.8547e-04 - val_loss: 825.0796 - val_mean_squared_error: 825.0792 - val_acc: 4.9674e-04\n",
      "Epoch 437/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 416.6154 - mean_squared_error: 416.6155 - acc: 6.1931e-04\n",
      "Epoch 00437: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 413.9402 - mean_squared_error: 413.9403 - acc: 6.3869e-04 - val_loss: 679.2619 - val_mean_squared_error: 679.2618 - val_acc: 3.5481e-04\n",
      "Epoch 438/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 458.7574 - mean_squared_error: 458.7574 - acc: 5.9246e-04\n",
      "Epoch 00438: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 456.7404 - mean_squared_error: 456.7404 - acc: 5.8547e-04 - val_loss: 726.7462 - val_mean_squared_error: 726.7462 - val_acc: 8.5155e-04\n",
      "Epoch 439/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56200/56365 [============================>.] - ETA: 0s - loss: 330.4755 - mean_squared_error: 330.4758 - acc: 6.5836e-04\n",
      "Epoch 00439: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 330.6488 - mean_squared_error: 330.6491 - acc: 6.5644e-04 - val_loss: 719.5087 - val_mean_squared_error: 719.5088 - val_acc: 0.0000e+00\n",
      "Epoch 440/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 367.6123 - mean_squared_error: 367.6125 - acc: 7.0780e-04\n",
      "Epoch 00440: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 366.4469 - mean_squared_error: 366.4472 - acc: 6.9192e-04 - val_loss: 1986.3983 - val_mean_squared_error: 1986.3981 - val_acc: 2.1289e-04\n",
      "Epoch 441/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 879.4260 - mean_squared_error: 879.4260 - acc: 4.8736e-04\n",
      "Epoch 00441: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 870.2897 - mean_squared_error: 870.2898 - acc: 4.7902e-04 - val_loss: 714.3531 - val_mean_squared_error: 714.3530 - val_acc: 3.5481e-04\n",
      "Epoch 442/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 495.0007 - mean_squared_error: 495.0006 - acc: 5.5357e-04\n",
      "Epoch 00442: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 493.9814 - mean_squared_error: 493.9812 - acc: 5.6773e-04 - val_loss: 757.5028 - val_mean_squared_error: 757.5030 - val_acc: 1.4192e-04\n",
      "Epoch 443/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 347.6281 - mean_squared_error: 347.6280 - acc: 6.7395e-04\n",
      "Epoch 00443: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 347.2713 - mean_squared_error: 347.2712 - acc: 6.5644e-04 - val_loss: 795.1898 - val_mean_squared_error: 795.1896 - val_acc: 2.1289e-04\n",
      "Epoch 444/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 322.9478 - mean_squared_error: 322.9478 - acc: 6.1261e-04\n",
      "Epoch 00444: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 322.5057 - mean_squared_error: 322.5056 - acc: 6.0321e-04 - val_loss: 898.8331 - val_mean_squared_error: 898.8333 - val_acc: 7.0962e-04\n",
      "Epoch 445/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 387.2317 - mean_squared_error: 387.2318 - acc: 5.7451e-04\n",
      "Epoch 00445: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 386.8632 - mean_squared_error: 386.8633 - acc: 6.0321e-04 - val_loss: 754.3887 - val_mean_squared_error: 754.3887 - val_acc: 1.4192e-04\n",
      "Epoch 446/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 393.0755 - mean_squared_error: 393.0756 - acc: 6.1594e-04\n",
      "Epoch 00446: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 392.2656 - mean_squared_error: 392.2657 - acc: 6.0321e-04 - val_loss: 716.9558 - val_mean_squared_error: 716.9559 - val_acc: 1.4192e-04\n",
      "Epoch 447/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 322.4599 - mean_squared_error: 322.4599 - acc: 6.7736e-04\n",
      "Epoch 00447: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 322.7161 - mean_squared_error: 322.7162 - acc: 6.7418e-04 - val_loss: 819.7521 - val_mean_squared_error: 819.7520 - val_acc: 2.8385e-04\n",
      "Epoch 448/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 321.3491 - mean_squared_error: 321.3491 - acc: 5.4152e-04\n",
      "Epoch 00448: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 321.1680 - mean_squared_error: 321.1680 - acc: 5.3225e-04 - val_loss: 727.8921 - val_mean_squared_error: 727.8921 - val_acc: 7.0962e-05\n",
      "Epoch 449/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 332.7442 - mean_squared_error: 332.7443 - acc: 7.6649e-04\n",
      "Epoch 00449: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 333.0484 - mean_squared_error: 333.0485 - acc: 7.6288e-04 - val_loss: 728.3519 - val_mean_squared_error: 728.3520 - val_acc: 4.2577e-04\n",
      "Epoch 450/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 458.2464 - mean_squared_error: 458.2466 - acc: 6.2612e-04\n",
      "Epoch 00450: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 456.8737 - mean_squared_error: 456.8739 - acc: 6.2095e-04 - val_loss: 736.6105 - val_mean_squared_error: 736.6107 - val_acc: 6.3866e-04\n",
      "Epoch 451/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 340.8792 - mean_squared_error: 340.8791 - acc: 5.8824e-04\n",
      "Epoch 00451: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.3547 - mean_squared_error: 340.3546 - acc: 5.8547e-04 - val_loss: 750.4975 - val_mean_squared_error: 750.4974 - val_acc: 1.4192e-04\n",
      "Epoch 452/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 406.4750 - mean_squared_error: 406.4749 - acc: 4.9815e-04\n",
      "Epoch 00452: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 404.9281 - mean_squared_error: 404.9281 - acc: 5.1450e-04 - val_loss: 1011.2678 - val_mean_squared_error: 1011.2679 - val_acc: 1.4192e-04\n",
      "Epoch 453/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 407.3898 - mean_squared_error: 407.3896 - acc: 5.5957e-04\n",
      "Epoch 00453: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 406.6762 - mean_squared_error: 406.6760 - acc: 5.4999e-04 - val_loss: 1180.2025 - val_mean_squared_error: 1180.2023 - val_acc: 7.0962e-05\n",
      "Epoch 454/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 499.2401 - mean_squared_error: 499.2403 - acc: 4.8214e-04\n",
      "Epoch 00454: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 499.1541 - mean_squared_error: 499.1543 - acc: 4.9676e-04 - val_loss: 879.9486 - val_mean_squared_error: 879.9489 - val_acc: 0.0000e+00\n",
      "Epoch 455/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 446.3484 - mean_squared_error: 446.3481 - acc: 6.6308e-04\n",
      "Epoch 00455: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 444.8377 - mean_squared_error: 444.8375 - acc: 6.9192e-04 - val_loss: 757.2497 - val_mean_squared_error: 757.2496 - val_acc: 1.4192e-04\n",
      "Epoch 456/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 322.8899 - mean_squared_error: 322.8899 - acc: 6.8345e-04\n",
      "Epoch 00456: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 322.8236 - mean_squared_error: 322.8236 - acc: 6.7418e-04 - val_loss: 697.8901 - val_mean_squared_error: 697.8901 - val_acc: 0.0000e+00\n",
      "Epoch 457/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 327.4866 - mean_squared_error: 327.4864 - acc: 6.6190e-04\n",
      "Epoch 00457: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 327.6959 - mean_squared_error: 327.6956 - acc: 6.7418e-04 - val_loss: 738.8313 - val_mean_squared_error: 738.8315 - val_acc: 2.1289e-04\n",
      "Epoch 458/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 341.8282 - mean_squared_error: 341.8281 - acc: 6.7496e-04\n",
      "Epoch 00458: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 341.7855 - mean_squared_error: 341.7854 - acc: 6.7418e-04 - val_loss: 876.0330 - val_mean_squared_error: 876.0331 - val_acc: 0.0013\n",
      "Epoch 459/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 349.7782 - mean_squared_error: 349.7784 - acc: 6.1261e-04\n",
      "Epoch 00459: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 349.1416 - mean_squared_error: 349.1417 - acc: 6.0321e-04 - val_loss: 1011.6476 - val_mean_squared_error: 1011.6475 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 348.8074 - mean_squared_error: 348.8073 - acc: 7.3214e-04\n",
      "Epoch 00460: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 348.8370 - mean_squared_error: 348.8369 - acc: 7.2740e-04 - val_loss: 698.2472 - val_mean_squared_error: 698.2471 - val_acc: 0.0000e+00\n",
      "Epoch 461/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 330.0998 - mean_squared_error: 330.0996 - acc: 6.4982e-04\n",
      "Epoch 00461: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 329.4807 - mean_squared_error: 329.4805 - acc: 6.3869e-04 - val_loss: 813.2149 - val_mean_squared_error: 813.2147 - val_acc: 7.0962e-05\n",
      "Epoch 462/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 362.3551 - mean_squared_error: 362.3550 - acc: 6.4103e-04\n",
      "Epoch 00462: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 361.2083 - mean_squared_error: 361.2082 - acc: 6.3869e-04 - val_loss: 710.4690 - val_mean_squared_error: 710.4689 - val_acc: 7.0962e-05\n",
      "Epoch 463/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 343.9133 - mean_squared_error: 343.9135 - acc: 5.5856e-04\n",
      "Epoch 00463: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 343.5783 - mean_squared_error: 343.5784 - acc: 5.4999e-04 - val_loss: 1056.2233 - val_mean_squared_error: 1056.2231 - val_acc: 1.4192e-04\n",
      "Epoch 464/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 375.5583 - mean_squared_error: 375.5585 - acc: 5.3571e-04\n",
      "Epoch 00464: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 375.2122 - mean_squared_error: 375.2125 - acc: 5.3225e-04 - val_loss: 879.8024 - val_mean_squared_error: 879.8024 - val_acc: 7.0962e-05\n",
      "Epoch 465/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 557.9062 - mean_squared_error: 557.9062 - acc: 7.1174e-04\n",
      "Epoch 00465: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 557.2039 - mean_squared_error: 557.2040 - acc: 7.2740e-04 - val_loss: 691.4569 - val_mean_squared_error: 691.4568 - val_acc: 7.8058e-04\n",
      "Epoch 466/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 516.8475 - mean_squared_error: 516.8476 - acc: 6.7029e-04\n",
      "Epoch 00466: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 514.5307 - mean_squared_error: 514.5307 - acc: 6.7418e-04 - val_loss: 761.5317 - val_mean_squared_error: 761.5316 - val_acc: 2.1289e-04\n",
      "Epoch 467/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 333.3487 - mean_squared_error: 333.3488 - acc: 5.5456e-04\n",
      "Epoch 00467: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 333.1314 - mean_squared_error: 333.1315 - acc: 5.6773e-04 - val_loss: 749.6104 - val_mean_squared_error: 749.6104 - val_acc: 2.1289e-04\n",
      "Epoch 468/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 352.4043 - mean_squared_error: 352.4042 - acc: 5.3860e-04\n",
      "Epoch 00468: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 352.2861 - mean_squared_error: 352.2860 - acc: 5.3225e-04 - val_loss: 704.6125 - val_mean_squared_error: 704.6122 - val_acc: 2.8385e-04\n",
      "Epoch 469/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 342.2829 - mean_squared_error: 342.2829 - acc: 5.9567e-04\n",
      "Epoch 00469: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 341.2580 - mean_squared_error: 341.2580 - acc: 6.5644e-04 - val_loss: 718.9438 - val_mean_squared_error: 718.9436 - val_acc: 1.4192e-04\n",
      "Epoch 470/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 344.0026 - mean_squared_error: 344.0028 - acc: 5.8394e-04\n",
      "Epoch 00470: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 344.0830 - mean_squared_error: 344.0830 - acc: 5.6773e-04 - val_loss: 702.6919 - val_mean_squared_error: 702.6919 - val_acc: 0.0000e+00\n",
      "Epoch 471/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 340.6603 - mean_squared_error: 340.6603 - acc: 7.5540e-04\n",
      "Epoch 00471: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.2345 - mean_squared_error: 340.2344 - acc: 7.4514e-04 - val_loss: 819.7970 - val_mean_squared_error: 819.7970 - val_acc: 0.0000e+00\n",
      "Epoch 472/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 335.9706 - mean_squared_error: 335.9706 - acc: 6.1041e-04\n",
      "Epoch 00472: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 336.0846 - mean_squared_error: 336.0847 - acc: 6.0321e-04 - val_loss: 2629.4381 - val_mean_squared_error: 2629.4377 - val_acc: 0.0000e+00\n",
      "Epoch 473/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 329.8421 - mean_squared_error: 329.8419 - acc: 4.3088e-04\n",
      "Epoch 00473: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 329.1212 - mean_squared_error: 329.1211 - acc: 4.4354e-04 - val_loss: 1219.9183 - val_mean_squared_error: 1219.9181 - val_acc: 0.0000e+00\n",
      "Epoch 474/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 673.4860 - mean_squared_error: 673.4861 - acc: 5.8076e-04\n",
      "Epoch 00474: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 665.4813 - mean_squared_error: 665.4816 - acc: 5.8547e-04 - val_loss: 682.9402 - val_mean_squared_error: 682.9401 - val_acc: 4.9674e-04\n",
      "Epoch 475/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 542.4973 - mean_squared_error: 542.4972 - acc: 6.9597e-04\n",
      "Epoch 00475: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 535.0521 - mean_squared_error: 535.0521 - acc: 6.9192e-04 - val_loss: 738.5558 - val_mean_squared_error: 738.5558 - val_acc: 2.8385e-04\n",
      "Epoch 476/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 337.6451 - mean_squared_error: 337.6451 - acc: 6.4748e-04\n",
      "Epoch 00476: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 336.9543 - mean_squared_error: 336.9543 - acc: 6.7418e-04 - val_loss: 1227.0970 - val_mean_squared_error: 1227.0969 - val_acc: 0.0000e+00\n",
      "Epoch 477/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 418.4607 - mean_squared_error: 418.4608 - acc: 6.2500e-04\n",
      "Epoch 00477: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 418.3011 - mean_squared_error: 418.3012 - acc: 6.2095e-04 - val_loss: 726.1769 - val_mean_squared_error: 726.1768 - val_acc: 7.0962e-05\n",
      "Epoch 478/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 405.0872 - mean_squared_error: 405.0869 - acc: 5.9891e-04\n",
      "Epoch 00478: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 402.8838 - mean_squared_error: 402.8835 - acc: 6.0321e-04 - val_loss: 923.1533 - val_mean_squared_error: 923.1531 - val_acc: 1.4192e-04\n",
      "Epoch 479/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 322.6982 - mean_squared_error: 322.6982 - acc: 5.6159e-04\n",
      "Epoch 00479: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 322.5169 - mean_squared_error: 322.5169 - acc: 5.4999e-04 - val_loss: 753.7143 - val_mean_squared_error: 753.7141 - val_acc: 7.0962e-04\n",
      "Epoch 480/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 352.3236 - mean_squared_error: 352.3236 - acc: 5.4845e-04\n",
      "Epoch 00480: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 352.1755 - mean_squared_error: 352.1755 - acc: 5.6773e-04 - val_loss: 1275.9678 - val_mean_squared_error: 1275.9677 - val_acc: 7.0962e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 316.6435 - mean_squared_error: 316.6436 - acc: 5.3476e-04\n",
      "Epoch 00481: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 316.7041 - mean_squared_error: 316.7041 - acc: 5.3225e-04 - val_loss: 1494.7309 - val_mean_squared_error: 1494.7305 - val_acc: 2.1289e-04\n",
      "Epoch 482/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 320.0907 - mean_squared_error: 320.0909 - acc: 6.1261e-04 ETA: 0s - loss: 321.5962 - mean_squared_error: 321.59\n",
      "Epoch 00482: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 320.0911 - mean_squared_error: 320.0912 - acc: 6.2095e-04 - val_loss: 2132.6751 - val_mean_squared_error: 2132.6753 - val_acc: 0.0000e+00\n",
      "Epoch 483/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 684.2762 - mean_squared_error: 684.2762 - acc: 6.0823e-04\n",
      "Epoch 00483: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 681.1608 - mean_squared_error: 681.1609 - acc: 6.0321e-04 - val_loss: 695.8793 - val_mean_squared_error: 695.8795 - val_acc: 2.1289e-04\n",
      "Epoch 484/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 391.0889 - mean_squared_error: 391.0889 - acc: 5.6940e-04\n",
      "Epoch 00484: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 390.7526 - mean_squared_error: 390.7527 - acc: 5.6773e-04 - val_loss: 721.3180 - val_mean_squared_error: 721.3181 - val_acc: 2.8385e-04\n",
      "Epoch 485/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 324.6694 - mean_squared_error: 324.6693 - acc: 5.5160e-04\n",
      "Epoch 00485: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 324.8710 - mean_squared_error: 324.8709 - acc: 5.4999e-04 - val_loss: 760.4958 - val_mean_squared_error: 760.4960 - val_acc: 0.0000e+00\n",
      "Epoch 486/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 517.4119 - mean_squared_error: 517.4117 - acc: 6.7979e-04\n",
      "Epoch 00486: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 515.6056 - mean_squared_error: 515.6054 - acc: 6.9192e-04 - val_loss: 1164.7127 - val_mean_squared_error: 1164.7126 - val_acc: 7.0962e-05\n",
      "Epoch 487/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 320.4839 - mean_squared_error: 320.4839 - acc: 5.6058e-04\n",
      "Epoch 00487: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 320.3166 - mean_squared_error: 320.3166 - acc: 5.4999e-04 - val_loss: 758.5914 - val_mean_squared_error: 758.5916 - val_acc: 1.4192e-04\n",
      "Epoch 488/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 319.1324 - mean_squared_error: 319.1325 - acc: 7.4275e-04\n",
      "Epoch 00488: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.3351 - mean_squared_error: 319.3351 - acc: 7.4514e-04 - val_loss: 1179.5541 - val_mean_squared_error: 1179.5542 - val_acc: 2.1289e-04\n",
      "Epoch 489/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 338.9580 - mean_squared_error: 338.9582 - acc: 6.8716e-04\n",
      "Epoch 00489: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 339.6833 - mean_squared_error: 339.6834 - acc: 6.9192e-04 - val_loss: 2000.9281 - val_mean_squared_error: 2000.9283 - val_acc: 2.8385e-04\n",
      "Epoch 490/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 562.2445 - mean_squared_error: 562.2446 - acc: 6.1372e-04\n",
      "Epoch 00490: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 557.7280 - mean_squared_error: 557.7281 - acc: 6.2095e-04 - val_loss: 725.9308 - val_mean_squared_error: 725.9306 - val_acc: 0.0000e+00\n",
      "Epoch 491/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 391.1842 - mean_squared_error: 391.1842 - acc: 6.1041e-04 ETA: 0s - loss: 310.4961 - mean_squared_error: 310.\n",
      "Epoch 00491: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 390.1576 - mean_squared_error: 390.1575 - acc: 6.0321e-04 - val_loss: 1007.7052 - val_mean_squared_error: 1007.7054 - val_acc: 1.4192e-04\n",
      "Epoch 492/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 374.4758 - mean_squared_error: 374.4759 - acc: 7.0018e-04\n",
      "Epoch 00492: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 373.1853 - mean_squared_error: 373.1853 - acc: 6.9192e-04 - val_loss: 1205.3300 - val_mean_squared_error: 1205.3300 - val_acc: 7.0962e-05\n",
      "Epoch 493/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 381.5878 - mean_squared_error: 381.5876 - acc: 5.6261e-04\n",
      "Epoch 00493: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 379.5647 - mean_squared_error: 379.5645 - acc: 6.0321e-04 - val_loss: 745.5171 - val_mean_squared_error: 745.5170 - val_acc: 7.0962e-05\n",
      "Epoch 494/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 359.7814 - mean_squared_error: 359.7818 - acc: 6.5719e-04\n",
      "Epoch 00494: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 359.7953 - mean_squared_error: 359.7956 - acc: 6.5644e-04 - val_loss: 1058.3525 - val_mean_squared_error: 1058.3524 - val_acc: 0.0000e+00\n",
      "Epoch 495/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 315.7801 - mean_squared_error: 315.7801 - acc: 6.7857e-04 ETA: 0s - loss: 316.1427 - mean_squared_err\n",
      "Epoch 00495: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 315.8642 - mean_squared_error: 315.8641 - acc: 6.9192e-04 - val_loss: 803.3275 - val_mean_squared_error: 803.3273 - val_acc: 1.4192e-04\n",
      "Epoch 496/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 353.5416 - mean_squared_error: 353.5417 - acc: 6.7766e-04\n",
      "Epoch 00496: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 351.5224 - mean_squared_error: 351.5226 - acc: 6.9192e-04 - val_loss: 1419.9404 - val_mean_squared_error: 1419.9401 - val_acc: 2.1289e-04\n",
      "Epoch 497/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 484.7011 - mean_squared_error: 484.7009 - acc: 6.2837e-04\n",
      "Epoch 00497: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 482.8211 - mean_squared_error: 482.8209 - acc: 6.3869e-04 - val_loss: 720.5129 - val_mean_squared_error: 720.5131 - val_acc: 0.0000e+00\n",
      "Epoch 498/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 443.8457 - mean_squared_error: 443.8454 - acc: 5.4054e-04\n",
      "Epoch 00498: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 441.7089 - mean_squared_error: 441.7086 - acc: 5.3225e-04 - val_loss: 727.6307 - val_mean_squared_error: 727.6309 - val_acc: 0.0000e+00\n",
      "Epoch 499/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 311.1679 - mean_squared_error: 311.1678 - acc: 5.6777e-04\n",
      "Epoch 00499: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.6252 - mean_squared_error: 310.6251 - acc: 5.6773e-04 - val_loss: 802.1920 - val_mean_squared_error: 802.1919 - val_acc: 0.0000e+00\n",
      "Epoch 500/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 315.5881 - mean_squared_error: 315.5880 - acc: 7.2333e-04\n",
      "Epoch 00500: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 315.2702 - mean_squared_error: 315.2701 - acc: 7.0966e-04 - val_loss: 1489.3883 - val_mean_squared_error: 1489.3885 - val_acc: 4.2577e-04\n",
      "Epoch 501/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 470.8107 - mean_squared_error: 470.8104 - acc: 6.9643e-04 ETA: 0s - loss: 718.8909 - mean_squared_err\n",
      "Epoch 00501: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 470.0115 - mean_squared_error: 470.0111 - acc: 6.9192e-04 - val_loss: 698.9692 - val_mean_squared_error: 698.9691 - val_acc: 6.3866e-04\n",
      "Epoch 502/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 410.0556 - mean_squared_error: 410.0556 - acc: 6.9519e-04\n",
      "Epoch 00502: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 409.6145 - mean_squared_error: 409.6144 - acc: 7.0966e-04 - val_loss: 720.6518 - val_mean_squared_error: 720.6520 - val_acc: 4.2577e-04\n",
      "Epoch 503/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 380.5978 - mean_squared_error: 380.5979 - acc: 7.3801e-04\n",
      "Epoch 00503: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 378.2414 - mean_squared_error: 378.2415 - acc: 7.0966e-04 - val_loss: 2837.9386 - val_mean_squared_error: 2837.9392 - val_acc: 6.3866e-04\n",
      "Epoch 504/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 341.0143 - mean_squared_error: 341.0143 - acc: 4.6346e-04\n",
      "Epoch 00504: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 340.8306 - mean_squared_error: 340.8305 - acc: 4.7902e-04 - val_loss: 733.4356 - val_mean_squared_error: 733.4357 - val_acc: 2.1289e-04\n",
      "Epoch 505/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 313.0215 - mean_squared_error: 313.0215 - acc: 7.3665e-04\n",
      "Epoch 00505: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 313.5186 - mean_squared_error: 313.5186 - acc: 7.4514e-04 - val_loss: 730.8588 - val_mean_squared_error: 730.8586 - val_acc: 4.9674e-04\n",
      "Epoch 506/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 313.3160 - mean_squared_error: 313.3160 - acc: 7.1556e-04\n",
      "Epoch 00506: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 313.1044 - mean_squared_error: 313.1044 - acc: 7.2740e-04 - val_loss: 716.0432 - val_mean_squared_error: 716.0430 - val_acc: 7.0962e-05\n",
      "Epoch 507/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 332.2591 - mean_squared_error: 332.2590 - acc: 6.5336e-04\n",
      "Epoch 00507: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 331.8318 - mean_squared_error: 331.8317 - acc: 6.3869e-04 - val_loss: 711.5287 - val_mean_squared_error: 711.5289 - val_acc: 1.4192e-04\n",
      "Epoch 508/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 455.3543 - mean_squared_error: 455.3545 - acc: 6.3406e-04\n",
      "Epoch 00508: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 452.2692 - mean_squared_error: 452.2693 - acc: 6.2095e-04 - val_loss: 723.6090 - val_mean_squared_error: 723.6088 - val_acc: 2.8385e-04\n",
      "Epoch 509/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 310.3645 - mean_squared_error: 310.3645 - acc: 7.1429e-04\n",
      "Epoch 00509: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.8242 - mean_squared_error: 310.8241 - acc: 6.9192e-04 - val_loss: 724.2528 - val_mean_squared_error: 724.2529 - val_acc: 7.8058e-04\n",
      "Epoch 510/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 351.6945 - mean_squared_error: 351.6945 - acc: 5.2920e-04\n",
      "Epoch 00510: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 351.2653 - mean_squared_error: 351.2651 - acc: 5.4999e-04 - val_loss: 1019.2053 - val_mean_squared_error: 1019.2054 - val_acc: 7.0962e-04\n",
      "Epoch 511/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 424.3519 - mean_squared_error: 424.3519 - acc: 7.2860e-04\n",
      "Epoch 00511: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 422.8692 - mean_squared_error: 422.8693 - acc: 7.2740e-04 - val_loss: 704.5067 - val_mean_squared_error: 704.5067 - val_acc: 7.0962e-05\n",
      "Epoch 512/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 743.8780 - mean_squared_error: 743.8782 - acc: 7.4074e-04\n",
      "Epoch 00512: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 726.4698 - mean_squared_error: 726.4700 - acc: 7.0966e-04 - val_loss: 731.7208 - val_mean_squared_error: 731.7207 - val_acc: 7.0962e-05\n",
      "Epoch 513/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 323.2228 - mean_squared_error: 323.2231 - acc: 6.3752e-04\n",
      "Epoch 00513: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 322.7433 - mean_squared_error: 322.7437 - acc: 6.2095e-04 - val_loss: 769.9800 - val_mean_squared_error: 769.9797 - val_acc: 4.9674e-04\n",
      "Epoch 514/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 433.5812 - mean_squared_error: 433.5809 - acc: 6.1706e-04\n",
      "Epoch 00514: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 430.0191 - mean_squared_error: 430.0189 - acc: 6.0321e-04 - val_loss: 678.1124 - val_mean_squared_error: 678.1125 - val_acc: 7.0962e-05\n",
      "Epoch 515/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 318.7076 - mean_squared_error: 318.7075 - acc: 7.3477e-04\n",
      "Epoch 00515: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 318.5544 - mean_squared_error: 318.5542 - acc: 7.2740e-04 - val_loss: 742.6524 - val_mean_squared_error: 742.6523 - val_acc: 7.0962e-05\n",
      "Epoch 516/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 367.9290 - mean_squared_error: 367.9289 - acc: 5.6777e-04\n",
      "Epoch 00516: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 365.8115 - mean_squared_error: 365.8113 - acc: 5.6773e-04 - val_loss: 730.6182 - val_mean_squared_error: 730.6181 - val_acc: 7.0962e-05\n",
      "Epoch 517/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 611.8244 - mean_squared_error: 611.8243 - acc: 6.0109e-04\n",
      "Epoch 00517: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 604.2972 - mean_squared_error: 604.2972 - acc: 6.2095e-04 - val_loss: 689.3486 - val_mean_squared_error: 689.3486 - val_acc: 7.0962e-05\n",
      "Epoch 518/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 396.3976 - mean_squared_error: 396.3976 - acc: 7.1038e-04 ETA: 0s - loss: 313.9721 - mean_squared_error: 313.97\n",
      "Epoch 00518: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 394.2183 - mean_squared_error: 394.2182 - acc: 7.0966e-04 - val_loss: 722.9369 - val_mean_squared_error: 722.9367 - val_acc: 3.5481e-04\n",
      "Epoch 519/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 320.4970 - mean_squared_error: 320.4970 - acc: 6.7273e-04 ETA: 0s - loss: 346.2843 - mean_squared\n",
      "Epoch 00519: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.9275 - mean_squared_error: 319.9276 - acc: 6.9192e-04 - val_loss: 729.5032 - val_mean_squared_error: 729.5030 - val_acc: 1.4192e-04\n",
      "Epoch 520/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 498.9554 - mean_squared_error: 498.9557 - acc: 7.8712e-04\n",
      "Epoch 00520: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 498.1047 - mean_squared_error: 498.1050 - acc: 7.9837e-04 - val_loss: 738.1482 - val_mean_squared_error: 738.1483 - val_acc: 0.0000e+00\n",
      "Epoch 521/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 418.6450 - mean_squared_error: 418.6450 - acc: 5.6058e-04\n",
      "Epoch 00521: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 416.5565 - mean_squared_error: 416.5565 - acc: 5.6773e-04 - val_loss: 757.9643 - val_mean_squared_error: 757.9641 - val_acc: 2.1289e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 350.4805 - mean_squared_error: 350.4804 - acc: 5.9459e-04\n",
      "Epoch 00522: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 349.8550 - mean_squared_error: 349.8550 - acc: 5.8547e-04 - val_loss: 749.8869 - val_mean_squared_error: 749.8870 - val_acc: 4.2577e-04\n",
      "Epoch 523/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 392.0535 - mean_squared_error: 392.0535 - acc: 5.8182e-04\n",
      "Epoch 00523: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 390.0889 - mean_squared_error: 390.0889 - acc: 5.8547e-04 - val_loss: 745.9430 - val_mean_squared_error: 745.9430 - val_acc: 2.1289e-04\n",
      "Epoch 524/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 319.3791 - mean_squared_error: 319.3791 - acc: 6.3869e-04\n",
      "Epoch 00524: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.0189 - mean_squared_error: 319.0189 - acc: 6.2095e-04 - val_loss: 724.0967 - val_mean_squared_error: 724.0967 - val_acc: 2.1289e-04\n",
      "Epoch 525/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 370.9061 - mean_squared_error: 370.9060 - acc: 7.1823e-04\n",
      "Epoch 00525: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 369.2894 - mean_squared_error: 369.2893 - acc: 7.0966e-04 - val_loss: 712.8730 - val_mean_squared_error: 712.8730 - val_acc: 7.0962e-05\n",
      "Epoch 526/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 441.7359 - mean_squared_error: 441.7361 - acc: 7.0144e-04\n",
      "Epoch 00526: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 440.4951 - mean_squared_error: 440.4953 - acc: 7.0966e-04 - val_loss: 755.4151 - val_mean_squared_error: 755.4150 - val_acc: 0.0000e+00\n",
      "Epoch 527/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 311.7814 - mean_squared_error: 311.7813 - acc: 6.2724e-04\n",
      "Epoch 00527: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 312.0148 - mean_squared_error: 312.0146 - acc: 6.2095e-04 - val_loss: 775.7503 - val_mean_squared_error: 775.7504 - val_acc: 1.4192e-04\n",
      "Epoch 528/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 309.5407 - mean_squared_error: 309.5409 - acc: 6.0823e-04\n",
      "Epoch 00528: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 309.2520 - mean_squared_error: 309.2521 - acc: 6.2095e-04 - val_loss: 715.7154 - val_mean_squared_error: 715.7154 - val_acc: 2.1289e-04\n",
      "Epoch 529/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 329.4280 - mean_squared_error: 329.4278 - acc: 5.6466e-04\n",
      "Epoch 00529: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 329.8029 - mean_squared_error: 329.8028 - acc: 5.4999e-04 - val_loss: 1520.1626 - val_mean_squared_error: 1520.1625 - val_acc: 0.0000e+00\n",
      "Epoch 530/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 423.2301 - mean_squared_error: 423.2299 - acc: 6.0440e-04\n",
      "Epoch 00530: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 419.7449 - mean_squared_error: 419.7447 - acc: 6.0321e-04 - val_loss: 704.8183 - val_mean_squared_error: 704.8185 - val_acc: 7.0962e-05\n",
      "Epoch 531/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 314.3293 - mean_squared_error: 314.3292 - acc: 6.6427e-04\n",
      "Epoch 00531: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 314.6959 - mean_squared_error: 314.6958 - acc: 6.5644e-04 - val_loss: 726.3968 - val_mean_squared_error: 726.3966 - val_acc: 9.2251e-04\n",
      "Epoch 532/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 318.8233 - mean_squared_error: 318.8234 - acc: 6.1931e-04\n",
      "Epoch 00532: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 317.3306 - mean_squared_error: 317.3306 - acc: 6.0321e-04 - val_loss: 722.2901 - val_mean_squared_error: 722.2902 - val_acc: 7.0962e-05\n",
      "Epoch 533/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 305.0594 - mean_squared_error: 305.0593 - acc: 6.0932e-04\n",
      "Epoch 00533: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.1618 - mean_squared_error: 305.1617 - acc: 6.0321e-04 - val_loss: 880.6462 - val_mean_squared_error: 880.6464 - val_acc: 1.4192e-04\n",
      "Epoch 534/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 314.0123 - mean_squared_error: 314.0124 - acc: 5.7143e-04\n",
      "Epoch 00534: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 313.9329 - mean_squared_error: 313.9330 - acc: 5.6773e-04 - val_loss: 976.8359 - val_mean_squared_error: 976.8361 - val_acc: 7.0962e-05\n",
      "Epoch 535/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 411.4509 - mean_squared_error: 411.4510 - acc: 5.7041e-04\n",
      "Epoch 00535: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 410.8395 - mean_squared_error: 410.8396 - acc: 5.6773e-04 - val_loss: 812.0250 - val_mean_squared_error: 812.0252 - val_acc: 7.0962e-05\n",
      "Epoch 536/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 315.8815 - mean_squared_error: 315.8812 - acc: 6.1151e-04\n",
      "Epoch 00536: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 315.7939 - mean_squared_error: 315.7937 - acc: 6.0321e-04 - val_loss: 710.7587 - val_mean_squared_error: 710.7589 - val_acc: 0.0000e+00\n",
      "Epoch 537/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 376.3483 - mean_squared_error: 376.3481 - acc: 5.5456e-04\n",
      "Epoch 00537: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 375.6718 - mean_squared_error: 375.6717 - acc: 5.4999e-04 - val_loss: 1432.4847 - val_mean_squared_error: 1432.4854 - val_acc: 2.1289e-04\n",
      "Epoch 538/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 305.6118 - mean_squared_error: 305.6118 - acc: 7.0018e-04\n",
      "Epoch 00538: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.5085 - mean_squared_error: 305.5085 - acc: 6.9192e-04 - val_loss: 1094.5676 - val_mean_squared_error: 1094.5677 - val_acc: 0.0000e+00\n",
      "Epoch 539/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 337.3159 - mean_squared_error: 337.3160 - acc: 6.7616e-04\n",
      "Epoch 00539: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.2827 - mean_squared_error: 337.2828 - acc: 6.7418e-04 - val_loss: 808.2158 - val_mean_squared_error: 808.2159 - val_acc: 9.9347e-04\n",
      "Epoch 540/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 553.1693 - mean_squared_error: 553.1693 - acc: 6.1372e-04\n",
      "Epoch 00540: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 549.1230 - mean_squared_error: 549.1230 - acc: 6.0321e-04 - val_loss: 704.9747 - val_mean_squared_error: 704.9747 - val_acc: 7.0962e-05\n",
      "Epoch 541/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 323.4100 - mean_squared_error: 323.4102 - acc: 6.9470e-04\n",
      "Epoch 00541: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 323.8719 - mean_squared_error: 323.8721 - acc: 6.7418e-04 - val_loss: 667.0719 - val_mean_squared_error: 667.0718 - val_acc: 7.0962e-05\n",
      "Epoch 542/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 415.5907 - mean_squared_error: 415.5905 - acc: 5.9140e-04\n",
      "Epoch 00542: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 414.8078 - mean_squared_error: 414.8076 - acc: 5.8547e-04 - val_loss: 732.7274 - val_mean_squared_error: 732.7272 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 543/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 305.8615 - mean_squared_error: 305.8615 - acc: 5.6838e-04\n",
      "Epoch 00543: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 305.7804 - mean_squared_error: 305.7804 - acc: 5.6773e-04 - val_loss: 706.6595 - val_mean_squared_error: 706.6595 - val_acc: 0.0000e+00\n",
      "Epoch 544/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 370.8550 - mean_squared_error: 370.8550 - acc: 6.6667e-04 ETA: 1s - loss: 287.986\n",
      "Epoch 00544: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 369.5046 - mean_squared_error: 369.5047 - acc: 6.5644e-04 - val_loss: 729.5254 - val_mean_squared_error: 729.5253 - val_acc: 4.2577e-04\n",
      "Epoch 545/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 424.3709 - mean_squared_error: 424.3707 - acc: 5.3860e-04\n",
      "Epoch 00545: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 423.5290 - mean_squared_error: 423.5288 - acc: 5.8547e-04 - val_loss: 690.4084 - val_mean_squared_error: 690.4086 - val_acc: 4.9674e-04\n",
      "Epoch 546/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 307.1258 - mean_squared_error: 307.1258 - acc: 6.5719e-04\n",
      "Epoch 00546: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 306.9471 - mean_squared_error: 306.9471 - acc: 6.5644e-04 - val_loss: 751.1589 - val_mean_squared_error: 751.1590 - val_acc: 2.1289e-04\n",
      "Epoch 547/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 302.7739 - mean_squared_error: 302.7740 - acc: 6.2724e-04\n",
      "Epoch 00547: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 302.4853 - mean_squared_error: 302.4854 - acc: 6.2095e-04 - val_loss: 707.5308 - val_mean_squared_error: 707.5306 - val_acc: 7.0962e-05\n",
      "Epoch 548/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 361.7187 - mean_squared_error: 361.7186 - acc: 6.1261e-04\n",
      "Epoch 00548: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 360.8353 - mean_squared_error: 360.8352 - acc: 6.0321e-04 - val_loss: 699.3759 - val_mean_squared_error: 699.3758 - val_acc: 4.2577e-04\n",
      "Epoch 549/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 343.9288 - mean_squared_error: 343.9288 - acc: 5.3763e-04\n",
      "Epoch 00549: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 344.0967 - mean_squared_error: 344.0967 - acc: 5.3225e-04 - val_loss: 734.2245 - val_mean_squared_error: 734.2244 - val_acc: 1.4192e-04\n",
      "Epoch 550/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 351.2002 - mean_squared_error: 351.2001 - acc: 7.7477e-04\n",
      "Epoch 00550: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 350.3867 - mean_squared_error: 350.3867 - acc: 7.6288e-04 - val_loss: 723.0770 - val_mean_squared_error: 723.0768 - val_acc: 0.0000e+00\n",
      "Epoch 551/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 491.6343 - mean_squared_error: 491.6344 - acc: 5.9783e-04\n",
      "Epoch 00551: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 487.2967 - mean_squared_error: 487.2967 - acc: 6.3869e-04 - val_loss: 721.9516 - val_mean_squared_error: 721.9516 - val_acc: 7.0962e-05\n",
      "Epoch 552/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 369.6116 - mean_squared_error: 369.6116 - acc: 6.0219e-04\n",
      "Epoch 00552: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 367.7121 - mean_squared_error: 367.7120 - acc: 6.2095e-04 - val_loss: 719.9413 - val_mean_squared_error: 719.9412 - val_acc: 0.0000e+00\n",
      "Epoch 553/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 311.8220 - mean_squared_error: 311.8222 - acc: 5.8824e-04\n",
      "Epoch 00553: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 311.3938 - mean_squared_error: 311.3939 - acc: 6.2095e-04 - val_loss: 707.2297 - val_mean_squared_error: 707.2297 - val_acc: 0.0000e+00\n",
      "Epoch 554/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 305.2682 - mean_squared_error: 305.2683 - acc: 6.0391e-04\n",
      "Epoch 00554: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.1611 - mean_squared_error: 305.1612 - acc: 6.0321e-04 - val_loss: 720.7210 - val_mean_squared_error: 720.7209 - val_acc: 7.0962e-05\n",
      "Epoch 555/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 379.2160 - mean_squared_error: 379.2160 - acc: 7.2333e-04\n",
      "Epoch 00555: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 378.3193 - mean_squared_error: 378.3192 - acc: 7.0966e-04 - val_loss: 723.1136 - val_mean_squared_error: 723.1135 - val_acc: 6.3866e-04\n",
      "Epoch 556/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 306.4880 - mean_squared_error: 306.4882 - acc: 6.4982e-04\n",
      "Epoch 00556: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 306.9580 - mean_squared_error: 306.9582 - acc: 6.9192e-04 - val_loss: 922.6440 - val_mean_squared_error: 922.6442 - val_acc: 7.0962e-05\n",
      "Epoch 557/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 338.3420 - mean_squared_error: 338.3419 - acc: 6.2724e-04\n",
      "Epoch 00557: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.7956 - mean_squared_error: 337.7955 - acc: 6.5644e-04 - val_loss: 767.6290 - val_mean_squared_error: 767.6287 - val_acc: 7.0962e-05\n",
      "Epoch 558/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 301.2249 - mean_squared_error: 301.2249 - acc: 6.4632e-04\n",
      "Epoch 00558: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 314.7925 - mean_squared_error: 314.7924 - acc: 6.3869e-04 - val_loss: 673.3986 - val_mean_squared_error: 673.3985 - val_acc: 0.0000e+00\n",
      "Epoch 559/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 483.2617 - mean_squared_error: 483.2619 - acc: 5.3407e-04\n",
      "Epoch 00559: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 476.7351 - mean_squared_error: 476.7352 - acc: 5.3225e-04 - val_loss: 710.0644 - val_mean_squared_error: 710.0644 - val_acc: 7.0962e-05\n",
      "Epoch 560/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 374.5227 - mean_squared_error: 374.5226 - acc: 6.2950e-04\n",
      "Epoch 00560: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 373.9353 - mean_squared_error: 373.9352 - acc: 6.2095e-04 - val_loss: 726.0668 - val_mean_squared_error: 726.0669 - val_acc: 0.0000e+00\n",
      "Epoch 561/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 298.4147 - mean_squared_error: 298.4146 - acc: 6.1594e-04\n",
      "Epoch 00561: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 298.8507 - mean_squared_error: 298.8507 - acc: 6.3869e-04 - val_loss: 707.3982 - val_mean_squared_error: 707.3983 - val_acc: 4.2577e-04\n",
      "Epoch 562/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 436.1305 - mean_squared_error: 436.1305 - acc: 5.1282e-04\n",
      "Epoch 00562: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 431.8629 - mean_squared_error: 431.8628 - acc: 5.3225e-04 - val_loss: 740.8502 - val_mean_squared_error: 740.8501 - val_acc: 0.0000e+00\n",
      "Epoch 563/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 326.0790 - mean_squared_error: 326.0790 - acc: 7.2202e-04\n",
      "Epoch 00563: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 325.9779 - mean_squared_error: 325.9778 - acc: 7.0966e-04 - val_loss: 1298.4639 - val_mean_squared_error: 1298.4639 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 504.7602 - mean_squared_error: 504.7603 - acc: 4.9911e-04\n",
      "Epoch 00564: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 503.9334 - mean_squared_error: 503.9335 - acc: 4.9676e-04 - val_loss: 700.5159 - val_mean_squared_error: 700.5159 - val_acc: 2.8385e-04\n",
      "Epoch 565/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 333.5692 - mean_squared_error: 333.5692 - acc: 6.9643e-04\n",
      "Epoch 00565: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 333.5828 - mean_squared_error: 333.5827 - acc: 6.9192e-04 - val_loss: 736.1069 - val_mean_squared_error: 736.1068 - val_acc: 0.0000e+00\n",
      "Epoch 566/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 312.3287 - mean_squared_error: 312.3288 - acc: 5.9675e-04\n",
      "Epoch 00566: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 311.6577 - mean_squared_error: 311.6578 - acc: 5.8547e-04 - val_loss: 728.8173 - val_mean_squared_error: 728.8173 - val_acc: 0.0000e+00\n",
      "Epoch 567/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 371.9358 - mean_squared_error: 371.9358 - acc: 7.3874e-04\n",
      "Epoch 00567: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 370.9385 - mean_squared_error: 370.9385 - acc: 7.2740e-04 - val_loss: 724.7367 - val_mean_squared_error: 724.7368 - val_acc: 7.0962e-05\n",
      "Epoch 568/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 318.6076 - mean_squared_error: 318.6076 - acc: 8.1522e-04\n",
      "Epoch 00568: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 318.3666 - mean_squared_error: 318.3666 - acc: 7.9837e-04 - val_loss: 727.6842 - val_mean_squared_error: 727.6840 - val_acc: 1.4192e-04\n",
      "Epoch 569/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 384.7991 - mean_squared_error: 384.7991 - acc: 6.6190e-04\n",
      "Epoch 00569: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 383.8228 - mean_squared_error: 383.8228 - acc: 6.7418e-04 - val_loss: 1106.0072 - val_mean_squared_error: 1106.0072 - val_acc: 0.0000e+00\n",
      "Epoch 570/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 328.5334 - mean_squared_error: 328.5333 - acc: 6.5719e-04\n",
      "Epoch 00570: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 328.8192 - mean_squared_error: 328.8191 - acc: 6.5644e-04 - val_loss: 719.0492 - val_mean_squared_error: 719.0493 - val_acc: 2.8385e-04\n",
      "Epoch 571/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 317.6468 - mean_squared_error: 317.6469 - acc: 6.4057e-04\n",
      "Epoch 00571: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 317.5491 - mean_squared_error: 317.5492 - acc: 6.3869e-04 - val_loss: 751.2666 - val_mean_squared_error: 751.2666 - val_acc: 6.3866e-04\n",
      "Epoch 572/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 383.6065 - mean_squared_error: 383.6065 - acc: 4.5045e-04\n",
      "Epoch 00572: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 381.8868 - mean_squared_error: 381.8868 - acc: 4.4354e-04 - val_loss: 743.7321 - val_mean_squared_error: 743.7324 - val_acc: 0.0000e+00\n",
      "Epoch 573/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 433.4047 - mean_squared_error: 433.4045 - acc: 7.0652e-04\n",
      "Epoch 00573: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 430.1671 - mean_squared_error: 430.1670 - acc: 7.0966e-04 - val_loss: 765.0398 - val_mean_squared_error: 765.0396 - val_acc: 7.0962e-05\n",
      "Epoch 574/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 311.1448 - mean_squared_error: 311.1448 - acc: 6.6667e-04\n",
      "Epoch 00574: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 310.7362 - mean_squared_error: 310.7361 - acc: 6.9192e-04 - val_loss: 759.1304 - val_mean_squared_error: 759.1304 - val_acc: 0.0000e+00\n",
      "Epoch 575/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 305.9658 - mean_squared_error: 305.9657 - acc: 6.2615e-04\n",
      "Epoch 00575: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 306.0073 - mean_squared_error: 306.0072 - acc: 6.3869e-04 - val_loss: 751.5108 - val_mean_squared_error: 751.5108 - val_acc: 7.0962e-05\n",
      "Epoch 576/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 298.6230 - mean_squared_error: 298.6228 - acc: 7.2727e-04\n",
      "Epoch 00576: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 299.7050 - mean_squared_error: 299.7049 - acc: 7.2740e-04 - val_loss: 753.6437 - val_mean_squared_error: 753.6436 - val_acc: 7.0962e-05\n",
      "Epoch 577/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 308.9269 - mean_squared_error: 308.9269 - acc: 5.5556e-04\n",
      "Epoch 00577: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 309.4056 - mean_squared_error: 309.4055 - acc: 5.6773e-04 - val_loss: 1108.2819 - val_mean_squared_error: 1108.2817 - val_acc: 5.6770e-04\n",
      "Epoch 578/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 310.3915 - mean_squared_error: 310.3914 - acc: 7.1301e-04\n",
      "Epoch 00578: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 310.2035 - mean_squared_error: 310.2034 - acc: 7.0966e-04 - val_loss: 1470.4465 - val_mean_squared_error: 1470.4465 - val_acc: 2.1289e-04\n",
      "Epoch 579/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 454.0991 - mean_squared_error: 454.0989 - acc: 5.3763e-04 ETA: 0s - loss: 302.8901 - mean_squared_error: \n",
      "Epoch 00579: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 452.2190 - mean_squared_error: 452.2188 - acc: 5.3225e-04 - val_loss: 748.8005 - val_mean_squared_error: 748.8006 - val_acc: 1.4192e-04\n",
      "Epoch 580/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 313.4406 - mean_squared_error: 313.4405 - acc: 7.2595e-04\n",
      "Epoch 00580: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 312.9970 - mean_squared_error: 312.9969 - acc: 7.0966e-04 - val_loss: 766.0662 - val_mean_squared_error: 766.0662 - val_acc: 0.0000e+00\n",
      "Epoch 581/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 358.0532 - mean_squared_error: 358.0529 - acc: 5.5160e-04\n",
      "Epoch 00581: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 357.7480 - mean_squared_error: 357.7478 - acc: 5.6773e-04 - val_loss: 724.9738 - val_mean_squared_error: 724.9738 - val_acc: 1.4192e-04\n",
      "Epoch 582/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 369.3719 - mean_squared_error: 369.3721 - acc: 6.5814e-04\n",
      "Epoch 00582: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 368.4661 - mean_squared_error: 368.4664 - acc: 6.5644e-04 - val_loss: 699.4378 - val_mean_squared_error: 699.4376 - val_acc: 0.0000e+00\n",
      "Epoch 583/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 361.5098 - mean_squared_error: 361.5099 - acc: 5.6777e-04\n",
      "Epoch 00583: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 359.5108 - mean_squared_error: 359.5109 - acc: 5.6773e-04 - val_loss: 712.1377 - val_mean_squared_error: 712.1376 - val_acc: 7.0962e-05\n",
      "Epoch 584/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 300.4264 - mean_squared_error: 300.4265 - acc: 6.3943e-04\n",
      "Epoch 00584: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 300.4587 - mean_squared_error: 300.4587 - acc: 6.3869e-04 - val_loss: 755.7560 - val_mean_squared_error: 755.7559 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 319.9071 - mean_squared_error: 319.9072 - acc: 6.5836e-04\n",
      "Epoch 00585: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.6843 - mean_squared_error: 319.6844 - acc: 6.5644e-04 - val_loss: 730.8271 - val_mean_squared_error: 730.8272 - val_acc: 3.5481e-04\n",
      "Epoch 586/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 320.0237 - mean_squared_error: 320.0238 - acc: 5.5249e-04\n",
      "Epoch 00586: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.6882 - mean_squared_error: 319.6882 - acc: 5.3225e-04 - val_loss: 734.6049 - val_mean_squared_error: 734.6049 - val_acc: 4.9674e-04\n",
      "Epoch 587/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 322.1780 - mean_squared_error: 322.1780 - acc: 6.6190e-04\n",
      "Epoch 00587: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 322.1060 - mean_squared_error: 322.1060 - acc: 6.5644e-04 - val_loss: 708.0785 - val_mean_squared_error: 708.0786 - val_acc: 3.5481e-04\n",
      "Epoch 588/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 306.3002 - mean_squared_error: 306.3004 - acc: 6.9853e-04\n",
      "Epoch 00588: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 305.7430 - mean_squared_error: 305.7432 - acc: 7.2740e-04 - val_loss: 730.2514 - val_mean_squared_error: 730.2513 - val_acc: 7.0962e-05\n",
      "Epoch 589/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 330.9663 - mean_squared_error: 330.9662 - acc: 6.7766e-04\n",
      "Epoch 00589: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 330.0093 - mean_squared_error: 330.0092 - acc: 6.5644e-04 - val_loss: 5435.4659 - val_mean_squared_error: 5435.4663 - val_acc: 0.0000e+00\n",
      "Epoch 590/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 425.3972 - mean_squared_error: 425.3971 - acc: 6.6055e-04 ETA: 0s - loss: 303.3502 - mean_squared_error: 30\n",
      "Epoch 00590: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 422.2420 - mean_squared_error: 422.2419 - acc: 6.5644e-04 - val_loss: 708.7758 - val_mean_squared_error: 708.7760 - val_acc: 1.4192e-04\n",
      "Epoch 591/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 314.3526 - mean_squared_error: 314.3527 - acc: 5.1282e-04\n",
      "Epoch 00591: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 313.3932 - mean_squared_error: 313.3932 - acc: 5.1450e-04 - val_loss: 698.5915 - val_mean_squared_error: 698.5916 - val_acc: 7.0962e-05\n",
      "Epoch 592/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 311.6162 - mean_squared_error: 311.6164 - acc: 5.7245e-04\n",
      "Epoch 00592: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 311.7227 - mean_squared_error: 311.7228 - acc: 5.6773e-04 - val_loss: 692.8716 - val_mean_squared_error: 692.8716 - val_acc: 7.0962e-05\n",
      "Epoch 593/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 304.8347 - mean_squared_error: 304.8346 - acc: 5.7554e-04\n",
      "Epoch 00593: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.9003 - mean_squared_error: 304.9003 - acc: 5.8547e-04 - val_loss: 679.3922 - val_mean_squared_error: 679.3922 - val_acc: 1.4192e-04\n",
      "Epoch 594/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 484.6951 - mean_squared_error: 484.6952 - acc: 6.0606e-04\n",
      "Epoch 00594: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 483.8352 - mean_squared_error: 483.8353 - acc: 6.0321e-04 - val_loss: 702.0983 - val_mean_squared_error: 702.0981 - val_acc: 2.1289e-04\n",
      "Epoch 595/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 454.7978 - mean_squared_error: 454.7981 - acc: 6.3943e-04 ETA: 0s - loss: 544.3909 - mean_squared_error: 544.39\n",
      "Epoch 00595: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 454.4456 - mean_squared_error: 454.4459 - acc: 6.3869e-04 - val_loss: 689.6713 - val_mean_squared_error: 689.6714 - val_acc: 0.0000e+00\n",
      "Epoch 596/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 306.5622 - mean_squared_error: 306.5622 - acc: 6.6547e-04\n",
      "Epoch 00596: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 306.4173 - mean_squared_error: 306.4173 - acc: 6.5644e-04 - val_loss: 690.6315 - val_mean_squared_error: 690.6316 - val_acc: 0.0000e+00\n",
      "Epoch 597/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 314.1715 - mean_squared_error: 314.1715 - acc: 7.1556e-04\n",
      "Epoch 00597: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 313.8275 - mean_squared_error: 313.8275 - acc: 7.0966e-04 - val_loss: 696.6642 - val_mean_squared_error: 696.6643 - val_acc: 5.6770e-04\n",
      "Epoch 598/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 301.3291 - mean_squared_error: 301.3292 - acc: 6.7496e-04\n",
      "Epoch 00598: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 301.3344 - mean_squared_error: 301.3344 - acc: 6.7418e-04 - val_loss: 691.8418 - val_mean_squared_error: 691.8417 - val_acc: 0.0000e+00\n",
      "Epoch 599/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 404.9457 - mean_squared_error: 404.9455 - acc: 6.7857e-04 ETA: 0s - loss: 292.3498 - mean_squared_error: 292.3498 - acc: 7. - ETA: 0s - loss: 291.6206 - mean_squared_error: 291.6206 - acc: \n",
      "Epoch 00599: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 404.3319 - mean_squared_error: 404.3317 - acc: 6.7418e-04 - val_loss: 880.9168 - val_mean_squared_error: 880.9169 - val_acc: 7.0962e-05\n",
      "Epoch 600/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 473.8613 - mean_squared_error: 473.8615 - acc: 5.0269e-04\n",
      "Epoch 00600: val_loss did not improve from 663.47691\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 472.3022 - mean_squared_error: 472.3023 - acc: 5.1450e-04 - val_loss: 850.2298 - val_mean_squared_error: 850.2298 - val_acc: 7.0962e-05\n",
      "Epoch 601/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 594.8432 - mean_squared_error: 594.8430 - acc: 6.9395e-04\n",
      "Epoch 00601: val_loss improved from 663.47691 to 660.03783, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 594.4595 - mean_squared_error: 594.4594 - acc: 6.9192e-04 - val_loss: 660.0378 - val_mean_squared_error: 660.0378 - val_acc: 1.4192e-04\n",
      "Epoch 602/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 307.0792 - mean_squared_error: 307.0791 - acc: 4.9911e-04\n",
      "Epoch 00602: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 307.5722 - mean_squared_error: 307.5721 - acc: 4.9676e-04 - val_loss: 666.1882 - val_mean_squared_error: 666.1884 - val_acc: 2.1289e-04\n",
      "Epoch 603/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 318.6798 - mean_squared_error: 318.6798 - acc: 6.9853e-04\n",
      "Epoch 00603: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 318.8349 - mean_squared_error: 318.8348 - acc: 6.7418e-04 - val_loss: 713.4367 - val_mean_squared_error: 713.4367 - val_acc: 0.0000e+00\n",
      "Epoch 604/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 304.8381 - mean_squared_error: 304.8382 - acc: 6.5693e-04\n",
      "Epoch 00604: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.9654 - mean_squared_error: 304.9655 - acc: 6.5644e-04 - val_loss: 724.2147 - val_mean_squared_error: 724.2145 - val_acc: 2.8385e-04\n",
      "Epoch 605/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55300/56365 [============================>.] - ETA: 0s - loss: 427.4148 - mean_squared_error: 427.4149 - acc: 6.1483e-04\n",
      "Epoch 00605: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 425.2977 - mean_squared_error: 425.2978 - acc: 6.2095e-04 - val_loss: 719.1471 - val_mean_squared_error: 719.1471 - val_acc: 4.2577e-04\n",
      "Epoch 606/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 371.2985 - mean_squared_error: 371.2987 - acc: 5.7451e-04\n",
      "Epoch 00606: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 370.4227 - mean_squared_error: 370.4229 - acc: 5.8547e-04 - val_loss: 707.3381 - val_mean_squared_error: 707.3381 - val_acc: 0.0000e+00\n",
      "Epoch 607/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 300.8382 - mean_squared_error: 300.8380 - acc: 6.3063e-04\n",
      "Epoch 00607: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 301.2952 - mean_squared_error: 301.2951 - acc: 6.3869e-04 - val_loss: 730.7381 - val_mean_squared_error: 730.7382 - val_acc: 4.9674e-04\n",
      "Epoch 608/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 293.2595 - mean_squared_error: 293.2595 - acc: 5.7143e-04\n",
      "Epoch 00608: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 292.9265 - mean_squared_error: 292.9265 - acc: 5.6773e-04 - val_loss: 730.1990 - val_mean_squared_error: 730.1989 - val_acc: 5.6770e-04\n",
      "Epoch 609/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 332.7167 - mean_squared_error: 332.7165 - acc: 7.2202e-04 ETA: 0s - loss: 344.9616 - mean_squared_error: 344.9614 -\n",
      "Epoch 00609: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 331.5988 - mean_squared_error: 331.5986 - acc: 7.6288e-04 - val_loss: 669.4026 - val_mean_squared_error: 669.4027 - val_acc: 3.5481e-04\n",
      "Epoch 610/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 433.6297 - mean_squared_error: 433.6298 - acc: 5.6838e-04\n",
      "Epoch 00610: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 433.5085 - mean_squared_error: 433.5086 - acc: 5.6773e-04 - val_loss: 725.0859 - val_mean_squared_error: 725.0861 - val_acc: 3.5481e-04\n",
      "Epoch 611/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 300.4145 - mean_squared_error: 300.4146 - acc: 6.8266e-04\n",
      "Epoch 00611: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 299.4418 - mean_squared_error: 299.4419 - acc: 6.7418e-04 - val_loss: 698.2186 - val_mean_squared_error: 698.2187 - val_acc: 0.0000e+00\n",
      "Epoch 612/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 339.7749 - mean_squared_error: 339.7749 - acc: 6.2389e-04\n",
      "Epoch 00612: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 339.5040 - mean_squared_error: 339.5039 - acc: 6.2095e-04 - val_loss: 697.0751 - val_mean_squared_error: 697.0751 - val_acc: 7.0962e-05\n",
      "Epoch 613/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 396.2116 - mean_squared_error: 396.2113 - acc: 6.0823e-04\n",
      "Epoch 00613: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 395.0624 - mean_squared_error: 395.0620 - acc: 6.0321e-04 - val_loss: 713.4146 - val_mean_squared_error: 713.4143 - val_acc: 2.1289e-04\n",
      "Epoch 614/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 379.7330 - mean_squared_error: 379.7327 - acc: 6.9767e-04\n",
      "Epoch 00614: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 378.8903 - mean_squared_error: 378.8900 - acc: 6.9192e-04 - val_loss: 713.1185 - val_mean_squared_error: 713.1183 - val_acc: 2.8385e-04\n",
      "Epoch 615/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 422.4164 - mean_squared_error: 422.4162 - acc: 6.1041e-04\n",
      "Epoch 00615: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 420.9183 - mean_squared_error: 420.9181 - acc: 6.0321e-04 - val_loss: 739.7600 - val_mean_squared_error: 739.7599 - val_acc: 0.0000e+00\n",
      "Epoch 616/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 297.5427 - mean_squared_error: 297.5427 - acc: 5.6881e-04 ETA: 0s - loss: 297.2925 - mean_squared_error: 297.2925 - acc: 6.21\n",
      "Epoch 00616: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 297.3437 - mean_squared_error: 297.3438 - acc: 6.0321e-04 - val_loss: 673.5133 - val_mean_squared_error: 673.5134 - val_acc: 0.0000e+00\n",
      "Epoch 617/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 338.7153 - mean_squared_error: 338.7155 - acc: 7.1813e-04\n",
      "Epoch 00617: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 338.4630 - mean_squared_error: 338.4632 - acc: 7.0966e-04 - val_loss: 782.4791 - val_mean_squared_error: 782.4790 - val_acc: 0.0000e+00\n",
      "Epoch 618/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 430.2931 - mean_squared_error: 430.2930 - acc: 5.3957e-04\n",
      "Epoch 00618: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 428.8951 - mean_squared_error: 428.8951 - acc: 5.3225e-04 - val_loss: 693.9827 - val_mean_squared_error: 693.9828 - val_acc: 0.0000e+00\n",
      "Epoch 619/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 710.9376 - mean_squared_error: 710.9378 - acc: 6.0886e-04\n",
      "Epoch 00619: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 696.3905 - mean_squared_error: 696.3906 - acc: 5.8547e-04 - val_loss: 750.5077 - val_mean_squared_error: 750.5078 - val_acc: 2.1289e-04\n",
      "Epoch 620/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 364.9285 - mean_squared_error: 364.9285 - acc: 5.5453e-04\n",
      "Epoch 00620: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 362.8654 - mean_squared_error: 362.8653 - acc: 5.4999e-04 - val_loss: 713.7493 - val_mean_squared_error: 713.7491 - val_acc: 2.1289e-04\n",
      "Epoch 621/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 323.4970 - mean_squared_error: 323.4970 - acc: 6.2612e-04\n",
      "Epoch 00621: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 323.7756 - mean_squared_error: 323.7756 - acc: 6.2095e-04 - val_loss: 724.9477 - val_mean_squared_error: 724.9476 - val_acc: 1.4192e-04\n",
      "Epoch 622/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 394.7887 - mean_squared_error: 394.7883 - acc: 6.8345e-04 ETA: 0s - loss: 455.5550 - mean_squared_error: 455.55\n",
      "Epoch 00622: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 393.2213 - mean_squared_error: 393.2210 - acc: 6.7418e-04 - val_loss: 711.4818 - val_mean_squared_error: 711.4819 - val_acc: 7.0962e-05\n",
      "Epoch 623/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 296.9744 - mean_squared_error: 296.9744 - acc: 6.6055e-04\n",
      "Epoch 00623: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 297.0225 - mean_squared_error: 297.0225 - acc: 6.3869e-04 - val_loss: 698.2794 - val_mean_squared_error: 698.2794 - val_acc: 0.0000e+00\n",
      "Epoch 624/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 295.2191 - mean_squared_error: 295.2192 - acc: 6.0606e-04\n",
      "Epoch 00624: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 295.2773 - mean_squared_error: 295.2774 - acc: 6.2095e-04 - val_loss: 698.2426 - val_mean_squared_error: 698.2426 - val_acc: 1.4192e-04\n",
      "Epoch 625/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 299.6029 - mean_squared_error: 299.6028 - acc: 7.1174e-04\n",
      "Epoch 00625: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 299.6677 - mean_squared_error: 299.6676 - acc: 7.0966e-04 - val_loss: 1020.4265 - val_mean_squared_error: 1020.4267 - val_acc: 0.0000e+00\n",
      "Epoch 626/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 406.3405 - mean_squared_error: 406.3407 - acc: 5.4745e-04\n",
      "Epoch 00626: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 403.6309 - mean_squared_error: 403.6310 - acc: 5.4999e-04 - val_loss: 666.4114 - val_mean_squared_error: 666.4114 - val_acc: 2.8385e-04\n",
      "Epoch 627/3000\n",
      "53900/56365 [===========================>..] - ETA: 0s - loss: 342.7539 - mean_squared_error: 342.7539 - acc: 5.9369e-04\n",
      "Epoch 00627: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.2875 - mean_squared_error: 340.2875 - acc: 6.0321e-04 - val_loss: 696.8553 - val_mean_squared_error: 696.8553 - val_acc: 7.0962e-05\n",
      "Epoch 628/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 565.4514 - mean_squared_error: 565.4518 - acc: 6.7736e-04\n",
      "Epoch 00628: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 564.1116 - mean_squared_error: 564.1120 - acc: 6.7418e-04 - val_loss: 753.5325 - val_mean_squared_error: 753.5327 - val_acc: 2.1289e-04\n",
      "Epoch 629/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 292.3528 - mean_squared_error: 292.3526 - acc: 6.0329e-04 ETA: 0s - loss: 294.2889 - mean_squared_error\n",
      "Epoch 00629: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 292.4198 - mean_squared_error: 292.4197 - acc: 6.3869e-04 - val_loss: 736.1361 - val_mean_squared_error: 736.1363 - val_acc: 1.4192e-04\n",
      "Epoch 630/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 291.4972 - mean_squared_error: 291.4971 - acc: 5.2920e-04\n",
      "Epoch 00630: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 291.1692 - mean_squared_error: 291.1691 - acc: 5.1450e-04 - val_loss: 711.8458 - val_mean_squared_error: 711.8457 - val_acc: 1.4192e-04\n",
      "Epoch 631/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 350.8613 - mean_squared_error: 350.8612 - acc: 6.7518e-04\n",
      "Epoch 00631: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 349.4989 - mean_squared_error: 349.4986 - acc: 6.7418e-04 - val_loss: 703.8740 - val_mean_squared_error: 703.8740 - val_acc: 2.1289e-04\n",
      "Epoch 632/3000\n",
      "53800/56365 [===========================>..] - ETA: 0s - loss: 495.4139 - mean_squared_error: 495.4139 - acc: 5.2045e-04\n",
      "Epoch 00632: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 485.7163 - mean_squared_error: 485.7163 - acc: 5.1450e-04 - val_loss: 743.8155 - val_mean_squared_error: 743.8155 - val_acc: 1.4192e-04\n",
      "Epoch 633/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 285.4671 - mean_squared_error: 285.4671 - acc: 5.5957e-04\n",
      "Epoch 00633: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.1713 - mean_squared_error: 286.1713 - acc: 5.4999e-04 - val_loss: 742.0179 - val_mean_squared_error: 742.0179 - val_acc: 4.2577e-04\n",
      "Epoch 634/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 301.4819 - mean_squared_error: 301.4819 - acc: 5.8719e-04\n",
      "Epoch 00634: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 301.2374 - mean_squared_error: 301.2374 - acc: 5.8547e-04 - val_loss: 720.7597 - val_mean_squared_error: 720.7596 - val_acc: 1.4192e-04\n",
      "Epoch 635/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 311.7963 - mean_squared_error: 311.7962 - acc: 5.6673e-04 ETA: 1s - loss: 287.9737 - mean\n",
      "Epoch 00635: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 311.2015 - mean_squared_error: 311.2014 - acc: 5.4999e-04 - val_loss: 704.0845 - val_mean_squared_error: 704.0846 - val_acc: 0.0000e+00\n",
      "Epoch 636/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 328.8111 - mean_squared_error: 328.8111 - acc: 4.8214e-04\n",
      "Epoch 00636: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 328.4917 - mean_squared_error: 328.4916 - acc: 4.7902e-04 - val_loss: 886.7596 - val_mean_squared_error: 886.7595 - val_acc: 1.4192e-04\n",
      "Epoch 637/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 387.5409 - mean_squared_error: 387.5410 - acc: 4.5872e-04\n",
      "Epoch 00637: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 385.3681 - mean_squared_error: 385.3681 - acc: 4.4354e-04 - val_loss: 683.1035 - val_mean_squared_error: 683.1035 - val_acc: 1.4192e-04\n",
      "Epoch 638/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 437.2358 - mean_squared_error: 437.2359 - acc: 7.8324e-04\n",
      "Epoch 00638: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 433.8309 - mean_squared_error: 433.8310 - acc: 7.9837e-04 - val_loss: 791.9847 - val_mean_squared_error: 791.9848 - val_acc: 4.2577e-04\n",
      "Epoch 639/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 304.5057 - mean_squared_error: 304.5056 - acc: 6.1818e-04\n",
      "Epoch 00639: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.3762 - mean_squared_error: 304.3761 - acc: 6.2095e-04 - val_loss: 1545.9898 - val_mean_squared_error: 1545.9897 - val_acc: 4.2577e-04\n",
      "Epoch 640/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 317.1990 - mean_squared_error: 317.1989 - acc: 6.2167e-04\n",
      "Epoch 00640: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 317.0743 - mean_squared_error: 317.0742 - acc: 6.2095e-04 - val_loss: 5404.4295 - val_mean_squared_error: 5404.4316 - val_acc: 3.5481e-04\n",
      "Epoch 641/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 312.8234 - mean_squared_error: 312.8233 - acc: 5.5357e-04\n",
      "Epoch 00641: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 312.4815 - mean_squared_error: 312.4814 - acc: 5.4999e-04 - val_loss: 923.7677 - val_mean_squared_error: 923.7673 - val_acc: 2.8385e-04\n",
      "Epoch 642/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 291.4172 - mean_squared_error: 291.4172 - acc: 5.3114e-04\n",
      "Epoch 00642: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 291.5479 - mean_squared_error: 291.5479 - acc: 5.3225e-04 - val_loss: 705.7817 - val_mean_squared_error: 705.7819 - val_acc: 2.1289e-04\n",
      "Epoch 643/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 355.8363 - mean_squared_error: 355.8362 - acc: 6.6667e-04\n",
      "Epoch 00643: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 355.5201 - mean_squared_error: 355.5201 - acc: 6.9192e-04 - val_loss: 855.5915 - val_mean_squared_error: 855.5914 - val_acc: 3.5481e-04\n",
      "Epoch 644/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 406.1983 - mean_squared_error: 406.1985 - acc: 7.6642e-04\n",
      "Epoch 00644: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 403.2189 - mean_squared_error: 403.2192 - acc: 7.4514e-04 - val_loss: 3058.6639 - val_mean_squared_error: 3058.6638 - val_acc: 4.9674e-04\n",
      "Epoch 645/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 591.2803 - mean_squared_error: 591.2805 - acc: 4.7882e-04\n",
      "Epoch 00645: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 583.2336 - mean_squared_error: 583.2338 - acc: 5.1450e-04 - val_loss: 720.9350 - val_mean_squared_error: 720.9351 - val_acc: 3.5481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 646/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 475.7108 - mean_squared_error: 475.7109 - acc: 4.9724e-04\n",
      "Epoch 00646: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 468.8334 - mean_squared_error: 468.8335 - acc: 4.9676e-04 - val_loss: 758.3230 - val_mean_squared_error: 758.3231 - val_acc: 1.4192e-04\n",
      "Epoch 647/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 395.0934 - mean_squared_error: 395.0933 - acc: 5.9891e-04\n",
      "Epoch 00647: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 393.1664 - mean_squared_error: 393.1664 - acc: 5.8547e-04 - val_loss: 735.9575 - val_mean_squared_error: 735.9573 - val_acc: 4.9674e-04\n",
      "Epoch 648/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 461.8708 - mean_squared_error: 461.8710 - acc: 7.3529e-04\n",
      "Epoch 00648: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 455.2920 - mean_squared_error: 455.2921 - acc: 7.0966e-04 - val_loss: 714.2405 - val_mean_squared_error: 714.2408 - val_acc: 7.0962e-05\n",
      "Epoch 649/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 327.1637 - mean_squared_error: 327.1637 - acc: 5.3114e-04\n",
      "Epoch 00649: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 326.0469 - mean_squared_error: 326.0469 - acc: 5.1450e-04 - val_loss: 709.9894 - val_mean_squared_error: 709.9893 - val_acc: 7.0962e-05\n",
      "Epoch 650/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 287.8287 - mean_squared_error: 287.8286 - acc: 6.3943e-04\n",
      "Epoch 00650: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.8395 - mean_squared_error: 287.8394 - acc: 6.3869e-04 - val_loss: 748.0468 - val_mean_squared_error: 748.0468 - val_acc: 0.0000e+00\n",
      "Epoch 651/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 294.6122 - mean_squared_error: 294.6122 - acc: 6.6190e-04\n",
      "Epoch 00651: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 295.1094 - mean_squared_error: 295.1094 - acc: 6.5644e-04 - val_loss: 721.6411 - val_mean_squared_error: 721.6409 - val_acc: 0.0000e+00\n",
      "Epoch 652/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 338.0801 - mean_squared_error: 338.0801 - acc: 6.4401e-04\n",
      "Epoch 00652: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.6429 - mean_squared_error: 337.6429 - acc: 6.3869e-04 - val_loss: 763.1088 - val_mean_squared_error: 763.1088 - val_acc: 2.1289e-04\n",
      "Epoch 653/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 371.1914 - mean_squared_error: 371.1910 - acc: 6.5217e-04\n",
      "Epoch 00653: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 370.4883 - mean_squared_error: 370.4880 - acc: 6.5644e-04 - val_loss: 734.4249 - val_mean_squared_error: 734.4247 - val_acc: 1.4192e-04\n",
      "Epoch 654/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 310.7698 - mean_squared_error: 310.7699 - acc: 5.6985e-04\n",
      "Epoch 00654: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.0442 - mean_squared_error: 310.0443 - acc: 5.8547e-04 - val_loss: 747.0784 - val_mean_squared_error: 747.0782 - val_acc: 0.0000e+00\n",
      "Epoch 655/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 481.4227 - mean_squared_error: 481.4226 - acc: 4.9734e-04\n",
      "Epoch 00655: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 481.1745 - mean_squared_error: 481.1745 - acc: 4.9676e-04 - val_loss: 737.7352 - val_mean_squared_error: 737.7350 - val_acc: 0.0000e+00\n",
      "Epoch 656/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 305.7304 - mean_squared_error: 305.7303 - acc: 4.9270e-04\n",
      "Epoch 00656: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 305.4557 - mean_squared_error: 305.4555 - acc: 5.4999e-04 - val_loss: 778.3905 - val_mean_squared_error: 778.3904 - val_acc: 0.0000e+00\n",
      "Epoch 657/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 370.7352 - mean_squared_error: 370.7350 - acc: 4.2279e-04\n",
      "Epoch 00657: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 369.9605 - mean_squared_error: 369.9603 - acc: 4.2580e-04 - val_loss: 718.1140 - val_mean_squared_error: 718.1138 - val_acc: 0.0000e+00\n",
      "Epoch 658/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 359.1468 - mean_squared_error: 359.1470 - acc: 5.0269e-04\n",
      "Epoch 00658: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 357.9716 - mean_squared_error: 357.9718 - acc: 5.3225e-04 - val_loss: 702.6814 - val_mean_squared_error: 702.6813 - val_acc: 0.0000e+00\n",
      "Epoch 659/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 358.4178 - mean_squared_error: 358.4178 - acc: 6.0714e-04\n",
      "Epoch 00659: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 357.8446 - mean_squared_error: 357.8445 - acc: 6.0321e-04 - val_loss: 739.7262 - val_mean_squared_error: 739.7261 - val_acc: 4.2577e-04\n",
      "Epoch 660/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 390.7458 - mean_squared_error: 390.7460 - acc: 5.5357e-04\n",
      "Epoch 00660: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 390.1318 - mean_squared_error: 390.1320 - acc: 5.4999e-04 - val_loss: 715.4668 - val_mean_squared_error: 715.4667 - val_acc: 7.0962e-05\n",
      "Epoch 661/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 288.7887 - mean_squared_error: 288.7887 - acc: 5.7762e-04\n",
      "Epoch 00661: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 288.6045 - mean_squared_error: 288.6046 - acc: 5.6773e-04 - val_loss: 752.4794 - val_mean_squared_error: 752.4796 - val_acc: 7.0962e-05\n",
      "Epoch 662/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 293.5108 - mean_squared_error: 293.5110 - acc: 5.9675e-04\n",
      "Epoch 00662: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 293.4727 - mean_squared_error: 293.4730 - acc: 6.0321e-04 - val_loss: 719.5302 - val_mean_squared_error: 719.5300 - val_acc: 2.8385e-04\n",
      "Epoch 663/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 535.5523 - mean_squared_error: 535.5522 - acc: 5.6261e-04\n",
      "Epoch 00663: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 530.8833 - mean_squared_error: 530.8833 - acc: 5.6773e-04 - val_loss: 774.1198 - val_mean_squared_error: 774.1200 - val_acc: 0.0000e+00\n",
      "Epoch 664/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 326.8251 - mean_squared_error: 326.8250 - acc: 5.3667e-04\n",
      "Epoch 00664: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 326.5062 - mean_squared_error: 326.5061 - acc: 5.6773e-04 - val_loss: 750.5364 - val_mean_squared_error: 750.5366 - val_acc: 2.1289e-04\n",
      "Epoch 665/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 372.7350 - mean_squared_error: 372.7348 - acc: 6.2615e-04\n",
      "Epoch 00665: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 370.2173 - mean_squared_error: 370.2172 - acc: 6.3869e-04 - val_loss: 727.1763 - val_mean_squared_error: 727.1764 - val_acc: 7.0962e-05\n",
      "Epoch 666/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 440.8443 - mean_squared_error: 440.8445 - acc: 4.9734e-04\n",
      "Epoch 00666: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 440.6871 - mean_squared_error: 440.6873 - acc: 4.9676e-04 - val_loss: 722.1929 - val_mean_squared_error: 722.1931 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 314.9317 - mean_squared_error: 314.9317 - acc: 6.5099e-04\n",
      "Epoch 00667: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 314.3975 - mean_squared_error: 314.3975 - acc: 6.3869e-04 - val_loss: 798.4579 - val_mean_squared_error: 798.4582 - val_acc: 7.0962e-05\n",
      "Epoch 668/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 393.0469 - mean_squared_error: 393.0470 - acc: 6.2612e-04\n",
      "Epoch 00668: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 392.8154 - mean_squared_error: 392.8156 - acc: 6.3869e-04 - val_loss: 671.6404 - val_mean_squared_error: 671.6406 - val_acc: 4.2577e-04\n",
      "Epoch 669/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 545.3830 - mean_squared_error: 545.3830 - acc: 7.0652e-04\n",
      "Epoch 00669: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 539.8107 - mean_squared_error: 539.8107 - acc: 6.9192e-04 - val_loss: 722.9036 - val_mean_squared_error: 722.9037 - val_acc: 1.4192e-04\n",
      "Epoch 670/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 298.8974 - mean_squared_error: 298.8974 - acc: 6.0440e-04\n",
      "Epoch 00670: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 297.8750 - mean_squared_error: 297.8750 - acc: 6.0321e-04 - val_loss: 705.8070 - val_mean_squared_error: 705.8072 - val_acc: 7.0962e-05\n",
      "Epoch 671/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 292.7796 - mean_squared_error: 292.7798 - acc: 5.4545e-04\n",
      "Epoch 00671: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 292.5268 - mean_squared_error: 292.5271 - acc: 5.4999e-04 - val_loss: 753.7212 - val_mean_squared_error: 753.7213 - val_acc: 2.1289e-04\n",
      "Epoch 672/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 297.1291 - mean_squared_error: 297.1290 - acc: 6.1151e-04\n",
      "Epoch 00672: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 296.8743 - mean_squared_error: 296.8742 - acc: 6.0321e-04 - val_loss: 725.8284 - val_mean_squared_error: 725.8285 - val_acc: 7.0962e-05\n",
      "Epoch 673/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 328.1076 - mean_squared_error: 328.1077 - acc: 6.7857e-04\n",
      "Epoch 00673: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 327.3992 - mean_squared_error: 327.3994 - acc: 6.7418e-04 - val_loss: 1080.7334 - val_mean_squared_error: 1080.7335 - val_acc: 0.0000e+00\n",
      "Epoch 674/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 300.6420 - mean_squared_error: 300.6420 - acc: 6.8223e-04\n",
      "Epoch 00674: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 300.5424 - mean_squared_error: 300.5424 - acc: 6.7418e-04 - val_loss: 747.7222 - val_mean_squared_error: 747.7224 - val_acc: 0.0000e+00\n",
      "Epoch 675/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 319.6049 - mean_squared_error: 319.6049 - acc: 7.1823e-04\n",
      "Epoch 00675: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.5209 - mean_squared_error: 319.5209 - acc: 7.0966e-04 - val_loss: 682.6172 - val_mean_squared_error: 682.6174 - val_acc: 2.1289e-04\n",
      "Epoch 676/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 291.8841 - mean_squared_error: 291.8841 - acc: 6.4865e-04\n",
      "Epoch 00676: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 291.5922 - mean_squared_error: 291.5921 - acc: 6.5644e-04 - val_loss: 705.8931 - val_mean_squared_error: 705.8930 - val_acc: 7.0962e-05\n",
      "Epoch 677/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 326.9449 - mean_squared_error: 326.9451 - acc: 6.5814e-04\n",
      "Epoch 00677: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 326.3766 - mean_squared_error: 326.3769 - acc: 6.7418e-04 - val_loss: 818.7785 - val_mean_squared_error: 818.7784 - val_acc: 0.0000e+00\n",
      "Epoch 678/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 419.1796 - mean_squared_error: 419.1799 - acc: 6.1261e-04\n",
      "Epoch 00678: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 417.9826 - mean_squared_error: 417.9828 - acc: 6.2095e-04 - val_loss: 690.1302 - val_mean_squared_error: 690.1303 - val_acc: 2.8385e-04\n",
      "Epoch 679/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 318.8329 - mean_squared_error: 318.8330 - acc: 6.9767e-04\n",
      "Epoch 00679: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 318.0712 - mean_squared_error: 318.0713 - acc: 6.9192e-04 - val_loss: 729.8029 - val_mean_squared_error: 729.8029 - val_acc: 3.5481e-04\n",
      "Epoch 680/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 289.9349 - mean_squared_error: 289.9349 - acc: 5.7971e-04\n",
      "Epoch 00680: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 289.4596 - mean_squared_error: 289.4597 - acc: 5.8547e-04 - val_loss: 708.3562 - val_mean_squared_error: 708.3561 - val_acc: 2.8385e-04\n",
      "Epoch 681/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 334.7279 - mean_squared_error: 334.7280 - acc: 5.9783e-04\n",
      "Epoch 00681: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 334.3750 - mean_squared_error: 334.3751 - acc: 5.8547e-04 - val_loss: 714.8940 - val_mean_squared_error: 714.8940 - val_acc: 7.0962e-05\n",
      "Epoch 682/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 324.8120 - mean_squared_error: 324.8121 - acc: 4.9632e-04\n",
      "Epoch 00682: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 324.6390 - mean_squared_error: 324.6390 - acc: 4.9676e-04 - val_loss: 687.7012 - val_mean_squared_error: 687.7013 - val_acc: 2.1289e-04\n",
      "Epoch 683/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 393.0347 - mean_squared_error: 393.0346 - acc: 6.2615e-04\n",
      "Epoch 00683: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 389.7577 - mean_squared_error: 389.7575 - acc: 6.5644e-04 - val_loss: 712.4806 - val_mean_squared_error: 712.4807 - val_acc: 7.0962e-05\n",
      "Epoch 684/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 327.6844 - mean_squared_error: 327.6841 - acc: 5.5147e-04\n",
      "Epoch 00684: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 326.4732 - mean_squared_error: 326.4730 - acc: 5.6773e-04 - val_loss: 1455.2522 - val_mean_squared_error: 1455.2523 - val_acc: 7.0962e-05\n",
      "Epoch 685/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 717.3165 - mean_squared_error: 717.3167 - acc: 6.4057e-04\n",
      "Epoch 00685: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 716.0947 - mean_squared_error: 716.0949 - acc: 6.3869e-04 - val_loss: 679.8139 - val_mean_squared_error: 679.8140 - val_acc: 7.0962e-05\n",
      "Epoch 686/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 334.7885 - mean_squared_error: 334.7886 - acc: 5.3860e-04\n",
      "Epoch 00686: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 334.3752 - mean_squared_error: 334.3753 - acc: 5.3225e-04 - val_loss: 672.2153 - val_mean_squared_error: 672.2154 - val_acc: 0.0000e+00\n",
      "Epoch 687/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 336.1652 - mean_squared_error: 336.1652 - acc: 6.4982e-04 ETA: 1s - loss: 280.2792 - mean_s\n",
      "Epoch 00687: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 335.2333 - mean_squared_error: 335.2333 - acc: 6.5644e-04 - val_loss: 676.2660 - val_mean_squared_error: 676.2661 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 287.3635 - mean_squared_error: 287.3634 - acc: 5.9459e-04\n",
      "Epoch 00688: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.5355 - mean_squared_error: 287.5355 - acc: 6.5644e-04 - val_loss: 760.4033 - val_mean_squared_error: 760.4035 - val_acc: 1.4192e-04\n",
      "Epoch 689/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 306.4420 - mean_squared_error: 306.4421 - acc: 4.9091e-04\n",
      "Epoch 00689: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.6040 - mean_squared_error: 305.6041 - acc: 4.9676e-04 - val_loss: 763.1649 - val_mean_squared_error: 763.1650 - val_acc: 4.9674e-04\n",
      "Epoch 690/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 324.5510 - mean_squared_error: 324.5509 - acc: 6.6908e-04\n",
      "Epoch 00690: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 323.9850 - mean_squared_error: 323.9849 - acc: 6.7418e-04 - val_loss: 727.3243 - val_mean_squared_error: 727.3242 - val_acc: 3.5481e-04\n",
      "Epoch 691/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 384.4758 - mean_squared_error: 384.4758 - acc: 5.8076e-04\n",
      "Epoch 00691: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 382.3287 - mean_squared_error: 382.3287 - acc: 6.0321e-04 - val_loss: 810.6154 - val_mean_squared_error: 810.6152 - val_acc: 3.5481e-04\n",
      "Epoch 692/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 290.4980 - mean_squared_error: 290.4979 - acc: 5.2823e-04\n",
      "Epoch 00692: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 290.2228 - mean_squared_error: 290.2227 - acc: 5.3225e-04 - val_loss: 745.5661 - val_mean_squared_error: 745.5660 - val_acc: 3.5481e-04\n",
      "Epoch 693/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 320.9309 - mean_squared_error: 320.9312 - acc: 5.4645e-04\n",
      "Epoch 00693: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.5276 - mean_squared_error: 319.5278 - acc: 5.8547e-04 - val_loss: 1055.3368 - val_mean_squared_error: 1055.3369 - val_acc: 0.0000e+00\n",
      "Epoch 694/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 322.5542 - mean_squared_error: 322.5541 - acc: 5.6569e-04\n",
      "Epoch 00694: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 321.1721 - mean_squared_error: 321.1721 - acc: 5.8547e-04 - val_loss: 691.7677 - val_mean_squared_error: 691.7678 - val_acc: 2.1289e-04\n",
      "Epoch 695/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 293.1612 - mean_squared_error: 293.1611 - acc: 6.5954e-04\n",
      "Epoch 00695: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 292.9309 - mean_squared_error: 292.9308 - acc: 6.5644e-04 - val_loss: 712.6341 - val_mean_squared_error: 712.6342 - val_acc: 0.0000e+00\n",
      "Epoch 696/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 341.1139 - mean_squared_error: 341.1137 - acc: 5.5755e-04\n",
      "Epoch 00696: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.1770 - mean_squared_error: 340.1768 - acc: 5.4999e-04 - val_loss: 682.2795 - val_mean_squared_error: 682.2795 - val_acc: 2.1289e-04\n",
      "Epoch 697/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 286.6582 - mean_squared_error: 286.6583 - acc: 6.2612e-04\n",
      "Epoch 00697: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.6460 - mean_squared_error: 286.6460 - acc: 6.2095e-04 - val_loss: 706.9828 - val_mean_squared_error: 706.9828 - val_acc: 2.8385e-04\n",
      "Epoch 698/3000\n",
      "53800/56365 [===========================>..] - ETA: 0s - loss: 442.9277 - mean_squared_error: 442.9276 - acc: 5.7621e-04\n",
      "Epoch 00698: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 436.5835 - mean_squared_error: 436.5833 - acc: 5.8547e-04 - val_loss: 701.6858 - val_mean_squared_error: 701.6859 - val_acc: 1.4192e-04\n",
      "Epoch 699/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 355.3164 - mean_squared_error: 355.3164 - acc: 5.5556e-04\n",
      "Epoch 00699: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 352.3067 - mean_squared_error: 352.3066 - acc: 5.6773e-04 - val_loss: 725.3780 - val_mean_squared_error: 725.3780 - val_acc: 0.0000e+00\n",
      "Epoch 700/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 287.3573 - mean_squared_error: 287.3573 - acc: 6.5336e-04\n",
      "Epoch 00700: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 287.9242 - mean_squared_error: 287.9243 - acc: 6.5644e-04 - val_loss: 733.2460 - val_mean_squared_error: 733.2460 - val_acc: 0.0000e+00\n",
      "Epoch 701/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 293.8599 - mean_squared_error: 293.8597 - acc: 7.9044e-04\n",
      "Epoch 00701: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 293.0959 - mean_squared_error: 293.0959 - acc: 7.6288e-04 - val_loss: 716.7974 - val_mean_squared_error: 716.7972 - val_acc: 2.8385e-04\n",
      "Epoch 702/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 338.1880 - mean_squared_error: 338.1884 - acc: 6.4748e-04\n",
      "Epoch 00702: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.3433 - mean_squared_error: 337.3436 - acc: 6.3869e-04 - val_loss: 687.7003 - val_mean_squared_error: 687.7004 - val_acc: 7.0962e-05\n",
      "Epoch 703/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 379.0989 - mean_squared_error: 379.0987 - acc: 6.8100e-04\n",
      "Epoch 00703: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 378.9177 - mean_squared_error: 378.9174 - acc: 6.7418e-04 - val_loss: 689.3142 - val_mean_squared_error: 689.3141 - val_acc: 0.0000e+00\n",
      "Epoch 704/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 322.9481 - mean_squared_error: 322.9480 - acc: 4.9911e-04\n",
      "Epoch 00704: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 322.8223 - mean_squared_error: 322.8222 - acc: 4.9676e-04 - val_loss: 719.4947 - val_mean_squared_error: 719.4946 - val_acc: 7.0962e-05\n",
      "Epoch 705/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 432.6228 - mean_squared_error: 432.6226 - acc: 5.1756e-04\n",
      "Epoch 00705: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 427.5657 - mean_squared_error: 427.5656 - acc: 6.2095e-04 - val_loss: 717.0258 - val_mean_squared_error: 717.0257 - val_acc: 0.0000e+00\n",
      "Epoch 706/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 327.4494 - mean_squared_error: 327.4495 - acc: 6.5455e-04\n",
      "Epoch 00706: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 326.0551 - mean_squared_error: 326.0551 - acc: 6.5644e-04 - val_loss: 713.6288 - val_mean_squared_error: 713.6290 - val_acc: 3.5481e-04\n",
      "Epoch 707/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 286.1830 - mean_squared_error: 286.1830 - acc: 5.1601e-04\n",
      "Epoch 00707: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.2101 - mean_squared_error: 286.2101 - acc: 5.1450e-04 - val_loss: 707.9401 - val_mean_squared_error: 707.9402 - val_acc: 0.0000e+00\n",
      "Epoch 708/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 296.5922 - mean_squared_error: 296.5923 - acc: 6.0606e-04\n",
      "Epoch 00708: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 296.6002 - mean_squared_error: 296.6003 - acc: 6.0321e-04 - val_loss: 721.6587 - val_mean_squared_error: 721.6587 - val_acc: 2.8385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 310.5987 - mean_squared_error: 310.5989 - acc: 7.0524e-04\n",
      "Epoch 00709: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.1511 - mean_squared_error: 310.1513 - acc: 6.9192e-04 - val_loss: 711.2942 - val_mean_squared_error: 711.2943 - val_acc: 2.1289e-04\n",
      "Epoch 710/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 283.2684 - mean_squared_error: 283.2684 - acc: 6.8140e-04\n",
      "Epoch 00710: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 282.9932 - mean_squared_error: 282.9933 - acc: 6.9192e-04 - val_loss: 745.5156 - val_mean_squared_error: 745.5156 - val_acc: 2.8385e-04\n",
      "Epoch 711/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 404.4066 - mean_squared_error: 404.4066 - acc: 5.2441e-04\n",
      "Epoch 00711: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 403.2011 - mean_squared_error: 403.2011 - acc: 5.1450e-04 - val_loss: 753.9665 - val_mean_squared_error: 753.9664 - val_acc: 7.0962e-05\n",
      "Epoch 712/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 437.1833 - mean_squared_error: 437.1834 - acc: 4.8561e-04\n",
      "Epoch 00712: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 435.3289 - mean_squared_error: 435.3290 - acc: 4.9676e-04 - val_loss: 667.7400 - val_mean_squared_error: 667.7400 - val_acc: 2.1289e-04\n",
      "Epoch 713/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 385.3102 - mean_squared_error: 385.3101 - acc: 7.5134e-04\n",
      "Epoch 00713: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 384.4968 - mean_squared_error: 384.4967 - acc: 7.4514e-04 - val_loss: 718.7409 - val_mean_squared_error: 718.7411 - val_acc: 0.0000e+00\n",
      "Epoch 714/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 307.3986 - mean_squared_error: 307.3985 - acc: 6.2950e-04\n",
      "Epoch 00714: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 308.1953 - mean_squared_error: 308.1952 - acc: 6.3869e-04 - val_loss: 690.2596 - val_mean_squared_error: 690.2596 - val_acc: 7.0962e-05\n",
      "Epoch 715/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 290.9846 - mean_squared_error: 290.9844 - acc: 6.9470e-04\n",
      "Epoch 00715: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 291.0388 - mean_squared_error: 291.0387 - acc: 6.9192e-04 - val_loss: 740.1878 - val_mean_squared_error: 740.1880 - val_acc: 2.1289e-04\n",
      "Epoch 716/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 303.0604 - mean_squared_error: 303.0603 - acc: 5.2441e-04\n",
      "Epoch 00716: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 302.3556 - mean_squared_error: 302.3555 - acc: 5.1450e-04 - val_loss: 736.6290 - val_mean_squared_error: 736.6292 - val_acc: 0.0000e+00\n",
      "Epoch 717/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 303.9344 - mean_squared_error: 303.9344 - acc: 6.6667e-04\n",
      "Epoch 00717: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 303.7413 - mean_squared_error: 303.7413 - acc: 6.7418e-04 - val_loss: 693.2156 - val_mean_squared_error: 693.2156 - val_acc: 0.0000e+00\n",
      "Epoch 718/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 330.8382 - mean_squared_error: 330.8382 - acc: 6.4338e-04\n",
      "Epoch 00718: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 329.6468 - mean_squared_error: 329.6468 - acc: 6.3869e-04 - val_loss: 694.5724 - val_mean_squared_error: 694.5726 - val_acc: 7.0962e-05\n",
      "Epoch 719/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 423.8607 - mean_squared_error: 423.8605 - acc: 5.5062e-04\n",
      "Epoch 00719: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 423.9996 - mean_squared_error: 423.9994 - acc: 5.4999e-04 - val_loss: 682.4020 - val_mean_squared_error: 682.4019 - val_acc: 7.0962e-05\n",
      "Epoch 720/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 377.9412 - mean_squared_error: 377.9412 - acc: 6.1041e-04 ETA: 1s - loss: 301.1951 - mean_squared_error: 301.1950 - acc:  - ETA: 0s - loss: 520.2727 - mean_squared_err\n",
      "Epoch 00720: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 377.1289 - mean_squared_error: 377.1290 - acc: 6.2095e-04 - val_loss: 737.3163 - val_mean_squared_error: 737.3164 - val_acc: 7.0962e-05\n",
      "Epoch 721/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 286.7320 - mean_squared_error: 286.7319 - acc: 6.6543e-04\n",
      "Epoch 00721: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 491.5677 - mean_squared_error: 491.5676 - acc: 6.3869e-04 - val_loss: 769.5368 - val_mean_squared_error: 769.5366 - val_acc: 0.0000e+00\n",
      "Epoch 722/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 299.0444 - mean_squared_error: 299.0444 - acc: 4.8387e-04\n",
      "Epoch 00722: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 299.0834 - mean_squared_error: 299.0834 - acc: 4.7902e-04 - val_loss: 703.3387 - val_mean_squared_error: 703.3386 - val_acc: 0.0000e+00\n",
      "Epoch 723/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 285.7118 - mean_squared_error: 285.7116 - acc: 5.8929e-04\n",
      "Epoch 00723: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 285.8454 - mean_squared_error: 285.8451 - acc: 5.8547e-04 - val_loss: 743.5099 - val_mean_squared_error: 743.5100 - val_acc: 0.0000e+00\n",
      "Epoch 724/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 320.0360 - mean_squared_error: 320.0359 - acc: 6.5836e-04 ETA: 1s - loss: 281.5383 - mean\n",
      "Epoch 00724: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 320.0277 - mean_squared_error: 320.0277 - acc: 6.5644e-04 - val_loss: 732.8123 - val_mean_squared_error: 732.8123 - val_acc: 2.8385e-04\n",
      "Epoch 725/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 287.3301 - mean_squared_error: 287.3300 - acc: 5.8929e-04\n",
      "Epoch 00725: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 288.1501 - mean_squared_error: 288.1499 - acc: 5.8547e-04 - val_loss: 755.8654 - val_mean_squared_error: 755.8654 - val_acc: 0.0000e+00\n",
      "Epoch 726/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 358.6010 - mean_squared_error: 358.6010 - acc: 4.4803e-04\n",
      "Epoch 00726: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 357.9789 - mean_squared_error: 357.9790 - acc: 4.6128e-04 - val_loss: 754.5110 - val_mean_squared_error: 754.5109 - val_acc: 0.0000e+00\n",
      "Epoch 727/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 487.1474 - mean_squared_error: 487.1472 - acc: 4.7957e-04\n",
      "Epoch 00727: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 486.9801 - mean_squared_error: 486.9800 - acc: 4.7902e-04 - val_loss: 743.5676 - val_mean_squared_error: 743.5678 - val_acc: 0.0000e+00\n",
      "Epoch 728/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 299.9409 - mean_squared_error: 299.9409 - acc: 5.2347e-04\n",
      "Epoch 00728: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 299.2458 - mean_squared_error: 299.2457 - acc: 5.1450e-04 - val_loss: 704.0675 - val_mean_squared_error: 704.0675 - val_acc: 0.0000e+00\n",
      "Epoch 729/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 315.9519 - mean_squared_error: 315.9518 - acc: 5.8716e-04\n",
      "Epoch 00729: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 314.0074 - mean_squared_error: 314.0072 - acc: 5.6773e-04 - val_loss: 854.0256 - val_mean_squared_error: 854.0257 - val_acc: 1.4192e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 730/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 392.5351 - mean_squared_error: 392.5355 - acc: 6.5934e-04 ETA: 0s - loss: 284.4542 - mean_squared_error: \n",
      "Epoch 00730: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 389.3664 - mean_squared_error: 389.3667 - acc: 6.5644e-04 - val_loss: 695.8407 - val_mean_squared_error: 695.8407 - val_acc: 7.0962e-05\n",
      "Epoch 731/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 353.9019 - mean_squared_error: 353.9021 - acc: 5.5755e-04\n",
      "Epoch 00731: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 353.0209 - mean_squared_error: 353.0211 - acc: 5.8547e-04 - val_loss: 702.7964 - val_mean_squared_error: 702.7966 - val_acc: 5.6770e-04\n",
      "Epoch 732/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 393.2535 - mean_squared_error: 393.2535 - acc: 5.2158e-04\n",
      "Epoch 00732: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 391.3654 - mean_squared_error: 391.3654 - acc: 5.1450e-04 - val_loss: 728.7640 - val_mean_squared_error: 728.7636 - val_acc: 0.0000e+00\n",
      "Epoch 733/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 337.4571 - mean_squared_error: 337.4569 - acc: 5.0000e-04\n",
      "Epoch 00733: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 337.1627 - mean_squared_error: 337.1626 - acc: 4.9676e-04 - val_loss: 684.3218 - val_mean_squared_error: 684.3219 - val_acc: 2.1289e-04\n",
      "Epoch 734/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 291.7959 - mean_squared_error: 291.7960 - acc: 4.9002e-04\n",
      "Epoch 00734: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 291.1686 - mean_squared_error: 291.1688 - acc: 4.9676e-04 - val_loss: 680.4758 - val_mean_squared_error: 680.4756 - val_acc: 1.4192e-04\n",
      "Epoch 735/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 389.9926 - mean_squared_error: 389.9928 - acc: 6.2612e-04\n",
      "Epoch 00735: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 389.1010 - mean_squared_error: 389.1011 - acc: 6.3869e-04 - val_loss: 729.9650 - val_mean_squared_error: 729.9650 - val_acc: 2.8385e-04\n",
      "Epoch 736/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 295.5939 - mean_squared_error: 295.5938 - acc: 7.4141e-04\n",
      "Epoch 00736: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 295.8537 - mean_squared_error: 295.8536 - acc: 7.2740e-04 - val_loss: 706.9546 - val_mean_squared_error: 706.9547 - val_acc: 1.4192e-04\n",
      "Epoch 737/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 382.2523 - mean_squared_error: 382.2523 - acc: 7.2333e-04\n",
      "Epoch 00737: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 381.8252 - mean_squared_error: 381.8251 - acc: 7.0966e-04 - val_loss: 758.9692 - val_mean_squared_error: 758.9692 - val_acc: 0.0000e+00\n",
      "Epoch 738/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 311.5492 - mean_squared_error: 311.5494 - acc: 6.4286e-04\n",
      "Epoch 00738: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 311.4672 - mean_squared_error: 311.4674 - acc: 6.3869e-04 - val_loss: 713.5999 - val_mean_squared_error: 713.5999 - val_acc: 2.8385e-04\n",
      "Epoch 739/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 284.0517 - mean_squared_error: 284.0517 - acc: 6.0550e-04\n",
      "Epoch 00739: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 283.1736 - mean_squared_error: 283.1736 - acc: 6.3869e-04 - val_loss: 705.2106 - val_mean_squared_error: 705.2106 - val_acc: 2.8385e-04\n",
      "Epoch 740/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 300.1820 - mean_squared_error: 300.1819 - acc: 6.4286e-04\n",
      "Epoch 00740: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 299.7709 - mean_squared_error: 299.7708 - acc: 6.3869e-04 - val_loss: 695.7659 - val_mean_squared_error: 695.7657 - val_acc: 7.0962e-05\n",
      "Epoch 741/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 364.2697 - mean_squared_error: 364.2697 - acc: 4.6181e-04\n",
      "Epoch 00741: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 364.1234 - mean_squared_error: 364.1234 - acc: 4.6128e-04 - val_loss: 728.4426 - val_mean_squared_error: 728.4425 - val_acc: 0.0000e+00\n",
      "Epoch 742/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 277.5992 - mean_squared_error: 277.5990 - acc: 6.9767e-04\n",
      "Epoch 00742: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 277.3605 - mean_squared_error: 277.3603 - acc: 7.0966e-04 - val_loss: 729.0269 - val_mean_squared_error: 729.0266 - val_acc: 0.0000e+00\n",
      "Epoch 743/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 300.7815 - mean_squared_error: 300.7816 - acc: 6.0391e-04\n",
      "Epoch 00743: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 300.7607 - mean_squared_error: 300.7609 - acc: 6.0321e-04 - val_loss: 677.2304 - val_mean_squared_error: 677.2304 - val_acc: 2.8385e-04\n",
      "Epoch 744/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 365.1053 - mean_squared_error: 365.1053 - acc: 6.2157e-04\n",
      "Epoch 00744: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 362.4530 - mean_squared_error: 362.4530 - acc: 6.0321e-04 - val_loss: 709.7610 - val_mean_squared_error: 709.7610 - val_acc: 1.4192e-04\n",
      "Epoch 745/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 359.8032 - mean_squared_error: 359.8032 - acc: 5.3957e-04\n",
      "Epoch 00745: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 358.6131 - mean_squared_error: 358.6131 - acc: 5.3225e-04 - val_loss: 701.1197 - val_mean_squared_error: 701.1197 - val_acc: 7.0962e-05\n",
      "Epoch 746/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 318.4774 - mean_squared_error: 318.4774 - acc: 5.3381e-04\n",
      "Epoch 00746: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 318.4848 - mean_squared_error: 318.4848 - acc: 5.3225e-04 - val_loss: 684.8522 - val_mean_squared_error: 684.8521 - val_acc: 0.0000e+00\n",
      "Epoch 747/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 465.4369 - mean_squared_error: 465.4367 - acc: 5.5856e-04\n",
      "Epoch 00747: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 462.2720 - mean_squared_error: 462.2719 - acc: 5.4999e-04 - val_loss: 664.5588 - val_mean_squared_error: 664.5589 - val_acc: 0.0000e+00\n",
      "Epoch 748/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 279.5009 - mean_squared_error: 279.5008 - acc: 5.5556e-04\n",
      "Epoch 00748: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 279.4628 - mean_squared_error: 279.4627 - acc: 5.4999e-04 - val_loss: 676.5288 - val_mean_squared_error: 676.5287 - val_acc: 7.0962e-05\n",
      "Epoch 749/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 287.6026 - mean_squared_error: 287.6025 - acc: 5.2920e-04\n",
      "Epoch 00749: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 288.4251 - mean_squared_error: 288.4251 - acc: 5.4999e-04 - val_loss: 705.6232 - val_mean_squared_error: 705.6231 - val_acc: 1.4192e-04\n",
      "Epoch 750/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 303.8016 - mean_squared_error: 303.8014 - acc: 5.2533e- - ETA: 0s - loss: 302.3194 - mean_squared_error: 302.3193 - acc: 5.2158e-04\n",
      "Epoch 00750: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 302.2599 - mean_squared_error: 302.2598 - acc: 5.3225e-04 - val_loss: 687.4126 - val_mean_squared_error: 687.4127 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 329.2011 - mean_squared_error: 329.2013 - acc: 5.4945e-04\n",
      "Epoch 00751: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 328.6684 - mean_squared_error: 328.6686 - acc: 5.6773e-04 - val_loss: 754.9816 - val_mean_squared_error: 754.9818 - val_acc: 7.0962e-05\n",
      "Epoch 752/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 319.8075 - mean_squared_error: 319.8076 - acc: 6.6547e-04\n",
      "Epoch 00752: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.1877 - mean_squared_error: 319.1879 - acc: 6.5644e-04 - val_loss: 739.6375 - val_mean_squared_error: 739.6375 - val_acc: 2.1289e-04\n",
      "Epoch 753/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 336.3880 - mean_squared_error: 336.3879 - acc: 6.1151e-04\n",
      "Epoch 00753: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 335.3475 - mean_squared_error: 335.3475 - acc: 6.0321e-04 - val_loss: 725.0571 - val_mean_squared_error: 725.0575 - val_acc: 0.0000e+00\n",
      "Epoch 754/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 430.3353 - mean_squared_error: 430.3349 - acc: 6.7857e-04\n",
      "Epoch 00754: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 429.2346 - mean_squared_error: 429.2342 - acc: 6.9192e-04 - val_loss: 724.8999 - val_mean_squared_error: 724.8999 - val_acc: 0.0000e+00\n",
      "Epoch 755/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 293.3726 - mean_squared_error: 293.3727 - acc: 6.6071e-04\n",
      "Epoch 00755: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 293.3057 - mean_squared_error: 293.3058 - acc: 6.5644e-04 - val_loss: 689.8259 - val_mean_squared_error: 689.8259 - val_acc: 2.1289e-04\n",
      "Epoch 756/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 437.3349 - mean_squared_error: 437.3348 - acc: 6.0662e-04\n",
      "Epoch 00756: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 431.8888 - mean_squared_error: 431.8887 - acc: 6.0321e-04 - val_loss: 722.8967 - val_mean_squared_error: 722.8965 - val_acc: 0.0000e+00\n",
      "Epoch 757/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 354.8764 - mean_squared_error: 354.8762 - acc: 6.1372e-04\n",
      "Epoch 00757: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 353.8900 - mean_squared_error: 353.8897 - acc: 6.2095e-04 - val_loss: 703.4865 - val_mean_squared_error: 703.4865 - val_acc: 2.8385e-04\n",
      "Epoch 758/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 285.2860 - mean_squared_error: 285.2860 - acc: 6.7642e-04\n",
      "Epoch 00758: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 284.5846 - mean_squared_error: 284.5845 - acc: 6.5644e-04 - val_loss: 732.2446 - val_mean_squared_error: 732.2448 - val_acc: 0.0000e+00\n",
      "Epoch 759/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 281.1861 - mean_squared_error: 281.1860 - acc: 6.7273e-04\n",
      "Epoch 00759: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 280.9936 - mean_squared_error: 280.9935 - acc: 6.5644e-04 - val_loss: 745.2968 - val_mean_squared_error: 745.2967 - val_acc: 7.0962e-05\n",
      "Epoch 760/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 301.9176 - mean_squared_error: 301.9175 - acc: 5.5062e-04\n",
      "Epoch 00760: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 301.7853 - mean_squared_error: 301.7852 - acc: 5.6773e-04 - val_loss: 834.1905 - val_mean_squared_error: 834.1904 - val_acc: 0.0000e+00\n",
      "Epoch 761/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 337.9619 - mean_squared_error: 337.9619 - acc: 6.8100e-04\n",
      "Epoch 00761: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.3766 - mean_squared_error: 337.3766 - acc: 6.9192e-04 - val_loss: 698.0006 - val_mean_squared_error: 698.0005 - val_acc: 7.0962e-05\n",
      "Epoch 762/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 310.1026 - mean_squared_error: 310.1027 - acc: 6.2500e-04\n",
      "Epoch 00762: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 309.3722 - mean_squared_error: 309.3724 - acc: 6.3869e-04 - val_loss: 747.7196 - val_mean_squared_error: 747.7194 - val_acc: 0.0000e+00\n",
      "Epoch 763/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 372.4017 - mean_squared_error: 372.4019 - acc: 6.8140e-04\n",
      "Epoch 00763: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 369.4088 - mean_squared_error: 369.4090 - acc: 6.5644e-04 - val_loss: 738.7909 - val_mean_squared_error: 738.7909 - val_acc: 7.0962e-05\n",
      "Epoch 764/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 374.0038 - mean_squared_error: 374.0035 - acc: 5.9034e-04\n",
      "Epoch 00764: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 372.9312 - mean_squared_error: 372.9309 - acc: 5.8547e-04 - val_loss: 727.6699 - val_mean_squared_error: 727.6699 - val_acc: 2.1289e-04\n",
      "Epoch 765/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 277.1425 - mean_squared_error: 277.1426 - acc: 5.3860e-04\n",
      "Epoch 00765: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 277.3299 - mean_squared_error: 277.3300 - acc: 5.3225e-04 - val_loss: 745.5440 - val_mean_squared_error: 745.5441 - val_acc: 7.0962e-05\n",
      "Epoch 766/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 300.8119 - mean_squared_error: 300.8120 - acc: 7.2824e-04\n",
      "Epoch 00766: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 300.7952 - mean_squared_error: 300.7953 - acc: 7.2740e-04 - val_loss: 778.5127 - val_mean_squared_error: 778.5127 - val_acc: 4.9674e-04\n",
      "Epoch 767/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 590.5730 - mean_squared_error: 590.5730 - acc: 4.1591e-04\n",
      "Epoch 00767: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 584.9902 - mean_squared_error: 584.9902 - acc: 4.0805e-04 - val_loss: 671.7998 - val_mean_squared_error: 671.8000 - val_acc: 7.0962e-05\n",
      "Epoch 768/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 346.2031 - mean_squared_error: 346.2032 - acc: 6.2612e-04\n",
      "Epoch 00768: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 345.2156 - mean_squared_error: 345.2156 - acc: 6.3869e-04 - val_loss: 692.3634 - val_mean_squared_error: 692.3635 - val_acc: 4.2577e-04\n",
      "Epoch 769/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 286.0569 - mean_squared_error: 286.0569 - acc: 6.6071e-04\n",
      "Epoch 00769: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.0385 - mean_squared_error: 286.0385 - acc: 6.5644e-04 - val_loss: 718.2206 - val_mean_squared_error: 718.2205 - val_acc: 0.0000e+00\n",
      "Epoch 770/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 275.4111 - mean_squared_error: 275.4112 - acc: 7.1813e-04\n",
      "Epoch 00770: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 275.2630 - mean_squared_error: 275.2631 - acc: 7.2740e-04 - val_loss: 684.7470 - val_mean_squared_error: 684.7469 - val_acc: 1.4192e-04\n",
      "Epoch 771/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 271.5866 - mean_squared_error: 271.5865 - acc: 6.1931e-04\n",
      "Epoch 00771: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 289.8464 - mean_squared_error: 289.8463 - acc: 6.3869e-04 - val_loss: 661.8887 - val_mean_squared_error: 661.8884 - val_acc: 2.1289e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 343.1147 - mean_squared_error: 343.1147 - acc: 5.5556e-04\n",
      "Epoch 00772: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 342.5049 - mean_squared_error: 342.5049 - acc: 5.4999e-04 - val_loss: 682.0757 - val_mean_squared_error: 682.0759 - val_acc: 0.0000e+00\n",
      "Epoch 773/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 293.0871 - mean_squared_error: 293.0871 - acc: 6.5099e-04\n",
      "Epoch 00773: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 293.3696 - mean_squared_error: 293.3695 - acc: 6.3869e-04 - val_loss: 723.4373 - val_mean_squared_error: 723.4374 - val_acc: 0.0000e+00\n",
      "Epoch 774/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 275.0106 - mean_squared_error: 275.0105 - acc: 7.6512e-04\n",
      "Epoch 00774: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 275.0241 - mean_squared_error: 275.0240 - acc: 7.6288e-04 - val_loss: 691.9649 - val_mean_squared_error: 691.9647 - val_acc: 2.8385e-04\n",
      "Epoch 775/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 278.3078 - mean_squared_error: 278.3076 - acc: 5.9140e-04\n",
      "Epoch 00775: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 278.5287 - mean_squared_error: 278.5285 - acc: 5.8547e-04 - val_loss: 722.3929 - val_mean_squared_error: 722.3931 - val_acc: 0.0000e+00\n",
      "Epoch 776/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 271.6375 - mean_squared_error: 271.6373 - acc: 7.3345e-04\n",
      "Epoch 00776: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 271.3954 - mean_squared_error: 271.3952 - acc: 7.2740e-04 - val_loss: 761.4348 - val_mean_squared_error: 761.4348 - val_acc: 7.0962e-05\n",
      "Epoch 777/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 294.1596 - mean_squared_error: 294.1596 - acc: 7.0270e-04\n",
      "Epoch 00777: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 294.0237 - mean_squared_error: 294.0237 - acc: 6.9192e-04 - val_loss: 717.6859 - val_mean_squared_error: 717.6859 - val_acc: 0.0000e+00\n",
      "Epoch 778/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 275.7643 - mean_squared_error: 275.7643 - acc: 5.7041e-04\n",
      "Epoch 00778: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 275.7046 - mean_squared_error: 275.7046 - acc: 5.6773e-04 - val_loss: 712.8809 - val_mean_squared_error: 712.8809 - val_acc: 7.0962e-05\n",
      "Epoch 779/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 289.3634 - mean_squared_error: 289.3633 - acc: 5.2441e-04\n",
      "Epoch 00779: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 290.7019 - mean_squared_error: 290.7018 - acc: 5.1450e-04 - val_loss: 693.2175 - val_mean_squared_error: 693.2173 - val_acc: 4.9674e-04\n",
      "Epoch 780/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 286.7832 - mean_squared_error: 286.7832 - acc: 4.9091e-04\n",
      "Epoch 00780: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.8708 - mean_squared_error: 286.8708 - acc: 4.9676e-04 - val_loss: 714.3758 - val_mean_squared_error: 714.3758 - val_acc: 7.0962e-05\n",
      "Epoch 781/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 665.3691 - mean_squared_error: 665.3695 - acc: 6.4815e-04\n",
      "Epoch 00781: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 649.6918 - mean_squared_error: 649.6923 - acc: 6.3869e-04 - val_loss: 703.6687 - val_mean_squared_error: 703.6685 - val_acc: 4.2577e-04\n",
      "Epoch 782/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 598.4028 - mean_squared_error: 598.4028 - acc: 5.6673e-04\n",
      "Epoch 00782: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 588.5112 - mean_squared_error: 588.5113 - acc: 5.4999e-04 - val_loss: 705.8358 - val_mean_squared_error: 705.8359 - val_acc: 0.0000e+00\n",
      "Epoch 783/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 297.4785 - mean_squared_error: 297.4786 - acc: 6.5099e-04\n",
      "Epoch 00783: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 297.2663 - mean_squared_error: 297.2664 - acc: 6.5644e-04 - val_loss: 707.5339 - val_mean_squared_error: 707.5339 - val_acc: 0.0000e+00\n",
      "Epoch 784/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 344.3177 - mean_squared_error: 344.3179 - acc: 5.7554e-04\n",
      "Epoch 00784: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 343.3393 - mean_squared_error: 343.3395 - acc: 5.6773e-04 - val_loss: 692.7551 - val_mean_squared_error: 692.7549 - val_acc: 0.0000e+00\n",
      "Epoch 785/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 285.3862 - mean_squared_error: 285.3862 - acc: 5.9567e-04\n",
      "Epoch 00785: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.8969 - mean_squared_error: 286.8969 - acc: 5.8547e-04 - val_loss: 712.0941 - val_mean_squared_error: 712.0941 - val_acc: 7.0962e-05\n",
      "Epoch 786/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 302.6750 - mean_squared_error: 302.6750 - acc: 4.6512e-04 ETA: 1s - loss: 263.7197 - mean_s\n",
      "Epoch 00786: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 302.3845 - mean_squared_error: 302.3846 - acc: 4.6128e-04 - val_loss: 742.8193 - val_mean_squared_error: 742.8196 - val_acc: 0.0000e+00\n",
      "Epoch 787/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 364.4314 - mean_squared_error: 364.4315 - acc: 5.4250e-04\n",
      "Epoch 00787: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 363.1211 - mean_squared_error: 363.1211 - acc: 5.3225e-04 - val_loss: 660.6921 - val_mean_squared_error: 660.6920 - val_acc: 0.0000e+00\n",
      "Epoch 788/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 307.0238 - mean_squared_error: 307.0239 - acc: 6.5814e-04\n",
      "Epoch 00788: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.8559 - mean_squared_error: 305.8560 - acc: 6.3869e-04 - val_loss: 708.8859 - val_mean_squared_error: 708.8858 - val_acc: 0.0000e+00\n",
      "Epoch 789/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 283.9951 - mean_squared_error: 283.9953 - acc: 6.9767e-04\n",
      "Epoch 00789: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 283.9297 - mean_squared_error: 283.9299 - acc: 6.9192e-04 - val_loss: 680.9271 - val_mean_squared_error: 680.9271 - val_acc: 0.0000e+00\n",
      "Epoch 790/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 271.9196 - mean_squared_error: 271.9197 - acc: 7.4866e-04\n",
      "Epoch 00790: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 272.0289 - mean_squared_error: 272.0290 - acc: 7.4514e-04 - val_loss: 706.2173 - val_mean_squared_error: 706.2172 - val_acc: 3.5481e-04\n",
      "Epoch 791/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 328.0967 - mean_squared_error: 328.0967 - acc: 5.7451e-04\n",
      "Epoch 00791: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 327.4127 - mean_squared_error: 327.4127 - acc: 5.6773e-04 - val_loss: 685.4471 - val_mean_squared_error: 685.4471 - val_acc: 0.0000e+00\n",
      "Epoch 792/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 360.9814 - mean_squared_error: 360.9814 - acc: 6.4286e-04\n",
      "Epoch 00792: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 360.3227 - mean_squared_error: 360.3227 - acc: 6.3869e-04 - val_loss: 679.6525 - val_mean_squared_error: 679.6522 - val_acc: 2.8385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 293.4192 - mean_squared_error: 293.4192 - acc: 7.2202e-04\n",
      "Epoch 00793: val_loss did not improve from 660.03783\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 293.4093 - mean_squared_error: 293.4093 - acc: 7.2740e-04 - val_loss: 715.2387 - val_mean_squared_error: 715.2386 - val_acc: 0.0000e+00\n",
      "Epoch 794/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 294.4527 - mean_squared_error: 294.4527 - acc: 5.2920e-04\n",
      "Epoch 00794: val_loss improved from 660.03783 to 654.98025, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 293.6076 - mean_squared_error: 293.6075 - acc: 5.4999e-04 - val_loss: 654.9802 - val_mean_squared_error: 654.9803 - val_acc: 4.2577e-04\n",
      "Epoch 795/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 341.0510 - mean_squared_error: 341.0511 - acc: 6.6427e-04\n",
      "Epoch 00795: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 340.3889 - mean_squared_error: 340.3889 - acc: 6.5644e-04 - val_loss: 682.4698 - val_mean_squared_error: 682.4698 - val_acc: 1.4192e-04\n",
      "Epoch 796/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 278.0499 - mean_squared_error: 278.0499 - acc: 7.8182e-04: 0s - loss: 282.5085 - mean_squar\n",
      "Epoch 00796: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 277.3258 - mean_squared_error: 277.3258 - acc: 7.6288e-04 - val_loss: 695.9342 - val_mean_squared_error: 695.9341 - val_acc: 0.0000e+00\n",
      "Epoch 797/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 287.0015 - mean_squared_error: 287.0015 - acc: 5.9246e-04 ETA: 0s - loss: 272.7583 - mean_squared_error: 27\n",
      "Epoch 00797: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.2264 - mean_squared_error: 287.2265 - acc: 6.0321e-04 - val_loss: 706.0535 - val_mean_squared_error: 706.0534 - val_acc: 2.1289e-04\n",
      "Epoch 798/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 273.0853 - mean_squared_error: 273.0855 - acc: 7.0270e-04\n",
      "Epoch 00798: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 285.4187 - mean_squared_error: 285.4189 - acc: 6.9192e-04 - val_loss: 667.6243 - val_mean_squared_error: 667.6242 - val_acc: 0.0000e+00\n",
      "Epoch 799/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 437.7033 - mean_squared_error: 437.7033 - acc: 5.7041e-04\n",
      "Epoch 00799: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 437.1522 - mean_squared_error: 437.1522 - acc: 5.6773e-04 - val_loss: 681.1541 - val_mean_squared_error: 681.1542 - val_acc: 7.0962e-05\n",
      "Epoch 800/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 269.0564 - mean_squared_error: 269.0565 - acc: 7.4545e-04\n",
      "Epoch 00800: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 269.8485 - mean_squared_error: 269.8486 - acc: 7.2740e-04 - val_loss: 691.0112 - val_mean_squared_error: 691.0110 - val_acc: 0.0000e+00\n",
      "Epoch 801/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 328.9036 - mean_squared_error: 328.9035 - acc: 6.6421e-04\n",
      "Epoch 00801: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 326.8333 - mean_squared_error: 326.8332 - acc: 6.5644e-04 - val_loss: 712.2055 - val_mean_squared_error: 712.2057 - val_acc: 0.0000e+00\n",
      "Epoch 802/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 286.1197 - mean_squared_error: 286.1197 - acc: 5.1510e-04\n",
      "Epoch 00802: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.1323 - mean_squared_error: 286.1323 - acc: 5.1450e-04 - val_loss: 713.0951 - val_mean_squared_error: 713.0952 - val_acc: 0.0000e+00\n",
      "Epoch 803/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 352.4166 - mean_squared_error: 352.4166 - acc: 7.4410e-04\n",
      "Epoch 00803: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 349.9724 - mean_squared_error: 349.9724 - acc: 7.2740e-04 - val_loss: 702.8500 - val_mean_squared_error: 702.8500 - val_acc: 7.0962e-05\n",
      "Epoch 804/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 329.8884 - mean_squared_error: 329.8883 - acc: 6.6176e-04 ETA: 0s - loss: 394.6516 - mean_squared_err\n",
      "Epoch 00804: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 327.2346 - mean_squared_error: 327.2345 - acc: 6.5644e-04 - val_loss: 696.7953 - val_mean_squared_error: 696.7952 - val_acc: 7.0962e-05\n",
      "Epoch 805/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 343.2871 - mean_squared_error: 343.2872 - acc: 6.0000e-04\n",
      "Epoch 00805: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 341.9573 - mean_squared_error: 341.9574 - acc: 5.8547e-04 - val_loss: 669.6715 - val_mean_squared_error: 669.6715 - val_acc: 0.0000e+00\n",
      "Epoch 806/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 306.5210 - mean_squared_error: 306.5210 - acc: 5.5556e-04 ETA: 0s - loss: 272.7032 - mean_squared_error: \n",
      "Epoch 00806: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 306.8070 - mean_squared_error: 306.8071 - acc: 5.6773e-04 - val_loss: 734.4387 - val_mean_squared_error: 734.4386 - val_acc: 7.0962e-05\n",
      "Epoch 807/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 478.3254 - mean_squared_error: 478.3252 - acc: 6.6667e- - ETA: 0s - loss: 469.1744 - mean_squared_error: 469.1742 - acc: 6.5836e-04\n",
      "Epoch 00807: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 469.0100 - mean_squared_error: 469.0099 - acc: 6.5644e-04 - val_loss: 702.7529 - val_mean_squared_error: 702.7529 - val_acc: 7.0962e-05\n",
      "Epoch 808/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 286.8961 - mean_squared_error: 286.8961 - acc: 6.8100e-04\n",
      "Epoch 00808: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.5346 - mean_squared_error: 286.5346 - acc: 6.7418e-04 - val_loss: 679.0912 - val_mean_squared_error: 679.0911 - val_acc: 0.0000e+00\n",
      "Epoch 809/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 279.6944 - mean_squared_error: 279.6944 - acc: 5.9246e-04\n",
      "Epoch 00809: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 279.4559 - mean_squared_error: 279.4559 - acc: 6.0321e-04 - val_loss: 698.3556 - val_mean_squared_error: 698.3555 - val_acc: 1.4192e-04\n",
      "Epoch 810/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 301.2384 - mean_squared_error: 301.2383 - acc: 6.2615e-04\n",
      "Epoch 00810: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 299.8417 - mean_squared_error: 299.8416 - acc: 6.0321e-04 - val_loss: 680.5434 - val_mean_squared_error: 680.5433 - val_acc: 7.0962e-05\n",
      "Epoch 811/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 569.3692 - mean_squared_error: 569.3694 - acc: 4.6847e-04\n",
      "Epoch 00811: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 564.7050 - mean_squared_error: 564.7051 - acc: 4.7902e-04 - val_loss: 677.9062 - val_mean_squared_error: 677.9062 - val_acc: 0.0000e+00\n",
      "Epoch 812/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 369.2216 - mean_squared_error: 369.2216 - acc: 5.2920e-04\n",
      "Epoch 00812: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 366.4908 - mean_squared_error: 366.4908 - acc: 5.1450e-04 - val_loss: 678.0473 - val_mean_squared_error: 678.0472 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 283.9484 - mean_squared_error: 283.9484 - acc: 6.6308e-04 ETA: 0s - loss: 289.4421 - mean_squared_error: 289.4420 - acc: \n",
      "Epoch 00813: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 283.5549 - mean_squared_error: 283.5549 - acc: 6.5644e-04 - val_loss: 707.6953 - val_mean_squared_error: 707.6953 - val_acc: 0.0000e+00\n",
      "Epoch 814/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 288.7481 - mean_squared_error: 288.7480 - acc: 6.2837e-04\n",
      "Epoch 00814: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 288.4960 - mean_squared_error: 288.4959 - acc: 6.2095e-04 - val_loss: 684.2138 - val_mean_squared_error: 684.2139 - val_acc: 4.2577e-04\n",
      "Epoch 815/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 416.9360 - mean_squared_error: 416.9362 - acc: 6.2271e-04\n",
      "Epoch 00815: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 412.3821 - mean_squared_error: 412.3822 - acc: 6.0321e-04 - val_loss: 701.5659 - val_mean_squared_error: 701.5659 - val_acc: 2.8385e-04\n",
      "Epoch 816/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 271.1678 - mean_squared_error: 271.1678 - acc: 6.3291e-04\n",
      "Epoch 00816: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 270.9016 - mean_squared_error: 270.9016 - acc: 6.3869e-04 - val_loss: 679.3960 - val_mean_squared_error: 679.3961 - val_acc: 7.0962e-05\n",
      "Epoch 817/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 281.2330 - mean_squared_error: 281.2331 - acc: 6.5934e-04\n",
      "Epoch 00817: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 280.8396 - mean_squared_error: 280.8397 - acc: 6.5644e-04 - val_loss: 689.8440 - val_mean_squared_error: 689.8439 - val_acc: 2.8385e-04\n",
      "Epoch 818/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 315.6826 - mean_squared_error: 315.6826 - acc: 6.1931e-04\n",
      "Epoch 00818: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 314.7293 - mean_squared_error: 314.7293 - acc: 6.3869e-04 - val_loss: 684.9932 - val_mean_squared_error: 684.9933 - val_acc: 7.0962e-05\n",
      "Epoch 819/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 278.5546 - mean_squared_error: 278.5547 - acc: 6.6298e-04\n",
      "Epoch 00819: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 278.6346 - mean_squared_error: 278.6347 - acc: 6.3869e-04 - val_loss: 737.2597 - val_mean_squared_error: 737.2598 - val_acc: 7.0962e-05\n",
      "Epoch 820/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 305.7660 - mean_squared_error: 305.7660 - acc: 5.5258e-04 ETA: 0s - loss: 305.3646 - mean_squared_error: 305.3646 - acc: 5.7407e-\n",
      "Epoch 00820: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 305.8403 - mean_squared_error: 305.8403 - acc: 5.4999e-04 - val_loss: 699.3479 - val_mean_squared_error: 699.3481 - val_acc: 1.4192e-04\n",
      "Epoch 821/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 300.0464 - mean_squared_error: 300.0465 - acc: 6.4286e-04\n",
      "Epoch 00821: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 299.9373 - mean_squared_error: 299.9375 - acc: 6.3869e-04 - val_loss: 683.4401 - val_mean_squared_error: 683.4399 - val_acc: 0.0000e+00\n",
      "Epoch 822/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 335.3868 - mean_squared_error: 335.3869 - acc: 6.5693e-04\n",
      "Epoch 00822: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 333.8066 - mean_squared_error: 333.8066 - acc: 6.9192e-04 - val_loss: 695.0306 - val_mean_squared_error: 695.0307 - val_acc: 7.0962e-05\n",
      "Epoch 823/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 296.7700 - mean_squared_error: 296.7700 - acc: 4.9911e-04\n",
      "Epoch 00823: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 296.3369 - mean_squared_error: 296.3369 - acc: 4.9676e-04 - val_loss: 698.9973 - val_mean_squared_error: 698.9975 - val_acc: 2.1289e-04\n",
      "Epoch 824/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 326.2198 - mean_squared_error: 326.2196 - acc: 6.3406e-04\n",
      "Epoch 00824: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 325.2987 - mean_squared_error: 325.2986 - acc: 6.3869e-04 - val_loss: 693.4352 - val_mean_squared_error: 693.4352 - val_acc: 7.0962e-05\n",
      "Epoch 825/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 301.4629 - mean_squared_error: 301.4632 - acc: 5.7245e-04 ETA: 0s - loss: 304.5077 - mean_squared_error: 304.5079 - acc: 5.\n",
      "Epoch 00825: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 301.0860 - mean_squared_error: 301.0863 - acc: 5.6773e-04 - val_loss: 711.8049 - val_mean_squared_error: 711.8051 - val_acc: 1.4192e-04\n",
      "Epoch 826/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 491.1101 - mean_squared_error: 491.1102 - acc: 5.8824e-04\n",
      "Epoch 00826: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 484.9403 - mean_squared_error: 484.9404 - acc: 5.8547e-04 - val_loss: 703.9560 - val_mean_squared_error: 703.9560 - val_acc: 3.5481e-04\n",
      "Epoch 827/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 450.1976 - mean_squared_error: 450.1973 - acc: 6.2837e-04\n",
      "Epoch 00827: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 448.0635 - mean_squared_error: 448.0632 - acc: 6.3869e-04 - val_loss: 706.1357 - val_mean_squared_error: 706.1354 - val_acc: 7.0962e-05\n",
      "Epoch 828/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 275.5270 - mean_squared_error: 275.5270 - acc: 6.4865e-04 ETA: 0s - loss: 274.4467 - mean_squared_error: 274.\n",
      "Epoch 00828: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 275.1489 - mean_squared_error: 275.1489 - acc: 6.3869e-04 - val_loss: 731.2775 - val_mean_squared_error: 731.2775 - val_acc: 7.0962e-05\n",
      "Epoch 829/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 385.6158 - mean_squared_error: 385.6159 - acc: 5.8929e-04\n",
      "Epoch 00829: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 384.4945 - mean_squared_error: 384.4945 - acc: 5.8547e-04 - val_loss: 871.0140 - val_mean_squared_error: 871.0139 - val_acc: 1.4192e-04\n",
      "Epoch 830/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 295.8548 - mean_squared_error: 295.8549 - acc: 5.3114e-04\n",
      "Epoch 00830: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 295.6726 - mean_squared_error: 295.6727 - acc: 5.3225e-04 - val_loss: 706.7040 - val_mean_squared_error: 706.7039 - val_acc: 0.0000e+00\n",
      "Epoch 831/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 320.1055 - mean_squared_error: 320.1055 - acc: 6.1041e-04\n",
      "Epoch 00831: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 320.0131 - mean_squared_error: 320.0131 - acc: 6.0321e-04 - val_loss: 825.0994 - val_mean_squared_error: 825.0995 - val_acc: 1.4192e-04\n",
      "Epoch 832/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 308.3818 - mean_squared_error: 308.3818 - acc: 5.4545e-04\n",
      "Epoch 00832: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 308.3690 - mean_squared_error: 308.3690 - acc: 5.6773e-04 - val_loss: 682.6317 - val_mean_squared_error: 682.6317 - val_acc: 0.0000e+00\n",
      "Epoch 833/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 414.5060 - mean_squared_error: 414.5060 - acc: 6.2385e-04\n",
      "Epoch 00833: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 410.1633 - mean_squared_error: 410.1634 - acc: 6.0321e-04 - val_loss: 738.1362 - val_mean_squared_error: 738.1361 - val_acc: 2.1289e-04\n",
      "Epoch 834/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 270.7249 - mean_squared_error: 270.7249 - acc: 7.3741e-04\n",
      "Epoch 00834: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 270.7754 - mean_squared_error: 270.7753 - acc: 7.6288e-04 - val_loss: 671.9089 - val_mean_squared_error: 671.9089 - val_acc: 3.5481e-04\n",
      "Epoch 835/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 510.1379 - mean_squared_error: 510.1379 - acc: 5.3860e-04\n",
      "Epoch 00835: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 507.4824 - mean_squared_error: 507.4825 - acc: 5.3225e-04 - val_loss: 691.0108 - val_mean_squared_error: 691.0107 - val_acc: 2.8385e-04\n",
      "Epoch 836/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 282.9063 - mean_squared_error: 282.9063 - acc: 5.7658e-04\n",
      "Epoch 00836: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 282.6293 - mean_squared_error: 282.6293 - acc: 5.8547e-04 - val_loss: 696.7246 - val_mean_squared_error: 696.7245 - val_acc: 0.0000e+00\n",
      "Epoch 837/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 326.9560 - mean_squared_error: 326.9560 - acc: 5.4348e-04\n",
      "Epoch 00837: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 325.4568 - mean_squared_error: 325.4569 - acc: 5.3225e-04 - val_loss: 714.7019 - val_mean_squared_error: 714.7021 - val_acc: 4.2577e-04\n",
      "Epoch 838/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 286.7624 - mean_squared_error: 286.7624 - acc: 4.9822e-04\n",
      "Epoch 00838: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 286.5676 - mean_squared_error: 286.5675 - acc: 4.9676e-04 - val_loss: 716.6623 - val_mean_squared_error: 716.6622 - val_acc: 7.0962e-05\n",
      "Epoch 839/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 278.5044 - mean_squared_error: 278.5043 - acc: 4.6181e-04\n",
      "Epoch 00839: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 278.4690 - mean_squared_error: 278.4690 - acc: 4.6128e-04 - val_loss: 696.4022 - val_mean_squared_error: 696.4023 - val_acc: 0.0000e+00\n",
      "Epoch 840/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 286.8088 - mean_squared_error: 286.8089 - acc: 6.0391e-04\n",
      "Epoch 00840: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.7074 - mean_squared_error: 286.7076 - acc: 6.0321e-04 - val_loss: 759.7302 - val_mean_squared_error: 759.7303 - val_acc: 1.4192e-04\n",
      "Epoch 841/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 452.5935 - mean_squared_error: 452.5934 - acc: 5.4054e-04\n",
      "Epoch 00841: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 449.8779 - mean_squared_error: 449.8778 - acc: 5.3225e-04 - val_loss: 703.3962 - val_mean_squared_error: 703.3965 - val_acc: 7.0962e-05\n",
      "Epoch 842/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 287.6094 - mean_squared_error: 287.6093 - acc: 6.4576e-04\n",
      "Epoch 00842: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.4911 - mean_squared_error: 286.4910 - acc: 6.7418e-04 - val_loss: 716.8654 - val_mean_squared_error: 716.8654 - val_acc: 0.0000e+00\n",
      "Epoch 843/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 271.5907 - mean_squared_error: 271.5906 - acc: 4.1591e-04\n",
      "Epoch 00843: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 271.6668 - mean_squared_error: 271.6668 - acc: 4.0805e-04 - val_loss: 685.5360 - val_mean_squared_error: 685.5359 - val_acc: 1.4192e-04\n",
      "Epoch 844/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 291.7309 - mean_squared_error: 291.7310 - acc: 6.0329e-04\n",
      "Epoch 00844: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 292.3313 - mean_squared_error: 292.3314 - acc: 5.8547e-04 - val_loss: 726.4352 - val_mean_squared_error: 726.4352 - val_acc: 0.0000e+00\n",
      "Epoch 845/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 366.2723 - mean_squared_error: 366.2724 - acc: 5.5351e-04\n",
      "Epoch 00845: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 362.8276 - mean_squared_error: 362.8277 - acc: 5.4999e-04 - val_loss: 709.9818 - val_mean_squared_error: 709.9821 - val_acc: 0.0000e+00\n",
      "Epoch 846/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 305.0116 - mean_squared_error: 305.0115 - acc: 6.4457e-04\n",
      "Epoch 00846: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 302.8537 - mean_squared_error: 302.8537 - acc: 6.2095e-04 - val_loss: 670.7283 - val_mean_squared_error: 670.7283 - val_acc: 0.0000e+00\n",
      "Epoch 847/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 316.7880 - mean_squared_error: 316.7877 - acc: 5.6940e-04\n",
      "Epoch 00847: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 316.7133 - mean_squared_error: 316.7130 - acc: 5.6773e-04 - val_loss: 661.1648 - val_mean_squared_error: 661.1650 - val_acc: 0.0000e+00\n",
      "Epoch 848/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 290.9173 - mean_squared_error: 290.9173 - acc: 5.8824e-04\n",
      "Epoch 00848: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 290.7104 - mean_squared_error: 290.7104 - acc: 5.8547e-04 - val_loss: 709.6446 - val_mean_squared_error: 709.6443 - val_acc: 2.8385e-04\n",
      "Epoch 849/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 397.4552 - mean_squared_error: 397.4552 - acc: 4.8649e-04\n",
      "Epoch 00849: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 396.3664 - mean_squared_error: 396.3664 - acc: 4.7902e-04 - val_loss: 667.3042 - val_mean_squared_error: 667.3043 - val_acc: 0.0000e+00\n",
      "Epoch 850/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 375.5109 - mean_squared_error: 375.5108 - acc: 6.9853e-04\n",
      "Epoch 00850: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 371.5973 - mean_squared_error: 371.5972 - acc: 6.9192e-04 - val_loss: 693.9079 - val_mean_squared_error: 693.9076 - val_acc: 7.0962e-05\n",
      "Epoch 851/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 302.6196 - mean_squared_error: 302.6196 - acc: 5.4152e-04\n",
      "Epoch 00851: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 303.1656 - mean_squared_error: 303.1656 - acc: 5.3225e-04 - val_loss: 668.3709 - val_mean_squared_error: 668.3708 - val_acc: 7.0962e-05\n",
      "Epoch 852/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 398.1769 - mean_squared_error: 398.1766 - acc: 5.8824e-04\n",
      "Epoch 00852: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 397.5510 - mean_squared_error: 397.5508 - acc: 5.8547e-04 - val_loss: 702.7064 - val_mean_squared_error: 702.7063 - val_acc: 0.0000e+00\n",
      "Epoch 853/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 279.4857 - mean_squared_error: 279.4858 - acc: 6.7029e-04\n",
      "Epoch 00853: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 279.7872 - mean_squared_error: 279.7874 - acc: 6.5644e-04 - val_loss: 679.9516 - val_mean_squared_error: 679.9515 - val_acc: 2.8385e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 270.2623 - mean_squared_error: 270.2624 - acc: 5.7971e-04\n",
      "Epoch 00854: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 270.1006 - mean_squared_error: 270.1007 - acc: 6.2095e-04 - val_loss: 689.1423 - val_mean_squared_error: 689.1422 - val_acc: 3.5481e-04\n",
      "Epoch 855/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 364.8908 - mean_squared_error: 364.8906 - acc: 6.5836e-04\n",
      "Epoch 00855: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 364.6647 - mean_squared_error: 364.6644 - acc: 6.5644e-04 - val_loss: 691.7870 - val_mean_squared_error: 691.7870 - val_acc: 0.0000e+00\n",
      "Epoch 856/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 324.6468 - mean_squared_error: 324.6469 - acc: 5.5655e-04\n",
      "Epoch 00856: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 324.0277 - mean_squared_error: 324.0278 - acc: 5.4999e-04 - val_loss: 683.9016 - val_mean_squared_error: 683.9014 - val_acc: 7.0962e-05\n",
      "Epoch 857/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 269.5460 - mean_squared_error: 269.5461 - acc: 6.9519e-04\n",
      "Epoch 00857: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 269.6861 - mean_squared_error: 269.6861 - acc: 7.0966e-04 - val_loss: 657.6698 - val_mean_squared_error: 657.6697 - val_acc: 7.0962e-05\n",
      "Epoch 858/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 432.3933 - mean_squared_error: 432.3933 - acc: 4.9822e-04\n",
      "Epoch 00858: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 431.7140 - mean_squared_error: 431.7141 - acc: 4.9676e-04 - val_loss: 727.9573 - val_mean_squared_error: 727.9575 - val_acc: 0.0000e+00\n",
      "Epoch 859/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 315.4286 - mean_squared_error: 315.4285 - acc: 4.5704e-04\n",
      "Epoch 00859: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 313.4507 - mean_squared_error: 313.4507 - acc: 4.7902e-04 - val_loss: 691.7998 - val_mean_squared_error: 691.7999 - val_acc: 7.0962e-05\n",
      "Epoch 860/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 332.5393 - mean_squared_error: 332.5394 - acc: 5.5351e-04\n",
      "Epoch 00860: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 329.9191 - mean_squared_error: 329.9193 - acc: 5.4999e-04 - val_loss: 690.8298 - val_mean_squared_error: 690.8298 - val_acc: 2.1289e-04\n",
      "Epoch 861/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 271.4662 - mean_squared_error: 271.4662 - acc: 6.6427e-04\n",
      "Epoch 00861: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 271.8926 - mean_squared_error: 271.8926 - acc: 6.7418e-04 - val_loss: 704.3326 - val_mean_squared_error: 704.3326 - val_acc: 0.0000e+00\n",
      "Epoch 862/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 280.1916 - mean_squared_error: 280.1917 - acc: 6.4286e-04\n",
      "Epoch 00862: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 280.2403 - mean_squared_error: 280.2404 - acc: 6.3869e-04 - val_loss: 717.3121 - val_mean_squared_error: 717.3121 - val_acc: 1.4192e-04\n",
      "Epoch 863/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 283.7535 - mean_squared_error: 283.7534 - acc: 5.7554e-04 ETA: 0s - loss: 290.4868 - mean_squared_error\n",
      "Epoch 00863: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 283.7499 - mean_squared_error: 283.7498 - acc: 6.0321e-04 - val_loss: 666.7661 - val_mean_squared_error: 666.7661 - val_acc: 2.1289e-04\n",
      "Epoch 864/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 300.7312 - mean_squared_error: 300.7312 - acc: 7.7199e-04\n",
      "Epoch 00864: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 300.9644 - mean_squared_error: 300.9645 - acc: 7.6288e-04 - val_loss: 660.7618 - val_mean_squared_error: 660.7618 - val_acc: 0.0000e+00\n",
      "Epoch 865/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 325.4876 - mean_squared_error: 325.4875 - acc: 5.8824e-04\n",
      "Epoch 00865: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 325.2027 - mean_squared_error: 325.2027 - acc: 5.8547e-04 - val_loss: 691.4814 - val_mean_squared_error: 691.4814 - val_acc: 0.0000e+00\n",
      "Epoch 866/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 353.8068 - mean_squared_error: 353.8067 - acc: 6.0886e-04\n",
      "Epoch 00866: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 350.6562 - mean_squared_error: 350.6561 - acc: 6.2095e-04 - val_loss: 699.3853 - val_mean_squared_error: 699.3854 - val_acc: 1.4192e-04\n",
      "Epoch 867/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 308.3504 - mean_squared_error: 308.3506 - acc: 5.8608e-04\n",
      "Epoch 00867: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 307.5119 - mean_squared_error: 307.5120 - acc: 5.8547e-04 - val_loss: 696.0703 - val_mean_squared_error: 696.0705 - val_acc: 0.0000e+00\n",
      "Epoch 868/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 299.6944 - mean_squared_error: 299.6944 - acc: 5.2536e-04\n",
      "Epoch 00868: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 299.2789 - mean_squared_error: 299.2790 - acc: 5.1450e-04 - val_loss: 689.6269 - val_mean_squared_error: 689.6268 - val_acc: 1.4192e-04\n",
      "Epoch 869/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 368.1285 - mean_squared_error: 368.1286 - acc: 6.8223e-04\n",
      "Epoch 00869: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 367.6633 - mean_squared_error: 367.6634 - acc: 6.9192e-04 - val_loss: 701.8618 - val_mean_squared_error: 701.8618 - val_acc: 1.4192e-04\n",
      "Epoch 870/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 276.6245 - mean_squared_error: 276.6245 - acc: 5.7348e-04\n",
      "Epoch 00870: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 276.8146 - mean_squared_error: 276.8146 - acc: 5.6773e-04 - val_loss: 666.7162 - val_mean_squared_error: 666.7161 - val_acc: 7.0962e-05\n",
      "Epoch 871/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 352.3049 - mean_squared_error: 352.3048 - acc: 5.6940e-04\n",
      "Epoch 00871: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 352.5692 - mean_squared_error: 352.5692 - acc: 5.8547e-04 - val_loss: 692.0600 - val_mean_squared_error: 692.0601 - val_acc: 7.0962e-05\n",
      "Epoch 872/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 285.5001 - mean_squared_error: 285.5001 - acc: 5.5456e-04\n",
      "Epoch 00872: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 285.1350 - mean_squared_error: 285.1350 - acc: 5.6773e-04 - val_loss: 714.4396 - val_mean_squared_error: 714.4396 - val_acc: 7.0962e-05\n",
      "Epoch 873/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 383.3306 - mean_squared_error: 383.3307 - acc: 4.9911e-04\n",
      "Epoch 00873: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 382.6739 - mean_squared_error: 382.6740 - acc: 5.1450e-04 - val_loss: 722.6656 - val_mean_squared_error: 722.6655 - val_acc: 2.8385e-04\n",
      "Epoch 874/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 345.2631 - mean_squared_error: 345.2633 - acc: 6.2731e-04\n",
      "Epoch 00874: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 342.5656 - mean_squared_error: 342.5658 - acc: 6.3869e-04 - val_loss: 704.1564 - val_mean_squared_error: 704.1565 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 271.6551 - mean_squared_error: 271.6552 - acc: 6.6547e-04\n",
      "Epoch 00875: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 271.4065 - mean_squared_error: 271.4065 - acc: 6.7418e-04 - val_loss: 698.3600 - val_mean_squared_error: 698.3601 - val_acc: 0.0000e+00\n",
      "Epoch 876/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 287.2948 - mean_squared_error: 287.2948 - acc: 4.3876e-04\n",
      "Epoch 00876: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.9145 - mean_squared_error: 286.9144 - acc: 4.4354e-04 - val_loss: 681.6457 - val_mean_squared_error: 681.6456 - val_acc: 0.0000e+00\n",
      "Epoch 877/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 273.9107 - mean_squared_error: 273.9108 - acc: 6.5719e-04\n",
      "Epoch 00877: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 273.8699 - mean_squared_error: 273.8700 - acc: 6.5644e-04 - val_loss: 727.8983 - val_mean_squared_error: 727.8985 - val_acc: 1.4192e-04\n",
      "Epoch 878/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 265.3199 - mean_squared_error: 265.3199 - acc: 6.6308e-04\n",
      "Epoch 00878: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 264.9070 - mean_squared_error: 264.9070 - acc: 6.9192e-04 - val_loss: 716.2494 - val_mean_squared_error: 716.2492 - val_acc: 3.5481e-04\n",
      "Epoch 879/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 272.5617 - mean_squared_error: 272.5619 - acc: 5.1601e-04\n",
      "Epoch 00879: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 272.6750 - mean_squared_error: 272.6753 - acc: 5.1450e-04 - val_loss: 686.4573 - val_mean_squared_error: 686.4572 - val_acc: 0.0000e+00\n",
      "Epoch 880/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 322.4331 - mean_squared_error: 322.4331 - acc: 4.6429e-04 ETA: 0s - loss: 340.6657 - mean_squared_error: 340.6658\n",
      "Epoch 00880: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 322.1667 - mean_squared_error: 322.1667 - acc: 4.6128e-04 - val_loss: 686.8401 - val_mean_squared_error: 686.8400 - val_acc: 0.0000e+00\n",
      "Epoch 881/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 290.3969 - mean_squared_error: 290.3969 - acc: 6.0606e-04\n",
      "Epoch 00881: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 290.2357 - mean_squared_error: 290.2357 - acc: 6.0321e-04 - val_loss: 709.4547 - val_mean_squared_error: 709.4547 - val_acc: 0.0000e+00\n",
      "Epoch 882/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 373.0999 - mean_squared_error: 373.0998 - acc: 5.1282e-04\n",
      "Epoch 00882: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 370.8736 - mean_squared_error: 370.8736 - acc: 5.3225e-04 - val_loss: 692.0453 - val_mean_squared_error: 692.0455 - val_acc: 7.0962e-05\n",
      "Epoch 883/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 304.4748 - mean_squared_error: 304.4748 - acc: 5.5755e-04\n",
      "Epoch 00883: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 304.1661 - mean_squared_error: 304.1661 - acc: 5.6773e-04 - val_loss: 696.2465 - val_mean_squared_error: 696.2465 - val_acc: 7.0962e-05\n",
      "Epoch 884/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 299.9636 - mean_squared_error: 299.9638 - acc: 5.4152e-04\n",
      "Epoch 00884: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 299.0521 - mean_squared_error: 299.0522 - acc: 5.3225e-04 - val_loss: 722.2586 - val_mean_squared_error: 722.2584 - val_acc: 0.0000e+00\n",
      "Epoch 885/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 292.7019 - mean_squared_error: 292.7019 - acc: 6.1151e-04\n",
      "Epoch 00885: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 292.6150 - mean_squared_error: 292.6149 - acc: 6.0321e-04 - val_loss: 697.1933 - val_mean_squared_error: 697.1931 - val_acc: 0.0000e+00\n",
      "Epoch 886/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 366.5809 - mean_squared_error: 366.5809 - acc: 5.7041e-04 ETA: 0s - loss: 511.3569 - mean_squared_error: 511.3568 - acc: 6. - ETA: 0s - loss: 446.5774 - mean_squared_error: 44\n",
      "Epoch 00886: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 366.0124 - mean_squared_error: 366.0124 - acc: 5.8547e-04 - val_loss: 701.0176 - val_mean_squared_error: 701.0175 - val_acc: 0.0000e+00\n",
      "Epoch 887/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 331.5602 - mean_squared_error: 331.5602 - acc: 5.7451e-04\n",
      "Epoch 00887: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 331.2566 - mean_squared_error: 331.2565 - acc: 5.6773e-04 - val_loss: 688.5477 - val_mean_squared_error: 688.5477 - val_acc: 0.0000e+00\n",
      "Epoch 888/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 353.3916 - mean_squared_error: 353.3915 - acc: 6.4220e-04\n",
      "Epoch 00888: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 350.3929 - mean_squared_error: 350.3929 - acc: 6.3869e-04 - val_loss: 682.3588 - val_mean_squared_error: 682.3588 - val_acc: 0.0000e+00\n",
      "Epoch 889/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 279.6108 - mean_squared_error: 279.6108 - acc: 7.4681e-04\n",
      "Epoch 00889: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 278.9378 - mean_squared_error: 278.9378 - acc: 7.2740e-04 - val_loss: 707.0836 - val_mean_squared_error: 707.0837 - val_acc: 0.0000e+00\n",
      "Epoch 890/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 326.4638 - mean_squared_error: 326.4639 - acc: 7.3394e-04\n",
      "Epoch 00890: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 323.8625 - mean_squared_error: 323.8626 - acc: 7.2740e-04 - val_loss: 699.3223 - val_mean_squared_error: 699.3223 - val_acc: 2.8385e-04\n",
      "Epoch 891/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 312.0950 - mean_squared_error: 312.0950 - acc: 5.9783e-04\n",
      "Epoch 00891: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.7533 - mean_squared_error: 310.7532 - acc: 6.0321e-04 - val_loss: 683.8030 - val_mean_squared_error: 683.8030 - val_acc: 1.4192e-04\n",
      "Epoch 892/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 394.5425 - mean_squared_error: 394.5424 - acc: 6.0606e-04\n",
      "Epoch 00892: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 393.6748 - mean_squared_error: 393.6747 - acc: 6.0321e-04 - val_loss: 701.7318 - val_mean_squared_error: 701.7318 - val_acc: 7.0962e-05\n",
      "Epoch 893/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 271.2339 - mean_squared_error: 271.2339 - acc: 6.0391e-04\n",
      "Epoch 00893: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 271.1362 - mean_squared_error: 271.1363 - acc: 6.0321e-04 - val_loss: 691.1072 - val_mean_squared_error: 691.1072 - val_acc: 0.0000e+00\n",
      "Epoch 894/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 304.5567 - mean_squared_error: 304.5568 - acc: 6.2950e-04\n",
      "Epoch 00894: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.2605 - mean_squared_error: 304.2607 - acc: 6.3869e-04 - val_loss: 707.4047 - val_mean_squared_error: 707.4046 - val_acc: 7.0962e-05\n",
      "Epoch 895/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 284.4799 - mean_squared_error: 284.4799 - acc: 6.4286e-04\n",
      "Epoch 00895: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 284.5761 - mean_squared_error: 284.5761 - acc: 6.3869e-04 - val_loss: 711.5819 - val_mean_squared_error: 711.5820 - val_acc: 4.9674e-04\n",
      "Epoch 896/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 287.6458 - mean_squared_error: 287.6459 - acc: 6.8223e-04\n",
      "Epoch 00896: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.9563 - mean_squared_error: 287.9564 - acc: 7.0966e-04 - val_loss: 726.5120 - val_mean_squared_error: 726.5120 - val_acc: 0.0000e+00\n",
      "Epoch 897/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 298.8016 - mean_squared_error: 298.8016 - acc: 6.4401e-04\n",
      "Epoch 00897: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 298.1727 - mean_squared_error: 298.1727 - acc: 6.3869e-04 - val_loss: 968.5684 - val_mean_squared_error: 968.5681 - val_acc: 0.0000e+00\n",
      "Epoch 898/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 546.3641 - mean_squared_error: 546.3643 - acc: 5.8615e-04\n",
      "Epoch 00898: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 546.0598 - mean_squared_error: 546.0599 - acc: 5.8547e-04 - val_loss: 698.9332 - val_mean_squared_error: 698.9332 - val_acc: 0.0000e+00\n",
      "Epoch 899/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 307.9900 - mean_squared_error: 307.9899 - acc: 5.5957e-04\n",
      "Epoch 00899: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 307.4184 - mean_squared_error: 307.4183 - acc: 5.6773e-04 - val_loss: 716.3030 - val_mean_squared_error: 716.3030 - val_acc: 0.0000e+00\n",
      "Epoch 900/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 308.6116 - mean_squared_error: 308.6115 - acc: 6.0823e-04\n",
      "Epoch 00900: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 308.2673 - mean_squared_error: 308.2671 - acc: 6.0321e-04 - val_loss: 704.2827 - val_mean_squared_error: 704.2828 - val_acc: 0.0000e+00\n",
      "Epoch 901/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 306.0516 - mean_squared_error: 306.0517 - acc: 5.9034e-04\n",
      "Epoch 00901: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 305.6339 - mean_squared_error: 305.6340 - acc: 6.0321e-04 - val_loss: 703.3391 - val_mean_squared_error: 703.3391 - val_acc: 0.0000e+00\n",
      "Epoch 902/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 275.4189 - mean_squared_error: 275.4189 - acc: 6.9767e-04\n",
      "Epoch 00902: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 275.2965 - mean_squared_error: 275.2966 - acc: 6.9192e-04 - val_loss: 686.9078 - val_mean_squared_error: 686.9078 - val_acc: 0.0000e+00\n",
      "Epoch 903/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 274.0531 - mean_squared_error: 274.0530 - acc: 7.2464e-04\n",
      "Epoch 00903: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 273.9019 - mean_squared_error: 273.9018 - acc: 7.2740e-04 - val_loss: 691.3496 - val_mean_squared_error: 691.3495 - val_acc: 7.0962e-05\n",
      "Epoch 904/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 270.6349 - mean_squared_error: 270.6347 - acc: 8.0000e-04\n",
      "Epoch 00904: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 271.2002 - mean_squared_error: 271.2000 - acc: 7.8063e-04 - val_loss: 704.6892 - val_mean_squared_error: 704.6894 - val_acc: 4.2577e-04\n",
      "Epoch 905/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 270.4574 - mean_squared_error: 270.4575 - acc: 5.5762e- - ETA: 0s - loss: 270.0803 - mean_squared_error: 270.0803 - acc: 5.7245e-04\n",
      "Epoch 00905: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 269.9553 - mean_squared_error: 269.9553 - acc: 5.8547e-04 - val_loss: 701.7785 - val_mean_squared_error: 701.7786 - val_acc: 0.0000e+00\n",
      "Epoch 906/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 298.6577 - mean_squared_error: 298.6577 - acc: 5.8716e-04\n",
      "Epoch 00906: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 297.6413 - mean_squared_error: 297.6413 - acc: 6.5644e-04 - val_loss: 771.3110 - val_mean_squared_error: 771.3110 - val_acc: 4.9674e-04\n",
      "Epoch 907/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 589.9934 - mean_squared_error: 589.9933 - acc: 6.2167e-04\n",
      "Epoch 00907: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 589.6897 - mean_squared_error: 589.6896 - acc: 6.3869e-04 - val_loss: 742.3146 - val_mean_squared_error: 742.3145 - val_acc: 0.0000e+00\n",
      "Epoch 908/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 361.8731 - mean_squared_error: 361.8729 - acc: 4.6263e-04\n",
      "Epoch 00908: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 361.4880 - mean_squared_error: 361.4878 - acc: 4.6128e-04 - val_loss: 705.6607 - val_mean_squared_error: 705.6607 - val_acc: 1.4192e-04\n",
      "Epoch 909/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 270.4639 - mean_squared_error: 270.4639 - acc: 6.1261e-04\n",
      "Epoch 00909: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 270.3595 - mean_squared_error: 270.3594 - acc: 6.0321e-04 - val_loss: 681.3049 - val_mean_squared_error: 681.3047 - val_acc: 1.4192e-04\n",
      "Epoch 910/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 276.5127 - mean_squared_error: 276.5126 - acc: 6.0498e-04 ETA: 0s - loss: 261.4386 - mean_squared_error: 261.4386 - acc: 6.9767e- - ETA: 0s - loss: 259.0928 - mean_squared_err\n",
      "Epoch 00910: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 276.6054 - mean_squared_error: 276.6053 - acc: 6.0321e-04 - val_loss: 723.6709 - val_mean_squared_error: 723.6710 - val_acc: 0.0000e+00\n",
      "Epoch 911/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 300.9280 - mean_squared_error: 300.9280 - acc: 6.9217e-04\n",
      "Epoch 00911: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 299.5483 - mean_squared_error: 299.5483 - acc: 6.9192e-04 - val_loss: 689.1126 - val_mean_squared_error: 689.1126 - val_acc: 0.0000e+00\n",
      "Epoch 912/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 263.7154 - mean_squared_error: 263.7155 - acc: 6.8716e-04\n",
      "Epoch 00912: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 264.3246 - mean_squared_error: 264.3247 - acc: 6.9192e-04 - val_loss: 725.0820 - val_mean_squared_error: 725.0820 - val_acc: 0.0000e+00\n",
      "Epoch 913/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 265.2997 - mean_squared_error: 265.2999 - acc: 6.4865e-04\n",
      "Epoch 00913: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 265.5277 - mean_squared_error: 265.5279 - acc: 6.3869e-04 - val_loss: 729.5809 - val_mean_squared_error: 729.5808 - val_acc: 0.0000e+00\n",
      "Epoch 914/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 265.6016 - mean_squared_error: 265.6016 - acc: 5.2065e-04\n",
      "Epoch 00914: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.1936 - mean_squared_error: 265.1936 - acc: 5.3225e-04 - val_loss: 705.1925 - val_mean_squared_error: 705.1925 - val_acc: 0.0000e+00\n",
      "Epoch 915/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000/56365 [============================>.] - ETA: 0s - loss: 330.7029 - mean_squared_error: 330.7027 - acc: 7.5000e-04\n",
      "Epoch 00915: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 330.0711 - mean_squared_error: 330.0710 - acc: 7.4514e-04 - val_loss: 673.0085 - val_mean_squared_error: 673.0085 - val_acc: 2.1289e-04\n",
      "Epoch 916/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 301.4572 - mean_squared_error: 301.4572 - acc: 5.7143e-04 ETA: 0s - loss: 261.0912 - mean_squared_error: 261.09\n",
      "Epoch 00916: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 301.2327 - mean_squared_error: 301.2326 - acc: 5.6773e-04 - val_loss: 696.2793 - val_mean_squared_error: 696.2795 - val_acc: 0.0000e+00\n",
      "Epoch 917/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 268.6080 - mean_squared_error: 268.6081 - acc: 6.2500e-04 ETA: 1s - loss: 269.4563 - mean_s\n",
      "Epoch 00917: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 268.5123 - mean_squared_error: 268.5124 - acc: 6.2095e-04 - val_loss: 681.0053 - val_mean_squared_error: 681.0054 - val_acc: 1.4192e-04\n",
      "Epoch 918/3000\n",
      "53800/56365 [===========================>..] - ETA: 0s - loss: 321.2159 - mean_squared_error: 321.2159 - acc: 5.0186e-04\n",
      "Epoch 00918: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 317.4421 - mean_squared_error: 317.4422 - acc: 4.7902e-04 - val_loss: 722.5167 - val_mean_squared_error: 722.5165 - val_acc: 2.8385e-04\n",
      "Epoch 919/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 264.6015 - mean_squared_error: 264.6013 - acc: 6.4516e-04\n",
      "Epoch 00919: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 264.4388 - mean_squared_error: 264.4386 - acc: 6.3869e-04 - val_loss: 689.3831 - val_mean_squared_error: 689.3832 - val_acc: 0.0000e+00\n",
      "Epoch 920/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 261.2403 - mean_squared_error: 261.2405 - acc: 6.1151e-04 ETA: 0s - loss: 258.4476 - mean_squared_error\n",
      "Epoch 00920: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 261.5767 - mean_squared_error: 261.5769 - acc: 6.0321e-04 - val_loss: 663.7897 - val_mean_squared_error: 663.7899 - val_acc: 0.0000e+00\n",
      "Epoch 921/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 328.9249 - mean_squared_error: 328.9250 - acc: 6.0932e-04\n",
      "Epoch 00921: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 328.7712 - mean_squared_error: 328.7714 - acc: 6.2095e-04 - val_loss: 1047.7177 - val_mean_squared_error: 1047.7178 - val_acc: 1.4192e-04\n",
      "Epoch 922/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 326.8820 - mean_squared_error: 326.8820 - acc: 6.2724e-04\n",
      "Epoch 00922: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 326.2980 - mean_squared_error: 326.2979 - acc: 6.2095e-04 - val_loss: 697.9053 - val_mean_squared_error: 697.9052 - val_acc: 4.9674e-04\n",
      "Epoch 923/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 285.3330 - mean_squared_error: 285.3331 - acc: 4.7619e-04\n",
      "Epoch 00923: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 285.1067 - mean_squared_error: 285.1068 - acc: 4.7902e-04 - val_loss: 723.9756 - val_mean_squared_error: 723.9755 - val_acc: 2.1289e-04\n",
      "Epoch 924/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 621.4377 - mean_squared_error: 621.4378 - acc: 7.1823e-04\n",
      "Epoch 00924: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 609.6013 - mean_squared_error: 609.6013 - acc: 6.9192e-04 - val_loss: 694.9127 - val_mean_squared_error: 694.9127 - val_acc: 0.0000e+00\n",
      "Epoch 925/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 301.7842 - mean_squared_error: 301.7841 - acc: 4.8561e-04\n",
      "Epoch 00925: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 301.1324 - mean_squared_error: 301.1323 - acc: 4.7902e-04 - val_loss: 689.4630 - val_mean_squared_error: 689.4630 - val_acc: 0.0000e+00\n",
      "Epoch 926/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 273.8660 - mean_squared_error: 273.8658 - acc: 6.3291e-04\n",
      "Epoch 00926: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 273.2156 - mean_squared_error: 273.2154 - acc: 6.5644e-04 - val_loss: 674.9460 - val_mean_squared_error: 674.9462 - val_acc: 0.0000e+00\n",
      "Epoch 927/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 292.1244 - mean_squared_error: 292.1246 - acc: 5.0542e-04\n",
      "Epoch 00927: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 291.9904 - mean_squared_error: 291.9905 - acc: 4.9676e-04 - val_loss: 748.0514 - val_mean_squared_error: 748.0512 - val_acc: 0.0000e+00\n",
      "Epoch 928/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 287.7139 - mean_squared_error: 287.7141 - acc: 6.4516e-04\n",
      "Epoch 00928: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.9618 - mean_squared_error: 287.9620 - acc: 6.5644e-04 - val_loss: 726.7337 - val_mean_squared_error: 726.7339 - val_acc: 2.8385e-04\n",
      "Epoch 929/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 266.4197 - mean_squared_error: 266.4197 - acc: 6.2612e-04\n",
      "Epoch 00929: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 266.3246 - mean_squared_error: 266.3246 - acc: 6.2095e-04 - val_loss: 681.3704 - val_mean_squared_error: 681.3704 - val_acc: 0.0000e+00\n",
      "Epoch 930/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 345.1066 - mean_squared_error: 345.1064 - acc: 7.0270e-04\n",
      "Epoch 00930: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 343.6179 - mean_squared_error: 343.6177 - acc: 6.9192e-04 - val_loss: 699.4690 - val_mean_squared_error: 699.4691 - val_acc: 0.0000e+00\n",
      "Epoch 931/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 373.1729 - mean_squared_error: 373.1729 - acc: 6.9395e-04\n",
      "Epoch 00931: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 372.6829 - mean_squared_error: 372.6829 - acc: 6.9192e-04 - val_loss: 684.0572 - val_mean_squared_error: 684.0572 - val_acc: 0.0000e+00\n",
      "Epoch 932/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 296.2157 - mean_squared_error: 296.2158 - acc: 5.5357e-04\n",
      "Epoch 00932: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 295.8534 - mean_squared_error: 295.8535 - acc: 5.4999e-04 - val_loss: 725.4390 - val_mean_squared_error: 725.4391 - val_acc: 0.0000e+00\n",
      "Epoch 933/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 264.2020 - mean_squared_error: 264.2021 - acc: 5.8182e-04\n",
      "Epoch 00933: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 264.3956 - mean_squared_error: 264.3957 - acc: 5.6773e-04 - val_loss: 732.0194 - val_mean_squared_error: 732.0193 - val_acc: 2.8385e-04\n",
      "Epoch 934/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 317.2066 - mean_squared_error: 317.2067 - acc: 5.4348e-04\n",
      "Epoch 00934: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 316.4078 - mean_squared_error: 316.4078 - acc: 5.3225e-04 - val_loss: 723.9691 - val_mean_squared_error: 723.9694 - val_acc: 0.0000e+00\n",
      "Epoch 935/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 396.6514 - mean_squared_error: 396.6513 - acc: 5.9034e-04\n",
      "Epoch 00935: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 395.6504 - mean_squared_error: 395.6502 - acc: 6.0321e-04 - val_loss: 703.6530 - val_mean_squared_error: 703.6531 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 319.7439 - mean_squared_error: 319.7438 - acc: 5.5258e-04\n",
      "Epoch 00936: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 319.5217 - mean_squared_error: 319.5217 - acc: 5.4999e-04 - val_loss: 706.0497 - val_mean_squared_error: 706.0499 - val_acc: 7.0962e-05\n",
      "Epoch 937/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 305.7693 - mean_squared_error: 305.7693 - acc: 6.7151e-04\n",
      "Epoch 00937: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.7837 - mean_squared_error: 304.7838 - acc: 6.5644e-04 - val_loss: 693.4915 - val_mean_squared_error: 693.4915 - val_acc: 0.0000e+00\n",
      "Epoch 938/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 340.8199 - mean_squared_error: 340.8200 - acc: 6.8223e-04\n",
      "Epoch 00938: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 339.6512 - mean_squared_error: 339.6513 - acc: 6.7418e-04 - val_loss: 700.0227 - val_mean_squared_error: 700.0226 - val_acc: 7.0962e-05\n",
      "Epoch 939/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 361.7243 - mean_squared_error: 361.7244 - acc: 5.9353e-04\n",
      "Epoch 00939: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 359.9466 - mean_squared_error: 359.9467 - acc: 5.8547e-04 - val_loss: 713.3295 - val_mean_squared_error: 713.3294 - val_acc: 2.1289e-04\n",
      "Epoch 940/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 316.0308 - mean_squared_error: 316.0308 - acc: 5.6466e-04\n",
      "Epoch 00940: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 314.7175 - mean_squared_error: 314.7175 - acc: 5.6773e-04 - val_loss: 702.7475 - val_mean_squared_error: 702.7474 - val_acc: 6.3866e-04\n",
      "Epoch 941/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 371.2608 - mean_squared_error: 371.2610 - acc: 5.8719e-04\n",
      "Epoch 00941: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 370.9018 - mean_squared_error: 370.9020 - acc: 5.8547e-04 - val_loss: 705.2540 - val_mean_squared_error: 705.2538 - val_acc: 4.2577e-04\n",
      "Epoch 942/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 266.6515 - mean_squared_error: 266.6516 - acc: 6.1483e-04 ETA: 0s - loss: 272.4864 - mean_squar\n",
      "Epoch 00942: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 266.8457 - mean_squared_error: 266.8458 - acc: 6.2095e-04 - val_loss: 721.1029 - val_mean_squared_error: 721.1030 - val_acc: 0.0000e+00\n",
      "Epoch 943/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 258.3095 - mean_squared_error: 258.3093 - acc: 4.6931e-04\n",
      "Epoch 00943: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 258.9077 - mean_squared_error: 258.9075 - acc: 4.6128e-04 - val_loss: 720.4733 - val_mean_squared_error: 720.4733 - val_acc: 0.0000e+00\n",
      "Epoch 944/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 261.6226 - mean_squared_error: 261.6226 - acc: 5.3763e-04\n",
      "Epoch 00944: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 261.2275 - mean_squared_error: 261.2275 - acc: 5.3225e-04 - val_loss: 682.4788 - val_mean_squared_error: 682.4787 - val_acc: 7.0962e-05\n",
      "Epoch 945/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 270.4896 - mean_squared_error: 270.4899 - acc: 5.3476e-04\n",
      "Epoch 00945: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 270.4819 - mean_squared_error: 270.4822 - acc: 5.3225e-04 - val_loss: 682.6246 - val_mean_squared_error: 682.6246 - val_acc: 0.0000e+00\n",
      "Epoch 946/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 278.9269 - mean_squared_error: 278.9267 - acc: 5.3667e-04\n",
      "Epoch 00946: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 279.1409 - mean_squared_error: 279.1407 - acc: 5.3225e-04 - val_loss: 718.2188 - val_mean_squared_error: 718.2189 - val_acc: 0.0000e+00\n",
      "Epoch 947/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 260.5308 - mean_squared_error: 260.5308 - acc: 7.2072e-04\n",
      "Epoch 00947: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 260.8459 - mean_squared_error: 260.8460 - acc: 7.4514e-04 - val_loss: 661.5648 - val_mean_squared_error: 661.5646 - val_acc: 0.0000e+00\n",
      "Epoch 948/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 313.9185 - mean_squared_error: 313.9185 - acc: 6.3869e-04\n",
      "Epoch 00948: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 312.7747 - mean_squared_error: 312.7747 - acc: 6.2095e-04 - val_loss: 713.5549 - val_mean_squared_error: 713.5549 - val_acc: 0.0000e+00\n",
      "Epoch 949/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 338.4057 - mean_squared_error: 338.4056 - acc: 6.1151e-04\n",
      "Epoch 00949: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 337.4822 - mean_squared_error: 337.4821 - acc: 6.0321e-04 - val_loss: 676.7810 - val_mean_squared_error: 676.7810 - val_acc: 1.4192e-04\n",
      "Epoch 950/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 278.6597 - mean_squared_error: 278.6597 - acc: 5.9675e-04\n",
      "Epoch 00950: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 278.1471 - mean_squared_error: 278.1470 - acc: 6.0321e-04 - val_loss: 690.1676 - val_mean_squared_error: 690.1675 - val_acc: 1.4192e-04\n",
      "Epoch 951/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 297.6672 - mean_squared_error: 297.6671 - acc: 6.6908e-04\n",
      "Epoch 00951: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 296.4547 - mean_squared_error: 296.4547 - acc: 6.7418e-04 - val_loss: 669.4339 - val_mean_squared_error: 669.4338 - val_acc: 0.0000e+00\n",
      "Epoch 952/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 302.4898 - mean_squared_error: 302.4898 - acc: 6.0714e-04\n",
      "Epoch 00952: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 302.3297 - mean_squared_error: 302.3297 - acc: 6.0321e-04 - val_loss: 724.6476 - val_mean_squared_error: 724.6474 - val_acc: 0.0000e+00\n",
      "Epoch 953/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 286.5476 - mean_squared_error: 286.5477 - acc: 5.6838e-04\n",
      "Epoch 00953: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.3540 - mean_squared_error: 286.3541 - acc: 5.6773e-04 - val_loss: 667.1272 - val_mean_squared_error: 667.1271 - val_acc: 0.0000e+00\n",
      "Epoch 954/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 266.7236 - mean_squared_error: 266.7236 - acc: 5.6777e-04\n",
      "Epoch 00954: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 266.4260 - mean_squared_error: 266.4260 - acc: 5.4999e-04 - val_loss: 695.6640 - val_mean_squared_error: 695.6640 - val_acc: 0.0000e+00\n",
      "Epoch 955/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 258.9264 - mean_squared_error: 258.9262 - acc: 4.9180e-04\n",
      "Epoch 00955: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 258.8280 - mean_squared_error: 258.8279 - acc: 4.9676e-04 - val_loss: 733.3253 - val_mean_squared_error: 733.3256 - val_acc: 0.0000e+00\n",
      "Epoch 956/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 259.1390 - mean_squared_error: 259.1390 - acc: 6.0440e-04\n",
      "Epoch 00956: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 259.4774 - mean_squared_error: 259.4774 - acc: 5.8547e-04 - val_loss: 696.0110 - val_mean_squared_error: 696.0109 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 341.4664 - mean_squared_error: 341.4665 - acc: 7.0270e-04\n",
      "Epoch 00957: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 340.6992 - mean_squared_error: 340.6992 - acc: 6.9192e-04 - val_loss: 707.4412 - val_mean_squared_error: 707.4411 - val_acc: 0.0000e+00\n",
      "Epoch 958/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 286.1979 - mean_squared_error: 286.1980 - acc: 6.2612e-04\n",
      "Epoch 00958: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 285.6670 - mean_squared_error: 285.6671 - acc: 6.2095e-04 - val_loss: 661.0858 - val_mean_squared_error: 661.0858 - val_acc: 0.0000e+00\n",
      "Epoch 959/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 263.5365 - mean_squared_error: 263.5365 - acc: 4.4964e-04\n",
      "Epoch 00959: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.6009 - mean_squared_error: 263.6009 - acc: 4.7902e-04 - val_loss: 694.0970 - val_mean_squared_error: 694.0969 - val_acc: 7.0962e-05\n",
      "Epoch 960/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 262.9020 - mean_squared_error: 262.9021 - acc: 6.2385e-04\n",
      "Epoch 00960: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.0494 - mean_squared_error: 263.0496 - acc: 6.3869e-04 - val_loss: 725.0822 - val_mean_squared_error: 725.0821 - val_acc: 7.0962e-05\n",
      "Epoch 961/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 477.9435 - mean_squared_error: 477.9437 - acc: 4.4118e-04\n",
      "Epoch 00961: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 470.2886 - mean_squared_error: 470.2889 - acc: 4.4354e-04 - val_loss: 707.5739 - val_mean_squared_error: 707.5740 - val_acc: 0.0000e+00\n",
      "Epoch 962/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 263.9204 - mean_squared_error: 263.9204 - acc: 5.8394e-04\n",
      "Epoch 00962: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.6485 - mean_squared_error: 263.6485 - acc: 5.6773e-04 - val_loss: 702.2314 - val_mean_squared_error: 702.2313 - val_acc: 0.0000e+00\n",
      "Epoch 963/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 260.0376 - mean_squared_error: 260.0377 - acc: 6.6427e-04\n",
      "Epoch 00963: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 267.6586 - mean_squared_error: 267.6587 - acc: 6.5644e-04 - val_loss: 780.7995 - val_mean_squared_error: 780.7996 - val_acc: 7.0962e-05\n",
      "Epoch 964/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 343.7987 - mean_squared_error: 343.7989 - acc: 6.2167e-04\n",
      "Epoch 00964: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 343.8662 - mean_squared_error: 343.8664 - acc: 6.2095e-04 - val_loss: 663.8330 - val_mean_squared_error: 663.8329 - val_acc: 6.3866e-04\n",
      "Epoch 965/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 271.8869 - mean_squared_error: 271.8870 - acc: 5.5655e-04\n",
      "Epoch 00965: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 272.2520 - mean_squared_error: 272.2520 - acc: 5.8547e-04 - val_loss: 696.7538 - val_mean_squared_error: 696.7538 - val_acc: 7.0962e-05\n",
      "Epoch 966/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 391.9571 - mean_squared_error: 391.9572 - acc: 7.3477e-04\n",
      "Epoch 00966: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 390.8918 - mean_squared_error: 390.8918 - acc: 7.2740e-04 - val_loss: 681.5823 - val_mean_squared_error: 681.5823 - val_acc: 0.0000e+00\n",
      "Epoch 967/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 403.0344 - mean_squared_error: 403.0341 - acc: 6.3869e-04 ETA: 1s - loss: 267.1043 - mean_squ\n",
      "Epoch 00967: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 399.6016 - mean_squared_error: 399.6013 - acc: 6.2095e-04 - val_loss: 702.4821 - val_mean_squared_error: 702.4818 - val_acc: 0.0000e+00\n",
      "Epoch 968/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 287.0985 - mean_squared_error: 287.0984 - acc: 6.4982e-04\n",
      "Epoch 00968: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.5530 - mean_squared_error: 286.5529 - acc: 6.5644e-04 - val_loss: 702.9075 - val_mean_squared_error: 702.9076 - val_acc: 0.0000e+00\n",
      "Epoch 969/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 269.7721 - mean_squared_error: 269.7721 - acc: 4.8301e-04\n",
      "Epoch 00969: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 269.7815 - mean_squared_error: 269.7815 - acc: 4.7902e-04 - val_loss: 698.5901 - val_mean_squared_error: 698.5902 - val_acc: 0.0000e+00\n",
      "Epoch 970/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 287.1249 - mean_squared_error: 287.1247 - acc: 6.2500e-04\n",
      "Epoch 00970: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 286.2429 - mean_squared_error: 286.2427 - acc: 6.2095e-04 - val_loss: 693.1303 - val_mean_squared_error: 693.1304 - val_acc: 0.0000e+00\n",
      "Epoch 971/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 390.5601 - mean_squared_error: 390.5598 - acc: 6.2847e-04\n",
      "Epoch 00971: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 385.5880 - mean_squared_error: 385.5877 - acc: 6.3869e-04 - val_loss: 715.0676 - val_mean_squared_error: 715.0677 - val_acc: 7.0962e-05\n",
      "Epoch 972/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 332.8725 - mean_squared_error: 332.8724 - acc: 6.0329e-04 ETA: 0s - loss: 373.9294 - mean_squared_error: 373.9295\n",
      "Epoch 00972: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 330.9586 - mean_squared_error: 330.9585 - acc: 6.0321e-04 - val_loss: 684.6420 - val_mean_squared_error: 684.6423 - val_acc: 0.0000e+00\n",
      "Epoch 973/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 306.4119 - mean_squared_error: 306.4119 - acc: 5.5357e-04\n",
      "Epoch 00973: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 306.1132 - mean_squared_error: 306.1132 - acc: 5.4999e-04 - val_loss: 700.3528 - val_mean_squared_error: 700.3526 - val_acc: 0.0000e+00\n",
      "Epoch 974/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 260.9634 - mean_squared_error: 260.9633 - acc: 5.7245e-04\n",
      "Epoch 00974: val_loss did not improve from 654.98025\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 261.0349 - mean_squared_error: 261.0348 - acc: 5.6773e-04 - val_loss: 728.7402 - val_mean_squared_error: 728.7401 - val_acc: 7.0962e-04\n",
      "Epoch 975/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 260.6673 - mean_squared_error: 260.6673 - acc: 5.7451e-04\n",
      "Epoch 00975: val_loss improved from 654.98025 to 649.04616, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 308.4246 - mean_squared_error: 308.4247 - acc: 5.6773e-04 - val_loss: 649.0462 - val_mean_squared_error: 649.0460 - val_acc: 0.0000e+00\n",
      "Epoch 976/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 320.7717 - mean_squared_error: 320.7718 - acc: 5.6777e-04\n",
      "Epoch 00976: val_loss did not improve from 649.04616\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 318.7458 - mean_squared_error: 318.7460 - acc: 5.4999e-04 - val_loss: 664.7712 - val_mean_squared_error: 664.7710 - val_acc: 4.2577e-04\n",
      "Epoch 977/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 280.5408 - mean_squared_error: 280.5409 - acc: 6.8841e-04\n",
      "Epoch 00977: val_loss did not improve from 649.04616\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 280.7229 - mean_squared_error: 280.7230 - acc: 6.7418e-04 - val_loss: 680.7998 - val_mean_squared_error: 680.8000 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 273.1597 - mean_squared_error: 273.1598 - acc: 6.0219e-04\n",
      "Epoch 00978: val_loss did not improve from 649.04616\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 273.3351 - mean_squared_error: 273.3351 - acc: 6.2095e-04 - val_loss: 677.9875 - val_mean_squared_error: 677.9875 - val_acc: 0.0000e+00\n",
      "Epoch 979/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 261.0745 - mean_squared_error: 261.0743 - acc: 6.7736e-04\n",
      "Epoch 00979: val_loss did not improve from 649.04616\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 261.0257 - mean_squared_error: 261.0255 - acc: 6.7418e-04 - val_loss: 678.0461 - val_mean_squared_error: 678.0460 - val_acc: 0.0000e+00\n",
      "Epoch 980/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 296.3714 - mean_squared_error: 296.3712 - acc: 7.4600e-04\n",
      "Epoch 00980: val_loss did not improve from 649.04616\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 296.2137 - mean_squared_error: 296.2136 - acc: 7.4514e-04 - val_loss: 670.8605 - val_mean_squared_error: 670.8604 - val_acc: 0.0000e+00\n",
      "Epoch 981/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 327.5064 - mean_squared_error: 327.5063 - acc: 5.4845e-04\n",
      "Epoch 00981: val_loss improved from 649.04616 to 634.83457, saving model to ./model_adr1/model1.h5\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 326.2540 - mean_squared_error: 326.2539 - acc: 5.3225e-04 - val_loss: 634.8346 - val_mean_squared_error: 634.8347 - val_acc: 0.0000e+00\n",
      "Epoch 982/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 290.6159 - mean_squared_error: 290.6159 - acc: 5.6058e-04\n",
      "Epoch 00982: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 289.4192 - mean_squared_error: 289.4192 - acc: 5.8547e-04 - val_loss: 663.7502 - val_mean_squared_error: 663.7502 - val_acc: 0.0000e+00\n",
      "Epoch 983/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 355.9114 - mean_squared_error: 355.9115 - acc: 5.1693e-04\n",
      "Epoch 00983: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 355.1550 - mean_squared_error: 355.1551 - acc: 5.3225e-04 - val_loss: 679.6232 - val_mean_squared_error: 679.6233 - val_acc: 0.0000e+00\n",
      "Epoch 984/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 269.7886 - mean_squared_error: 269.7887 - acc: 6.0391e-04\n",
      "Epoch 00984: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 269.6998 - mean_squared_error: 269.6998 - acc: 6.0321e-04 - val_loss: 669.7889 - val_mean_squared_error: 669.7891 - val_acc: 7.0962e-05\n",
      "Epoch 985/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 275.6445 - mean_squared_error: 275.6445 - acc: 7.5368e-04\n",
      "Epoch 00985: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.5862 - mean_squared_error: 274.5862 - acc: 7.4514e-04 - val_loss: 677.4205 - val_mean_squared_error: 677.4206 - val_acc: 0.0000e+00\n",
      "Epoch 986/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 261.3393 - mean_squared_error: 261.3392 - acc: 5.1878e-04\n",
      "Epoch 00986: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 261.4585 - mean_squared_error: 261.4584 - acc: 5.1450e-04 - val_loss: 667.7832 - val_mean_squared_error: 667.7832 - val_acc: 0.0000e+00\n",
      "Epoch 987/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 328.3243 - mean_squared_error: 328.3241 - acc: 6.0391e-04\n",
      "Epoch 00987: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 328.1887 - mean_squared_error: 328.1885 - acc: 6.0321e-04 - val_loss: 699.7377 - val_mean_squared_error: 699.7377 - val_acc: 7.0962e-04\n",
      "Epoch 988/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 262.1136 - mean_squared_error: 262.1137 - acc: 6.7642e-04\n",
      "Epoch 00988: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 262.0866 - mean_squared_error: 262.0867 - acc: 6.7418e-04 - val_loss: 694.2695 - val_mean_squared_error: 694.2693 - val_acc: 0.0000e+00\n",
      "Epoch 989/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 357.6801 - mean_squared_error: 357.6799 - acc: 5.8824e-04\n",
      "Epoch 00989: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 353.9088 - mean_squared_error: 353.9086 - acc: 6.0321e-04 - val_loss: 678.2439 - val_mean_squared_error: 678.2439 - val_acc: 0.0000e+00\n",
      "Epoch 990/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 291.2990 - mean_squared_error: 291.2990 - acc: 6.1151e-04\n",
      "Epoch 00990: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 290.9998 - mean_squared_error: 290.9998 - acc: 6.2095e-04 - val_loss: 721.6411 - val_mean_squared_error: 721.6409 - val_acc: 0.0000e+00\n",
      "Epoch 991/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 437.3258 - mean_squared_error: 437.3258 - acc: 8.4715e-04\n",
      "Epoch 00991: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 431.5981 - mean_squared_error: 431.5981 - acc: 8.3385e-04 - val_loss: 699.5447 - val_mean_squared_error: 699.5445 - val_acc: 0.0000e+00\n",
      "Epoch 992/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 461.8105 - mean_squared_error: 461.8106 - acc: 6.5954e-04\n",
      "Epoch 00992: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 461.0263 - mean_squared_error: 461.0264 - acc: 6.5644e-04 - val_loss: 702.5560 - val_mean_squared_error: 702.5559 - val_acc: 0.0000e+00\n",
      "Epoch 993/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 264.3626 - mean_squared_error: 264.3627 - acc: 5.8716e-04\n",
      "Epoch 00993: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 317.0532 - mean_squared_error: 317.0533 - acc: 6.2095e-04 - val_loss: 653.7439 - val_mean_squared_error: 653.7440 - val_acc: 0.0000e+00\n",
      "Epoch 994/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 277.1661 - mean_squared_error: 277.1660 - acc: 5.0089e-04\n",
      "Epoch 00994: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 277.2315 - mean_squared_error: 277.2313 - acc: 4.9676e-04 - val_loss: 688.1043 - val_mean_squared_error: 688.1041 - val_acc: 0.0000e+00\n",
      "Epoch 995/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 295.9752 - mean_squared_error: 295.9752 - acc: 4.6679e-04\n",
      "Epoch 00995: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 295.9154 - mean_squared_error: 295.9153 - acc: 4.7902e-04 - val_loss: 711.8433 - val_mean_squared_error: 711.8431 - val_acc: 0.0000e+00\n",
      "Epoch 996/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 258.8549 - mean_squared_error: 258.8549 - acc: 5.7451e-04\n",
      "Epoch 00996: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.7869 - mean_squared_error: 258.7869 - acc: 5.6773e-04 - val_loss: 669.1668 - val_mean_squared_error: 669.1667 - val_acc: 0.0000e+00\n",
      "Epoch 997/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 273.4379 - mean_squared_error: 273.4379 - acc: 6.0498e-04\n",
      "Epoch 00997: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 273.2612 - mean_squared_error: 273.2611 - acc: 6.0321e-04 - val_loss: 688.6640 - val_mean_squared_error: 688.6640 - val_acc: 0.0000e+00\n",
      "Epoch 998/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 308.5339 - mean_squared_error: 308.5339 - acc: 7.5646e-04\n",
      "Epoch 00998: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 306.4337 - mean_squared_error: 306.4337 - acc: 7.2740e-04 - val_loss: 679.7328 - val_mean_squared_error: 679.7330 - val_acc: 4.9674e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 307.7119 - mean_squared_error: 307.7118 - acc: 5.3407e-04\n",
      "Epoch 00999: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 306.1814 - mean_squared_error: 306.1814 - acc: 5.1450e-04 - val_loss: 725.5083 - val_mean_squared_error: 725.5083 - val_acc: 0.0000e+00\n",
      "Epoch 1000/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 266.3046 - mean_squared_error: 266.3047 - acc: 5.9259e-04\n",
      "Epoch 01000: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 265.5997 - mean_squared_error: 265.5997 - acc: 6.2095e-04 - val_loss: 690.3624 - val_mean_squared_error: 690.3624 - val_acc: 0.0000e+00\n",
      "Epoch 1001/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 286.7531 - mean_squared_error: 286.7531 - acc: 6.9470e-04\n",
      "Epoch 01001: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 285.4793 - mean_squared_error: 285.4793 - acc: 7.2740e-04 - val_loss: 699.3507 - val_mean_squared_error: 699.3509 - val_acc: 0.0000e+00\n",
      "Epoch 1002/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 322.9875 - mean_squared_error: 322.9877 - acc: 7.5092e-04\n",
      "Epoch 01002: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 321.1610 - mean_squared_error: 321.1613 - acc: 7.6288e-04 - val_loss: 689.4080 - val_mean_squared_error: 689.4079 - val_acc: 2.1289e-04\n",
      "Epoch 1003/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 416.5635 - mean_squared_error: 416.5631 - acc: 8.3929e-04\n",
      "Epoch 01003: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 415.6040 - mean_squared_error: 415.6037 - acc: 8.3385e-04 - val_loss: 707.2700 - val_mean_squared_error: 707.2700 - val_acc: 0.0000e+00\n",
      "Epoch 1004/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 288.2596 - mean_squared_error: 288.2596 - acc: 5.5856e-04\n",
      "Epoch 01004: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 288.0176 - mean_squared_error: 288.0176 - acc: 5.8547e-04 - val_loss: 702.3049 - val_mean_squared_error: 702.3049 - val_acc: 7.0962e-05\n",
      "Epoch 1005/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 277.9470 - mean_squared_error: 277.9471 - acc: 6.8223e-04\n",
      "Epoch 01005: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 277.6989 - mean_squared_error: 277.6990 - acc: 6.9192e-04 - val_loss: 697.5973 - val_mean_squared_error: 697.5972 - val_acc: 0.0000e+00\n",
      "Epoch 1006/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 281.6408 - mean_squared_error: 281.6407 - acc: 6.2950e-04\n",
      "Epoch 01006: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 280.7983 - mean_squared_error: 280.7982 - acc: 6.2095e-04 - val_loss: 722.3931 - val_mean_squared_error: 722.3931 - val_acc: 0.0000e+00\n",
      "Epoch 1007/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 282.2093 - mean_squared_error: 282.2095 - acc: 7.2954e-04\n",
      "Epoch 01007: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 282.0359 - mean_squared_error: 282.0360 - acc: 7.2740e-04 - val_loss: 709.0511 - val_mean_squared_error: 709.0511 - val_acc: 0.0000e+00\n",
      "Epoch 1008/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 335.4216 - mean_squared_error: 335.4218 - acc: 6.3406e-04\n",
      "Epoch 01008: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 334.2436 - mean_squared_error: 334.2437 - acc: 6.2095e-04 - val_loss: 710.7548 - val_mean_squared_error: 710.7549 - val_acc: 0.0000e+00\n",
      "Epoch 1009/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 258.0739 - mean_squared_error: 258.0737 - acc: 5.6261e-04\n",
      "Epoch 01009: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.9113 - mean_squared_error: 258.9112 - acc: 5.4999e-04 - val_loss: 708.4159 - val_mean_squared_error: 708.4158 - val_acc: 0.0000e+00\n",
      "Epoch 1010/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 289.0558 - mean_squared_error: 289.0558 - acc: 7.1560e-04\n",
      "Epoch 01010: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 288.6797 - mean_squared_error: 288.6796 - acc: 6.9192e-04 - val_loss: 705.8966 - val_mean_squared_error: 705.8964 - val_acc: 0.0000e+00\n",
      "Epoch 1011/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 292.2467 - mean_squared_error: 292.2465 - acc: 5.9891e-04\n",
      "Epoch 01011: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 291.7610 - mean_squared_error: 291.7608 - acc: 5.8547e-04 - val_loss: 685.1640 - val_mean_squared_error: 685.1639 - val_acc: 0.0000e+00\n",
      "Epoch 1012/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 407.8722 - mean_squared_error: 407.8724 - acc: 5.9459e-04\n",
      "Epoch 01012: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 405.4236 - mean_squared_error: 405.4237 - acc: 5.8547e-04 - val_loss: 725.1067 - val_mean_squared_error: 725.1065 - val_acc: 0.0000e+00\n",
      "Epoch 1013/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 392.6057 - mean_squared_error: 392.6058 - acc: 5.2252e-04 ETA: 0s - loss: 269.2134 - mean_squar\n",
      "Epoch 01013: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 391.0945 - mean_squared_error: 391.0946 - acc: 5.1450e-04 - val_loss: 669.4775 - val_mean_squared_error: 669.4774 - val_acc: 0.0000e+00\n",
      "Epoch 1014/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 274.7270 - mean_squared_error: 274.7272 - acc: 5.6159e-04\n",
      "Epoch 01014: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.4736 - mean_squared_error: 274.4738 - acc: 5.4999e-04 - val_loss: 693.4696 - val_mean_squared_error: 693.4697 - val_acc: 0.0000e+00\n",
      "Epoch 1015/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 258.8922 - mean_squared_error: 258.8922 - acc: 5.8929e-04\n",
      "Epoch 01015: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.5652 - mean_squared_error: 258.5651 - acc: 5.8547e-04 - val_loss: 707.7485 - val_mean_squared_error: 707.7486 - val_acc: 2.8385e-04\n",
      "Epoch 1016/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 254.1441 - mean_squared_error: 254.1443 - acc: 6.7642e-04\n",
      "Epoch 01016: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.9608 - mean_squared_error: 253.9609 - acc: 6.5644e-04 - val_loss: 724.4071 - val_mean_squared_error: 724.4072 - val_acc: 0.0000e+00\n",
      "Epoch 1017/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 260.1974 - mean_squared_error: 260.1973 - acc: 6.3521e-04\n",
      "Epoch 01017: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 259.4432 - mean_squared_error: 259.4432 - acc: 6.3869e-04 - val_loss: 704.8127 - val_mean_squared_error: 704.8128 - val_acc: 4.2577e-04\n",
      "Epoch 1018/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 276.7402 - mean_squared_error: 276.7404 - acc: 6.6547e-04\n",
      "Epoch 01018: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 276.5851 - mean_squared_error: 276.5853 - acc: 6.5644e-04 - val_loss: 979.1175 - val_mean_squared_error: 979.1176 - val_acc: 0.0000e+00\n",
      "Epoch 1019/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 345.7045 - mean_squared_error: 345.7044 - acc: 5.1510e-04\n",
      "Epoch 01019: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 345.5422 - mean_squared_error: 345.5421 - acc: 5.1450e-04 - val_loss: 698.0340 - val_mean_squared_error: 698.0341 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1020/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 264.1952 - mean_squared_error: 264.1953 - acc: 6.7616e-04\n",
      "Epoch 01020: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 264.1544 - mean_squared_error: 264.1545 - acc: 6.7418e-04 - val_loss: 724.0979 - val_mean_squared_error: 724.0978 - val_acc: 0.0000e+00\n",
      "Epoch 1021/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 276.7952 - mean_squared_error: 276.7951 - acc: 5.9034e-04\n",
      "Epoch 01021: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 276.6211 - mean_squared_error: 276.6211 - acc: 6.0321e-04 - val_loss: 710.6677 - val_mean_squared_error: 710.6675 - val_acc: 1.4192e-04\n",
      "Epoch 1022/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 255.9044 - mean_squared_error: 255.9044 - acc: 5.7196e-04\n",
      "Epoch 01022: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.2934 - mean_squared_error: 256.2934 - acc: 5.6773e-04 - val_loss: 681.7263 - val_mean_squared_error: 681.7261 - val_acc: 0.0000e+00\n",
      "Epoch 1023/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 285.0427 - mean_squared_error: 285.0427 - acc: 5.6985e-04\n",
      "Epoch 01023: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 284.5231 - mean_squared_error: 284.5230 - acc: 6.2095e-04 - val_loss: 1201.2232 - val_mean_squared_error: 1201.2231 - val_acc: 0.0000e+00\n",
      "Epoch 1024/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 313.3003 - mean_squared_error: 313.3004 - acc: 5.5456e-04\n",
      "Epoch 01024: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 312.6788 - mean_squared_error: 312.6789 - acc: 5.4999e-04 - val_loss: 725.7832 - val_mean_squared_error: 725.7828 - val_acc: 0.0000e+00\n",
      "Epoch 1025/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 256.5100 - mean_squared_error: 256.5100 - acc: 6.5934e-04\n",
      "Epoch 01025: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.8451 - mean_squared_error: 256.8452 - acc: 6.3869e-04 - val_loss: 718.8864 - val_mean_squared_error: 718.8865 - val_acc: 0.0000e+00\n",
      "Epoch 1026/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 284.7382 - mean_squared_error: 284.7383 - acc: 6.4748e-04\n",
      "Epoch 01026: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 284.5349 - mean_squared_error: 284.5350 - acc: 6.3869e-04 - val_loss: 1050.3045 - val_mean_squared_error: 1050.3044 - val_acc: 0.0000e+00\n",
      "Epoch 1027/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 342.9969 - mean_squared_error: 342.9969 - acc: 6.3063e-04\n",
      "Epoch 01027: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 341.7926 - mean_squared_error: 341.7926 - acc: 6.3869e-04 - val_loss: 696.2510 - val_mean_squared_error: 696.2509 - val_acc: 0.0000e+00\n",
      "Epoch 1028/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 256.7470 - mean_squared_error: 256.7470 - acc: 7.1942e-04\n",
      "Epoch 01028: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.5206 - mean_squared_error: 256.5206 - acc: 7.2740e-04 - val_loss: 724.0404 - val_mean_squared_error: 724.0402 - val_acc: 0.0000e+00\n",
      "Epoch 1029/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 294.6108 - mean_squared_error: 294.6107 - acc: 5.8929e-04\n",
      "Epoch 01029: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 294.1755 - mean_squared_error: 294.1755 - acc: 5.8547e-04 - val_loss: 699.7660 - val_mean_squared_error: 699.7661 - val_acc: 0.0000e+00\n",
      "Epoch 1030/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 285.8703 - mean_squared_error: 285.8702 - acc: 6.4695e-04\n",
      "Epoch 01030: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 284.6555 - mean_squared_error: 284.6554 - acc: 6.5644e-04 - val_loss: 726.3680 - val_mean_squared_error: 726.3679 - val_acc: 0.0000e+00\n",
      "Epoch 1031/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 256.9041 - mean_squared_error: 256.9040 - acc: 5.5957e-04\n",
      "Epoch 01031: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 256.5783 - mean_squared_error: 256.5781 - acc: 5.4999e-04 - val_loss: 709.4478 - val_mean_squared_error: 709.4478 - val_acc: 0.0000e+00\n",
      "Epoch 1032/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 276.6176 - mean_squared_error: 276.6176 - acc: 5.8716e-04\n",
      "Epoch 01032: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 275.5680 - mean_squared_error: 275.5681 - acc: 6.0321e-04 - val_loss: 777.1303 - val_mean_squared_error: 777.1304 - val_acc: 0.0000e+00\n",
      "Epoch 1033/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 259.7323 - mean_squared_error: 259.7325 - acc: 5.5249e-04\n",
      "Epoch 01033: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.7876 - mean_squared_error: 258.7878 - acc: 5.3225e-04 - val_loss: 701.8859 - val_mean_squared_error: 701.8857 - val_acc: 0.0000e+00\n",
      "Epoch 1034/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 280.4112 - mean_squared_error: 280.4112 - acc: 5.8824e-04\n",
      "Epoch 01034: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 279.3182 - mean_squared_error: 279.3182 - acc: 6.0321e-04 - val_loss: 754.7069 - val_mean_squared_error: 754.7068 - val_acc: 4.9674e-04\n",
      "Epoch 1035/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 449.8353 - mean_squared_error: 449.8355 - acc: 6.8223e-04\n",
      "Epoch 01035: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 447.5103 - mean_squared_error: 447.5104 - acc: 6.7418e-04 - val_loss: 702.1448 - val_mean_squared_error: 702.1447 - val_acc: 2.1289e-04\n",
      "Epoch 1036/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 329.4808 - mean_squared_error: 329.4810 - acc: 6.1594e-04\n",
      "Epoch 01036: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 327.8063 - mean_squared_error: 327.8064 - acc: 6.2095e-04 - val_loss: 702.4271 - val_mean_squared_error: 702.4270 - val_acc: 0.0000e+00\n",
      "Epoch 1037/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 257.0048 - mean_squared_error: 257.0048 - acc: 6.4286e-04\n",
      "Epoch 01037: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.8494 - mean_squared_error: 256.8493 - acc: 6.3869e-04 - val_loss: 710.1194 - val_mean_squared_error: 710.1194 - val_acc: 0.0000e+00\n",
      "Epoch 1038/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 293.3253 - mean_squared_error: 293.3253 - acc: 6.3521e-04\n",
      "Epoch 01038: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 292.1832 - mean_squared_error: 292.1832 - acc: 6.5644e-04 - val_loss: 710.7495 - val_mean_squared_error: 710.7496 - val_acc: 0.0000e+00\n",
      "Epoch 1039/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 286.4360 - mean_squared_error: 286.4362 - acc: 4.7794e-04\n",
      "Epoch 01039: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 285.6403 - mean_squared_error: 285.6404 - acc: 4.9676e-04 - val_loss: 677.2927 - val_mean_squared_error: 677.2928 - val_acc: 0.0000e+00\n",
      "Epoch 1040/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 262.3200 - mean_squared_error: 262.3200 - acc: 5.8716e-04\n",
      "Epoch 01040: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 261.9247 - mean_squared_error: 261.9247 - acc: 5.6773e-04 - val_loss: 695.1513 - val_mean_squared_error: 695.1513 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 273.9374 - mean_squared_error: 273.9373 - acc: 5.3860e-04\n",
      "Epoch 01041: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.0539 - mean_squared_error: 274.0538 - acc: 5.4999e-04 - val_loss: 734.5140 - val_mean_squared_error: 734.5137 - val_acc: 0.0000e+00\n",
      "Epoch 1042/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 282.5033 - mean_squared_error: 282.5033 - acc: 5.8929e-04\n",
      "Epoch 01042: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 282.2380 - mean_squared_error: 282.2380 - acc: 5.8547e-04 - val_loss: 694.2661 - val_mean_squared_error: 694.2660 - val_acc: 0.0000e+00\n",
      "Epoch 1043/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 278.5192 - mean_squared_error: 278.5191 - acc: 4.6346e-04\n",
      "Epoch 01043: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 278.5040 - mean_squared_error: 278.5040 - acc: 4.6128e-04 - val_loss: 716.9034 - val_mean_squared_error: 716.9033 - val_acc: 0.0000e+00\n",
      "Epoch 1044/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 255.7448 - mean_squared_error: 255.7448 - acc: 5.5258e-04\n",
      "Epoch 01044: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.5226 - mean_squared_error: 255.5226 - acc: 5.4999e-04 - val_loss: 704.1661 - val_mean_squared_error: 704.1661 - val_acc: 0.0000e+00\n",
      "Epoch 1045/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 253.7686 - mean_squared_error: 253.7686 - acc: 7.0018e-04\n",
      "Epoch 01045: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 323.8368 - mean_squared_error: 323.8368 - acc: 6.9192e-04 - val_loss: 802.3729 - val_mean_squared_error: 802.3727 - val_acc: 0.0000e+00\n",
      "Epoch 1046/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 299.1619 - mean_squared_error: 299.1619 - acc: 5.5957e-04\n",
      "Epoch 01046: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 299.1120 - mean_squared_error: 299.1121 - acc: 5.6773e-04 - val_loss: 755.2298 - val_mean_squared_error: 755.2296 - val_acc: 0.0000e+00\n",
      "Epoch 1047/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 294.5715 - mean_squared_error: 294.5716 - acc: 5.0360e-04\n",
      "Epoch 01047: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 294.0942 - mean_squared_error: 294.0943 - acc: 4.9676e-04 - val_loss: 687.2730 - val_mean_squared_error: 687.2730 - val_acc: 0.0000e+00\n",
      "Epoch 1048/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 309.0992 - mean_squared_error: 309.0991 - acc: 5.3476e-04\n",
      "Epoch 01048: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 308.9239 - mean_squared_error: 308.9239 - acc: 5.3225e-04 - val_loss: 685.4332 - val_mean_squared_error: 685.4329 - val_acc: 0.0000e+00\n",
      "Epoch 1049/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 274.9356 - mean_squared_error: 274.9356 - acc: 6.4632e-04\n",
      "Epoch 01049: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.7047 - mean_squared_error: 274.7047 - acc: 6.3869e-04 - val_loss: 704.8415 - val_mean_squared_error: 704.8416 - val_acc: 0.0000e+00\n",
      "Epoch 1050/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 331.7347 - mean_squared_error: 331.7348 - acc: 5.7348e-04\n",
      "Epoch 01050: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 331.4060 - mean_squared_error: 331.4060 - acc: 5.6773e-04 - val_loss: 688.0506 - val_mean_squared_error: 688.0505 - val_acc: 3.5481e-04\n",
      "Epoch 1051/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 255.8791 - mean_squared_error: 255.8792 - acc: 5.3381e-04\n",
      "Epoch 01051: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.8749 - mean_squared_error: 255.8749 - acc: 5.3225e-04 - val_loss: 702.5296 - val_mean_squared_error: 702.5294 - val_acc: 0.0000e+00\n",
      "Epoch 1052/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 281.2163 - mean_squared_error: 281.2162 - acc: 6.0886e-04\n",
      "Epoch 01052: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 280.7655 - mean_squared_error: 280.7654 - acc: 6.0321e-04 - val_loss: 664.9809 - val_mean_squared_error: 664.9809 - val_acc: 0.0000e+00\n",
      "Epoch 1053/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 253.5948 - mean_squared_error: 253.5949 - acc: 6.5099e-04\n",
      "Epoch 01053: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.8858 - mean_squared_error: 253.8859 - acc: 6.3869e-04 - val_loss: 718.0649 - val_mean_squared_error: 718.0649 - val_acc: 3.5481e-04\n",
      "Epoch 1054/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 255.1226 - mean_squared_error: 255.1225 - acc: 5.9783e-04\n",
      "Epoch 01054: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.0032 - mean_squared_error: 255.0032 - acc: 6.0321e-04 - val_loss: 708.4190 - val_mean_squared_error: 708.4188 - val_acc: 7.0962e-05\n",
      "Epoch 1055/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 476.3386 - mean_squared_error: 476.3385 - acc: 5.8288e-04\n",
      "Epoch 01055: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 470.5764 - mean_squared_error: 470.5763 - acc: 5.8547e-04 - val_loss: 694.9633 - val_mean_squared_error: 694.9634 - val_acc: 7.0962e-05\n",
      "Epoch 1056/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 285.7175 - mean_squared_error: 285.7175 - acc: 5.5456e-04\n",
      "Epoch 01056: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 285.7490 - mean_squared_error: 285.7490 - acc: 5.6773e-04 - val_loss: 712.6627 - val_mean_squared_error: 712.6627 - val_acc: 2.8385e-04\n",
      "Epoch 1057/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 305.0843 - mean_squared_error: 305.0844 - acc: 5.7041e-04\n",
      "Epoch 01057: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 304.8309 - mean_squared_error: 304.8309 - acc: 5.8547e-04 - val_loss: 717.7954 - val_mean_squared_error: 717.7953 - val_acc: 0.0000e+00\n",
      "Epoch 1058/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 255.7656 - mean_squared_error: 255.7655 - acc: 6.6547e-04\n",
      "Epoch 01058: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.5984 - mean_squared_error: 255.5983 - acc: 6.7418e-04 - val_loss: 668.6103 - val_mean_squared_error: 668.6104 - val_acc: 0.0000e+00\n",
      "Epoch 1059/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 282.6143 - mean_squared_error: 282.6143 - acc: 6.4057e-04\n",
      "Epoch 01059: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 282.4844 - mean_squared_error: 282.4844 - acc: 6.3869e-04 - val_loss: 667.5508 - val_mean_squared_error: 667.5509 - val_acc: 7.0962e-05\n",
      "Epoch 1060/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 291.8361 - mean_squared_error: 291.8362 - acc: 6.0391e-04\n",
      "Epoch 01060: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 291.8819 - mean_squared_error: 291.8819 - acc: 6.0321e-04 - val_loss: 720.4896 - val_mean_squared_error: 720.4894 - val_acc: 0.0000e+00\n",
      "Epoch 1061/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 301.3058 - mean_squared_error: 301.3059 - acc: 6.0823e-04\n",
      "Epoch 01061: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 300.8696 - mean_squared_error: 300.8698 - acc: 6.0321e-04 - val_loss: 675.7280 - val_mean_squared_error: 675.7280 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1062/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 280.1620 - mean_squared_error: 280.1619 - acc: 6.2271e-04\n",
      "Epoch 01062: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 279.7445 - mean_squared_error: 279.7444 - acc: 6.2095e-04 - val_loss: 703.7587 - val_mean_squared_error: 703.7588 - val_acc: 4.2577e-04\n",
      "Epoch 1063/3000\n",
      "53700/56365 [===========================>..] - ETA: 0s - loss: 278.5256 - mean_squared_error: 278.5255 - acc: 6.3315e-04\n",
      "Epoch 01063: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 277.9192 - mean_squared_error: 277.9191 - acc: 6.2095e-04 - val_loss: 713.9440 - val_mean_squared_error: 713.9442 - val_acc: 7.0962e-05\n",
      "Epoch 1064/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 312.0923 - mean_squared_error: 312.0924 - acc: 5.2441e-04\n",
      "Epoch 01064: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 311.0815 - mean_squared_error: 311.0815 - acc: 5.1450e-04 - val_loss: 688.5335 - val_mean_squared_error: 688.5333 - val_acc: 0.0000e+00\n",
      "Epoch 1065/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 252.8871 - mean_squared_error: 252.8871 - acc: 5.1188e-04\n",
      "Epoch 01065: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.0217 - mean_squared_error: 253.0217 - acc: 4.9676e-04 - val_loss: 699.9728 - val_mean_squared_error: 699.9727 - val_acc: 7.0962e-05\n",
      "Epoch 1066/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 276.9673 - mean_squared_error: 276.9674 - acc: 6.4338e-04\n",
      "Epoch 01066: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 276.6602 - mean_squared_error: 276.6603 - acc: 6.5644e-04 - val_loss: 707.8520 - val_mean_squared_error: 707.8519 - val_acc: 2.8385e-04\n",
      "Epoch 1067/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 369.1585 - mean_squared_error: 369.1588 - acc: 5.9140e-04\n",
      "Epoch 01067: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 367.6833 - mean_squared_error: 367.6836 - acc: 5.8547e-04 - val_loss: 715.8877 - val_mean_squared_error: 715.8875 - val_acc: 0.0000e+00\n",
      "Epoch 1068/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 291.0531 - mean_squared_error: 291.0531 - acc: 5.5755e-04\n",
      "Epoch 01068: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 290.3449 - mean_squared_error: 290.3448 - acc: 5.4999e-04 - val_loss: 756.3800 - val_mean_squared_error: 756.3802 - val_acc: 0.0000e+00\n",
      "Epoch 1069/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 278.0892 - mean_squared_error: 278.0892 - acc: 6.6667e-04\n",
      "Epoch 01069: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 277.5339 - mean_squared_error: 277.5339 - acc: 6.5644e-04 - val_loss: 696.5786 - val_mean_squared_error: 696.5786 - val_acc: 0.0000e+00\n",
      "Epoch 1070/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 253.8117 - mean_squared_error: 253.8115 - acc: 7.9044e-04\n",
      "Epoch 01070: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 33us/sample - loss: 254.8808 - mean_squared_error: 254.8806 - acc: 7.6288e-04 - val_loss: 708.9464 - val_mean_squared_error: 708.9464 - val_acc: 0.0000e+00\n",
      "Epoch 1071/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 259.7786 - mean_squared_error: 259.7786 - acc: 5.4152e-04\n",
      "Epoch 01071: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 260.1940 - mean_squared_error: 260.1940 - acc: 5.4999e-04 - val_loss: 677.2500 - val_mean_squared_error: 677.2501 - val_acc: 0.0000e+00\n",
      "Epoch 1072/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 279.0069 - mean_squared_error: 279.0069 - acc: 5.6261e-04\n",
      "Epoch 01072: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 278.4244 - mean_squared_error: 278.4244 - acc: 5.4999e-04 - val_loss: 689.2642 - val_mean_squared_error: 689.2642 - val_acc: 0.0000e+00\n",
      "Epoch 1073/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 276.3423 - mean_squared_error: 276.3423 - acc: 6.3291e-04\n",
      "Epoch 01073: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 276.1704 - mean_squared_error: 276.1703 - acc: 6.3869e-04 - val_loss: 738.4709 - val_mean_squared_error: 738.4709 - val_acc: 0.0000e+00\n",
      "Epoch 1074/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 251.2089 - mean_squared_error: 251.2088 - acc: 5.5957e-04\n",
      "Epoch 01074: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.1838 - mean_squared_error: 319.1837 - acc: 5.4999e-04 - val_loss: 805.5098 - val_mean_squared_error: 805.5097 - val_acc: 0.0000e+00\n",
      "Epoch 1075/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 261.0651 - mean_squared_error: 261.0650 - acc: 5.8076e-04\n",
      "Epoch 01075: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 284.8150 - mean_squared_error: 284.8149 - acc: 5.8547e-04 - val_loss: 650.8569 - val_mean_squared_error: 650.8569 - val_acc: 0.0000e+00\n",
      "Epoch 1076/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 263.5959 - mean_squared_error: 263.5960 - acc: 7.0909e-04\n",
      "Epoch 01076: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.4868 - mean_squared_error: 263.4869 - acc: 6.9192e-04 - val_loss: 699.9314 - val_mean_squared_error: 699.9314 - val_acc: 0.0000e+00\n",
      "Epoch 1077/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 391.7113 - mean_squared_error: 391.7113 - acc: 5.6569e-04\n",
      "Epoch 01077: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 387.7310 - mean_squared_error: 387.7310 - acc: 5.4999e-04 - val_loss: 690.8043 - val_mean_squared_error: 690.8042 - val_acc: 0.0000e+00\n",
      "Epoch 1078/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 328.6829 - mean_squared_error: 328.6829 - acc: 6.1483e-04\n",
      "Epoch 01078: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 327.5878 - mean_squared_error: 327.5878 - acc: 6.0321e-04 - val_loss: 668.8605 - val_mean_squared_error: 668.8607 - val_acc: 0.0000e+00\n",
      "Epoch 1079/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 254.7334 - mean_squared_error: 254.7336 - acc: 6.8223e-04\n",
      "Epoch 01079: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 254.5744 - mean_squared_error: 254.5746 - acc: 6.7418e-04 - val_loss: 695.9265 - val_mean_squared_error: 695.9268 - val_acc: 0.0000e+00\n",
      "Epoch 1080/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 252.5474 - mean_squared_error: 252.5474 - acc: 7.2954e-04\n",
      "Epoch 01080: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 252.5231 - mean_squared_error: 252.5231 - acc: 7.2740e-04 - val_loss: 719.8019 - val_mean_squared_error: 719.8020 - val_acc: 0.0000e+00\n",
      "Epoch 1081/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 294.0529 - mean_squared_error: 294.0529 - acc: 5.5046e-04\n",
      "Epoch 01081: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 293.6585 - mean_squared_error: 293.6585 - acc: 5.4999e-04 - val_loss: 687.5609 - val_mean_squared_error: 687.5612 - val_acc: 0.0000e+00\n",
      "Epoch 1082/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 290.7864 - mean_squared_error: 290.7865 - acc: 4.5620e-04\n",
      "Epoch 01082: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 289.4782 - mean_squared_error: 289.4782 - acc: 4.7902e-04 - val_loss: 708.2932 - val_mean_squared_error: 708.2931 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1083/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 339.3221 - mean_squared_error: 339.3223 - acc: 7.1429e-04\n",
      "Epoch 01083: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 339.1562 - mean_squared_error: 339.1564 - acc: 7.0966e-04 - val_loss: 704.4358 - val_mean_squared_error: 704.4360 - val_acc: 0.0000e+00\n",
      "Epoch 1084/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 335.7624 - mean_squared_error: 335.7623 - acc: 6.9343e-04\n",
      "Epoch 01084: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 333.5307 - mean_squared_error: 333.5306 - acc: 6.7418e-04 - val_loss: 689.9424 - val_mean_squared_error: 689.9426 - val_acc: 0.0000e+00\n",
      "Epoch 1085/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 293.1611 - mean_squared_error: 293.1610 - acc: 6.7857e-04\n",
      "Epoch 01085: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 292.6833 - mean_squared_error: 292.6833 - acc: 6.7418e-04 - val_loss: 722.0467 - val_mean_squared_error: 722.0466 - val_acc: 0.0000e+00\n",
      "Epoch 1086/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 404.8157 - mean_squared_error: 404.8154 - acc: 5.3860e-04\n",
      "Epoch 01086: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 403.2460 - mean_squared_error: 403.2457 - acc: 5.3225e-04 - val_loss: 738.0991 - val_mean_squared_error: 738.0991 - val_acc: 0.0000e+00\n",
      "Epoch 1087/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 285.7115 - mean_squared_error: 285.7114 - acc: 5.2823e-04\n",
      "Epoch 01087: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 285.1681 - mean_squared_error: 285.1681 - acc: 5.3225e-04 - val_loss: 687.1656 - val_mean_squared_error: 687.1655 - val_acc: 1.4192e-04\n",
      "Epoch 1088/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 306.9880 - mean_squared_error: 306.9879 - acc: 4.9091e-04\n",
      "Epoch 01088: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 305.3595 - mean_squared_error: 305.3595 - acc: 4.7902e-04 - val_loss: 712.8155 - val_mean_squared_error: 712.8155 - val_acc: 0.0000e+00\n",
      "Epoch 1089/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 258.2328 - mean_squared_error: 258.2326 - acc: 6.0000e-04\n",
      "Epoch 01089: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 260.2857 - mean_squared_error: 260.2855 - acc: 6.2095e-04 - val_loss: 686.9340 - val_mean_squared_error: 686.9340 - val_acc: 0.0000e+00\n",
      "Epoch 1090/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 283.0464 - mean_squared_error: 283.0464 - acc: 6.4982e-04\n",
      "Epoch 01090: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 282.1921 - mean_squared_error: 282.1921 - acc: 6.3869e-04 - val_loss: 675.2409 - val_mean_squared_error: 675.2410 - val_acc: 0.0000e+00\n",
      "Epoch 1091/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 316.1149 - mean_squared_error: 316.1148 - acc: 6.2837e-04\n",
      "Epoch 01091: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 315.0015 - mean_squared_error: 315.0014 - acc: 6.2095e-04 - val_loss: 705.3619 - val_mean_squared_error: 705.3621 - val_acc: 0.0000e+00\n",
      "Epoch 1092/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 301.5288 - mean_squared_error: 301.5288 - acc: 6.3177e-04\n",
      "Epoch 01092: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 300.8412 - mean_squared_error: 300.8412 - acc: 6.3869e-04 - val_loss: 703.4401 - val_mean_squared_error: 703.4399 - val_acc: 0.0000e+00\n",
      "Epoch 1093/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 251.6159 - mean_squared_error: 251.6160 - acc: 5.9459e-04\n",
      "Epoch 01093: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 251.3312 - mean_squared_error: 251.3313 - acc: 6.0321e-04 - val_loss: 693.6624 - val_mean_squared_error: 693.6624 - val_acc: 0.0000e+00\n",
      "Epoch 1094/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 282.2976 - mean_squared_error: 282.2976 - acc: 7.8182e-04 ETA: 0s - loss: 301.7994 - mean_squared_error: 30\n",
      "Epoch 01094: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 281.8872 - mean_squared_error: 281.8871 - acc: 7.8063e-04 - val_loss: 693.4385 - val_mean_squared_error: 693.4385 - val_acc: 0.0000e+00\n",
      "Epoch 1095/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 480.4650 - mean_squared_error: 480.4650 - acc: 4.7187e-04\n",
      "Epoch 01095: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 475.5237 - mean_squared_error: 475.5237 - acc: 4.9676e-04 - val_loss: 703.1038 - val_mean_squared_error: 703.1040 - val_acc: 0.0000e+00\n",
      "Epoch 1096/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 428.9699 - mean_squared_error: 428.9699 - acc: 6.0219e-04\n",
      "Epoch 01096: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 424.7569 - mean_squared_error: 424.7570 - acc: 6.2095e-04 - val_loss: 731.7070 - val_mean_squared_error: 731.7072 - val_acc: 0.0000e+00\n",
      "Epoch 1097/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 256.4068 - mean_squared_error: 256.4068 - acc: 6.1372e-04\n",
      "Epoch 01097: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 256.3965 - mean_squared_error: 256.3965 - acc: 6.0321e-04 - val_loss: 691.4350 - val_mean_squared_error: 691.4350 - val_acc: 7.0962e-05\n",
      "Epoch 1098/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 447.2619 - mean_squared_error: 447.2618 - acc: 4.9632e-04\n",
      "Epoch 01098: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 442.0481 - mean_squared_error: 442.0479 - acc: 5.4999e-04 - val_loss: 734.2498 - val_mean_squared_error: 734.2499 - val_acc: 7.0962e-05\n",
      "Epoch 1099/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 252.7011 - mean_squared_error: 252.7011 - acc: 7.0144e-04\n",
      "Epoch 01099: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 252.5344 - mean_squared_error: 252.5345 - acc: 7.0966e-04 - val_loss: 722.1212 - val_mean_squared_error: 722.1210 - val_acc: 0.0000e+00\n",
      "Epoch 1100/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 386.9275 - mean_squared_error: 386.9273 - acc: 6.8592e-04\n",
      "Epoch 01100: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 384.8499 - mean_squared_error: 384.8496 - acc: 6.9192e-04 - val_loss: 714.7457 - val_mean_squared_error: 714.7456 - val_acc: 0.0000e+00\n",
      "Epoch 1101/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 373.3902 - mean_squared_error: 373.3902 - acc: 6.0391e-04\n",
      "Epoch 01101: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 373.2527 - mean_squared_error: 373.2527 - acc: 6.0321e-04 - val_loss: 688.6569 - val_mean_squared_error: 688.6571 - val_acc: 0.0000e+00\n",
      "Epoch 1102/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 266.9253 - mean_squared_error: 266.9254 - acc: 5.8076e-04\n",
      "Epoch 01102: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 266.9962 - mean_squared_error: 266.9962 - acc: 5.8547e-04 - val_loss: 701.4145 - val_mean_squared_error: 701.4147 - val_acc: 0.0000e+00\n",
      "Epoch 1103/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 255.5831 - mean_squared_error: 255.5831 - acc: 7.4954e-04 ETA: 0s - loss: 255.7251 - mean_squared_error: 255.7250 - acc: \n",
      "Epoch 01103: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 255.4392 - mean_squared_error: 255.4392 - acc: 7.2740e-04 - val_loss: 694.2897 - val_mean_squared_error: 694.2897 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1104/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 258.9452 - mean_squared_error: 258.9450 - acc: 5.9459e-04\n",
      "Epoch 01104: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 258.7781 - mean_squared_error: 258.7779 - acc: 5.8547e-04 - val_loss: 695.4268 - val_mean_squared_error: 695.4268 - val_acc: 1.4192e-04\n",
      "Epoch 1105/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 254.5661 - mean_squared_error: 254.5661 - acc: 5.8501e-04\n",
      "Epoch 01105: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 254.5405 - mean_squared_error: 254.5406 - acc: 6.0321e-04 - val_loss: 698.0876 - val_mean_squared_error: 698.0874 - val_acc: 6.3866e-04\n",
      "Epoch 1106/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 262.0048 - mean_squared_error: 262.0048 - acc: 4.7016e-04\n",
      "Epoch 01106: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 261.9711 - mean_squared_error: 261.9711 - acc: 4.7902e-04 - val_loss: 715.0239 - val_mean_squared_error: 715.0237 - val_acc: 0.0000e+00\n",
      "Epoch 1107/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 319.8155 - mean_squared_error: 319.8155 - acc: 6.7616e-04\n",
      "Epoch 01107: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.7481 - mean_squared_error: 319.7482 - acc: 6.7418e-04 - val_loss: 696.8466 - val_mean_squared_error: 696.8466 - val_acc: 0.0000e+00\n",
      "Epoch 1108/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 289.7923 - mean_squared_error: 289.7922 - acc: 5.0179e-04\n",
      "Epoch 01108: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 289.7380 - mean_squared_error: 289.7379 - acc: 4.9676e-04 - val_loss: 723.4377 - val_mean_squared_error: 723.4379 - val_acc: 0.0000e+00\n",
      "Epoch 1109/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 252.1503 - mean_squared_error: 252.1503 - acc: 6.7029e-04\n",
      "Epoch 01109: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 252.8322 - mean_squared_error: 252.8323 - acc: 6.5644e-04 - val_loss: 719.7231 - val_mean_squared_error: 719.7230 - val_acc: 2.1289e-04\n",
      "Epoch 1110/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 261.7450 - mean_squared_error: 261.7452 - acc: 5.5556e-04\n",
      "Epoch 01110: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 261.5043 - mean_squared_error: 261.5045 - acc: 5.8547e-04 - val_loss: 697.3895 - val_mean_squared_error: 697.3896 - val_acc: 0.0000e+00\n",
      "Epoch 1111/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 296.6555 - mean_squared_error: 296.6556 - acc: 6.0391e-04\n",
      "Epoch 01111: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 296.8433 - mean_squared_error: 296.8435 - acc: 6.0321e-04 - val_loss: 690.9177 - val_mean_squared_error: 690.9177 - val_acc: 0.0000e+00\n",
      "Epoch 1112/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 252.8773 - mean_squared_error: 252.8772 - acc: 6.3521e-04 ETA: 0s - loss: 245.4592 - mean_squared_error: 245.45\n",
      "Epoch 01112: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.7475 - mean_squared_error: 253.7474 - acc: 6.2095e-04 - val_loss: 709.2597 - val_mean_squared_error: 709.2596 - val_acc: 0.0000e+00\n",
      "Epoch 1113/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 253.5222 - mean_squared_error: 253.5223 - acc: 6.0714e-04\n",
      "Epoch 01113: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.4108 - mean_squared_error: 253.4109 - acc: 6.0321e-04 - val_loss: 718.0778 - val_mean_squared_error: 718.0778 - val_acc: 0.0000e+00\n",
      "Epoch 1114/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 393.1448 - mean_squared_error: 393.1448 - acc: 5.3506e-04\n",
      "Epoch 01114: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 390.0658 - mean_squared_error: 390.0659 - acc: 5.8547e-04 - val_loss: 666.2090 - val_mean_squared_error: 666.2090 - val_acc: 0.0000e+00\n",
      "Epoch 1115/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 315.3906 - mean_squared_error: 315.3906 - acc: 6.5574e-04\n",
      "Epoch 01115: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 313.5805 - mean_squared_error: 313.5806 - acc: 6.3869e-04 - val_loss: 675.8497 - val_mean_squared_error: 675.8497 - val_acc: 0.0000e+00\n",
      "Epoch 1116/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 253.5753 - mean_squared_error: 253.5751 - acc: 7.0018e-04\n",
      "Epoch 01116: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.3781 - mean_squared_error: 253.3780 - acc: 6.9192e-04 - val_loss: 686.7259 - val_mean_squared_error: 686.7260 - val_acc: 0.0000e+00\n",
      "Epoch 1117/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 251.2257 - mean_squared_error: 251.2258 - acc: 5.2252e-04\n",
      "Epoch 01117: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 251.2797 - mean_squared_error: 251.2798 - acc: 5.1450e-04 - val_loss: 675.9215 - val_mean_squared_error: 675.9215 - val_acc: 0.0000e+00\n",
      "Epoch 1118/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 273.4269 - mean_squared_error: 273.4270 - acc: 5.8929e-04\n",
      "Epoch 01118: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 273.4035 - mean_squared_error: 273.4036 - acc: 5.8547e-04 - val_loss: 713.5604 - val_mean_squared_error: 713.5602 - val_acc: 1.4192e-04\n",
      "Epoch 1119/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 377.5049 - mean_squared_error: 377.5047 - acc: 6.5455e-04\n",
      "Epoch 01119: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 374.5065 - mean_squared_error: 374.5063 - acc: 6.3869e-04 - val_loss: 635.1823 - val_mean_squared_error: 635.1823 - val_acc: 6.3866e-04\n",
      "Epoch 1120/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 260.2414 - mean_squared_error: 260.2414 - acc: 6.2157e-04\n",
      "Epoch 01120: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 259.8889 - mean_squared_error: 259.8889 - acc: 6.0321e-04 - val_loss: 692.4066 - val_mean_squared_error: 692.4067 - val_acc: 0.0000e+00\n",
      "Epoch 1121/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 273.4762 - mean_squared_error: 273.4763 - acc: 5.0360e-04\n",
      "Epoch 01121: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 273.3107 - mean_squared_error: 273.3107 - acc: 4.9676e-04 - val_loss: 678.4465 - val_mean_squared_error: 678.4464 - val_acc: 0.0000e+00\n",
      "Epoch 1122/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 336.6614 - mean_squared_error: 336.6613 - acc: 4.7706e-04\n",
      "Epoch 01122: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 333.7756 - mean_squared_error: 333.7755 - acc: 4.7902e-04 - val_loss: 681.9115 - val_mean_squared_error: 681.9116 - val_acc: 0.0000e+00\n",
      "Epoch 1123/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 248.7276 - mean_squared_error: 248.7276 - acc: 5.9783e-04\n",
      "Epoch 01123: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 248.6975 - mean_squared_error: 248.6975 - acc: 6.0321e-04 - val_loss: 682.1953 - val_mean_squared_error: 682.1953 - val_acc: 0.0000e+00\n",
      "Epoch 1124/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 278.6871 - mean_squared_error: 278.6871 - acc: 5.6159e-04\n",
      "Epoch 01124: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 278.1740 - mean_squared_error: 278.1741 - acc: 6.0321e-04 - val_loss: 684.4137 - val_mean_squared_error: 684.4138 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1125/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 288.7122 - mean_squared_error: 288.7122 - acc: 6.0000e-04\n",
      "Epoch 01125: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.8520 - mean_squared_error: 287.8520 - acc: 5.8547e-04 - val_loss: 711.3690 - val_mean_squared_error: 711.3691 - val_acc: 0.0000e+00\n",
      "Epoch 1126/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 257.9235 - mean_squared_error: 257.9236 - acc: 5.9567e-04\n",
      "Epoch 01126: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 258.1233 - mean_squared_error: 258.1234 - acc: 5.8547e-04 - val_loss: 667.0626 - val_mean_squared_error: 667.0626 - val_acc: 0.0000e+00\n",
      "Epoch 1127/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 257.2404 - mean_squared_error: 257.2404 - acc: 6.4748e-04\n",
      "Epoch 01127: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 257.5284 - mean_squared_error: 257.5284 - acc: 6.3869e-04 - val_loss: 708.9015 - val_mean_squared_error: 708.9014 - val_acc: 0.0000e+00\n",
      "Epoch 1128/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 282.2213 - mean_squared_error: 282.2214 - acc: 6.6908e-04\n",
      "Epoch 01128: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 281.8784 - mean_squared_error: 281.8785 - acc: 7.2740e-04 - val_loss: 642.9174 - val_mean_squared_error: 642.9174 - val_acc: 0.0000e+00\n",
      "Epoch 1129/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 314.7238 - mean_squared_error: 314.7236 - acc: 5.5147e-04\n",
      "Epoch 01129: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 312.8230 - mean_squared_error: 312.8229 - acc: 5.4999e-04 - val_loss: 726.8187 - val_mean_squared_error: 726.8187 - val_acc: 0.0000e+00\n",
      "Epoch 1130/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 253.9149 - mean_squared_error: 253.9147 - acc: 4.7706e-04\n",
      "Epoch 01130: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.5126 - mean_squared_error: 253.5124 - acc: 4.6128e-04 - val_loss: 667.9961 - val_mean_squared_error: 667.9960 - val_acc: 0.0000e+00\n",
      "Epoch 1131/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 253.1825 - mean_squared_error: 253.1826 - acc: 6.3985e-04\n",
      "Epoch 01131: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 252.5976 - mean_squared_error: 252.5977 - acc: 6.3869e-04 - val_loss: 650.3513 - val_mean_squared_error: 650.3511 - val_acc: 2.1289e-04\n",
      "Epoch 1132/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 255.6539 - mean_squared_error: 255.6537 - acc: 5.7866e-04\n",
      "Epoch 01132: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 259.6978 - mean_squared_error: 259.6977 - acc: 5.8547e-04 - val_loss: 665.3154 - val_mean_squared_error: 665.3152 - val_acc: 7.0962e-05\n",
      "Epoch 1133/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 292.0180 - mean_squared_error: 292.0179 - acc: 6.7029e-04\n",
      "Epoch 01133: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 291.7055 - mean_squared_error: 291.7053 - acc: 6.7418e-04 - val_loss: 645.9043 - val_mean_squared_error: 645.9045 - val_acc: 0.0000e+00\n",
      "Epoch 1134/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 285.9970 - mean_squared_error: 285.9969 - acc: 6.8345e-04\n",
      "Epoch 01134: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 285.7967 - mean_squared_error: 285.7967 - acc: 6.7418e-04 - val_loss: 714.5728 - val_mean_squared_error: 714.5730 - val_acc: 0.0000e+00\n",
      "Epoch 1135/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 267.5657 - mean_squared_error: 267.5657 - acc: 5.0450e-04\n",
      "Epoch 01135: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 267.1857 - mean_squared_error: 267.1858 - acc: 5.1450e-04 - val_loss: 724.0526 - val_mean_squared_error: 724.0527 - val_acc: 0.0000e+00\n",
      "Epoch 1136/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 346.9678 - mean_squared_error: 346.9676 - acc: 5.8719e-04\n",
      "Epoch 01136: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 346.5684 - mean_squared_error: 346.5683 - acc: 5.8547e-04 - val_loss: 678.3105 - val_mean_squared_error: 678.3106 - val_acc: 0.0000e+00\n",
      "Epoch 1137/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 321.4565 - mean_squared_error: 321.4565 - acc: 7.3801e-04\n",
      "Epoch 01137: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 318.6222 - mean_squared_error: 318.6222 - acc: 7.2740e-04 - val_loss: 662.1480 - val_mean_squared_error: 662.1478 - val_acc: 0.0000e+00\n",
      "Epoch 1138/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 444.0485 - mean_squared_error: 444.0484 - acc: 5.7971e-04\n",
      "Epoch 01138: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 440.3886 - mean_squared_error: 440.3885 - acc: 5.8547e-04 - val_loss: 715.1800 - val_mean_squared_error: 715.1802 - val_acc: 3.5481e-04\n",
      "Epoch 1139/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 254.5948 - mean_squared_error: 254.5948 - acc: 5.6838e-04\n",
      "Epoch 01139: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 254.5494 - mean_squared_error: 254.5494 - acc: 5.6773e-04 - val_loss: 681.7933 - val_mean_squared_error: 681.7933 - val_acc: 0.0000e+00\n",
      "Epoch 1140/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 257.5074 - mean_squared_error: 257.5075 - acc: 7.0270e-04\n",
      "Epoch 01140: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 257.7542 - mean_squared_error: 257.7543 - acc: 6.9192e-04 - val_loss: 707.8496 - val_mean_squared_error: 707.8496 - val_acc: 0.0000e+00\n",
      "Epoch 1141/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 251.4580 - mean_squared_error: 251.4579 - acc: 5.4945e-04\n",
      "Epoch 01141: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 251.7171 - mean_squared_error: 251.7170 - acc: 5.3225e-04 - val_loss: 694.5849 - val_mean_squared_error: 694.5850 - val_acc: 1.4192e-04\n",
      "Epoch 1142/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 257.1852 - mean_squared_error: 257.1852 - acc: 5.7866e-04\n",
      "Epoch 01142: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.5950 - mean_squared_error: 256.5951 - acc: 5.6773e-04 - val_loss: 718.2757 - val_mean_squared_error: 718.2759 - val_acc: 0.0000e+00\n",
      "Epoch 1143/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 294.4834 - mean_squared_error: 294.4834 - acc: 5.4054e-04\n",
      "Epoch 01143: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 293.6960 - mean_squared_error: 293.6960 - acc: 5.3225e-04 - val_loss: 702.6196 - val_mean_squared_error: 702.6197 - val_acc: 0.0000e+00\n",
      "Epoch 1144/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 323.6953 - mean_squared_error: 323.6955 - acc: 5.9567e-04\n",
      "Epoch 01144: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 323.2857 - mean_squared_error: 323.2858 - acc: 5.8547e-04 - val_loss: 733.4628 - val_mean_squared_error: 733.4628 - val_acc: 0.0000e+00\n",
      "Epoch 1145/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 407.9074 - mean_squared_error: 407.9074 - acc: 4.6679e-04\n",
      "Epoch 01145: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 406.0826 - mean_squared_error: 406.0826 - acc: 4.7902e-04 - val_loss: 694.7553 - val_mean_squared_error: 694.7554 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1146/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 286.6598 - mean_squared_error: 286.6595 - acc: 5.5856e-04\n",
      "Epoch 01146: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 286.7568 - mean_squared_error: 286.7566 - acc: 5.6773e-04 - val_loss: 707.5483 - val_mean_squared_error: 707.5484 - val_acc: 0.0000e+00\n",
      "Epoch 1147/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 260.2506 - mean_squared_error: 260.2506 - acc: 6.8519e-04\n",
      "Epoch 01147: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.9077 - mean_squared_error: 258.9077 - acc: 7.0966e-04 - val_loss: 680.9923 - val_mean_squared_error: 680.9923 - val_acc: 0.0000e+00\n",
      "Epoch 1148/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 279.0086 - mean_squared_error: 279.0087 - acc: 5.4152e-04\n",
      "Epoch 01148: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 279.1223 - mean_squared_error: 279.1224 - acc: 5.3225e-04 - val_loss: 702.9247 - val_mean_squared_error: 702.9247 - val_acc: 0.0000e+00\n",
      "Epoch 1149/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 258.2390 - mean_squared_error: 258.2391 - acc: 4.6125e-04\n",
      "Epoch 01149: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.2682 - mean_squared_error: 258.2683 - acc: 4.4354e-04 - val_loss: 709.1123 - val_mean_squared_error: 709.1122 - val_acc: 0.0000e+00\n",
      "Epoch 1150/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 257.7163 - mean_squared_error: 257.7163 - acc: 6.3636e-04\n",
      "Epoch 01150: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 257.4014 - mean_squared_error: 257.4014 - acc: 6.5644e-04 - val_loss: 692.0176 - val_mean_squared_error: 692.0176 - val_acc: 0.0000e+00\n",
      "Epoch 1151/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 259.4754 - mean_squared_error: 259.4754 - acc: 5.5456e-04\n",
      "Epoch 01151: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 259.9805 - mean_squared_error: 259.9806 - acc: 5.4999e-04 - val_loss: 696.2154 - val_mean_squared_error: 696.2153 - val_acc: 0.0000e+00\n",
      "Epoch 1152/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 359.7996 - mean_squared_error: 359.7997 - acc: 6.7496e-04\n",
      "Epoch 01152: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 24us/sample - loss: 359.7455 - mean_squared_error: 359.7456 - acc: 6.7418e-04 - val_loss: 675.2786 - val_mean_squared_error: 675.2787 - val_acc: 0.0000e+00\n",
      "Epoch 1153/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 278.4711 - mean_squared_error: 278.4709 - acc: 6.0998e-04\n",
      "Epoch 01153: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 277.1251 - mean_squared_error: 277.1250 - acc: 6.0321e-04 - val_loss: 686.2335 - val_mean_squared_error: 686.2336 - val_acc: 3.5481e-04\n",
      "Epoch 1154/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 409.4722 - mean_squared_error: 409.4723 - acc: 6.8468e-04\n",
      "Epoch 01154: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 407.0032 - mean_squared_error: 407.0033 - acc: 6.7418e-04 - val_loss: 718.0634 - val_mean_squared_error: 718.0635 - val_acc: 0.0000e+00\n",
      "Epoch 1155/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 277.8225 - mean_squared_error: 277.8225 - acc: 5.0542e-04\n",
      "Epoch 01155: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 278.0179 - mean_squared_error: 278.0178 - acc: 4.9676e-04 - val_loss: 719.3597 - val_mean_squared_error: 719.3597 - val_acc: 0.0000e+00\n",
      "Epoch 1156/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 311.3668 - mean_squared_error: 311.3668 - acc: 5.1095e-04\n",
      "Epoch 01156: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 310.9314 - mean_squared_error: 310.9313 - acc: 5.1450e-04 - val_loss: 692.1313 - val_mean_squared_error: 692.1314 - val_acc: 7.0962e-05\n",
      "Epoch 1157/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 277.7899 - mean_squared_error: 277.7901 - acc: 7.1556e-04\n",
      "Epoch 01157: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 277.8901 - mean_squared_error: 277.8903 - acc: 7.0966e-04 - val_loss: 665.9898 - val_mean_squared_error: 665.9899 - val_acc: 6.3866e-04\n",
      "Epoch 1158/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 280.7722 - mean_squared_error: 280.7723 - acc: 6.4286e-04\n",
      "Epoch 01158: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 280.4825 - mean_squared_error: 280.4826 - acc: 6.3869e-04 - val_loss: 729.6518 - val_mean_squared_error: 729.6517 - val_acc: 3.5481e-04\n",
      "Epoch 1159/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 255.4560 - mean_squared_error: 255.4561 - acc: 6.5574e-04\n",
      "Epoch 01159: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 255.5601 - mean_squared_error: 255.5601 - acc: 6.5644e-04 - val_loss: 691.5806 - val_mean_squared_error: 691.5804 - val_acc: 0.0000e+00\n",
      "Epoch 1160/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 246.5172 - mean_squared_error: 246.5172 - acc: 5.9246e-04\n",
      "Epoch 01160: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.6851 - mean_squared_error: 246.6851 - acc: 5.8547e-04 - val_loss: 672.9227 - val_mean_squared_error: 672.9227 - val_acc: 0.0000e+00\n",
      "Epoch 1161/3000\n",
      "53900/56365 [===========================>..] - ETA: 0s - loss: 254.4568 - mean_squared_error: 254.4568 - acc: 6.1224e-04\n",
      "Epoch 01161: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 253.5358 - mean_squared_error: 253.5357 - acc: 6.3869e-04 - val_loss: 698.3448 - val_mean_squared_error: 698.3450 - val_acc: 0.0000e+00\n",
      "Epoch 1162/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 252.1179 - mean_squared_error: 252.1180 - acc: 6.5719e-04\n",
      "Epoch 01162: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 252.1403 - mean_squared_error: 252.1404 - acc: 6.5644e-04 - val_loss: 726.7790 - val_mean_squared_error: 726.7787 - val_acc: 1.4192e-04\n",
      "Epoch 1163/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 284.8370 - mean_squared_error: 284.8370 - acc: 6.0823e-04\n",
      "Epoch 01163: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 284.5384 - mean_squared_error: 284.5385 - acc: 6.0321e-04 - val_loss: 644.6597 - val_mean_squared_error: 644.6597 - val_acc: 0.0000e+00\n",
      "Epoch 1164/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 268.1618 - mean_squared_error: 268.1618 - acc: 7.2464e-04\n",
      "Epoch 01164: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 267.6241 - mean_squared_error: 267.6242 - acc: 7.2740e-04 - val_loss: 664.8518 - val_mean_squared_error: 664.8518 - val_acc: 0.0000e+00\n",
      "Epoch 1165/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 270.0989 - mean_squared_error: 270.0990 - acc: 6.0219e-04\n",
      "Epoch 01165: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 269.7252 - mean_squared_error: 269.7253 - acc: 6.0321e-04 - val_loss: 669.6672 - val_mean_squared_error: 669.6671 - val_acc: 0.0000e+00\n",
      "Epoch 1166/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 246.4104 - mean_squared_error: 246.4105 - acc: 6.8015e-04\n",
      "Epoch 01166: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.4650 - mean_squared_error: 246.4650 - acc: 6.5644e-04 - val_loss: 701.6598 - val_mean_squared_error: 701.6597 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1167/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 254.3149 - mean_squared_error: 254.3149 - acc: 6.9091e-04\n",
      "Epoch 01167: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.8816 - mean_squared_error: 253.8816 - acc: 6.7418e-04 - val_loss: 757.8332 - val_mean_squared_error: 757.8332 - val_acc: 0.0000e+00\n",
      "Epoch 1168/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 316.8357 - mean_squared_error: 316.8357 - acc: 3.7634e-04\n",
      "Epoch 01168: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 316.1916 - mean_squared_error: 316.1917 - acc: 4.0805e-04 - val_loss: 699.0146 - val_mean_squared_error: 699.0148 - val_acc: 1.4192e-04\n",
      "Epoch 1169/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 302.3175 - mean_squared_error: 302.3176 - acc: 6.1483e-04\n",
      "Epoch 01169: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 301.5929 - mean_squared_error: 301.5930 - acc: 6.2095e-04 - val_loss: 852.6037 - val_mean_squared_error: 852.6036 - val_acc: 0.0000e+00\n",
      "Epoch 1170/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 263.2748 - mean_squared_error: 263.2748 - acc: 5.8501e-04\n",
      "Epoch 01170: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 263.2904 - mean_squared_error: 263.2904 - acc: 6.3869e-04 - val_loss: 694.1902 - val_mean_squared_error: 694.1903 - val_acc: 0.0000e+00\n",
      "Epoch 1171/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 255.1771 - mean_squared_error: 255.1772 - acc: 6.6308e-04\n",
      "Epoch 01171: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 255.3172 - mean_squared_error: 255.3172 - acc: 6.5644e-04 - val_loss: 696.5225 - val_mean_squared_error: 696.5226 - val_acc: 0.0000e+00\n",
      "Epoch 1172/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 264.1429 - mean_squared_error: 264.1431 - acc: 5.7348e-04\n",
      "Epoch 01172: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 263.9738 - mean_squared_error: 263.9740 - acc: 5.6773e-04 - val_loss: 719.3201 - val_mean_squared_error: 719.3203 - val_acc: 0.0000e+00\n",
      "Epoch 1173/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 251.4122 - mean_squared_error: 251.4122 - acc: 5.1756e-04\n",
      "Epoch 01173: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 250.7515 - mean_squared_error: 250.7515 - acc: 4.9676e-04 - val_loss: 690.8703 - val_mean_squared_error: 690.8704 - val_acc: 0.0000e+00\n",
      "Epoch 1174/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 353.1911 - mean_squared_error: 353.1906 - acc: 4.4118e-04\n",
      "Epoch 01174: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 349.7484 - mean_squared_error: 349.7478 - acc: 4.2580e-04 - val_loss: 675.8781 - val_mean_squared_error: 675.8781 - val_acc: 0.0000e+00\n",
      "Epoch 1175/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 272.0265 - mean_squared_error: 272.0265 - acc: 6.1818e-04\n",
      "Epoch 01175: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 271.6983 - mean_squared_error: 271.6983 - acc: 6.2095e-04 - val_loss: 690.4597 - val_mean_squared_error: 690.4600 - val_acc: 0.0000e+00\n",
      "Epoch 1176/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 269.6683 - mean_squared_error: 269.6683 - acc: 6.6071e-04\n",
      "Epoch 01176: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 269.2817 - mean_squared_error: 269.2817 - acc: 6.5644e-04 - val_loss: 680.8569 - val_mean_squared_error: 680.8569 - val_acc: 1.4192e-04\n",
      "Epoch 1177/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 284.1078 - mean_squared_error: 284.1078 - acc: 5.2347e-04\n",
      "Epoch 01177: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 283.6000 - mean_squared_error: 283.5999 - acc: 5.1450e-04 - val_loss: 677.7284 - val_mean_squared_error: 677.7283 - val_acc: 0.0000e+00\n",
      "Epoch 1178/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 251.5921 - mean_squared_error: 251.5921 - acc: 6.5099e-04\n",
      "Epoch 01178: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 251.6909 - mean_squared_error: 251.6909 - acc: 6.5644e-04 - val_loss: 660.8418 - val_mean_squared_error: 660.8417 - val_acc: 0.0000e+00\n",
      "Epoch 1179/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 251.1076 - mean_squared_error: 251.1077 - acc: 6.2389e-04\n",
      "Epoch 01179: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 251.0703 - mean_squared_error: 251.0704 - acc: 6.2095e-04 - val_loss: 683.7505 - val_mean_squared_error: 683.7505 - val_acc: 0.0000e+00\n",
      "Epoch 1180/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 255.1438 - mean_squared_error: 255.1438 - acc: 6.6190e-04\n",
      "Epoch 01180: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 255.0181 - mean_squared_error: 255.0181 - acc: 6.5644e-04 - val_loss: 718.5541 - val_mean_squared_error: 718.5543 - val_acc: 0.0000e+00\n",
      "Epoch 1181/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 246.7874 - mean_squared_error: 246.7874 - acc: 8.1031e-04\n",
      "Epoch 01181: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 246.9338 - mean_squared_error: 246.9338 - acc: 7.8063e-04 - val_loss: 698.9287 - val_mean_squared_error: 698.9287 - val_acc: 0.0000e+00\n",
      "Epoch 1182/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 293.7439 - mean_squared_error: 293.7437 - acc: 7.0018e-04 ETA: 0s - loss: 244.0704 - mean_squared_error: 244.0704 -\n",
      "Epoch 01182: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 293.0651 - mean_squared_error: 293.0650 - acc: 6.9192e-04 - val_loss: 683.9882 - val_mean_squared_error: 683.9883 - val_acc: 0.0000e+00\n",
      "Epoch 1183/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 404.4831 - mean_squared_error: 404.4831 - acc: 6.1818e-04\n",
      "Epoch 01183: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 400.5508 - mean_squared_error: 400.5508 - acc: 6.0321e-04 - val_loss: 672.6829 - val_mean_squared_error: 672.6829 - val_acc: 0.0000e+00\n",
      "Epoch 1184/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 402.8696 - mean_squared_error: 402.8696 - acc: 6.9643e-04\n",
      "Epoch 01184: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 401.9505 - mean_squared_error: 401.9505 - acc: 6.9192e-04 - val_loss: 696.7041 - val_mean_squared_error: 696.7039 - val_acc: 0.0000e+00\n",
      "Epoch 1185/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 318.2947 - mean_squared_error: 318.2946 - acc: 6.6908e-04\n",
      "Epoch 01185: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 317.9026 - mean_squared_error: 317.9025 - acc: 6.7418e-04 - val_loss: 698.6412 - val_mean_squared_error: 698.6412 - val_acc: 0.0000e+00\n",
      "Epoch 1186/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 273.8575 - mean_squared_error: 273.8576 - acc: 5.4545e-04\n",
      "Epoch 01186: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 273.6820 - mean_squared_error: 273.6822 - acc: 5.3225e-04 - val_loss: 672.0294 - val_mean_squared_error: 672.0294 - val_acc: 0.0000e+00\n",
      "Epoch 1187/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 248.1155 - mean_squared_error: 248.1156 - acc: 5.6777e-04\n",
      "Epoch 01187: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 247.5944 - mean_squared_error: 247.5945 - acc: 5.8547e-04 - val_loss: 677.2029 - val_mean_squared_error: 677.2029 - val_acc: 7.0962e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 255.8285 - mean_squared_error: 255.8285 - acc: 5.9353e-04\n",
      "Epoch 01188: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 255.5365 - mean_squared_error: 255.5366 - acc: 5.8547e-04 - val_loss: 689.1981 - val_mean_squared_error: 689.1982 - val_acc: 0.0000e+00\n",
      "Epoch 1189/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 263.1091 - mean_squared_error: 263.1092 - acc: 6.8015e-04\n",
      "Epoch 01189: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.8216 - mean_squared_error: 263.8216 - acc: 6.5644e-04 - val_loss: 662.6365 - val_mean_squared_error: 662.6366 - val_acc: 0.0000e+00\n",
      "Epoch 1190/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 292.6125 - mean_squared_error: 292.6125 - acc: 7.1168e-04\n",
      "Epoch 01190: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 291.4153 - mean_squared_error: 291.4154 - acc: 6.9192e-04 - val_loss: 710.7469 - val_mean_squared_error: 710.7470 - val_acc: 0.0000e+00\n",
      "Epoch 1191/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 558.8343 - mean_squared_error: 558.8343 - acc: 6.3177e-04\n",
      "Epoch 01191: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 553.6139 - mean_squared_error: 553.6139 - acc: 6.2095e-04 - val_loss: 688.1190 - val_mean_squared_error: 688.1192 - val_acc: 0.0000e+00\n",
      "Epoch 1192/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 250.6941 - mean_squared_error: 250.6942 - acc: 4.9091e-04\n",
      "Epoch 01192: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 249.8927 - mean_squared_error: 249.8928 - acc: 5.1450e-04 - val_loss: 703.6801 - val_mean_squared_error: 703.6801 - val_acc: 2.1289e-04\n",
      "Epoch 1193/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 264.2244 - mean_squared_error: 264.2243 - acc: 6.7736e-04\n",
      "Epoch 01193: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 264.1755 - mean_squared_error: 264.1755 - acc: 6.9192e-04 - val_loss: 670.6218 - val_mean_squared_error: 670.6219 - val_acc: 0.0000e+00\n",
      "Epoch 1194/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 286.5118 - mean_squared_error: 286.5118 - acc: 6.4865e-04\n",
      "Epoch 01194: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 285.9214 - mean_squared_error: 285.9214 - acc: 6.5644e-04 - val_loss: 674.5784 - val_mean_squared_error: 674.5784 - val_acc: 0.0000e+00\n",
      "Epoch 1195/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 274.4139 - mean_squared_error: 274.4140 - acc: 7.0780e-04\n",
      "Epoch 01195: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 273.7591 - mean_squared_error: 273.7591 - acc: 6.9192e-04 - val_loss: 665.3725 - val_mean_squared_error: 665.3727 - val_acc: 0.0000e+00\n",
      "Epoch 1196/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 254.0350 - mean_squared_error: 254.0349 - acc: 5.6881e-04\n",
      "Epoch 01196: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.9236 - mean_squared_error: 253.9235 - acc: 5.4999e-04 - val_loss: 700.3113 - val_mean_squared_error: 700.3113 - val_acc: 0.0000e+00\n",
      "Epoch 1197/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 311.9050 - mean_squared_error: 311.9051 - acc: 6.9892e-04\n",
      "Epoch 01197: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 310.8578 - mean_squared_error: 310.8579 - acc: 6.9192e-04 - val_loss: 672.4456 - val_mean_squared_error: 672.4456 - val_acc: 0.0000e+00\n",
      "Epoch 1198/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 429.1450 - mean_squared_error: 429.1451 - acc: 5.8929e-04\n",
      "Epoch 01198: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 427.9766 - mean_squared_error: 427.9767 - acc: 5.8547e-04 - val_loss: 737.8208 - val_mean_squared_error: 737.8207 - val_acc: 2.8385e-04\n",
      "Epoch 1199/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 390.7854 - mean_squared_error: 390.7856 - acc: 6.0932e-04\n",
      "Epoch 01199: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 389.2463 - mean_squared_error: 389.2465 - acc: 6.0321e-04 - val_loss: 686.0094 - val_mean_squared_error: 686.0095 - val_acc: 0.0000e+00\n",
      "Epoch 1200/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 251.3075 - mean_squared_error: 251.3075 - acc: 6.0498e-04\n",
      "Epoch 01200: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 251.1362 - mean_squared_error: 251.1361 - acc: 6.0321e-04 - val_loss: 687.1534 - val_mean_squared_error: 687.1533 - val_acc: 7.0962e-05\n",
      "Epoch 1201/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 273.2950 - mean_squared_error: 273.2950 - acc: 6.8841e-04\n",
      "Epoch 01201: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 272.3607 - mean_squared_error: 272.3607 - acc: 6.9192e-04 - val_loss: 672.1953 - val_mean_squared_error: 672.1952 - val_acc: 0.0000e+00\n",
      "Epoch 1202/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 264.4022 - mean_squared_error: 264.4021 - acc: 5.1095e-04\n",
      "Epoch 01202: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.4048 - mean_squared_error: 263.4048 - acc: 4.9676e-04 - val_loss: 669.3436 - val_mean_squared_error: 669.3434 - val_acc: 0.0000e+00\n",
      "Epoch 1203/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 246.9908 - mean_squared_error: 246.9908 - acc: 5.5351e-04\n",
      "Epoch 01203: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 246.9239 - mean_squared_error: 246.9240 - acc: 5.3225e-04 - val_loss: 685.3733 - val_mean_squared_error: 685.3734 - val_acc: 7.0962e-05\n",
      "Epoch 1204/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 247.8966 - mean_squared_error: 247.8966 - acc: 6.5814e-04\n",
      "Epoch 01204: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 247.3807 - mean_squared_error: 247.3806 - acc: 6.3869e-04 - val_loss: 674.9711 - val_mean_squared_error: 674.9711 - val_acc: 0.0000e+00\n",
      "Epoch 1205/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 244.9106 - mean_squared_error: 244.9104 - acc: 5.7143e-04\n",
      "Epoch 01205: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 244.6905 - mean_squared_error: 244.6904 - acc: 5.6773e-04 - val_loss: 726.4115 - val_mean_squared_error: 726.4113 - val_acc: 0.0000e+00\n",
      "Epoch 1206/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 325.1058 - mean_squared_error: 325.1059 - acc: 5.7451e-04\n",
      "Epoch 01206: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 324.2554 - mean_squared_error: 324.2553 - acc: 5.8547e-04 - val_loss: 668.8562 - val_mean_squared_error: 668.8562 - val_acc: 0.0000e+00\n",
      "Epoch 1207/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 248.6893 - mean_squared_error: 248.6893 - acc: 6.5574e-04\n",
      "Epoch 01207: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 248.8102 - mean_squared_error: 248.8102 - acc: 6.5644e-04 - val_loss: 708.9623 - val_mean_squared_error: 708.9620 - val_acc: 6.3866e-04\n",
      "Epoch 1208/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 246.7554 - mean_squared_error: 246.7553 - acc: 5.9459e-04\n",
      "Epoch 01208: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 260.8631 - mean_squared_error: 260.8631 - acc: 6.0321e-04 - val_loss: 770.4482 - val_mean_squared_error: 770.4482 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 271.5815 - mean_squared_error: 271.5815 - acc: 7.4545e-04\n",
      "Epoch 01209: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 270.9819 - mean_squared_error: 270.9819 - acc: 7.4514e-04 - val_loss: 660.1486 - val_mean_squared_error: 660.1486 - val_acc: 0.0000e+00\n",
      "Epoch 1210/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 336.1896 - mean_squared_error: 336.1895 - acc: 6.4286e-04\n",
      "Epoch 01210: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 336.0970 - mean_squared_error: 336.0969 - acc: 6.3869e-04 - val_loss: 692.5069 - val_mean_squared_error: 692.5070 - val_acc: 0.0000e+00\n",
      "Epoch 1211/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 337.7077 - mean_squared_error: 337.7077 - acc: 5.3381e-04\n",
      "Epoch 01211: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 337.7777 - mean_squared_error: 337.7777 - acc: 5.3225e-04 - val_loss: 737.9675 - val_mean_squared_error: 737.9676 - val_acc: 2.1289e-04\n",
      "Epoch 1212/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 249.1869 - mean_squared_error: 249.1870 - acc: 6.4457e-04\n",
      "Epoch 01212: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 250.0357 - mean_squared_error: 250.0358 - acc: 6.2095e-04 - val_loss: 707.4421 - val_mean_squared_error: 707.4419 - val_acc: 0.0000e+00\n",
      "Epoch 1213/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 245.3457 - mean_squared_error: 245.3458 - acc: 7.1174e-04\n",
      "Epoch 01213: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 245.1675 - mean_squared_error: 245.1676 - acc: 7.0966e-04 - val_loss: 705.7253 - val_mean_squared_error: 705.7253 - val_acc: 0.0000e+00\n",
      "Epoch 1214/3000\n",
      "54000/56365 [===========================>..] - ETA: 0s - loss: 246.3485 - mean_squared_error: 246.3486 - acc: 6.1111e-04\n",
      "Epoch 01214: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 246.8005 - mean_squared_error: 246.8006 - acc: 6.2095e-04 - val_loss: 675.6672 - val_mean_squared_error: 675.6671 - val_acc: 0.0000e+00\n",
      "Epoch 1215/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 240.9934 - mean_squared_error: 240.9934 - acc: 6.0109e-04\n",
      "Epoch 01215: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 240.8642 - mean_squared_error: 240.8642 - acc: 6.0321e-04 - val_loss: 682.6006 - val_mean_squared_error: 682.6006 - val_acc: 0.0000e+00\n",
      "Epoch 1216/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 246.4290 - mean_squared_error: 246.4289 - acc: 5.7348e-04\n",
      "Epoch 01216: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 246.4862 - mean_squared_error: 246.4861 - acc: 5.8547e-04 - val_loss: 684.3742 - val_mean_squared_error: 684.3743 - val_acc: 0.0000e+00\n",
      "Epoch 1217/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 348.0481 - mean_squared_error: 348.0479 - acc: 6.7151e-04\n",
      "Epoch 01217: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 346.2995 - mean_squared_error: 346.2992 - acc: 6.7418e-04 - val_loss: 699.1371 - val_mean_squared_error: 699.1371 - val_acc: 0.0000e+00\n",
      "Epoch 1218/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 247.8827 - mean_squared_error: 247.8828 - acc: 5.5062e-04\n",
      "Epoch 01218: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 247.8162 - mean_squared_error: 247.8163 - acc: 5.4999e-04 - val_loss: 701.9524 - val_mean_squared_error: 701.9526 - val_acc: 0.0000e+00\n",
      "Epoch 1219/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 274.9560 - mean_squared_error: 274.9561 - acc: 6.0329e-04\n",
      "Epoch 01219: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.3331 - mean_squared_error: 274.3333 - acc: 6.0321e-04 - val_loss: 677.6445 - val_mean_squared_error: 677.6445 - val_acc: 0.0000e+00\n",
      "Epoch 1220/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 285.5612 - mean_squared_error: 285.5613 - acc: 5.5160e-04\n",
      "Epoch 01220: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 285.4979 - mean_squared_error: 285.4979 - acc: 5.4999e-04 - val_loss: 670.1269 - val_mean_squared_error: 670.1266 - val_acc: 0.0000e+00\n",
      "Epoch 1221/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 335.8914 - mean_squared_error: 335.8914 - acc: 7.4275e-04\n",
      "Epoch 01221: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 333.6808 - mean_squared_error: 333.6808 - acc: 7.4514e-04 - val_loss: 682.5955 - val_mean_squared_error: 682.5956 - val_acc: 0.0000e+00\n",
      "Epoch 1222/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 277.0382 - mean_squared_error: 277.0380 - acc: 4.6931e-04\n",
      "Epoch 01222: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 276.2052 - mean_squared_error: 276.2050 - acc: 4.6128e-04 - val_loss: 695.2667 - val_mean_squared_error: 695.2669 - val_acc: 0.0000e+00\n",
      "Epoch 1223/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 421.4006 - mean_squared_error: 421.4005 - acc: 5.4348e-04\n",
      "Epoch 01223: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 418.3612 - mean_squared_error: 418.3611 - acc: 6.0321e-04 - val_loss: 705.5214 - val_mean_squared_error: 705.5214 - val_acc: 7.0962e-05\n",
      "Epoch 1224/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 248.4132 - mean_squared_error: 248.4133 - acc: 6.5217e-04\n",
      "Epoch 01224: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 248.1742 - mean_squared_error: 248.1742 - acc: 6.7418e-04 - val_loss: 692.8042 - val_mean_squared_error: 692.8044 - val_acc: 0.0000e+00\n",
      "Epoch 1225/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 246.9349 - mean_squared_error: 246.9348 - acc: 6.0550e-04\n",
      "Epoch 01225: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 247.1479 - mean_squared_error: 247.1479 - acc: 6.0321e-04 - val_loss: 678.2038 - val_mean_squared_error: 678.2038 - val_acc: 7.0962e-05\n",
      "Epoch 1226/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 243.4779 - mean_squared_error: 243.4778 - acc: 6.4103e-04\n",
      "Epoch 01226: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 243.1390 - mean_squared_error: 243.1389 - acc: 6.7418e-04 - val_loss: 696.4234 - val_mean_squared_error: 696.4235 - val_acc: 0.0000e+00\n",
      "Epoch 1227/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 248.2364 - mean_squared_error: 248.2363 - acc: 6.2500e-04\n",
      "Epoch 01227: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 248.2178 - mean_squared_error: 248.2178 - acc: 6.2095e-04 - val_loss: 675.3766 - val_mean_squared_error: 675.3766 - val_acc: 0.0000e+00\n",
      "Epoch 1228/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 343.3681 - mean_squared_error: 343.3682 - acc: 6.1818e-04\n",
      "Epoch 01228: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 340.9052 - mean_squared_error: 340.9052 - acc: 6.2095e-04 - val_loss: 726.1323 - val_mean_squared_error: 726.1321 - val_acc: 0.0000e+00\n",
      "Epoch 1229/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 292.3840 - mean_squared_error: 292.3841 - acc: 5.6466e-04\n",
      "Epoch 01229: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 291.5945 - mean_squared_error: 291.5947 - acc: 5.8547e-04 - val_loss: 707.6568 - val_mean_squared_error: 707.6567 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1230/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 251.2806 - mean_squared_error: 251.2806 - acc: 7.4818e-04\n",
      "Epoch 01230: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 250.7398 - mean_squared_error: 250.7399 - acc: 7.2740e-04 - val_loss: 703.7754 - val_mean_squared_error: 703.7757 - val_acc: 0.0000e+00\n",
      "Epoch 1231/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 320.4941 - mean_squared_error: 320.4942 - acc: 5.2632e-04\n",
      "Epoch 01231: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 318.8974 - mean_squared_error: 318.8976 - acc: 5.3225e-04 - val_loss: 699.0210 - val_mean_squared_error: 699.0211 - val_acc: 1.4192e-04\n",
      "Epoch 1232/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 358.0601 - mean_squared_error: 358.0601 - acc: 7.1429e-04 ETA: 0s - loss: 248.0873 - mean_squar\n",
      "Epoch 01232: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 357.3670 - mean_squared_error: 357.3669 - acc: 7.0966e-04 - val_loss: 711.6818 - val_mean_squared_error: 711.6819 - val_acc: 0.0000e+00\n",
      "Epoch 1233/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 298.1411 - mean_squared_error: 298.1411 - acc: 5.5147e-04\n",
      "Epoch 01233: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 297.3868 - mean_squared_error: 297.3868 - acc: 5.6773e-04 - val_loss: 698.9962 - val_mean_squared_error: 698.9961 - val_acc: 0.0000e+00\n",
      "Epoch 1234/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 251.4983 - mean_squared_error: 251.4983 - acc: 5.5258e-04\n",
      "Epoch 01234: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 252.0806 - mean_squared_error: 252.0805 - acc: 5.4999e-04 - val_loss: 675.6807 - val_mean_squared_error: 675.6807 - val_acc: 0.0000e+00\n",
      "Epoch 1235/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 249.2533 - mean_squared_error: 249.2533 - acc: 5.0542e-04\n",
      "Epoch 01235: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 248.7800 - mean_squared_error: 248.7800 - acc: 4.9676e-04 - val_loss: 687.8477 - val_mean_squared_error: 687.8477 - val_acc: 0.0000e+00\n",
      "Epoch 1236/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 244.8091 - mean_squared_error: 244.8092 - acc: 6.9725e-04\n",
      "Epoch 01236: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 245.6465 - mean_squared_error: 245.6465 - acc: 7.2740e-04 - val_loss: 676.6367 - val_mean_squared_error: 676.6368 - val_acc: 7.0962e-05\n",
      "Epoch 1237/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 293.1919 - mean_squared_error: 293.1921 - acc: 4.9451e-04\n",
      "Epoch 01237: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 290.9277 - mean_squared_error: 290.9279 - acc: 5.1450e-04 - val_loss: 742.3352 - val_mean_squared_error: 742.3350 - val_acc: 0.0000e+00\n",
      "Epoch 1238/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 314.6532 - mean_squared_error: 314.6532 - acc: 5.6364e-04\n",
      "Epoch 01238: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 313.2766 - mean_squared_error: 313.2765 - acc: 5.8547e-04 - val_loss: 694.5035 - val_mean_squared_error: 694.5034 - val_acc: 0.0000e+00\n",
      "Epoch 1239/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 302.2561 - mean_squared_error: 302.2560 - acc: 5.7348e-04\n",
      "Epoch 01239: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 301.6662 - mean_squared_error: 301.6662 - acc: 5.8547e-04 - val_loss: 665.6003 - val_mean_squared_error: 665.6002 - val_acc: 0.0000e+00\n",
      "Epoch 1240/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 248.8567 - mean_squared_error: 248.8568 - acc: 6.3521e-04\n",
      "Epoch 01240: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 248.2839 - mean_squared_error: 248.2839 - acc: 6.2095e-04 - val_loss: 652.9843 - val_mean_squared_error: 652.9843 - val_acc: 0.0000e+00\n",
      "Epoch 1241/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 265.0008 - mean_squared_error: 265.0007 - acc: 6.6547e-04\n",
      "Epoch 01241: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 264.5524 - mean_squared_error: 264.5523 - acc: 6.9192e-04 - val_loss: 676.1875 - val_mean_squared_error: 676.1875 - val_acc: 7.0962e-05\n",
      "Epoch 1242/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 247.8775 - mean_squared_error: 247.8774 - acc: 4.7445e-04\n",
      "Epoch 01242: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 248.0633 - mean_squared_error: 248.0632 - acc: 5.1450e-04 - val_loss: 714.2239 - val_mean_squared_error: 714.2239 - val_acc: 0.0000e+00\n",
      "Epoch 1243/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 274.9061 - mean_squared_error: 274.9061 - acc: 5.9140e-04\n",
      "Epoch 01243: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.4296 - mean_squared_error: 274.4296 - acc: 5.8547e-04 - val_loss: 708.1422 - val_mean_squared_error: 708.1422 - val_acc: 2.8385e-04\n",
      "Epoch 1244/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 268.1636 - mean_squared_error: 268.1635 - acc: 5.8824e-04\n",
      "Epoch 01244: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 267.8678 - mean_squared_error: 267.8677 - acc: 5.8547e-04 - val_loss: 703.8285 - val_mean_squared_error: 703.8282 - val_acc: 0.0000e+00\n",
      "Epoch 1245/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 255.1941 - mean_squared_error: 255.1942 - acc: 5.9891e-04\n",
      "Epoch 01245: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 254.3672 - mean_squared_error: 254.3673 - acc: 6.0321e-04 - val_loss: 721.5247 - val_mean_squared_error: 721.5245 - val_acc: 0.0000e+00\n",
      "Epoch 1246/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 242.8115 - mean_squared_error: 242.8114 - acc: 5.8932e-04\n",
      "Epoch 01246: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 243.2690 - mean_squared_error: 243.2688 - acc: 5.8547e-04 - val_loss: 680.5176 - val_mean_squared_error: 680.5176 - val_acc: 0.0000e+00\n",
      "Epoch 1247/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 243.0475 - mean_squared_error: 243.0475 - acc: 6.3636e-04\n",
      "Epoch 01247: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.7941 - mean_squared_error: 242.7942 - acc: 6.2095e-04 - val_loss: 710.0207 - val_mean_squared_error: 710.0206 - val_acc: 0.0000e+00\n",
      "Epoch 1248/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 243.4636 - mean_squared_error: 243.4636 - acc: 5.0633e-04\n",
      "Epoch 01248: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 243.7898 - mean_squared_error: 243.7898 - acc: 5.1450e-04 - val_loss: 699.9676 - val_mean_squared_error: 699.9676 - val_acc: 0.0000e+00\n",
      "Epoch 1249/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 258.2415 - mean_squared_error: 258.2415 - acc: 6.2389e-04\n",
      "Epoch 01249: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.0757 - mean_squared_error: 258.0757 - acc: 6.2095e-04 - val_loss: 721.2874 - val_mean_squared_error: 721.2874 - val_acc: 0.0000e+00\n",
      "Epoch 1250/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 324.0434 - mean_squared_error: 324.0435 - acc: 7.2993e-04\n",
      "Epoch 01250: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 322.7501 - mean_squared_error: 322.7502 - acc: 7.0966e-04 - val_loss: 673.3831 - val_mean_squared_error: 673.3834 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 320.5857 - mean_squared_error: 320.5857 - acc: 5.7348e-04\n",
      "Epoch 01251: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 319.6401 - mean_squared_error: 319.6400 - acc: 5.6773e-04 - val_loss: 665.4729 - val_mean_squared_error: 665.4730 - val_acc: 0.0000e+00\n",
      "Epoch 1252/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 265.4203 - mean_squared_error: 265.4204 - acc: 4.7957e-04\n",
      "Epoch 01252: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.3191 - mean_squared_error: 265.3192 - acc: 4.7902e-04 - val_loss: 656.1768 - val_mean_squared_error: 656.1766 - val_acc: 0.0000e+00\n",
      "Epoch 1253/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 281.0417 - mean_squared_error: 281.0417 - acc: 7.4818e-04 ETA: 0s - loss: 247.2571 - mean_squared_error: 247.2571 - a\n",
      "Epoch 01253: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 279.7295 - mean_squared_error: 279.7295 - acc: 7.2740e-04 - val_loss: 718.1984 - val_mean_squared_error: 718.1982 - val_acc: 0.0000e+00\n",
      "Epoch 1254/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 244.7467 - mean_squared_error: 244.7465 - acc: 6.1706e-04\n",
      "Epoch 01254: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 244.3498 - mean_squared_error: 244.3497 - acc: 6.0321e-04 - val_loss: 697.4241 - val_mean_squared_error: 697.4241 - val_acc: 0.0000e+00\n",
      "Epoch 1255/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 260.6149 - mean_squared_error: 260.6150 - acc: 5.2065e-04\n",
      "Epoch 01255: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 260.4548 - mean_squared_error: 260.4548 - acc: 5.1450e-04 - val_loss: 734.5508 - val_mean_squared_error: 734.5509 - val_acc: 1.4192e-04\n",
      "Epoch 1256/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 286.1926 - mean_squared_error: 286.1928 - acc: 7.1813e-04\n",
      "Epoch 01256: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 286.2664 - mean_squared_error: 286.2666 - acc: 7.0966e-04 - val_loss: 712.6909 - val_mean_squared_error: 712.6910 - val_acc: 3.5481e-04\n",
      "Epoch 1257/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 248.8050 - mean_squared_error: 248.8049 - acc: 6.4103e-04\n",
      "Epoch 01257: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 248.7567 - mean_squared_error: 248.7566 - acc: 6.5644e-04 - val_loss: 681.2092 - val_mean_squared_error: 681.2090 - val_acc: 0.0000e+00\n",
      "Epoch 1258/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 279.9228 - mean_squared_error: 279.9227 - acc: 5.8716e-04 ETA: 0s - loss: 248.9366 - mean_squared\n",
      "Epoch 01258: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 279.3040 - mean_squared_error: 279.3039 - acc: 5.8547e-04 - val_loss: 702.0104 - val_mean_squared_error: 702.0104 - val_acc: 4.9674e-04\n",
      "Epoch 1259/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 319.0170 - mean_squared_error: 319.0170 - acc: 6.7766e-04\n",
      "Epoch 01259: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 317.1552 - mean_squared_error: 317.1552 - acc: 6.5644e-04 - val_loss: 731.8050 - val_mean_squared_error: 731.8049 - val_acc: 0.0000e+00\n",
      "Epoch 1260/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 250.4442 - mean_squared_error: 250.4442 - acc: 5.4446e-04\n",
      "Epoch 01260: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 250.2488 - mean_squared_error: 250.2488 - acc: 5.4999e-04 - val_loss: 678.0184 - val_mean_squared_error: 678.0182 - val_acc: 0.0000e+00\n",
      "Epoch 1261/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 323.0265 - mean_squared_error: 323.0266 - acc: 7.0111e-04\n",
      "Epoch 01261: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 320.0281 - mean_squared_error: 320.0282 - acc: 6.9192e-04 - val_loss: 705.8229 - val_mean_squared_error: 705.8229 - val_acc: 0.0000e+00\n",
      "Epoch 1262/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 361.0603 - mean_squared_error: 361.0602 - acc: 6.2950e-04\n",
      "Epoch 01262: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 359.6990 - mean_squared_error: 359.6990 - acc: 6.3869e-04 - val_loss: 670.8039 - val_mean_squared_error: 670.8040 - val_acc: 0.0000e+00\n",
      "Epoch 1263/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 260.8487 - mean_squared_error: 260.8486 - acc: 6.1041e-04\n",
      "Epoch 01263: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 261.5908 - mean_squared_error: 261.5908 - acc: 6.0321e-04 - val_loss: 664.1194 - val_mean_squared_error: 664.1194 - val_acc: 0.0000e+00\n",
      "Epoch 1264/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 268.0841 - mean_squared_error: 268.0841 - acc: 6.9853e-04 ETA: 1s - loss: 246.3446 - mean_squ - ETA: 0s - loss: 269.7468 - mean_squared_error: 269.7468 - acc: 7.1713\n",
      "Epoch 01264: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 267.3702 - mean_squared_error: 267.3701 - acc: 6.9192e-04 - val_loss: 697.8003 - val_mean_squared_error: 697.8003 - val_acc: 0.0000e+00\n",
      "Epoch 1265/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 242.6120 - mean_squared_error: 242.6120 - acc: 5.1002e-04\n",
      "Epoch 01265: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 243.4280 - mean_squared_error: 243.4279 - acc: 5.1450e-04 - val_loss: 665.6948 - val_mean_squared_error: 665.6949 - val_acc: 0.0000e+00\n",
      "Epoch 1266/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 264.8023 - mean_squared_error: 264.8023 - acc: 5.4745e-04\n",
      "Epoch 01266: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.0368 - mean_squared_error: 265.0368 - acc: 5.4999e-04 - val_loss: 693.6790 - val_mean_squared_error: 693.6790 - val_acc: 0.0000e+00\n",
      "Epoch 1267/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 255.3207 - mean_squared_error: 255.3207 - acc: 7.1168e-04\n",
      "Epoch 01267: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 254.7677 - mean_squared_error: 254.7677 - acc: 6.9192e-04 - val_loss: 659.7984 - val_mean_squared_error: 659.7983 - val_acc: 0.0000e+00\n",
      "Epoch 1268/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 251.1785 - mean_squared_error: 251.1783 - acc: 6.0391e-04\n",
      "Epoch 01268: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 251.1728 - mean_squared_error: 251.1726 - acc: 6.0321e-04 - val_loss: 683.9651 - val_mean_squared_error: 683.9652 - val_acc: 0.0000e+00\n",
      "Epoch 1269/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 247.0050 - mean_squared_error: 247.0052 - acc: 5.2441e-04\n",
      "Epoch 01269: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 246.7312 - mean_squared_error: 246.7314 - acc: 5.1450e-04 - val_loss: 677.6754 - val_mean_squared_error: 677.6754 - val_acc: 0.0000e+00\n",
      "Epoch 1270/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 253.3935 - mean_squared_error: 253.3936 - acc: 5.1510e-04\n",
      "Epoch 01270: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.3582 - mean_squared_error: 253.3583 - acc: 5.1450e-04 - val_loss: 679.6451 - val_mean_squared_error: 679.6452 - val_acc: 0.0000e+00\n",
      "Epoch 1271/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 276.4578 - mean_squared_error: 276.4578 - acc: 6.0329e-04\n",
      "Epoch 01271: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 276.5205 - mean_squared_error: 276.5205 - acc: 5.8547e-04 - val_loss: 690.6875 - val_mean_squared_error: 690.6874 - val_acc: 0.0000e+00\n",
      "Epoch 1272/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 255.9665 - mean_squared_error: 255.9665 - acc: 5.7348e-04\n",
      "Epoch 01272: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 255.8691 - mean_squared_error: 255.8691 - acc: 5.8547e-04 - val_loss: 693.3013 - val_mean_squared_error: 693.3012 - val_acc: 0.0000e+00\n",
      "Epoch 1273/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 260.8848 - mean_squared_error: 260.8849 - acc: 7.4275e-04\n",
      "Epoch 01273: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 260.9195 - mean_squared_error: 260.9196 - acc: 7.4514e-04 - val_loss: 680.3385 - val_mean_squared_error: 680.3386 - val_acc: 0.0000e+00\n",
      "Epoch 1274/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 600.8295 - mean_squared_error: 600.8295 - acc: 7.1813e-04\n",
      "Epoch 01274: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 597.5657 - mean_squared_error: 597.5657 - acc: 7.2740e-04 - val_loss: 647.9794 - val_mean_squared_error: 647.9796 - val_acc: 0.0000e+00\n",
      "Epoch 1275/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 270.3201 - mean_squared_error: 270.3202 - acc: 4.9002e-04\n",
      "Epoch 01275: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 269.9747 - mean_squared_error: 269.9748 - acc: 5.1450e-04 - val_loss: 719.3238 - val_mean_squared_error: 719.3237 - val_acc: 0.0000e+00\n",
      "Epoch 1276/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 261.5807 - mean_squared_error: 261.5808 - acc: 5.1188e-04 ETA: 0s - loss: 245.5941 - mean_squared_error: \n",
      "Epoch 01276: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 260.9098 - mean_squared_error: 260.9098 - acc: 4.9676e-04 - val_loss: 700.6435 - val_mean_squared_error: 700.6434 - val_acc: 0.0000e+00\n",
      "Epoch 1277/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 291.1830 - mean_squared_error: 291.1832 - acc: 6.2950e-04\n",
      "Epoch 01277: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 290.6351 - mean_squared_error: 290.6352 - acc: 6.3869e-04 - val_loss: 697.0479 - val_mean_squared_error: 697.0477 - val_acc: 0.0000e+00\n",
      "Epoch 1278/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 291.1814 - mean_squared_error: 291.1815 - acc: 5.3016e-04\n",
      "Epoch 01278: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 290.6767 - mean_squared_error: 290.6768 - acc: 5.3225e-04 - val_loss: 674.4921 - val_mean_squared_error: 674.4920 - val_acc: 0.0000e+00\n",
      "Epoch 1279/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 339.8805 - mean_squared_error: 339.8806 - acc: 6.4457e-04\n",
      "Epoch 01279: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 335.9985 - mean_squared_error: 335.9987 - acc: 6.7418e-04 - val_loss: 693.6232 - val_mean_squared_error: 693.6232 - val_acc: 0.0000e+00\n",
      "Epoch 1280/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 244.3633 - mean_squared_error: 244.3634 - acc: 5.5957e-04\n",
      "Epoch 01280: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 244.2114 - mean_squared_error: 244.2116 - acc: 5.4999e-04 - val_loss: 678.9267 - val_mean_squared_error: 678.9269 - val_acc: 0.0000e+00\n",
      "Epoch 1281/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 277.5824 - mean_squared_error: 277.5825 - acc: 5.4845e-04 ETA: 0s - loss: 280.7921 - mean_squared_error: 280.7921 - acc: 5.9406\n",
      "Epoch 01281: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 276.7253 - mean_squared_error: 276.7253 - acc: 5.4999e-04 - val_loss: 676.3831 - val_mean_squared_error: 676.3831 - val_acc: 0.0000e+00\n",
      "Epoch 1282/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 371.9883 - mean_squared_error: 371.9883 - acc: 6.5693e-04\n",
      "Epoch 01282: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 368.4983 - mean_squared_error: 368.4983 - acc: 6.3869e-04 - val_loss: 695.0168 - val_mean_squared_error: 695.0167 - val_acc: 0.0000e+00\n",
      "Epoch 1283/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 271.6086 - mean_squared_error: 271.6086 - acc: 6.6071e-04\n",
      "Epoch 01283: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 271.4199 - mean_squared_error: 271.4198 - acc: 6.5644e-04 - val_loss: 658.5299 - val_mean_squared_error: 658.5300 - val_acc: 0.0000e+00\n",
      "Epoch 1284/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 246.2075 - mean_squared_error: 246.2077 - acc: 6.4220e-04\n",
      "Epoch 01284: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.2543 - mean_squared_error: 265.2544 - acc: 6.3869e-04 - val_loss: 665.1579 - val_mean_squared_error: 665.1577 - val_acc: 0.0000e+00\n",
      "Epoch 1285/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 274.1559 - mean_squared_error: 274.1559 - acc: 5.5046e-04\n",
      "Epoch 01285: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 273.7648 - mean_squared_error: 273.7648 - acc: 5.3225e-04 - val_loss: 674.8356 - val_mean_squared_error: 674.8356 - val_acc: 6.3866e-04\n",
      "Epoch 1286/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 243.2425 - mean_squared_error: 243.2425 - acc: 6.0932e-04\n",
      "Epoch 01286: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 242.8632 - mean_squared_error: 242.8632 - acc: 6.0321e-04 - val_loss: 682.7628 - val_mean_squared_error: 682.7628 - val_acc: 0.0000e+00\n",
      "Epoch 1287/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 239.2316 - mean_squared_error: 239.2315 - acc: 6.5336e-04\n",
      "Epoch 01287: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 239.6782 - mean_squared_error: 239.6782 - acc: 6.3869e-04 - val_loss: 686.0439 - val_mean_squared_error: 686.0438 - val_acc: 1.4192e-04\n",
      "Epoch 1288/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 246.4268 - mean_squared_error: 246.4269 - acc: 5.6569e-04\n",
      "Epoch 01288: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 246.8569 - mean_squared_error: 246.8570 - acc: 5.8547e-04 - val_loss: 658.5597 - val_mean_squared_error: 658.5598 - val_acc: 7.0962e-05\n",
      "Epoch 1289/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 283.3103 - mean_squared_error: 283.3102 - acc: 7.3260e-04\n",
      "Epoch 01289: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 281.9457 - mean_squared_error: 281.9456 - acc: 7.4514e-04 - val_loss: 710.6713 - val_mean_squared_error: 710.6711 - val_acc: 0.0000e+00\n",
      "Epoch 1290/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 329.5811 - mean_squared_error: 329.5809 - acc: 3.6364e-04\n",
      "Epoch 01290: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 328.4700 - mean_squared_error: 328.4698 - acc: 3.7257e-04 - val_loss: 697.7179 - val_mean_squared_error: 697.7179 - val_acc: 7.0962e-05\n",
      "Epoch 1291/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 269.4227 - mean_squared_error: 269.4228 - acc: 5.7196e-04\n",
      "Epoch 01291: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 268.4025 - mean_squared_error: 268.4026 - acc: 5.4999e-04 - val_loss: 746.8198 - val_mean_squared_error: 746.8198 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1292/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 249.0109 - mean_squared_error: 249.0108 - acc: 6.8592e-04\n",
      "Epoch 01292: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 249.0259 - mean_squared_error: 249.0258 - acc: 6.7418e-04 - val_loss: 725.1182 - val_mean_squared_error: 725.1183 - val_acc: 0.0000e+00\n",
      "Epoch 1293/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 437.3677 - mean_squared_error: 437.3679 - acc: 6.2157e-04\n",
      "Epoch 01293: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 432.0134 - mean_squared_error: 432.0136 - acc: 6.0321e-04 - val_loss: 677.1481 - val_mean_squared_error: 677.1482 - val_acc: 1.4192e-04\n",
      "Epoch 1294/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 252.9418 - mean_squared_error: 252.9417 - acc: 5.3763e-04\n",
      "Epoch 01294: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 252.5621 - mean_squared_error: 252.5620 - acc: 5.3225e-04 - val_loss: 699.9220 - val_mean_squared_error: 699.9219 - val_acc: 0.0000e+00\n",
      "Epoch 1295/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 265.3307 - mean_squared_error: 265.3307 - acc: 6.2389e-04\n",
      "Epoch 01295: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 265.5037 - mean_squared_error: 265.5037 - acc: 6.2095e-04 - val_loss: 708.8204 - val_mean_squared_error: 708.8206 - val_acc: 7.0962e-04\n",
      "Epoch 1296/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 302.6422 - mean_squared_error: 302.6423 - acc: 5.5556e-04 ETA: 0s - loss: 384.7264 - mean_squared_error: 384.7264 - acc:  - ETA: 0s - loss: 344.2255 - mean_squared_error: 344.\n",
      "Epoch 01296: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 301.7785 - mean_squared_error: 301.7786 - acc: 5.4999e-04 - val_loss: 674.9938 - val_mean_squared_error: 674.9938 - val_acc: 0.0000e+00\n",
      "Epoch 1297/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 263.3205 - mean_squared_error: 263.3206 - acc: 5.7658e-04\n",
      "Epoch 01297: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 263.5650 - mean_squared_error: 263.5651 - acc: 6.0321e-04 - val_loss: 728.8672 - val_mean_squared_error: 728.8673 - val_acc: 0.0000e+00\n",
      "Epoch 1298/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 256.9668 - mean_squared_error: 256.9668 - acc: 6.0000e-04\n",
      "Epoch 01298: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 256.4875 - mean_squared_error: 256.4875 - acc: 6.0321e-04 - val_loss: 665.1195 - val_mean_squared_error: 665.1195 - val_acc: 0.0000e+00\n",
      "Epoch 1299/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 250.0813 - mean_squared_error: 250.0812 - acc: 5.8716e-04\n",
      "Epoch 01299: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 249.7412 - mean_squared_error: 249.7411 - acc: 6.2095e-04 - val_loss: 677.0361 - val_mean_squared_error: 677.0359 - val_acc: 0.0000e+00\n",
      "Epoch 1300/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 242.5204 - mean_squared_error: 242.5206 - acc: 6.2612e-04\n",
      "Epoch 01300: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 242.4346 - mean_squared_error: 242.4347 - acc: 6.2095e-04 - val_loss: 718.8181 - val_mean_squared_error: 718.8181 - val_acc: 0.0000e+00\n",
      "Epoch 1301/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 256.0158 - mean_squared_error: 256.0157 - acc: 5.3016e-04\n",
      "Epoch 01301: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 255.3788 - mean_squared_error: 255.3786 - acc: 5.3225e-04 - val_loss: 656.9340 - val_mean_squared_error: 656.9338 - val_acc: 0.0000e+00\n",
      "Epoch 1302/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 256.7917 - mean_squared_error: 256.7917 - acc: 6.0440e-04\n",
      "Epoch 01302: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 255.6568 - mean_squared_error: 255.6568 - acc: 6.5644e-04 - val_loss: 669.9704 - val_mean_squared_error: 669.9704 - val_acc: 1.4192e-04\n",
      "Epoch 1303/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 255.2185 - mean_squared_error: 255.2186 - acc: 6.7029e-04\n",
      "Epoch 01303: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 254.6491 - mean_squared_error: 254.6492 - acc: 6.5644e-04 - val_loss: 702.0724 - val_mean_squared_error: 702.0723 - val_acc: 0.0000e+00\n",
      "Epoch 1304/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 313.3893 - mean_squared_error: 313.3894 - acc: 5.1756e-04\n",
      "Epoch 01304: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 311.1856 - mean_squared_error: 311.1858 - acc: 5.3225e-04 - val_loss: 695.7166 - val_mean_squared_error: 695.7166 - val_acc: 0.0000e+00\n",
      "Epoch 1305/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 249.1572 - mean_squared_error: 249.1571 - acc: 6.9091e-04\n",
      "Epoch 01305: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 248.7287 - mean_squared_error: 248.7287 - acc: 6.7418e-04 - val_loss: 673.2267 - val_mean_squared_error: 673.2265 - val_acc: 0.0000e+00\n",
      "Epoch 1306/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 253.7293 - mean_squared_error: 253.7295 - acc: 6.7766e-04\n",
      "Epoch 01306: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 253.6765 - mean_squared_error: 253.6767 - acc: 6.5644e-04 - val_loss: 669.5821 - val_mean_squared_error: 669.5821 - val_acc: 0.0000e+00\n",
      "Epoch 1307/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 313.6266 - mean_squared_error: 313.6265 - acc: 7.1301e-04\n",
      "Epoch 01307: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 313.4618 - mean_squared_error: 313.4618 - acc: 7.0966e-04 - val_loss: 662.7374 - val_mean_squared_error: 662.7372 - val_acc: 0.0000e+00\n",
      "Epoch 1308/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 693.4511 - mean_squared_error: 693.4510 - acc: 5.5556e-04 ETA: 0s - loss: 751.1117 - mean_squared_error: 751.1120 - acc: 5.66\n",
      "Epoch 01308: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 689.3791 - mean_squared_error: 689.3791 - acc: 5.4999e-04 - val_loss: 680.1793 - val_mean_squared_error: 680.1793 - val_acc: 0.0000e+00\n",
      "Epoch 1309/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 242.9793 - mean_squared_error: 242.9792 - acc: 4.2934e-04\n",
      "Epoch 01309: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 242.9457 - mean_squared_error: 242.9456 - acc: 4.2580e-04 - val_loss: 703.3497 - val_mean_squared_error: 703.3496 - val_acc: 0.0000e+00\n",
      "Epoch 1310/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 510.9553 - mean_squared_error: 510.9552 - acc: 6.8966e-04\n",
      "Epoch 01310: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 504.6240 - mean_squared_error: 504.6240 - acc: 6.7418e-04 - val_loss: 697.5858 - val_mean_squared_error: 697.5856 - val_acc: 0.0000e+00\n",
      "Epoch 1311/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 302.0644 - mean_squared_error: 302.0644 - acc: 7.3345e-04\n",
      "Epoch 01311: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 302.2656 - mean_squared_error: 302.2656 - acc: 7.2740e-04 - val_loss: 694.8623 - val_mean_squared_error: 694.8624 - val_acc: 2.8385e-04\n",
      "Epoch 1312/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 347.1996 - mean_squared_error: 347.1996 - acc: 7.3665e-04\n",
      "Epoch 01312: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 344.1290 - mean_squared_error: 344.1290 - acc: 7.0966e-04 - val_loss: 660.8670 - val_mean_squared_error: 660.8670 - val_acc: 0.0000e+00\n",
      "Epoch 1313/3000\n",
      "53900/56365 [===========================>..] - ETA: 0s - loss: 300.4837 - mean_squared_error: 300.4836 - acc: 5.7514e-04\n",
      "Epoch 01313: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 298.6054 - mean_squared_error: 298.6053 - acc: 5.4999e-04 - val_loss: 649.8819 - val_mean_squared_error: 649.8819 - val_acc: 0.0000e+00\n",
      "Epoch 1314/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 248.1833 - mean_squared_error: 248.1834 - acc: 7.2727e-04\n",
      "Epoch 01314: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 248.1222 - mean_squared_error: 248.1223 - acc: 7.4514e-04 - val_loss: 673.4536 - val_mean_squared_error: 673.4537 - val_acc: 0.0000e+00\n",
      "Epoch 1315/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 277.3660 - mean_squared_error: 277.3659 - acc: 6.7151e-04\n",
      "Epoch 01315: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 276.3921 - mean_squared_error: 276.3920 - acc: 6.5644e-04 - val_loss: 639.2810 - val_mean_squared_error: 639.2811 - val_acc: 0.0000e+00\n",
      "Epoch 1316/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 273.1968 - mean_squared_error: 273.1968 - acc: 6.3636e-04\n",
      "Epoch 01316: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 272.3135 - mean_squared_error: 272.3135 - acc: 6.5644e-04 - val_loss: 688.3812 - val_mean_squared_error: 688.3812 - val_acc: 0.0000e+00\n",
      "Epoch 1317/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 282.3063 - mean_squared_error: 282.3063 - acc: 7.5404e-04\n",
      "Epoch 01317: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 281.4762 - mean_squared_error: 281.4763 - acc: 7.6288e-04 - val_loss: 652.5115 - val_mean_squared_error: 652.5117 - val_acc: 0.0000e+00\n",
      "Epoch 1318/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 242.2021 - mean_squared_error: 242.2021 - acc: 6.1706e-04\n",
      "Epoch 01318: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.3672 - mean_squared_error: 242.3672 - acc: 6.2095e-04 - val_loss: 665.4493 - val_mean_squared_error: 665.4494 - val_acc: 0.0000e+00\n",
      "Epoch 1319/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 244.0750 - mean_squared_error: 244.0751 - acc: 5.1756e-04\n",
      "Epoch 01319: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 244.1077 - mean_squared_error: 244.1077 - acc: 5.1450e-04 - val_loss: 678.5521 - val_mean_squared_error: 678.5519 - val_acc: 7.0962e-05\n",
      "Epoch 1320/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 256.0826 - mean_squared_error: 256.0826 - acc: 6.2724e-04\n",
      "Epoch 01320: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.0705 - mean_squared_error: 256.0705 - acc: 6.3869e-04 - val_loss: 673.4200 - val_mean_squared_error: 673.4201 - val_acc: 2.1289e-04\n",
      "Epoch 1321/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 258.7080 - mean_squared_error: 258.7079 - acc: 6.0498e-04\n",
      "Epoch 01321: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.5729 - mean_squared_error: 258.5728 - acc: 6.0321e-04 - val_loss: 681.5294 - val_mean_squared_error: 681.5295 - val_acc: 0.0000e+00\n",
      "Epoch 1322/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 241.0130 - mean_squared_error: 241.0131 - acc: 6.2167e-04\n",
      "Epoch 01322: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 241.0910 - mean_squared_error: 241.0910 - acc: 6.2095e-04 - val_loss: 681.1454 - val_mean_squared_error: 681.1453 - val_acc: 0.0000e+00\n",
      "Epoch 1323/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 356.7616 - mean_squared_error: 356.7614 - acc: 4.3321e-04\n",
      "Epoch 01323: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 355.2687 - mean_squared_error: 355.2684 - acc: 4.2580e-04 - val_loss: 688.0207 - val_mean_squared_error: 688.0208 - val_acc: 7.0962e-05\n",
      "Epoch 1324/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 371.6465 - mean_squared_error: 371.6464 - acc: 4.6847e-04\n",
      "Epoch 01324: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 370.1857 - mean_squared_error: 370.1856 - acc: 4.6128e-04 - val_loss: 676.8348 - val_mean_squared_error: 676.8349 - val_acc: 0.0000e+00\n",
      "Epoch 1325/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 249.1677 - mean_squared_error: 249.1677 - acc: 7.3084e-04\n",
      "Epoch 01325: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 249.2506 - mean_squared_error: 249.2505 - acc: 7.2740e-04 - val_loss: 673.0118 - val_mean_squared_error: 673.0117 - val_acc: 0.0000e+00\n",
      "Epoch 1326/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 243.0648 - mean_squared_error: 243.0647 - acc: 6.6667e-04\n",
      "Epoch 01326: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 243.3653 - mean_squared_error: 243.3652 - acc: 6.5644e-04 - val_loss: 674.7292 - val_mean_squared_error: 674.7294 - val_acc: 0.0000e+00\n",
      "Epoch 1327/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 242.3192 - mean_squared_error: 242.3192 - acc: 5.2158e-04\n",
      "Epoch 01327: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.0369 - mean_squared_error: 242.0369 - acc: 5.1450e-04 - val_loss: 708.5346 - val_mean_squared_error: 708.5346 - val_acc: 7.0962e-05\n",
      "Epoch 1328/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 241.3704 - mean_squared_error: 241.3704 - acc: 5.1002e-04\n",
      "Epoch 01328: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 257.0456 - mean_squared_error: 257.0457 - acc: 5.1450e-04 - val_loss: 663.8282 - val_mean_squared_error: 663.8282 - val_acc: 0.0000e+00\n",
      "Epoch 1329/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 375.4866 - mean_squared_error: 375.4866 - acc: 6.4516e-04\n",
      "Epoch 01329: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 374.1546 - mean_squared_error: 374.1547 - acc: 6.3869e-04 - val_loss: 701.9432 - val_mean_squared_error: 701.9432 - val_acc: 0.0000e+00\n",
      "Epoch 1330/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 253.1072 - mean_squared_error: 253.1073 - acc: 6.2500e-04\n",
      "Epoch 01330: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.1377 - mean_squared_error: 253.1378 - acc: 6.2095e-04 - val_loss: 670.8152 - val_mean_squared_error: 670.8150 - val_acc: 0.0000e+00\n",
      "Epoch 1331/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 242.6733 - mean_squared_error: 242.6734 - acc: 5.0817e-04\n",
      "Epoch 01331: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.8013 - mean_squared_error: 242.8013 - acc: 5.4999e-04 - val_loss: 705.6797 - val_mean_squared_error: 705.6796 - val_acc: 0.0000e+00\n",
      "Epoch 1332/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 246.0781 - mean_squared_error: 246.0782 - acc: 6.6298e-04\n",
      "Epoch 01332: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.4148 - mean_squared_error: 246.4149 - acc: 6.3869e-04 - val_loss: 683.7050 - val_mean_squared_error: 683.7051 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1333/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 258.5815 - mean_squared_error: 258.5816 - acc: 6.0662e-04\n",
      "Epoch 01333: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 258.6772 - mean_squared_error: 258.6773 - acc: 5.8547e-04 - val_loss: 684.5854 - val_mean_squared_error: 684.5853 - val_acc: 0.0000e+00\n",
      "Epoch 1334/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 262.2847 - mean_squared_error: 262.2847 - acc: 6.1372e-04\n",
      "Epoch 01334: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 262.2445 - mean_squared_error: 262.2444 - acc: 6.2095e-04 - val_loss: 675.9661 - val_mean_squared_error: 675.9660 - val_acc: 1.4192e-04\n",
      "Epoch 1335/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 282.6325 - mean_squared_error: 282.6325 - acc: 6.2837e-04\n",
      "Epoch 01335: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 282.6512 - mean_squared_error: 282.6512 - acc: 6.2095e-04 - val_loss: 708.2264 - val_mean_squared_error: 708.2264 - val_acc: 0.0000e+00\n",
      "Epoch 1336/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 326.8886 - mean_squared_error: 326.8885 - acc: 4.6679e-04\n",
      "Epoch 01336: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 326.1596 - mean_squared_error: 326.1595 - acc: 4.6128e-04 - val_loss: 681.1719 - val_mean_squared_error: 681.1719 - val_acc: 0.0000e+00\n",
      "Epoch 1337/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 279.5162 - mean_squared_error: 279.5164 - acc: 5.4845e-04\n",
      "Epoch 01337: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 278.9152 - mean_squared_error: 278.9153 - acc: 5.3225e-04 - val_loss: 734.3509 - val_mean_squared_error: 734.3509 - val_acc: 6.3866e-04\n",
      "Epoch 1338/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 244.7589 - mean_squared_error: 244.7589 - acc: 6.2167e-04\n",
      "Epoch 01338: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 244.7476 - mean_squared_error: 244.7476 - acc: 6.2095e-04 - val_loss: 690.3708 - val_mean_squared_error: 690.3708 - val_acc: 0.0000e+00\n",
      "Epoch 1339/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 266.1199 - mean_squared_error: 266.1200 - acc: 5.1471e-04\n",
      "Epoch 01339: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 265.1013 - mean_squared_error: 265.1013 - acc: 4.9676e-04 - val_loss: 695.2636 - val_mean_squared_error: 695.2636 - val_acc: 0.0000e+00\n",
      "Epoch 1340/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 347.9988 - mean_squared_error: 347.9987 - acc: 6.2389e-04\n",
      "Epoch 01340: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 347.3497 - mean_squared_error: 347.3495 - acc: 6.2095e-04 - val_loss: 671.6142 - val_mean_squared_error: 671.6144 - val_acc: 0.0000e+00\n",
      "Epoch 1341/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 253.7992 - mean_squared_error: 253.7993 - acc: 6.4401e-04\n",
      "Epoch 01341: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.5346 - mean_squared_error: 253.5346 - acc: 6.3869e-04 - val_loss: 714.4684 - val_mean_squared_error: 714.4684 - val_acc: 0.0000e+00\n",
      "Epoch 1342/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 360.4203 - mean_squared_error: 360.4203 - acc: 6.6190e-04\n",
      "Epoch 01342: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 359.8418 - mean_squared_error: 359.8418 - acc: 6.5644e-04 - val_loss: 680.1189 - val_mean_squared_error: 680.1188 - val_acc: 0.0000e+00\n",
      "Epoch 1343/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 249.5360 - mean_squared_error: 249.5360 - acc: 6.5719e-04\n",
      "Epoch 01343: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 249.5027 - mean_squared_error: 249.5027 - acc: 6.5644e-04 - val_loss: 649.6105 - val_mean_squared_error: 649.6105 - val_acc: 0.0000e+00\n",
      "Epoch 1344/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 242.7282 - mean_squared_error: 242.7284 - acc: 5.3957e-04\n",
      "Epoch 01344: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.7492 - mean_squared_error: 242.7494 - acc: 5.4999e-04 - val_loss: 649.4406 - val_mean_squared_error: 649.4404 - val_acc: 0.0000e+00\n",
      "Epoch 1345/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 264.2492 - mean_squared_error: 264.2493 - acc: 5.0179e-04\n",
      "Epoch 01345: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 264.0418 - mean_squared_error: 264.0419 - acc: 5.1450e-04 - val_loss: 679.9828 - val_mean_squared_error: 679.9827 - val_acc: 0.0000e+00\n",
      "Epoch 1346/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 312.1210 - mean_squared_error: 312.1210 - acc: 6.1818e-04\n",
      "Epoch 01346: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 311.2083 - mean_squared_error: 311.2083 - acc: 6.0321e-04 - val_loss: 684.6450 - val_mean_squared_error: 684.6448 - val_acc: 0.0000e+00\n",
      "Epoch 1347/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 270.7866 - mean_squared_error: 270.7865 - acc: 5.7762e-04\n",
      "Epoch 01347: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 270.4034 - mean_squared_error: 270.4032 - acc: 5.8547e-04 - val_loss: 704.6812 - val_mean_squared_error: 704.6813 - val_acc: 0.0000e+00\n",
      "Epoch 1348/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 240.3983 - mean_squared_error: 240.3983 - acc: 6.6543e-04 ETA: 0s - loss: 240.9289 - mean_squared_error: 240.9288 - acc: \n",
      "Epoch 01348: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 467.0343 - mean_squared_error: 467.0343 - acc: 6.9192e-04 - val_loss: 647.2706 - val_mean_squared_error: 647.2706 - val_acc: 7.0962e-05\n",
      "Epoch 1349/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 255.3834 - mean_squared_error: 255.3833 - acc: 6.8100e-04\n",
      "Epoch 01349: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.1246 - mean_squared_error: 255.1245 - acc: 6.7418e-04 - val_loss: 688.1168 - val_mean_squared_error: 688.1170 - val_acc: 0.0000e+00\n",
      "Epoch 1350/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 243.7584 - mean_squared_error: 243.7584 - acc: 5.1878e-04\n",
      "Epoch 01350: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 243.7859 - mean_squared_error: 243.7859 - acc: 5.1450e-04 - val_loss: 685.8059 - val_mean_squared_error: 685.8060 - val_acc: 0.0000e+00\n",
      "Epoch 1351/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 254.9032 - mean_squared_error: 254.9033 - acc: 5.7451e-04\n",
      "Epoch 01351: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 255.1786 - mean_squared_error: 255.1787 - acc: 5.6773e-04 - val_loss: 671.1390 - val_mean_squared_error: 671.1393 - val_acc: 3.5481e-04\n",
      "Epoch 1352/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 389.5195 - mean_squared_error: 389.5197 - acc: 7.1048e-04\n",
      "Epoch 01352: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 389.4031 - mean_squared_error: 389.4033 - acc: 7.0966e-04 - val_loss: 654.0770 - val_mean_squared_error: 654.0770 - val_acc: 0.0000e+00\n",
      "Epoch 1353/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 549.2615 - mean_squared_error: 549.2615 - acc: 5.9246e-04\n",
      "Epoch 01353: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 545.4672 - mean_squared_error: 545.4672 - acc: 6.0321e-04 - val_loss: 682.7005 - val_mean_squared_error: 682.7003 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 284.3860 - mean_squared_error: 284.3860 - acc: 7.2595e-04\n",
      "Epoch 01354: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 284.3861 - mean_squared_error: 284.3861 - acc: 7.0966e-04 - val_loss: 681.6782 - val_mean_squared_error: 681.6783 - val_acc: 0.0000e+00\n",
      "Epoch 1355/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 248.4984 - mean_squared_error: 248.4984 - acc: 6.2044e-04\n",
      "Epoch 01355: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 247.5516 - mean_squared_error: 247.5515 - acc: 6.0321e-04 - val_loss: 674.9848 - val_mean_squared_error: 674.9847 - val_acc: 0.0000e+00\n",
      "Epoch 1356/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 278.8154 - mean_squared_error: 278.8154 - acc: 6.3063e-04\n",
      "Epoch 01356: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 278.0042 - mean_squared_error: 278.0042 - acc: 6.3869e-04 - val_loss: 681.2208 - val_mean_squared_error: 681.2208 - val_acc: 0.0000e+00\n",
      "Epoch 1357/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 262.7116 - mean_squared_error: 262.7115 - acc: 6.8100e-04\n",
      "Epoch 01357: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 262.5621 - mean_squared_error: 262.5620 - acc: 6.7418e-04 - val_loss: 688.3714 - val_mean_squared_error: 688.3714 - val_acc: 1.4192e-04\n",
      "Epoch 1358/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 246.1625 - mean_squared_error: 246.1625 - acc: 6.9725e-04\n",
      "Epoch 01358: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.1233 - mean_squared_error: 246.1233 - acc: 6.9192e-04 - val_loss: 686.9335 - val_mean_squared_error: 686.9336 - val_acc: 0.0000e+00\n",
      "Epoch 1359/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 247.5040 - mean_squared_error: 247.5039 - acc: 5.7658e-04\n",
      "Epoch 01359: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.8573 - mean_squared_error: 246.8573 - acc: 5.6773e-04 - val_loss: 676.7441 - val_mean_squared_error: 676.7440 - val_acc: 4.2577e-04\n",
      "Epoch 1360/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 240.1144 - mean_squared_error: 240.1144 - acc: 5.7143e-04\n",
      "Epoch 01360: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 240.2153 - mean_squared_error: 240.2153 - acc: 5.6773e-04 - val_loss: 707.4842 - val_mean_squared_error: 707.4843 - val_acc: 0.0000e+00\n",
      "Epoch 1361/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 250.9874 - mean_squared_error: 250.9874 - acc: 7.7064e-04\n",
      "Epoch 01361: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 250.9603 - mean_squared_error: 250.9603 - acc: 7.6288e-04 - val_loss: 711.0543 - val_mean_squared_error: 711.0544 - val_acc: 0.0000e+00\n",
      "Epoch 1362/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 244.9049 - mean_squared_error: 244.9050 - acc: 6.7273e-04\n",
      "Epoch 01362: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 245.5118 - mean_squared_error: 245.5118 - acc: 6.5644e-04 - val_loss: 744.5031 - val_mean_squared_error: 744.5031 - val_acc: 0.0000e+00\n",
      "Epoch 1363/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 283.0231 - mean_squared_error: 283.0229 - acc: 6.5693e-04\n",
      "Epoch 01363: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 282.2644 - mean_squared_error: 282.2643 - acc: 6.3869e-04 - val_loss: 726.9617 - val_mean_squared_error: 726.9618 - val_acc: 0.0000e+00\n",
      "Epoch 1364/3000\n",
      "55800/56365 [============================>.] - ETA: 0s - loss: 241.8385 - mean_squared_error: 241.8386 - acc: 6.4516e-04\n",
      "Epoch 01364: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 241.3922 - mean_squared_error: 241.3923 - acc: 6.3869e-04 - val_loss: 692.1057 - val_mean_squared_error: 692.1057 - val_acc: 0.0000e+00\n",
      "Epoch 1365/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 242.1736 - mean_squared_error: 242.1736 - acc: 5.5147e-04\n",
      "Epoch 01365: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.0191 - mean_squared_error: 242.0191 - acc: 5.6773e-04 - val_loss: 710.6682 - val_mean_squared_error: 710.6682 - val_acc: 0.0000e+00\n",
      "Epoch 1366/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 265.5960 - mean_squared_error: 265.5958 - acc: 6.7736e-04\n",
      "Epoch 01366: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 265.5406 - mean_squared_error: 265.5405 - acc: 6.7418e-04 - val_loss: 699.8733 - val_mean_squared_error: 699.8733 - val_acc: 0.0000e+00\n",
      "Epoch 1367/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 285.8372 - mean_squared_error: 285.8372 - acc: 5.6673e-04\n",
      "Epoch 01367: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 284.5577 - mean_squared_error: 284.5577 - acc: 5.6773e-04 - val_loss: 705.9352 - val_mean_squared_error: 705.9350 - val_acc: 0.0000e+00\n",
      "Epoch 1368/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 311.7647 - mean_squared_error: 311.7648 - acc: 6.4286e-04\n",
      "Epoch 01368: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 311.1439 - mean_squared_error: 311.1440 - acc: 6.3869e-04 - val_loss: 696.2787 - val_mean_squared_error: 696.2787 - val_acc: 0.0000e+00\n",
      "Epoch 1369/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 362.1834 - mean_squared_error: 362.1833 - acc: 5.5249e-04\n",
      "Epoch 01369: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 357.2731 - mean_squared_error: 357.2731 - acc: 5.3225e-04 - val_loss: 670.6997 - val_mean_squared_error: 670.6997 - val_acc: 0.0000e+00\n",
      "Epoch 1370/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 268.1231 - mean_squared_error: 268.1230 - acc: 6.9343e-04\n",
      "Epoch 01370: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 267.0691 - mean_squared_error: 267.0691 - acc: 6.7418e-04 - val_loss: 657.6450 - val_mean_squared_error: 657.6450 - val_acc: 0.0000e+00\n",
      "Epoch 1371/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 247.5013 - mean_squared_error: 247.5012 - acc: 6.7979e-04\n",
      "Epoch 01371: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 247.9906 - mean_squared_error: 247.9905 - acc: 6.9192e-04 - val_loss: 675.8164 - val_mean_squared_error: 675.8165 - val_acc: 0.0000e+00\n",
      "Epoch 1372/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 274.3070 - mean_squared_error: 274.3071 - acc: 6.2612e-04\n",
      "Epoch 01372: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 273.8939 - mean_squared_error: 273.8940 - acc: 6.2095e-04 - val_loss: 693.0114 - val_mean_squared_error: 693.0114 - val_acc: 0.0000e+00\n",
      "Epoch 1373/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 386.0570 - mean_squared_error: 386.0570 - acc: 6.4865e-04\n",
      "Epoch 01373: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 383.5414 - mean_squared_error: 383.5414 - acc: 6.3869e-04 - val_loss: 689.4546 - val_mean_squared_error: 689.4547 - val_acc: 0.0000e+00\n",
      "Epoch 1374/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 268.9223 - mean_squared_error: 268.9221 - acc: 5.3476e-04\n",
      "Epoch 01374: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 268.6629 - mean_squared_error: 268.6627 - acc: 5.3225e-04 - val_loss: 706.7379 - val_mean_squared_error: 706.7379 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1375/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 245.1078 - mean_squared_error: 245.1079 - acc: 6.1706e-04\n",
      "Epoch 01375: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 245.1651 - mean_squared_error: 245.1652 - acc: 6.0321e-04 - val_loss: 688.4562 - val_mean_squared_error: 688.4561 - val_acc: 0.0000e+00\n",
      "Epoch 1376/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 257.9992 - mean_squared_error: 257.9993 - acc: 5.2065e-04\n",
      "Epoch 01376: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 257.8790 - mean_squared_error: 257.8792 - acc: 5.3225e-04 - val_loss: 689.0762 - val_mean_squared_error: 689.0762 - val_acc: 0.0000e+00\n",
      "Epoch 1377/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 254.7639 - mean_squared_error: 254.7638 - acc: 5.9675e-04\n",
      "Epoch 01377: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 254.1929 - mean_squared_error: 254.1929 - acc: 6.0321e-04 - val_loss: 679.5569 - val_mean_squared_error: 679.5570 - val_acc: 0.0000e+00\n",
      "Epoch 1378/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 262.6143 - mean_squared_error: 262.6142 - acc: 5.2632e-04\n",
      "Epoch 01378: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 262.4119 - mean_squared_error: 262.4119 - acc: 5.4999e-04 - val_loss: 688.3972 - val_mean_squared_error: 688.3972 - val_acc: 0.0000e+00\n",
      "Epoch 1379/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 239.0058 - mean_squared_error: 239.0058 - acc: 5.9783e-04\n",
      "Epoch 01379: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 239.4016 - mean_squared_error: 239.4016 - acc: 5.8547e-04 - val_loss: 693.8160 - val_mean_squared_error: 693.8160 - val_acc: 0.0000e+00\n",
      "Epoch 1380/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 238.2131 - mean_squared_error: 238.2132 - acc: 6.1372e-04\n",
      "Epoch 01380: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 239.0882 - mean_squared_error: 239.0883 - acc: 6.3869e-04 - val_loss: 688.6437 - val_mean_squared_error: 688.6440 - val_acc: 0.0000e+00\n",
      "Epoch 1381/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 246.3303 - mean_squared_error: 246.3304 - acc: 5.7245e-04\n",
      "Epoch 01381: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 246.5018 - mean_squared_error: 246.5019 - acc: 5.6773e-04 - val_loss: 709.3879 - val_mean_squared_error: 709.3879 - val_acc: 0.0000e+00\n",
      "Epoch 1382/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 271.0826 - mean_squared_error: 271.0827 - acc: 5.8932e-04\n",
      "Epoch 01382: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 270.6911 - mean_squared_error: 270.6912 - acc: 5.6773e-04 - val_loss: 727.1184 - val_mean_squared_error: 727.1184 - val_acc: 0.0000e+00\n",
      "Epoch 1383/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 245.4020 - mean_squared_error: 245.4020 - acc: 4.2514e-04\n",
      "Epoch 01383: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 244.7863 - mean_squared_error: 244.7863 - acc: 4.2580e-04 - val_loss: 672.3717 - val_mean_squared_error: 672.3717 - val_acc: 0.0000e+00\n",
      "Epoch 1384/3000\n",
      "56200/56365 [============================>.] - ETA: 0s - loss: 276.8639 - mean_squared_error: 276.8639 - acc: 5.5160e-04\n",
      "Epoch 01384: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 276.8098 - mean_squared_error: 276.8098 - acc: 5.6773e-04 - val_loss: 699.4328 - val_mean_squared_error: 699.4327 - val_acc: 7.0962e-05\n",
      "Epoch 1385/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 244.2965 - mean_squared_error: 244.2965 - acc: 6.7395e-04\n",
      "Epoch 01385: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 244.2970 - mean_squared_error: 244.2970 - acc: 7.0966e-04 - val_loss: 671.0501 - val_mean_squared_error: 671.0504 - val_acc: 0.0000e+00\n",
      "Epoch 1386/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 277.0790 - mean_squared_error: 277.0790 - acc: 6.7395e-04\n",
      "Epoch 01386: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 275.7780 - mean_squared_error: 275.7780 - acc: 6.5644e-04 - val_loss: 693.6674 - val_mean_squared_error: 693.6672 - val_acc: 0.0000e+00\n",
      "Epoch 1387/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 348.7315 - mean_squared_error: 348.7316 - acc: 6.7395e-04\n",
      "Epoch 01387: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 345.7210 - mean_squared_error: 345.7211 - acc: 6.5644e-04 - val_loss: 681.9830 - val_mean_squared_error: 681.9829 - val_acc: 0.0000e+00\n",
      "Epoch 1388/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 289.8528 - mean_squared_error: 289.8528 - acc: 7.1942e-04\n",
      "Epoch 01388: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 289.4869 - mean_squared_error: 289.4868 - acc: 7.0966e-04 - val_loss: 681.3388 - val_mean_squared_error: 681.3390 - val_acc: 2.8385e-04\n",
      "Epoch 1389/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 242.1806 - mean_squared_error: 242.1807 - acc: 6.6071e-04\n",
      "Epoch 01389: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 242.2679 - mean_squared_error: 242.2679 - acc: 6.5644e-04 - val_loss: 676.6450 - val_mean_squared_error: 676.6450 - val_acc: 7.0962e-05\n",
      "Epoch 1390/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 339.7169 - mean_squared_error: 339.7169 - acc: 5.0000e-04 ETA: 0s - loss: 485.3277 - mean_squared_error: 48 - ETA: 0s - loss: 357.0928 - mean_squared_error: 357.0930 - acc: 5.\n",
      "Epoch 01390: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 338.8795 - mean_squared_error: 338.8796 - acc: 4.9676e-04 - val_loss: 696.1328 - val_mean_squared_error: 696.1328 - val_acc: 0.0000e+00\n",
      "Epoch 1391/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 250.1240 - mean_squared_error: 250.1238 - acc: 6.7029e-04 ETA: 0s - loss: 267.6468 - mean_squared_e\n",
      "Epoch 01391: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 249.4743 - mean_squared_error: 249.4742 - acc: 6.7418e-04 - val_loss: 670.6520 - val_mean_squared_error: 670.6519 - val_acc: 0.0000e+00\n",
      "Epoch 1392/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 237.6168 - mean_squared_error: 237.6169 - acc: 6.1483e-04\n",
      "Epoch 01392: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 242.9129 - mean_squared_error: 242.9130 - acc: 6.0321e-04 - val_loss: 655.2827 - val_mean_squared_error: 655.2827 - val_acc: 0.0000e+00\n",
      "Epoch 1393/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 241.1203 - mean_squared_error: 241.1202 - acc: 6.1818e-04\n",
      "Epoch 01393: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 240.4568 - mean_squared_error: 240.4568 - acc: 6.2095e-04 - val_loss: 704.8209 - val_mean_squared_error: 704.8210 - val_acc: 2.1289e-04\n",
      "Epoch 1394/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 340.6362 - mean_squared_error: 340.6361 - acc: 6.1261e-04\n",
      "Epoch 01394: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 338.9942 - mean_squared_error: 338.9941 - acc: 6.0321e-04 - val_loss: 707.6170 - val_mean_squared_error: 707.6172 - val_acc: 7.0962e-05\n",
      "Epoch 1395/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 574.1487 - mean_squared_error: 574.1490 - acc: 5.6673e-04\n",
      "Epoch 01395: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 565.7653 - mean_squared_error: 565.7656 - acc: 5.8547e-04 - val_loss: 713.7300 - val_mean_squared_error: 713.7299 - val_acc: 0.0000e+00\n",
      "Epoch 1396/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 268.1259 - mean_squared_error: 268.1259 - acc: 5.7658e-04\n",
      "Epoch 01396: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 267.4860 - mean_squared_error: 267.4861 - acc: 5.6773e-04 - val_loss: 685.8740 - val_mean_squared_error: 685.8740 - val_acc: 0.0000e+00\n",
      "Epoch 1397/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 254.0239 - mean_squared_error: 254.0238 - acc: 6.5719e-04\n",
      "Epoch 01397: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 254.0342 - mean_squared_error: 254.0341 - acc: 6.5644e-04 - val_loss: 681.5612 - val_mean_squared_error: 681.5610 - val_acc: 2.1289e-04\n",
      "Epoch 1398/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 241.6744 - mean_squared_error: 241.6745 - acc: 6.7857e-04\n",
      "Epoch 01398: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 241.6573 - mean_squared_error: 241.6574 - acc: 6.9192e-04 - val_loss: 711.3395 - val_mean_squared_error: 711.3395 - val_acc: 0.0000e+00\n",
      "Epoch 1399/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 246.4412 - mean_squared_error: 246.4410 - acc: 4.4405e-04\n",
      "Epoch 01399: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 246.4183 - mean_squared_error: 246.4182 - acc: 4.4354e-04 - val_loss: 676.8123 - val_mean_squared_error: 676.8123 - val_acc: 0.0000e+00\n",
      "Epoch 1400/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 280.8480 - mean_squared_error: 280.8480 - acc: 6.7857e-04\n",
      "Epoch 01400: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 280.3366 - mean_squared_error: 280.3366 - acc: 6.7418e-04 - val_loss: 686.2437 - val_mean_squared_error: 686.2437 - val_acc: 0.0000e+00\n",
      "Epoch 1401/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 304.7607 - mean_squared_error: 304.7607 - acc: 6.6071e-04\n",
      "Epoch 01401: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 304.4597 - mean_squared_error: 304.4598 - acc: 6.7418e-04 - val_loss: 684.4501 - val_mean_squared_error: 684.4502 - val_acc: 0.0000e+00\n",
      "Epoch 1402/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 272.8005 - mean_squared_error: 272.8003 - acc: 5.8824e-04\n",
      "Epoch 01402: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 272.6914 - mean_squared_error: 272.6913 - acc: 6.0321e-04 - val_loss: 662.9568 - val_mean_squared_error: 662.9567 - val_acc: 0.0000e+00\n",
      "Epoch 1403/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 252.2492 - mean_squared_error: 252.2492 - acc: 7.3345e-04\n",
      "Epoch 01403: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 251.9493 - mean_squared_error: 251.9493 - acc: 7.2740e-04 - val_loss: 682.3488 - val_mean_squared_error: 682.3488 - val_acc: 0.0000e+00\n",
      "Epoch 1404/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 307.2207 - mean_squared_error: 307.2207 - acc: 8.2290e-04\n",
      "Epoch 01404: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 306.8237 - mean_squared_error: 306.8237 - acc: 8.1611e-04 - val_loss: 687.8642 - val_mean_squared_error: 687.8640 - val_acc: 0.0000e+00\n",
      "Epoch 1405/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 238.8263 - mean_squared_error: 238.8262 - acc: 6.1931e-04\n",
      "Epoch 01405: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 237.8870 - mean_squared_error: 237.8869 - acc: 6.0321e-04 - val_loss: 711.4218 - val_mean_squared_error: 711.4218 - val_acc: 0.0000e+00\n",
      "Epoch 1406/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 273.6259 - mean_squared_error: 273.6258 - acc: 5.5957e-04\n",
      "Epoch 01406: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 272.9748 - mean_squared_error: 272.9748 - acc: 5.6773e-04 - val_loss: 672.6808 - val_mean_squared_error: 672.6807 - val_acc: 0.0000e+00\n",
      "Epoch 1407/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 254.2676 - mean_squared_error: 254.2676 - acc: 5.6985e-04\n",
      "Epoch 01407: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 255.2208 - mean_squared_error: 255.2208 - acc: 5.6773e-04 - val_loss: 698.4950 - val_mean_squared_error: 698.4948 - val_acc: 0.0000e+00\n",
      "Epoch 1408/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 243.0730 - mean_squared_error: 243.0730 - acc: 6.0329e-04\n",
      "Epoch 01408: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 243.4574 - mean_squared_error: 243.4574 - acc: 6.0321e-04 - val_loss: 699.3781 - val_mean_squared_error: 699.3781 - val_acc: 0.0000e+00\n",
      "Epoch 1409/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 288.9390 - mean_squared_error: 288.9391 - acc: 7.3394e-04\n",
      "Epoch 01409: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 287.4442 - mean_squared_error: 287.4442 - acc: 7.0966e-04 - val_loss: 682.7601 - val_mean_squared_error: 682.7599 - val_acc: 0.0000e+00\n",
      "Epoch 1410/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 266.2106 - mean_squared_error: 266.2106 - acc: 5.5957e-04 ETA: 0s - loss: 273.6124 - mean_squared_error: 273.6123 - a\n",
      "Epoch 01410: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.9516 - mean_squared_error: 265.9516 - acc: 5.6773e-04 - val_loss: 664.7920 - val_mean_squared_error: 664.7919 - val_acc: 0.0000e+00\n",
      "Epoch 1411/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 254.4001 - mean_squared_error: 254.4001 - acc: 7.1556e-04 ETA: 1s - loss: 253.1931 - me\n",
      "Epoch 01411: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 254.3582 - mean_squared_error: 254.3582 - acc: 7.0966e-04 - val_loss: 700.3863 - val_mean_squared_error: 700.3863 - val_acc: 0.0000e+00\n",
      "Epoch 1412/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 318.7314 - mean_squared_error: 318.7313 - acc: 7.5812e-04\n",
      "Epoch 01412: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 318.1338 - mean_squared_error: 318.1338 - acc: 7.4514e-04 - val_loss: 682.8595 - val_mean_squared_error: 682.8596 - val_acc: 2.8385e-04\n",
      "Epoch 1413/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 242.6904 - mean_squared_error: 242.6905 - acc: 5.4845e-04\n",
      "Epoch 01413: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 241.9740 - mean_squared_error: 241.9740 - acc: 5.3225e-04 - val_loss: 676.4180 - val_mean_squared_error: 676.4182 - val_acc: 0.0000e+00\n",
      "Epoch 1414/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 305.5752 - mean_squared_error: 305.5753 - acc: 7.1691e-04\n",
      "Epoch 01414: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 303.2737 - mean_squared_error: 303.2738 - acc: 7.2740e-04 - val_loss: 702.5978 - val_mean_squared_error: 702.5979 - val_acc: 0.0000e+00\n",
      "Epoch 1415/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55400/56365 [============================>.] - ETA: 0s - loss: 257.7592 - mean_squared_error: 257.7591 - acc: 7.0397e-04 ETA: 0s - loss: 257.6575 - mean_squared_error\n",
      "Epoch 01415: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 257.4113 - mean_squared_error: 257.4112 - acc: 7.0966e-04 - val_loss: 688.6598 - val_mean_squared_error: 688.6599 - val_acc: 7.0962e-05\n",
      "Epoch 1416/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 360.0523 - mean_squared_error: 360.0525 - acc: 6.6190e-04\n",
      "Epoch 01416: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 358.7034 - mean_squared_error: 358.7036 - acc: 6.7418e-04 - val_loss: 666.2652 - val_mean_squared_error: 666.2652 - val_acc: 7.0962e-05\n",
      "Epoch 1417/3000\n",
      "55900/56365 [============================>.] - ETA: 0s - loss: 258.9588 - mean_squared_error: 258.9586 - acc: 6.7979e-04\n",
      "Epoch 01417: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 258.5947 - mean_squared_error: 258.5945 - acc: 6.7418e-04 - val_loss: 684.4909 - val_mean_squared_error: 684.4908 - val_acc: 0.0000e+00\n",
      "Epoch 1418/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 241.4695 - mean_squared_error: 241.4696 - acc: 6.4982e-04\n",
      "Epoch 01418: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 242.1327 - mean_squared_error: 242.1328 - acc: 6.5644e-04 - val_loss: 667.7020 - val_mean_squared_error: 667.7020 - val_acc: 0.0000e+00\n",
      "Epoch 1419/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 288.5951 - mean_squared_error: 288.5951 - acc: 6.3406e-04\n",
      "Epoch 01419: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 288.2150 - mean_squared_error: 288.2151 - acc: 6.3869e-04 - val_loss: 683.9170 - val_mean_squared_error: 683.9171 - val_acc: 0.0000e+00\n",
      "Epoch 1420/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 286.6991 - mean_squared_error: 286.6989 - acc: 6.6667e-04\n",
      "Epoch 01420: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 285.8916 - mean_squared_error: 285.8914 - acc: 6.7418e-04 - val_loss: 694.1955 - val_mean_squared_error: 694.1956 - val_acc: 0.0000e+00\n",
      "Epoch 1421/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 240.2940 - mean_squared_error: 240.2941 - acc: 6.6055e-04\n",
      "Epoch 01421: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 239.8679 - mean_squared_error: 239.8680 - acc: 6.3869e-04 - val_loss: 694.9579 - val_mean_squared_error: 694.9581 - val_acc: 0.0000e+00\n",
      "Epoch 1422/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 240.0969 - mean_squared_error: 240.0969 - acc: 7.3609e-04\n",
      "Epoch 01422: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 240.0204 - mean_squared_error: 240.0203 - acc: 7.2740e-04 - val_loss: 679.4942 - val_mean_squared_error: 679.4943 - val_acc: 0.0000e+00\n",
      "Epoch 1423/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 237.8069 - mean_squared_error: 237.8070 - acc: 6.2500e-04\n",
      "Epoch 01423: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 238.7927 - mean_squared_error: 238.7928 - acc: 6.2095e-04 - val_loss: 676.0166 - val_mean_squared_error: 676.0166 - val_acc: 0.0000e+00\n",
      "Epoch 1424/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 288.7403 - mean_squared_error: 288.7404 - acc: 5.8824e-04\n",
      "Epoch 01424: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 288.7189 - mean_squared_error: 288.7189 - acc: 5.8547e-04 - val_loss: 680.5099 - val_mean_squared_error: 680.5099 - val_acc: 1.4192e-04\n",
      "Epoch 1425/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 263.3441 - mean_squared_error: 263.3441 - acc: 6.2615e-04\n",
      "Epoch 01425: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 262.8607 - mean_squared_error: 262.8607 - acc: 6.2095e-04 - val_loss: 691.6092 - val_mean_squared_error: 691.6094 - val_acc: 0.0000e+00\n",
      "Epoch 1426/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 342.4622 - mean_squared_error: 342.4625 - acc: 4.9002e-04\n",
      "Epoch 01426: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 340.2321 - mean_squared_error: 340.2324 - acc: 5.1450e-04 - val_loss: 690.6541 - val_mean_squared_error: 690.6539 - val_acc: 0.0000e+00\n",
      "Epoch 1427/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 240.3956 - mean_squared_error: 240.3955 - acc: 6.2500e-04\n",
      "Epoch 01427: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 240.7065 - mean_squared_error: 240.7065 - acc: 6.3869e-04 - val_loss: 687.7262 - val_mean_squared_error: 687.7261 - val_acc: 0.0000e+00\n",
      "Epoch 1428/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 269.1677 - mean_squared_error: 269.1676 - acc: 4.6763e-04\n",
      "Epoch 01428: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 28us/sample - loss: 268.6363 - mean_squared_error: 268.6363 - acc: 4.6128e-04 - val_loss: 734.5420 - val_mean_squared_error: 734.5422 - val_acc: 0.0000e+00\n",
      "Epoch 1429/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 266.8024 - mean_squared_error: 266.8022 - acc: 6.8015e-04\n",
      "Epoch 01429: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 265.8087 - mean_squared_error: 265.8085 - acc: 6.5644e-04 - val_loss: 681.2061 - val_mean_squared_error: 681.2061 - val_acc: 0.0000e+00\n",
      "Epoch 1430/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 335.1286 - mean_squared_error: 335.1286 - acc: 6.4748e-04\n",
      "Epoch 01430: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 333.5898 - mean_squared_error: 333.5898 - acc: 6.3869e-04 - val_loss: 688.1836 - val_mean_squared_error: 688.1837 - val_acc: 0.0000e+00\n",
      "Epoch 1431/3000\n",
      "54900/56365 [============================>.] - ETA: 0s - loss: 236.3530 - mean_squared_error: 236.3529 - acc: 5.2823e-04\n",
      "Epoch 01431: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 29us/sample - loss: 236.6015 - mean_squared_error: 236.6014 - acc: 5.1450e-04 - val_loss: 719.0699 - val_mean_squared_error: 719.0699 - val_acc: 0.0000e+00\n",
      "Epoch 1432/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 242.9044 - mean_squared_error: 242.9044 - acc: 7.4600e-04\n",
      "Epoch 01432: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 27us/sample - loss: 243.0694 - mean_squared_error: 243.0695 - acc: 7.4514e-04 - val_loss: 686.2176 - val_mean_squared_error: 686.2176 - val_acc: 0.0000e+00\n",
      "Epoch 1433/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 288.0895 - mean_squared_error: 288.0895 - acc: 6.3985e-04\n",
      "Epoch 01433: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 286.8001 - mean_squared_error: 286.8002 - acc: 6.3869e-04 - val_loss: 692.1932 - val_mean_squared_error: 692.1933 - val_acc: 0.0000e+00\n",
      "Epoch 1434/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 261.6726 - mean_squared_error: 261.6728 - acc: 5.7041e-04\n",
      "Epoch 01434: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 261.5078 - mean_squared_error: 261.5080 - acc: 5.6773e-04 - val_loss: 668.8145 - val_mean_squared_error: 668.8147 - val_acc: 0.0000e+00\n",
      "Epoch 1435/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 234.5378 - mean_squared_error: 234.5378 - acc: 6.0714e-04\n",
      "Epoch 01435: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 234.6264 - mean_squared_error: 234.6263 - acc: 6.0321e-04 - val_loss: 662.7400 - val_mean_squared_error: 662.7397 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1436/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 236.6047 - mean_squared_error: 236.6047 - acc: 6.9519e-04\n",
      "Epoch 01436: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 236.3537 - mean_squared_error: 236.3537 - acc: 6.9192e-04 - val_loss: 692.1893 - val_mean_squared_error: 692.1894 - val_acc: 0.0000e+00\n",
      "Epoch 1437/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 259.7886 - mean_squared_error: 259.7886 - acc: 6.6055e-04\n",
      "Epoch 01437: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 259.2475 - mean_squared_error: 259.2475 - acc: 6.3869e-04 - val_loss: 686.6206 - val_mean_squared_error: 686.6206 - val_acc: 0.0000e+00\n",
      "Epoch 1438/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 242.0336 - mean_squared_error: 242.0338 - acc: 6.3869e-04\n",
      "Epoch 01438: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 242.2227 - mean_squared_error: 242.2229 - acc: 6.2095e-04 - val_loss: 675.9770 - val_mean_squared_error: 675.9770 - val_acc: 0.0000e+00\n",
      "Epoch 1439/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 247.7831 - mean_squared_error: 247.7832 - acc: 6.8345e-04\n",
      "Epoch 01439: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 247.7133 - mean_squared_error: 247.7134 - acc: 6.7418e-04 - val_loss: 685.3572 - val_mean_squared_error: 685.3573 - val_acc: 1.4192e-04\n",
      "Epoch 1440/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 279.3246 - mean_squared_error: 279.3245 - acc: 5.5258e-04\n",
      "Epoch 01440: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 279.4281 - mean_squared_error: 279.4279 - acc: 5.4999e-04 - val_loss: 687.2426 - val_mean_squared_error: 687.2426 - val_acc: 0.0000e+00\n",
      "Epoch 1441/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 264.6209 - mean_squared_error: 264.6210 - acc: 6.4632e-04\n",
      "Epoch 01441: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 264.8015 - mean_squared_error: 264.8015 - acc: 6.3869e-04 - val_loss: 691.6822 - val_mean_squared_error: 691.6823 - val_acc: 1.4192e-04\n",
      "Epoch 1442/3000\n",
      "56300/56365 [============================>.] - ETA: 0s - loss: 255.7305 - mean_squared_error: 255.7305 - acc: 6.5719e-04\n",
      "Epoch 01442: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 255.6962 - mean_squared_error: 255.6962 - acc: 6.5644e-04 - val_loss: 663.6379 - val_mean_squared_error: 663.6378 - val_acc: 0.0000e+00\n",
      "Epoch 1443/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 281.5195 - mean_squared_error: 281.5195 - acc: 6.6547e-04\n",
      "Epoch 01443: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 281.0792 - mean_squared_error: 281.0792 - acc: 6.5644e-04 - val_loss: 689.1660 - val_mean_squared_error: 689.1659 - val_acc: 0.0000e+00\n",
      "Epoch 1444/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 252.1748 - mean_squared_error: 252.1747 - acc: 5.9783e-04\n",
      "Epoch 01444: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 252.5134 - mean_squared_error: 252.5133 - acc: 6.2095e-04 - val_loss: 718.4901 - val_mean_squared_error: 718.4901 - val_acc: 0.0000e+00\n",
      "Epoch 1445/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 244.9488 - mean_squared_error: 244.9489 - acc: 5.4152e-04\n",
      "Epoch 01445: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 245.0983 - mean_squared_error: 245.0984 - acc: 5.4999e-04 - val_loss: 687.5604 - val_mean_squared_error: 687.5602 - val_acc: 0.0000e+00\n",
      "Epoch 1446/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 245.6186 - mean_squared_error: 245.6185 - acc: 6.1483e-04\n",
      "Epoch 01446: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 245.4678 - mean_squared_error: 245.4677 - acc: 6.5644e-04 - val_loss: 685.1430 - val_mean_squared_error: 685.1431 - val_acc: 7.0962e-05\n",
      "Epoch 1447/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 235.4011 - mean_squared_error: 235.4012 - acc: 6.2385e-04 ETA: 0s - loss: 236.0462 - mean_squared_error: 236.0463 - acc: 6.\n",
      "Epoch 01447: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 234.9203 - mean_squared_error: 234.9204 - acc: 6.0321e-04 - val_loss: 668.5471 - val_mean_squared_error: 668.5470 - val_acc: 0.0000e+00\n",
      "Epoch 1448/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 259.1895 - mean_squared_error: 259.1895 - acc: 7.3874e-04\n",
      "Epoch 01448: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 259.4003 - mean_squared_error: 259.4003 - acc: 7.2740e-04 - val_loss: 679.6251 - val_mean_squared_error: 679.6251 - val_acc: 0.0000e+00\n",
      "Epoch 1449/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 295.3809 - mean_squared_error: 295.3810 - acc: 6.5934e-04\n",
      "Epoch 01449: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 293.2543 - mean_squared_error: 293.2544 - acc: 6.3869e-04 - val_loss: 690.9204 - val_mean_squared_error: 690.9207 - val_acc: 0.0000e+00\n",
      "Epoch 1450/3000\n",
      "56000/56365 [============================>.] - ETA: 0s - loss: 347.8338 - mean_squared_error: 347.8336 - acc: 6.6071e-04\n",
      "Epoch 01450: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 347.1488 - mean_squared_error: 347.1487 - acc: 6.5644e-04 - val_loss: 698.4828 - val_mean_squared_error: 698.4827 - val_acc: 0.0000e+00\n",
      "Epoch 1451/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 284.9916 - mean_squared_error: 284.9917 - acc: 4.7882e-04\n",
      "Epoch 01451: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 283.4597 - mean_squared_error: 283.4597 - acc: 4.6128e-04 - val_loss: 680.1876 - val_mean_squared_error: 680.1875 - val_acc: 0.0000e+00\n",
      "Epoch 1452/3000\n",
      "55700/56365 [============================>.] - ETA: 0s - loss: 283.1796 - mean_squared_error: 283.1796 - acc: 5.3860e-04 ETA: 0s - loss: 316.2624 - mean_squared_error: 316.\n",
      "Epoch 01452: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 282.3049 - mean_squared_error: 282.3049 - acc: 5.3225e-04 - val_loss: 700.6644 - val_mean_squared_error: 700.6645 - val_acc: 0.0000e+00\n",
      "Epoch 1453/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 253.7281 - mean_squared_error: 253.7282 - acc: 6.8592e-04\n",
      "Epoch 01453: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 253.5299 - mean_squared_error: 253.5300 - acc: 6.7418e-04 - val_loss: 695.6479 - val_mean_squared_error: 695.6480 - val_acc: 7.0962e-05\n",
      "Epoch 1454/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 241.0338 - mean_squared_error: 241.0338 - acc: 6.8345e-04\n",
      "Epoch 01454: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 241.0034 - mean_squared_error: 241.0034 - acc: 6.9192e-04 - val_loss: 673.3352 - val_mean_squared_error: 673.3352 - val_acc: 0.0000e+00\n",
      "Epoch 1455/3000\n",
      "54700/56365 [============================>.] - ETA: 0s - loss: 281.0903 - mean_squared_error: 281.0904 - acc: 6.9470e-04\n",
      "Epoch 01455: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 279.7690 - mean_squared_error: 279.7690 - acc: 6.7418e-04 - val_loss: 693.2733 - val_mean_squared_error: 693.2735 - val_acc: 0.0000e+00\n",
      "Epoch 1456/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 247.5743 - mean_squared_error: 247.5741 - acc: 5.3476e-04\n",
      "Epoch 01456: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 247.7106 - mean_squared_error: 247.7105 - acc: 5.3225e-04 - val_loss: 691.9067 - val_mean_squared_error: 691.9068 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1457/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 339.0545 - mean_squared_error: 339.0545 - acc: 7.0144e-04\n",
      "Epoch 01457: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 337.6868 - mean_squared_error: 337.6867 - acc: 7.0966e-04 - val_loss: 720.7295 - val_mean_squared_error: 720.7295 - val_acc: 0.0000e+00\n",
      "Epoch 1458/3000\n",
      "54500/56365 [============================>.] - ETA: 0s - loss: 275.7350 - mean_squared_error: 275.7348 - acc: 7.5229e-04\n",
      "Epoch 01458: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 274.7363 - mean_squared_error: 274.7361 - acc: 7.2740e-04 - val_loss: 674.4510 - val_mean_squared_error: 674.4509 - val_acc: 0.0000e+00\n",
      "Epoch 1459/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 234.5175 - mean_squared_error: 234.5176 - acc: 5.8394e-04\n",
      "Epoch 01459: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 234.6629 - mean_squared_error: 234.6631 - acc: 6.2095e-04 - val_loss: 682.7334 - val_mean_squared_error: 682.7334 - val_acc: 4.2577e-04\n",
      "Epoch 1460/3000\n",
      "55200/56365 [============================>.] - ETA: 0s - loss: 247.5467 - mean_squared_error: 247.5467 - acc: 6.5217e-04\n",
      "Epoch 01460: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 247.4529 - mean_squared_error: 247.4528 - acc: 6.5644e-04 - val_loss: 712.0056 - val_mean_squared_error: 712.0057 - val_acc: 0.0000e+00\n",
      "Epoch 1461/3000\n",
      "54300/56365 [===========================>..] - ETA: 0s - loss: 248.6592 - mean_squared_error: 248.6592 - acc: 6.4457e-04\n",
      "Epoch 01461: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 248.4251 - mean_squared_error: 248.4251 - acc: 6.3869e-04 - val_loss: 669.6974 - val_mean_squared_error: 669.6975 - val_acc: 0.0000e+00\n",
      "Epoch 1462/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 282.3705 - mean_squared_error: 282.3705 - acc: 6.7518e-04\n",
      "Epoch 01462: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 280.8342 - mean_squared_error: 280.8342 - acc: 6.7418e-04 - val_loss: 679.5409 - val_mean_squared_error: 679.5410 - val_acc: 0.0000e+00\n",
      "Epoch 1463/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 302.8970 - mean_squared_error: 302.8970 - acc: 6.3636e-04\n",
      "Epoch 01463: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 302.3230 - mean_squared_error: 302.3231 - acc: 6.2095e-04 - val_loss: 672.1437 - val_mean_squared_error: 672.1437 - val_acc: 7.0962e-05\n",
      "Epoch 1464/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 324.0228 - mean_squared_error: 324.0228 - acc: 5.5755e-04\n",
      "Epoch 01464: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 323.0775 - mean_squared_error: 323.0775 - acc: 5.4999e-04 - val_loss: 697.8693 - val_mean_squared_error: 697.8694 - val_acc: 0.0000e+00\n",
      "Epoch 1465/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 287.7558 - mean_squared_error: 287.7557 - acc: 6.5954e-04\n",
      "Epoch 01465: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 287.6231 - mean_squared_error: 287.6230 - acc: 6.5644e-04 - val_loss: 673.6729 - val_mean_squared_error: 673.6729 - val_acc: 0.0000e+00\n",
      "Epoch 1466/3000\n",
      "55100/56365 [============================>.] - ETA: 0s - loss: 757.8876 - mean_squared_error: 757.8873 - acc: 5.0817e-04\n",
      "Epoch 01466: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 746.2229 - mean_squared_error: 746.2225 - acc: 5.1450e-04 - val_loss: 687.0845 - val_mean_squared_error: 687.0845 - val_acc: 0.0000e+00\n",
      "Epoch 1467/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 388.2947 - mean_squared_error: 388.2947 - acc: 6.8345e-04\n",
      "Epoch 01467: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 386.4640 - mean_squared_error: 386.4639 - acc: 6.7418e-04 - val_loss: 697.7897 - val_mean_squared_error: 697.7901 - val_acc: 0.0000e+00\n",
      "Epoch 1468/3000\n",
      "55500/56365 [============================>.] - ETA: 0s - loss: 263.4844 - mean_squared_error: 263.4844 - acc: 4.5045e-04\n",
      "Epoch 01468: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 262.9436 - mean_squared_error: 262.9436 - acc: 4.4354e-04 - val_loss: 688.5231 - val_mean_squared_error: 688.5233 - val_acc: 7.0962e-05\n",
      "Epoch 1469/3000\n",
      "55300/56365 [============================>.] - ETA: 0s - loss: 256.6544 - mean_squared_error: 256.6544 - acc: 5.0633e-04\n",
      "Epoch 01469: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 256.2231 - mean_squared_error: 256.2231 - acc: 4.9676e-04 - val_loss: 675.5888 - val_mean_squared_error: 675.5885 - val_acc: 0.0000e+00\n",
      "Epoch 1470/3000\n",
      "54200/56365 [===========================>..] - ETA: 0s - loss: 244.9070 - mean_squared_error: 244.9071 - acc: 7.1956e-04\n",
      "Epoch 01470: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 245.4585 - mean_squared_error: 245.4586 - acc: 7.0966e-04 - val_loss: 674.4677 - val_mean_squared_error: 674.4678 - val_acc: 0.0000e+00\n",
      "Epoch 1471/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 242.1139 - mean_squared_error: 242.1140 - acc: 5.8608e-04\n",
      "Epoch 01471: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 26us/sample - loss: 242.5090 - mean_squared_error: 242.5090 - acc: 6.0321e-04 - val_loss: 694.3984 - val_mean_squared_error: 694.3983 - val_acc: 0.0000e+00\n",
      "Epoch 1472/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 233.4284 - mean_squared_error: 233.4284 - acc: 5.3957e-04\n",
      "Epoch 01472: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 233.1977 - mean_squared_error: 233.1978 - acc: 5.3225e-04 - val_loss: 705.6701 - val_mean_squared_error: 705.6702 - val_acc: 0.0000e+00\n",
      "Epoch 1473/3000\n",
      "55000/56365 [============================>.] - ETA: 0s - loss: 238.1044 - mean_squared_error: 238.1045 - acc: 6.7273e-04\n",
      "Epoch 01473: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 238.7581 - mean_squared_error: 238.7581 - acc: 6.5644e-04 - val_loss: 698.5207 - val_mean_squared_error: 698.5206 - val_acc: 7.0962e-05\n",
      "Epoch 1474/3000\n",
      "55600/56365 [============================>.] - ETA: 0s - loss: 233.3759 - mean_squared_error: 233.3760 - acc: 7.5540e-04\n",
      "Epoch 01474: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 233.7245 - mean_squared_error: 233.7245 - acc: 7.6288e-04 - val_loss: 658.1257 - val_mean_squared_error: 658.1257 - val_acc: 0.0000e+00\n",
      "Epoch 1475/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 307.5292 - mean_squared_error: 307.5291 - acc: 5.6985e-04\n",
      "Epoch 01475: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 304.9827 - mean_squared_error: 304.9826 - acc: 5.4999e-04 - val_loss: 697.6817 - val_mean_squared_error: 697.6816 - val_acc: 0.0000e+00\n",
      "Epoch 1476/3000\n",
      "54100/56365 [===========================>..] - ETA: 0s - loss: 318.5246 - mean_squared_error: 318.5245 - acc: 5.7301e-04\n",
      "Epoch 01476: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 314.5256 - mean_squared_error: 314.5254 - acc: 5.6773e-04 - val_loss: 691.0716 - val_mean_squared_error: 691.0715 - val_acc: 0.0000e+00\n",
      "Epoch 1477/3000\n",
      "54400/56365 [===========================>..] - ETA: 0s - loss: 288.1464 - mean_squared_error: 288.1465 - acc: 4.5956e-04 ETA: 0s - loss: 318.4546 - mean_squared_error: 318.\n",
      "Epoch 01477: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 27us/sample - loss: 286.0621 - mean_squared_error: 286.0621 - acc: 4.7902e-04 - val_loss: 660.1878 - val_mean_squared_error: 660.1877 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1478/3000\n",
      "55400/56365 [============================>.] - ETA: 0s - loss: 293.0995 - mean_squared_error: 293.0995 - acc: 6.3177e-04\n",
      "Epoch 01478: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 292.9027 - mean_squared_error: 292.9027 - acc: 6.5644e-04 - val_loss: 656.0182 - val_mean_squared_error: 656.0181 - val_acc: 0.0000e+00\n",
      "Epoch 1479/3000\n",
      "56100/56365 [============================>.] - ETA: 0s - loss: 241.1636 - mean_squared_error: 241.1635 - acc: 7.1301e-04\n",
      "Epoch 01479: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 241.1430 - mean_squared_error: 241.1429 - acc: 7.0966e-04 - val_loss: 689.1919 - val_mean_squared_error: 689.1920 - val_acc: 0.0000e+00\n",
      "Epoch 1480/3000\n",
      "54800/56365 [============================>.] - ETA: 0s - loss: 241.3985 - mean_squared_error: 241.3984 - acc: 5.6569e-04\n",
      "Epoch 01480: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 1s 25us/sample - loss: 241.9346 - mean_squared_error: 241.9345 - acc: 5.8547e-04 - val_loss: 673.4685 - val_mean_squared_error: 673.4683 - val_acc: 0.0000e+00\n",
      "Epoch 1481/3000\n",
      "54600/56365 [============================>.] - ETA: 0s - loss: 234.9580 - mean_squared_error: 234.9581 - acc: 6.7766e-04\n",
      "Epoch 01481: val_loss did not improve from 634.83457\n",
      "56365/56365 [==============================] - 2s 32us/sample - loss: 281.7362 - mean_squared_error: 281.7363 - acc: 6.7418e-04 - val_loss: 655.6918 - val_mean_squared_error: 655.6919 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('./model_adr1/')\n",
    "save_dir = \"./model_adr1/\"\n",
    "#先預測 adr\n",
    "import tensorflow.keras.backend as KB\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# This returns a tensor\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256,input_shape=(73,),activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024,activation='relu',kernel_initializer='normal'))\n",
    "# model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(units=256,activation='relu',kernel_initializer='normal'))\n",
    "#model.add(Dense(units=64,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(units=1,activation='linear',kernel_initializer='normal'))\n",
    "es = EarlyStopping(monitor='val_loss',patience=500,restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+'model1.h5', \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                mode='min')\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse','accuracy'])\n",
    "train_history = model.fit(X, Y,validation_split=0.2, epochs=3000, batch_size=100,callbacks=[es,checkpoint])  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model_adr1/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "now = 'adr_predict_dnn'\n",
    "#plot_model(model, to_file='./static/model'+now+'.png',show_shapes=True)\n",
    "# summarize history for accuracy\n",
    "plt.plot(train_history.history['acc'])\n",
    "plt.plot(train_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./model_adr1/model_acurracy1.png')\n",
    "plt.show()\n",
    "# summarize history for loss \n",
    "plt.plot(train_history.history['loss']) \n",
    "plt.plot(train_history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./model_adr1/model_loss1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 75.37405 ,  68.96787 ,  71.17329 , ..., 127.69181 , 141.97127 ,\n",
       "        52.397964], dtype=float32)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = model.predict(test)\n",
    "Y_predict = np.reshape(Y_predict,(Y_predict.shape[0],))\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_label = pd.read_csv('./train_label.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "X,Y,test,X_booking,test_booking = pre_adr_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_booking['booking_total_revenue'] = Y_predict*(test_booking['stays_in_week_nights']+test_booking['stays_in_weekend_nights']+1)\n",
    "X_tmp = X_booking.groupby('arrival_date').sum()\n",
    "test_X_tmp = test_booking.groupby('arrival_date').sum()\n",
    "#leadtime 先保留\n",
    "X_tmp.drop(['ID','agent','adr'],axis=1,inplace=True)\n",
    "test_X_tmp.drop(['ID','agent'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_tmp.values\n",
    "test_X = test_X_tmp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_label.drop(['arrival_date'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.reshape(Y,(Y.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 73)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 73)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/3000\n",
      "100/512 [====>.........................] - ETA: 1s - loss: 386.1860 - mean_absolute_error: 386.1860 - soft_acc: 0.0000e+00\n",
      "Epoch 00001: val_mean_absolute_error improved from inf to 1154.43384, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 2s 4ms/sample - loss: 2061.1072 - mean_absolute_error: 2061.1072 - soft_acc: 0.0000e+00 - val_loss: 1154.4338 - val_mean_absolute_error: 1154.4338 - val_soft_acc: 0.0000e+00\n",
      "Epoch 2/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2035.5101 - mean_absolute_error: 2035.5101 - soft_acc: 0.0000e+00\n",
      "Epoch 00002: val_mean_absolute_error improved from 1154.43384 to 484.19153, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 111us/sample - loss: 922.4306 - mean_absolute_error: 922.4306 - soft_acc: 0.0000e+00 - val_loss: 484.1915 - val_mean_absolute_error: 484.1915 - val_soft_acc: 0.0000e+00\n",
      "Epoch 3/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 704.9871 - mean_absolute_error: 704.9871 - soft_acc: 0.0000e+00\n",
      "Epoch 00003: val_mean_absolute_error improved from 484.19153 to 255.86015, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 368.4230 - mean_absolute_error: 368.4230 - soft_acc: 0.0017 - val_loss: 255.8602 - val_mean_absolute_error: 255.8602 - val_soft_acc: 0.0000e+00\n",
      "Epoch 4/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 365.9286 - mean_absolute_error: 365.9286 - soft_acc: 0.0000e+00\n",
      "Epoch 00004: val_mean_absolute_error improved from 255.86015 to 103.10666, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 222.8279 - mean_absolute_error: 222.8279 - soft_acc: 0.0017 - val_loss: 103.1067 - val_mean_absolute_error: 103.1067 - val_soft_acc: 0.0000e+00\n",
      "Epoch 5/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 148.5237 - mean_absolute_error: 148.5237 - soft_acc: 0.0000e+00\n",
      "Epoch 00005: val_mean_absolute_error improved from 103.10666 to 24.80955, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 151.8643 - mean_absolute_error: 151.8643 - soft_acc: 0.0139 - val_loss: 24.8096 - val_mean_absolute_error: 24.8096 - val_soft_acc: 0.0000e+00\n",
      "Epoch 6/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 60.7608 - mean_absolute_error: 60.7608 - soft_acc: 0.0000e+00\n",
      "Epoch 00006: val_mean_absolute_error improved from 24.80955 to 7.70622, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 106us/sample - loss: 69.4028 - mean_absolute_error: 69.4028 - soft_acc: 0.0311 - val_loss: 7.7062 - val_mean_absolute_error: 7.7062 - val_soft_acc: 0.0329\n",
      "Epoch 7/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 43.6227 - mean_absolute_error: 43.6227 - soft_acc: 0.0100\n",
      "Epoch 00007: val_mean_absolute_error improved from 7.70622 to 5.49203, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 36.3397 - mean_absolute_error: 36.3397 - soft_acc: 0.0100 - val_loss: 5.4920 - val_mean_absolute_error: 5.4920 - val_soft_acc: 0.0607\n",
      "Epoch 8/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 28.7846 - mean_absolute_error: 28.7846 - soft_acc: 0.0200\n",
      "Epoch 00008: val_mean_absolute_error did not improve from 5.49203\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 29.5305 - mean_absolute_error: 29.5305 - soft_acc: 0.0167 - val_loss: 12.0118 - val_mean_absolute_error: 12.0118 - val_soft_acc: 0.0000e+00\n",
      "Epoch 9/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 27.3108 - mean_absolute_error: 27.3108 - soft_acc: 0.0300\n",
      "Epoch 00009: val_mean_absolute_error improved from 5.49203 to 4.40174, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 24.5805 - mean_absolute_error: 24.5805 - soft_acc: 0.0250 - val_loss: 4.4017 - val_mean_absolute_error: 4.4017 - val_soft_acc: 0.0329\n",
      "Epoch 10/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 19.4940 - mean_absolute_error: 19.4940 - soft_acc: 0.0400\n",
      "Epoch 00010: val_mean_absolute_error did not improve from 4.40174\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 19.0772 - mean_absolute_error: 19.0772 - soft_acc: 0.0389 - val_loss: 6.2034 - val_mean_absolute_error: 6.2034 - val_soft_acc: 0.0379\n",
      "Epoch 11/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 15.7031 - mean_absolute_error: 15.7031 - soft_acc: 0.0500\n",
      "Epoch 00011: val_mean_absolute_error improved from 4.40174 to 4.10869, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 101us/sample - loss: 17.5032 - mean_absolute_error: 17.5032 - soft_acc: 0.0200 - val_loss: 4.1087 - val_mean_absolute_error: 4.1087 - val_soft_acc: 0.0457\n",
      "Epoch 12/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 15.3549 - mean_absolute_error: 15.3549 - soft_acc: 0.0200\n",
      "Epoch 00012: val_mean_absolute_error improved from 4.10869 to 3.80381, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 15.3069 - mean_absolute_error: 15.3069 - soft_acc: 0.0183 - val_loss: 3.8038 - val_mean_absolute_error: 3.8038 - val_soft_acc: 0.0329\n",
      "Epoch 13/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 14.5340 - mean_absolute_error: 14.5340 - soft_acc: 0.0300\n",
      "Epoch 00013: val_mean_absolute_error did not improve from 3.80381\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 15.2088 - mean_absolute_error: 15.2088 - soft_acc: 0.0283 - val_loss: 14.9755 - val_mean_absolute_error: 14.9755 - val_soft_acc: 0.0000e+00\n",
      "Epoch 14/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 16.6775 - mean_absolute_error: 16.6775 - soft_acc: 0.0100\n",
      "Epoch 00014: val_mean_absolute_error did not improve from 3.80381\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 17.0793 - mean_absolute_error: 17.0793 - soft_acc: 0.0217 - val_loss: 6.1948 - val_mean_absolute_error: 6.1948 - val_soft_acc: 0.0050\n",
      "Epoch 15/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 13.1495 - mean_absolute_error: 13.1495 - soft_acc: 0.0200\n",
      "Epoch 00015: val_mean_absolute_error improved from 3.80381 to 2.34397, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 95us/sample - loss: 13.5440 - mean_absolute_error: 13.5440 - soft_acc: 0.0383 - val_loss: 2.3440 - val_mean_absolute_error: 2.3440 - val_soft_acc: 0.1700\n",
      "Epoch 16/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 11.7716 - mean_absolute_error: 11.7716 - soft_acc: 0.0300\n",
      "Epoch 00016: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 13.3766 - mean_absolute_error: 13.3766 - soft_acc: 0.0356 - val_loss: 3.4785 - val_mean_absolute_error: 3.4785 - val_soft_acc: 0.0000e+00\n",
      "Epoch 17/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 9.8554 - mean_absolute_error: 9.8554 - soft_acc: 0.0500\n",
      "Epoch 00017: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 11.9751 - mean_absolute_error: 11.9751 - soft_acc: 0.0611 - val_loss: 3.8532 - val_mean_absolute_error: 3.8532 - val_soft_acc: 0.0000e+00\n",
      "Epoch 18/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 11.6018 - mean_absolute_error: 11.6018 - soft_acc: 0.0300\n",
      "Epoch 00018: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 11.8792 - mean_absolute_error: 11.8792 - soft_acc: 0.0489 - val_loss: 7.1637 - val_mean_absolute_error: 7.1637 - val_soft_acc: 0.0000e+00\n",
      "Epoch 19/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 11.0105 - mean_absolute_error: 11.0105 - soft_acc: 0.0200\n",
      "Epoch 00019: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 10.9294 - mean_absolute_error: 10.9294 - soft_acc: 0.0367 - val_loss: 8.2278 - val_mean_absolute_error: 8.2278 - val_soft_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 10.6663 - mean_absolute_error: 10.6663 - soft_acc: 0.0500\n",
      "Epoch 00020: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 10.8850 - mean_absolute_error: 10.8850 - soft_acc: 0.0556 - val_loss: 4.4996 - val_mean_absolute_error: 4.4996 - val_soft_acc: 0.0507\n",
      "Epoch 21/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 9.3468 - mean_absolute_error: 9.3468 - soft_acc: 0.0300\n",
      "Epoch 00021: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 9.4702 - mean_absolute_error: 9.4702 - soft_acc: 0.0522 - val_loss: 2.5740 - val_mean_absolute_error: 2.5740 - val_soft_acc: 0.1793\n",
      "Epoch 22/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 11.1466 - mean_absolute_error: 11.1466 - soft_acc: 0.0400\n",
      "Epoch 00022: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 10.6399 - mean_absolute_error: 10.6399 - soft_acc: 0.0467 - val_loss: 4.1883 - val_mean_absolute_error: 4.1883 - val_soft_acc: 0.0229\n",
      "Epoch 23/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.7467 - mean_absolute_error: 7.7467 - soft_acc: 0.0700\n",
      "Epoch 00023: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 8.9251 - mean_absolute_error: 8.9251 - soft_acc: 0.0483 - val_loss: 7.1485 - val_mean_absolute_error: 7.1485 - val_soft_acc: 0.0050\n",
      "Epoch 24/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 10.2808 - mean_absolute_error: 10.2808 - soft_acc: 0.0200\n",
      "Epoch 00024: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 8.9871 - mean_absolute_error: 8.9871 - soft_acc: 0.0644 - val_loss: 2.8895 - val_mean_absolute_error: 2.8895 - val_soft_acc: 0.0579\n",
      "Epoch 25/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.3399 - mean_absolute_error: 7.3399 - soft_acc: 0.1100\n",
      "Epoch 00025: val_mean_absolute_error did not improve from 2.34397\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 7.8149 - mean_absolute_error: 7.8149 - soft_acc: 0.0467 - val_loss: 2.7357 - val_mean_absolute_error: 2.7357 - val_soft_acc: 0.0557\n",
      "Epoch 26/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.3810 - mean_absolute_error: 7.3810 - soft_acc: 0.0500\n",
      "Epoch 00026: val_mean_absolute_error improved from 2.34397 to 1.24742, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 7.1176 - mean_absolute_error: 7.1176 - soft_acc: 0.0756 - val_loss: 1.2474 - val_mean_absolute_error: 1.2474 - val_soft_acc: 0.2429\n",
      "Epoch 27/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.8878 - mean_absolute_error: 6.8878 - soft_acc: 0.1400\n",
      "Epoch 00027: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 6.8563 - mean_absolute_error: 6.8563 - soft_acc: 0.0856 - val_loss: 5.3009 - val_mean_absolute_error: 5.3009 - val_soft_acc: 0.0000e+00\n",
      "Epoch 28/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.1484 - mean_absolute_error: 7.1484 - soft_acc: 0.0300\n",
      "Epoch 00028: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 6.6791 - mean_absolute_error: 6.6791 - soft_acc: 0.0617 - val_loss: 2.9076 - val_mean_absolute_error: 2.9076 - val_soft_acc: 0.0179\n",
      "Epoch 29/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.6505 - mean_absolute_error: 6.6505 - soft_acc: 0.0300\n",
      "Epoch 00029: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 6.2082 - mean_absolute_error: 6.2082 - soft_acc: 0.0622 - val_loss: 1.4179 - val_mean_absolute_error: 1.4179 - val_soft_acc: 0.1764\n",
      "Epoch 30/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.4035 - mean_absolute_error: 7.4035 - soft_acc: 0.0500\n",
      "Epoch 00030: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 6.3248 - mean_absolute_error: 6.3248 - soft_acc: 0.0806 - val_loss: 2.0666 - val_mean_absolute_error: 2.0666 - val_soft_acc: 0.0300\n",
      "Epoch 31/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.8741 - mean_absolute_error: 4.8741 - soft_acc: 0.1300\n",
      "Epoch 00031: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 5.7901 - mean_absolute_error: 5.7901 - soft_acc: 0.0833 - val_loss: 4.6769 - val_mean_absolute_error: 4.6769 - val_soft_acc: 0.0000e+00\n",
      "Epoch 32/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.2644 - mean_absolute_error: 6.2644 - soft_acc: 0.1100\n",
      "Epoch 00032: val_mean_absolute_error did not improve from 1.24742\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 5.8690 - mean_absolute_error: 5.8690 - soft_acc: 0.1089 - val_loss: 6.6895 - val_mean_absolute_error: 6.6895 - val_soft_acc: 0.0000e+00\n",
      "Epoch 33/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.5490 - mean_absolute_error: 7.5490 - soft_acc: 0.0600\n",
      "Epoch 00033: val_mean_absolute_error improved from 1.24742 to 1.10223, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 6.8510 - mean_absolute_error: 6.8510 - soft_acc: 0.0683 - val_loss: 1.1022 - val_mean_absolute_error: 1.1022 - val_soft_acc: 0.2571\n",
      "Epoch 34/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 5.1393 - mean_absolute_error: 5.1393 - soft_acc: 0.0800\n",
      "Epoch 00034: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 5.7527 - mean_absolute_error: 5.7527 - soft_acc: 0.0917 - val_loss: 2.1891 - val_mean_absolute_error: 2.1891 - val_soft_acc: 0.1864\n",
      "Epoch 35/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.7598 - mean_absolute_error: 7.7598 - soft_acc: 0.1100\n",
      "Epoch 00035: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 6.2856 - mean_absolute_error: 6.2856 - soft_acc: 0.0822 - val_loss: 1.2136 - val_mean_absolute_error: 1.2136 - val_soft_acc: 0.2071\n",
      "Epoch 36/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 5.7637 - mean_absolute_error: 5.7637 - soft_acc: 0.0900\n",
      "Epoch 00036: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 5.5930 - mean_absolute_error: 5.5930 - soft_acc: 0.0889 - val_loss: 1.7112 - val_mean_absolute_error: 1.7112 - val_soft_acc: 0.2293\n",
      "Epoch 37/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 6.6214 - mean_absolute_error: 6.6214 - soft_acc: 0.0600\n",
      "Epoch 00037: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 5.8896 - mean_absolute_error: 5.8896 - soft_acc: 0.0856 - val_loss: 3.2098 - val_mean_absolute_error: 3.2098 - val_soft_acc: 0.0000e+00\n",
      "Epoch 38/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.8745 - mean_absolute_error: 4.8745 - soft_acc: 0.1000\n",
      "Epoch 00038: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 5.1107 - mean_absolute_error: 5.1107 - soft_acc: 0.1250 - val_loss: 3.2873 - val_mean_absolute_error: 3.2873 - val_soft_acc: 0.0279\n",
      "Epoch 39/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.6177 - mean_absolute_error: 4.6177 - soft_acc: 0.1000\n",
      "Epoch 00039: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 4.7520 - mean_absolute_error: 4.7520 - soft_acc: 0.1294 - val_loss: 1.6901 - val_mean_absolute_error: 1.6901 - val_soft_acc: 0.0707\n",
      "Epoch 40/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.3895 - mean_absolute_error: 4.3895 - soft_acc: 0.0900\n",
      "Epoch 00040: val_mean_absolute_error did not improve from 1.10223\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 4.3815 - mean_absolute_error: 4.3815 - soft_acc: 0.1283 - val_loss: 2.7212 - val_mean_absolute_error: 2.7212 - val_soft_acc: 0.1343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 5.2608 - mean_absolute_error: 5.2608 - soft_acc: 0.1200\n",
      "Epoch 00041: val_mean_absolute_error improved from 1.10223 to 1.05100, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 5.0808 - mean_absolute_error: 5.0808 - soft_acc: 0.1039 - val_loss: 1.0510 - val_mean_absolute_error: 1.0510 - val_soft_acc: 0.2279\n",
      "Epoch 42/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.2252 - mean_absolute_error: 4.2252 - soft_acc: 0.0900\n",
      "Epoch 00042: val_mean_absolute_error did not improve from 1.05100\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 4.4134 - mean_absolute_error: 4.4134 - soft_acc: 0.0856 - val_loss: 3.4990 - val_mean_absolute_error: 3.4990 - val_soft_acc: 0.0179\n",
      "Epoch 43/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 5.6134 - mean_absolute_error: 5.6134 - soft_acc: 0.0700\n",
      "Epoch 00043: val_mean_absolute_error did not improve from 1.05100\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 4.2507 - mean_absolute_error: 4.2507 - soft_acc: 0.1033 - val_loss: 4.7950 - val_mean_absolute_error: 4.7950 - val_soft_acc: 0.0000e+00\n",
      "Epoch 44/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 7.6923 - mean_absolute_error: 7.6923 - soft_acc: 0.0400\n",
      "Epoch 00044: val_mean_absolute_error did not improve from 1.05100\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 5.6979 - mean_absolute_error: 5.6979 - soft_acc: 0.1044 - val_loss: 1.2674 - val_mean_absolute_error: 1.2674 - val_soft_acc: 0.2493\n",
      "Epoch 45/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.8711 - mean_absolute_error: 3.8711 - soft_acc: 0.1300\n",
      "Epoch 00045: val_mean_absolute_error improved from 1.05100 to 0.82287, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 3.9025 - mean_absolute_error: 3.9025 - soft_acc: 0.1261 - val_loss: 0.8229 - val_mean_absolute_error: 0.8229 - val_soft_acc: 0.3436\n",
      "Epoch 46/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.4109 - mean_absolute_error: 3.4109 - soft_acc: 0.1200\n",
      "Epoch 00046: val_mean_absolute_error did not improve from 0.82287\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 3.5084 - mean_absolute_error: 3.5084 - soft_acc: 0.1456 - val_loss: 0.9642 - val_mean_absolute_error: 0.9642 - val_soft_acc: 0.2521\n",
      "Epoch 47/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.2308 - mean_absolute_error: 3.2308 - soft_acc: 0.1200\n",
      "Epoch 00047: val_mean_absolute_error did not improve from 0.82287\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 3.4474 - mean_absolute_error: 3.4474 - soft_acc: 0.1322 - val_loss: 2.6056 - val_mean_absolute_error: 2.6056 - val_soft_acc: 0.0100\n",
      "Epoch 48/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 4.2132 - mean_absolute_error: 4.2132 - soft_acc: 0.0700\n",
      "Epoch 00048: val_mean_absolute_error did not improve from 0.82287\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 3.6641 - mean_absolute_error: 3.6641 - soft_acc: 0.1211 - val_loss: 1.7282 - val_mean_absolute_error: 1.7282 - val_soft_acc: 0.0100\n",
      "Epoch 49/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.4480 - mean_absolute_error: 3.4480 - soft_acc: 0.1500\n",
      "Epoch 00049: val_mean_absolute_error improved from 0.82287 to 0.60909, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 3.4995 - mean_absolute_error: 3.4995 - soft_acc: 0.1306 - val_loss: 0.6091 - val_mean_absolute_error: 0.6091 - val_soft_acc: 0.4921\n",
      "Epoch 50/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.8325 - mean_absolute_error: 2.8325 - soft_acc: 0.1700\n",
      "Epoch 00050: val_mean_absolute_error did not improve from 0.60909\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 3.0142 - mean_absolute_error: 3.0142 - soft_acc: 0.1544 - val_loss: 1.2010 - val_mean_absolute_error: 1.2010 - val_soft_acc: 0.3007\n",
      "Epoch 51/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.3739 - mean_absolute_error: 3.3739 - soft_acc: 0.1600\n",
      "Epoch 00051: val_mean_absolute_error did not improve from 0.60909\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 3.0397 - mean_absolute_error: 3.0397 - soft_acc: 0.1406 - val_loss: 1.1030 - val_mean_absolute_error: 1.1030 - val_soft_acc: 0.2800\n",
      "Epoch 52/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.4324 - mean_absolute_error: 3.4324 - soft_acc: 0.0800\n",
      "Epoch 00052: val_mean_absolute_error improved from 0.60909 to 0.59052, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 2.8416 - mean_absolute_error: 2.8416 - soft_acc: 0.1422 - val_loss: 0.5905 - val_mean_absolute_error: 0.5905 - val_soft_acc: 0.4664\n",
      "Epoch 53/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.1581 - mean_absolute_error: 3.1581 - soft_acc: 0.2000\n",
      "Epoch 00053: val_mean_absolute_error did not improve from 0.59052\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 2.7849 - mean_absolute_error: 2.7849 - soft_acc: 0.1500 - val_loss: 0.6479 - val_mean_absolute_error: 0.6479 - val_soft_acc: 0.4371\n",
      "Epoch 54/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.5879 - mean_absolute_error: 2.5879 - soft_acc: 0.1800\n",
      "Epoch 00054: val_mean_absolute_error did not improve from 0.59052\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 2.4148 - mean_absolute_error: 2.4148 - soft_acc: 0.2083 - val_loss: 1.7339 - val_mean_absolute_error: 1.7339 - val_soft_acc: 0.0607\n",
      "Epoch 55/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 3.1078 - mean_absolute_error: 3.1078 - soft_acc: 0.1100\n",
      "Epoch 00055: val_mean_absolute_error improved from 0.59052 to 0.56878, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 2.7668 - mean_absolute_error: 2.7668 - soft_acc: 0.1733 - val_loss: 0.5688 - val_mean_absolute_error: 0.5688 - val_soft_acc: 0.5000\n",
      "Epoch 56/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.2201 - mean_absolute_error: 2.2201 - soft_acc: 0.1300\n",
      "Epoch 00056: val_mean_absolute_error did not improve from 0.56878\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 2.5157 - mean_absolute_error: 2.5157 - soft_acc: 0.1833 - val_loss: 0.6076 - val_mean_absolute_error: 0.6076 - val_soft_acc: 0.3850\n",
      "Epoch 57/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.4181 - mean_absolute_error: 2.4181 - soft_acc: 0.1700\n",
      "Epoch 00057: val_mean_absolute_error did not improve from 0.56878\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 2.2633 - mean_absolute_error: 2.2633 - soft_acc: 0.2000 - val_loss: 0.7056 - val_mean_absolute_error: 0.7056 - val_soft_acc: 0.4571\n",
      "Epoch 58/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.1844 - mean_absolute_error: 2.1844 - soft_acc: 0.2000\n",
      "Epoch 00058: val_mean_absolute_error did not improve from 0.56878\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 2.1642 - mean_absolute_error: 2.1642 - soft_acc: 0.2028 - val_loss: 0.9021 - val_mean_absolute_error: 0.9021 - val_soft_acc: 0.2136\n",
      "Epoch 59/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.0185 - mean_absolute_error: 2.0185 - soft_acc: 0.2100\n",
      "Epoch 00059: val_mean_absolute_error improved from 0.56878 to 0.45700, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 94us/sample - loss: 2.1828 - mean_absolute_error: 2.1828 - soft_acc: 0.2594 - val_loss: 0.4570 - val_mean_absolute_error: 0.4570 - val_soft_acc: 0.5629\n",
      "Epoch 60/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.9031 - mean_absolute_error: 1.9031 - soft_acc: 0.2600\n",
      "Epoch 00060: val_mean_absolute_error did not improve from 0.45700\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 2.0654 - mean_absolute_error: 2.0654 - soft_acc: 0.2283 - val_loss: 1.3242 - val_mean_absolute_error: 1.3242 - val_soft_acc: 0.1336\n",
      "Epoch 61/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.9796 - mean_absolute_error: 1.9796 - soft_acc: 0.2700\n",
      "Epoch 00061: val_mean_absolute_error did not improve from 0.45700\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 1.9599 - mean_absolute_error: 1.9599 - soft_acc: 0.2156 - val_loss: 1.0359 - val_mean_absolute_error: 1.0359 - val_soft_acc: 0.1386\n",
      "Epoch 62/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 2.0770 - mean_absolute_error: 2.0770 - soft_acc: 0.1900\n",
      "Epoch 00062: val_mean_absolute_error did not improve from 0.45700\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 1.8292 - mean_absolute_error: 1.8292 - soft_acc: 0.2411 - val_loss: 1.0524 - val_mean_absolute_error: 1.0524 - val_soft_acc: 0.2229\n",
      "Epoch 63/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.7013 - mean_absolute_error: 1.7013 - soft_acc: 0.1700\n",
      "Epoch 00063: val_mean_absolute_error did not improve from 0.45700\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 1.7287 - mean_absolute_error: 1.7287 - soft_acc: 0.2283 - val_loss: 0.4580 - val_mean_absolute_error: 0.4580 - val_soft_acc: 0.6671\n",
      "Epoch 64/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3123 - mean_absolute_error: 1.3123 - soft_acc: 0.2400\n",
      "Epoch 00064: val_mean_absolute_error improved from 0.45700 to 0.42401, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 1.5447 - mean_absolute_error: 1.5447 - soft_acc: 0.2711 - val_loss: 0.4240 - val_mean_absolute_error: 0.4240 - val_soft_acc: 0.6336\n",
      "Epoch 65/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.5498 - mean_absolute_error: 1.5498 - soft_acc: 0.2500\n",
      "Epoch 00065: val_mean_absolute_error improved from 0.42401 to 0.41726, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 1.5783 - mean_absolute_error: 1.5783 - soft_acc: 0.2911 - val_loss: 0.4173 - val_mean_absolute_error: 0.4173 - val_soft_acc: 0.6157\n",
      "Epoch 66/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.5214 - mean_absolute_error: 1.5214 - soft_acc: 0.2800\n",
      "Epoch 00066: val_mean_absolute_error improved from 0.41726 to 0.41431, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 104us/sample - loss: 1.4756 - mean_absolute_error: 1.4756 - soft_acc: 0.3094 - val_loss: 0.4143 - val_mean_absolute_error: 0.4143 - val_soft_acc: 0.6921\n",
      "Epoch 67/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3451 - mean_absolute_error: 1.3451 - soft_acc: 0.3100\n",
      "Epoch 00067: val_mean_absolute_error did not improve from 0.41431\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 1.3124 - mean_absolute_error: 1.3124 - soft_acc: 0.3111 - val_loss: 0.4298 - val_mean_absolute_error: 0.4298 - val_soft_acc: 0.7286\n",
      "Epoch 68/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.2204 - mean_absolute_error: 1.2204 - soft_acc: 0.2700\n",
      "Epoch 00068: val_mean_absolute_error did not improve from 0.41431\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 1.3017 - mean_absolute_error: 1.3017 - soft_acc: 0.2956 - val_loss: 0.4770 - val_mean_absolute_error: 0.4770 - val_soft_acc: 0.6114\n",
      "Epoch 69/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3432 - mean_absolute_error: 1.3432 - soft_acc: 0.3100\n",
      "Epoch 00069: val_mean_absolute_error did not improve from 0.41431\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 1.2579 - mean_absolute_error: 1.2579 - soft_acc: 0.2956 - val_loss: 0.4498 - val_mean_absolute_error: 0.4498 - val_soft_acc: 0.6471\n",
      "Epoch 70/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.3247 - mean_absolute_error: 1.3247 - soft_acc: 0.3200\n",
      "Epoch 00070: val_mean_absolute_error improved from 0.41431 to 0.35884, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 92us/sample - loss: 1.1846 - mean_absolute_error: 1.1846 - soft_acc: 0.3111 - val_loss: 0.3588 - val_mean_absolute_error: 0.3588 - val_soft_acc: 0.7171\n",
      "Epoch 71/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0196 - mean_absolute_error: 1.0196 - soft_acc: 0.4200\n",
      "Epoch 00071: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.0785 - mean_absolute_error: 1.0785 - soft_acc: 0.3683 - val_loss: 0.3832 - val_mean_absolute_error: 0.3832 - val_soft_acc: 0.6200\n",
      "Epoch 72/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.0057 - mean_absolute_error: 1.0057 - soft_acc: 0.3500\n",
      "Epoch 00072: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.0281 - mean_absolute_error: 1.0281 - soft_acc: 0.3439 - val_loss: 0.3601 - val_mean_absolute_error: 0.3601 - val_soft_acc: 0.6943\n",
      "Epoch 73/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.8622 - mean_absolute_error: 0.8622 - soft_acc: 0.4600\n",
      "Epoch 00073: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.8844 - mean_absolute_error: 0.8844 - soft_acc: 0.4217 - val_loss: 0.4469 - val_mean_absolute_error: 0.4469 - val_soft_acc: 0.5957\n",
      "Epoch 74/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.1450 - mean_absolute_error: 1.1450 - soft_acc: 0.2700\n",
      "Epoch 00074: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.9928 - mean_absolute_error: 0.9928 - soft_acc: 0.3967 - val_loss: 0.4290 - val_mean_absolute_error: 0.4290 - val_soft_acc: 0.6850\n",
      "Epoch 75/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.9511 - mean_absolute_error: 0.9511 - soft_acc: 0.4300\n",
      "Epoch 00075: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.8901 - mean_absolute_error: 0.8901 - soft_acc: 0.4050 - val_loss: 0.4831 - val_mean_absolute_error: 0.4831 - val_soft_acc: 0.5879\n",
      "Epoch 76/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.8310 - mean_absolute_error: 0.8310 - soft_acc: 0.4900\n",
      "Epoch 00076: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.8022 - mean_absolute_error: 0.8022 - soft_acc: 0.4450 - val_loss: 0.4190 - val_mean_absolute_error: 0.4190 - val_soft_acc: 0.6950\n",
      "Epoch 77/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.9499 - mean_absolute_error: 0.9499 - soft_acc: 0.3500\n",
      "Epoch 00077: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.8881 - mean_absolute_error: 0.8881 - soft_acc: 0.4744 - val_loss: 0.4051 - val_mean_absolute_error: 0.4051 - val_soft_acc: 0.6714\n",
      "Epoch 78/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7104 - mean_absolute_error: 0.7104 - soft_acc: 0.5400\n",
      "Epoch 00078: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.6697 - mean_absolute_error: 0.6697 - soft_acc: 0.4883 - val_loss: 0.3941 - val_mean_absolute_error: 0.3941 - val_soft_acc: 0.6893\n",
      "Epoch 79/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6567 - mean_absolute_error: 0.6567 - soft_acc: 0.4900\n",
      "Epoch 00079: val_mean_absolute_error did not improve from 0.35884\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.6733 - mean_absolute_error: 0.6733 - soft_acc: 0.5489 - val_loss: 0.3722 - val_mean_absolute_error: 0.3722 - val_soft_acc: 0.6657\n",
      "Epoch 80/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 1.1634 - mean_absolute_error: 1.1634 - soft_acc: 0.4900\n",
      "Epoch 00080: val_mean_absolute_error improved from 0.35884 to 0.35013, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.7269 - mean_absolute_error: 0.7269 - soft_acc: 0.4889 - val_loss: 0.3501 - val_mean_absolute_error: 0.3501 - val_soft_acc: 0.7429\n",
      "Epoch 81/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5618 - mean_absolute_error: 0.5618 - soft_acc: 0.5500\n",
      "Epoch 00081: val_mean_absolute_error improved from 0.35013 to 0.32687, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 100us/sample - loss: 0.5626 - mean_absolute_error: 0.5626 - soft_acc: 0.5417 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_soft_acc: 0.7350\n",
      "Epoch 82/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5525 - mean_absolute_error: 0.5525 - soft_acc: 0.5000\n",
      "Epoch 00082: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.5464 - mean_absolute_error: 0.5464 - soft_acc: 0.5417 - val_loss: 0.3376 - val_mean_absolute_error: 0.3376 - val_soft_acc: 0.8064\n",
      "Epoch 83/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4838 - mean_absolute_error: 0.4838 - soft_acc: 0.6000\n",
      "Epoch 00083: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5025 - mean_absolute_error: 0.5025 - soft_acc: 0.6350 - val_loss: 0.3300 - val_mean_absolute_error: 0.3300 - val_soft_acc: 0.7600\n",
      "Epoch 84/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5471 - mean_absolute_error: 0.5471 - soft_acc: 0.5500\n",
      "Epoch 00084: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5042 - mean_absolute_error: 0.5042 - soft_acc: 0.6183 - val_loss: 0.3596 - val_mean_absolute_error: 0.3596 - val_soft_acc: 0.6786\n",
      "Epoch 85/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5883 - mean_absolute_error: 0.5883 - soft_acc: 0.5300\n",
      "Epoch 00085: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5742 - mean_absolute_error: 0.5742 - soft_acc: 0.5406 - val_loss: 0.3363 - val_mean_absolute_error: 0.3363 - val_soft_acc: 0.7529\n",
      "Epoch 86/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5048 - mean_absolute_error: 0.5048 - soft_acc: 0.5500\n",
      "Epoch 00086: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5342 - mean_absolute_error: 0.5342 - soft_acc: 0.5972 - val_loss: 0.3427 - val_mean_absolute_error: 0.3427 - val_soft_acc: 0.7171\n",
      "Epoch 87/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4943 - mean_absolute_error: 0.4943 - soft_acc: 0.5700\n",
      "Epoch 00087: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.5379 - mean_absolute_error: 0.5379 - soft_acc: 0.5600 - val_loss: 0.3451 - val_mean_absolute_error: 0.3451 - val_soft_acc: 0.7500\n",
      "Epoch 88/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4668 - mean_absolute_error: 0.4668 - soft_acc: 0.6400\n",
      "Epoch 00088: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5763 - mean_absolute_error: 0.5763 - soft_acc: 0.5639 - val_loss: 0.3370 - val_mean_absolute_error: 0.3370 - val_soft_acc: 0.7600\n",
      "Epoch 89/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5010 - mean_absolute_error: 0.5010 - soft_acc: 0.6500\n",
      "Epoch 00089: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5769 - mean_absolute_error: 0.5769 - soft_acc: 0.5517 - val_loss: 0.4153 - val_mean_absolute_error: 0.4153 - val_soft_acc: 0.6643\n",
      "Epoch 90/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4721 - mean_absolute_error: 0.4721 - soft_acc: 0.6200\n",
      "Epoch 00090: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.6926 - mean_absolute_error: 0.6926 - soft_acc: 0.4872 - val_loss: 0.3480 - val_mean_absolute_error: 0.3480 - val_soft_acc: 0.6686\n",
      "Epoch 91/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5741 - mean_absolute_error: 0.5741 - soft_acc: 0.5700\n",
      "Epoch 00091: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6027 - mean_absolute_error: 0.6027 - soft_acc: 0.5394 - val_loss: 0.5155 - val_mean_absolute_error: 0.5155 - val_soft_acc: 0.4821\n",
      "Epoch 92/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7246 - mean_absolute_error: 0.7246 - soft_acc: 0.3800\n",
      "Epoch 00092: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.6003 - mean_absolute_error: 0.6003 - soft_acc: 0.4994 - val_loss: 0.3991 - val_mean_absolute_error: 0.3991 - val_soft_acc: 0.6821\n",
      "Epoch 93/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5221 - mean_absolute_error: 0.5221 - soft_acc: 0.5300\n",
      "Epoch 00093: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5274 - mean_absolute_error: 0.5274 - soft_acc: 0.6017 - val_loss: 0.3713 - val_mean_absolute_error: 0.3713 - val_soft_acc: 0.6379\n",
      "Epoch 94/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5262 - mean_absolute_error: 0.5262 - soft_acc: 0.5900\n",
      "Epoch 00094: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5041 - mean_absolute_error: 0.5041 - soft_acc: 0.5989 - val_loss: 0.3290 - val_mean_absolute_error: 0.3290 - val_soft_acc: 0.7400\n",
      "Epoch 95/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5104 - mean_absolute_error: 0.5104 - soft_acc: 0.6700\n",
      "Epoch 00095: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5339 - mean_absolute_error: 0.5339 - soft_acc: 0.5761 - val_loss: 0.3342 - val_mean_absolute_error: 0.3342 - val_soft_acc: 0.7443\n",
      "Epoch 96/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3754 - mean_absolute_error: 0.3754 - soft_acc: 0.7000\n",
      "Epoch 00096: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4581 - mean_absolute_error: 0.4581 - soft_acc: 0.5978 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303 - val_soft_acc: 0.7571\n",
      "Epoch 97/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4825 - mean_absolute_error: 0.4825 - soft_acc: 0.6100\n",
      "Epoch 00097: val_mean_absolute_error did not improve from 0.32687\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4596 - mean_absolute_error: 0.4596 - soft_acc: 0.6494 - val_loss: 0.4021 - val_mean_absolute_error: 0.4021 - val_soft_acc: 0.7150\n",
      "Epoch 98/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5397 - mean_absolute_error: 0.5397 - soft_acc: 0.5900\n",
      "Epoch 00098: val_mean_absolute_error improved from 0.32687 to 0.32254, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 102us/sample - loss: 0.4798 - mean_absolute_error: 0.4798 - soft_acc: 0.6722 - val_loss: 0.3225 - val_mean_absolute_error: 0.3225 - val_soft_acc: 0.7679\n",
      "Epoch 99/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4733 - mean_absolute_error: 0.4733 - soft_acc: 0.5600\n",
      "Epoch 00099: val_mean_absolute_error did not improve from 0.32254\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4463 - mean_absolute_error: 0.4463 - soft_acc: 0.6117 - val_loss: 0.3338 - val_mean_absolute_error: 0.3338 - val_soft_acc: 0.7907\n",
      "Epoch 100/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4559 - mean_absolute_error: 0.4559 - soft_acc: 0.6800\n",
      "Epoch 00100: val_mean_absolute_error did not improve from 0.32254\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5056 - mean_absolute_error: 0.5056 - soft_acc: 0.5722 - val_loss: 0.4953 - val_mean_absolute_error: 0.4953 - val_soft_acc: 0.6293\n",
      "Epoch 101/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5811 - mean_absolute_error: 0.5811 - soft_acc: 0.5500\n",
      "Epoch 00101: val_mean_absolute_error did not improve from 0.32254\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.6832 - mean_absolute_error: 0.6832 - soft_acc: 0.4594 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_soft_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4377 - mean_absolute_error: 0.4377 - soft_acc: 0.6700\n",
      "Epoch 00102: val_mean_absolute_error did not improve from 0.32254\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5266 - mean_absolute_error: 0.5266 - soft_acc: 0.6128 - val_loss: 0.4309 - val_mean_absolute_error: 0.4309 - val_soft_acc: 0.6286\n",
      "Epoch 103/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6595 - mean_absolute_error: 0.6595 - soft_acc: 0.4300\n",
      "Epoch 00103: val_mean_absolute_error did not improve from 0.32254\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5238 - mean_absolute_error: 0.5238 - soft_acc: 0.5822 - val_loss: 0.3759 - val_mean_absolute_error: 0.3759 - val_soft_acc: 0.6814\n",
      "Epoch 104/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5329 - mean_absolute_error: 0.5329 - soft_acc: 0.5200\n",
      "Epoch 00104: val_mean_absolute_error improved from 0.32254 to 0.32110, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 93us/sample - loss: 0.5215 - mean_absolute_error: 0.5215 - soft_acc: 0.6217 - val_loss: 0.3211 - val_mean_absolute_error: 0.3211 - val_soft_acc: 0.6936\n",
      "Epoch 105/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4523 - mean_absolute_error: 0.4523 - soft_acc: 0.6100\n",
      "Epoch 00105: val_mean_absolute_error improved from 0.32110 to 0.31993, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 99us/sample - loss: 0.4547 - mean_absolute_error: 0.4547 - soft_acc: 0.6628 - val_loss: 0.3199 - val_mean_absolute_error: 0.3199 - val_soft_acc: 0.7321\n",
      "Epoch 106/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3656 - mean_absolute_error: 0.3656 - soft_acc: 0.7100\n",
      "Epoch 00106: val_mean_absolute_error did not improve from 0.31993\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4320 - mean_absolute_error: 0.4320 - soft_acc: 0.6939 - val_loss: 0.3662 - val_mean_absolute_error: 0.3662 - val_soft_acc: 0.7371\n",
      "Epoch 107/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4069 - mean_absolute_error: 0.4069 - soft_acc: 0.7100\n",
      "Epoch 00107: val_mean_absolute_error did not improve from 0.31993\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4575 - mean_absolute_error: 0.4575 - soft_acc: 0.6689 - val_loss: 0.3227 - val_mean_absolute_error: 0.3227 - val_soft_acc: 0.7757\n",
      "Epoch 108/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4483 - mean_absolute_error: 0.4483 - soft_acc: 0.6700\n",
      "Epoch 00108: val_mean_absolute_error did not improve from 0.31993\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4427 - mean_absolute_error: 0.4427 - soft_acc: 0.5711 - val_loss: 0.3450 - val_mean_absolute_error: 0.3450 - val_soft_acc: 0.8036\n",
      "Epoch 109/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4208 - mean_absolute_error: 0.4208 - soft_acc: 0.6300\n",
      "Epoch 00109: val_mean_absolute_error did not improve from 0.31993\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4971 - mean_absolute_error: 0.4971 - soft_acc: 0.6733 - val_loss: 0.3256 - val_mean_absolute_error: 0.3256 - val_soft_acc: 0.7550\n",
      "Epoch 110/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4087 - mean_absolute_error: 0.4087 - soft_acc: 0.6800\n",
      "Epoch 00110: val_mean_absolute_error did not improve from 0.31993\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4260 - mean_absolute_error: 0.4260 - soft_acc: 0.6594 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_soft_acc: 0.7757\n",
      "Epoch 111/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3936 - mean_absolute_error: 0.3936 - soft_acc: 0.7000\n",
      "Epoch 00111: val_mean_absolute_error improved from 0.31993 to 0.31850, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.4214 - mean_absolute_error: 0.4214 - soft_acc: 0.6439 - val_loss: 0.3185 - val_mean_absolute_error: 0.3185 - val_soft_acc: 0.7321\n",
      "Epoch 112/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3676 - mean_absolute_error: 0.3676 - soft_acc: 0.7200\n",
      "Epoch 00112: val_mean_absolute_error did not improve from 0.31850\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4492 - mean_absolute_error: 0.4492 - soft_acc: 0.6356 - val_loss: 0.3476 - val_mean_absolute_error: 0.3476 - val_soft_acc: 0.7629\n",
      "Epoch 113/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4622 - mean_absolute_error: 0.4622 - soft_acc: 0.6400\n",
      "Epoch 00113: val_mean_absolute_error did not improve from 0.31850\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4301 - mean_absolute_error: 0.4301 - soft_acc: 0.6333 - val_loss: 0.3224 - val_mean_absolute_error: 0.3224 - val_soft_acc: 0.7550\n",
      "Epoch 114/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4700 - mean_absolute_error: 0.4700 - soft_acc: 0.5900\n",
      "Epoch 00114: val_mean_absolute_error did not improve from 0.31850\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4556 - mean_absolute_error: 0.4556 - soft_acc: 0.6378 - val_loss: 0.3297 - val_mean_absolute_error: 0.3297 - val_soft_acc: 0.7114\n",
      "Epoch 115/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4733 - mean_absolute_error: 0.4733 - soft_acc: 0.6100\n",
      "Epoch 00115: val_mean_absolute_error improved from 0.31850 to 0.31805, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.4593 - mean_absolute_error: 0.4593 - soft_acc: 0.6017 - val_loss: 0.3181 - val_mean_absolute_error: 0.3181 - val_soft_acc: 0.7321\n",
      "Epoch 116/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4620 - mean_absolute_error: 0.4620 - soft_acc: 0.6300\n",
      "Epoch 00116: val_mean_absolute_error did not improve from 0.31805\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4272 - mean_absolute_error: 0.4272 - soft_acc: 0.6967 - val_loss: 0.3893 - val_mean_absolute_error: 0.3893 - val_soft_acc: 0.7279\n",
      "Epoch 117/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5003 - mean_absolute_error: 0.5003 - soft_acc: 0.6500\n",
      "Epoch 00117: val_mean_absolute_error did not improve from 0.31805\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4432 - mean_absolute_error: 0.4432 - soft_acc: 0.6756 - val_loss: 0.3253 - val_mean_absolute_error: 0.3253 - val_soft_acc: 0.7550\n",
      "Epoch 118/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4015 - mean_absolute_error: 0.4015 - soft_acc: 0.7500\n",
      "Epoch 00118: val_mean_absolute_error did not improve from 0.31805\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4310 - mean_absolute_error: 0.4310 - soft_acc: 0.6972 - val_loss: 0.3887 - val_mean_absolute_error: 0.3887 - val_soft_acc: 0.7357\n",
      "Epoch 119/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4760 - mean_absolute_error: 0.4760 - soft_acc: 0.6100\n",
      "Epoch 00119: val_mean_absolute_error improved from 0.31805 to 0.31723, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.4613 - mean_absolute_error: 0.4613 - soft_acc: 0.6439 - val_loss: 0.3172 - val_mean_absolute_error: 0.3172 - val_soft_acc: 0.7500\n",
      "Epoch 120/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4240 - mean_absolute_error: 0.4240 - soft_acc: 0.6800\n",
      "Epoch 00120: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4294 - mean_absolute_error: 0.4294 - soft_acc: 0.6900 - val_loss: 0.3269 - val_mean_absolute_error: 0.3269 - val_soft_acc: 0.7371\n",
      "Epoch 121/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3908 - mean_absolute_error: 0.3908 - soft_acc: 0.6900\n",
      "Epoch 00121: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4084 - mean_absolute_error: 0.4084 - soft_acc: 0.7228 - val_loss: 0.4446 - val_mean_absolute_error: 0.4446 - val_soft_acc: 0.7079\n",
      "Epoch 122/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4878 - mean_absolute_error: 0.4878 - soft_acc: 0.6200\n",
      "Epoch 00122: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4590 - mean_absolute_error: 0.4590 - soft_acc: 0.6411 - val_loss: 0.3774 - val_mean_absolute_error: 0.3774 - val_soft_acc: 0.6814\n",
      "Epoch 123/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4055 - mean_absolute_error: 0.4055 - soft_acc: 0.7000\n",
      "Epoch 00123: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4322 - mean_absolute_error: 0.4322 - soft_acc: 0.6478 - val_loss: 0.4032 - val_mean_absolute_error: 0.4032 - val_soft_acc: 0.7071\n",
      "Epoch 124/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3786 - mean_absolute_error: 0.3786 - soft_acc: 0.7000\n",
      "Epoch 00124: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4032 - mean_absolute_error: 0.4032 - soft_acc: 0.7056 - val_loss: 0.3198 - val_mean_absolute_error: 0.3198 - val_soft_acc: 0.7371\n",
      "Epoch 125/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4183 - mean_absolute_error: 0.4183 - soft_acc: 0.6400\n",
      "Epoch 00125: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3782 - mean_absolute_error: 0.3782 - soft_acc: 0.7011 - val_loss: 0.3390 - val_mean_absolute_error: 0.3390 - val_soft_acc: 0.7757\n",
      "Epoch 126/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5096 - mean_absolute_error: 0.5096 - soft_acc: 0.5600\n",
      "Epoch 00126: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4685 - mean_absolute_error: 0.4685 - soft_acc: 0.6361 - val_loss: 0.3487 - val_mean_absolute_error: 0.3487 - val_soft_acc: 0.7729\n",
      "Epoch 127/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4085 - mean_absolute_error: 0.4085 - soft_acc: 0.6800\n",
      "Epoch 00127: val_mean_absolute_error did not improve from 0.31723\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4612 - mean_absolute_error: 0.4612 - soft_acc: 0.6783 - val_loss: 0.4723 - val_mean_absolute_error: 0.4723 - val_soft_acc: 0.6057\n",
      "Epoch 128/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5869 - mean_absolute_error: 0.5869 - soft_acc: 0.5300\n",
      "Epoch 00128: val_mean_absolute_error improved from 0.31723 to 0.31311, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 113us/sample - loss: 0.4891 - mean_absolute_error: 0.4891 - soft_acc: 0.6022 - val_loss: 0.3131 - val_mean_absolute_error: 0.3131 - val_soft_acc: 0.7164\n",
      "Epoch 129/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3710 - mean_absolute_error: 0.3710 - soft_acc: 0.7300\n",
      "Epoch 00129: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4195 - mean_absolute_error: 0.4195 - soft_acc: 0.7161 - val_loss: 0.3242 - val_mean_absolute_error: 0.3242 - val_soft_acc: 0.7986\n",
      "Epoch 130/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3573 - mean_absolute_error: 0.3573 - soft_acc: 0.7300\n",
      "Epoch 00130: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4125 - mean_absolute_error: 0.4125 - soft_acc: 0.6478 - val_loss: 0.4611 - val_mean_absolute_error: 0.4611 - val_soft_acc: 0.6336\n",
      "Epoch 131/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4752 - mean_absolute_error: 0.4752 - soft_acc: 0.6100\n",
      "Epoch 00131: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5537 - mean_absolute_error: 0.5537 - soft_acc: 0.5578 - val_loss: 0.6327 - val_mean_absolute_error: 0.6327 - val_soft_acc: 0.4543\n",
      "Epoch 132/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.8307 - mean_absolute_error: 0.8307 - soft_acc: 0.4400\n",
      "Epoch 00132: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.7950 - mean_absolute_error: 0.7950 - soft_acc: 0.3800 - val_loss: 0.3228 - val_mean_absolute_error: 0.3228 - val_soft_acc: 0.6857\n",
      "Epoch 133/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4950 - mean_absolute_error: 0.4950 - soft_acc: 0.6200\n",
      "Epoch 00133: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5989 - mean_absolute_error: 0.5989 - soft_acc: 0.5494 - val_loss: 0.3857 - val_mean_absolute_error: 0.3857 - val_soft_acc: 0.7021\n",
      "Epoch 134/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6400 - mean_absolute_error: 0.6400 - soft_acc: 0.4500\n",
      "Epoch 00134: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5580 - mean_absolute_error: 0.5580 - soft_acc: 0.5639 - val_loss: 0.3631 - val_mean_absolute_error: 0.3631 - val_soft_acc: 0.7250\n",
      "Epoch 135/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6226 - mean_absolute_error: 0.6226 - soft_acc: 0.4800\n",
      "Epoch 00135: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5232 - mean_absolute_error: 0.5232 - soft_acc: 0.5928 - val_loss: 0.3174 - val_mean_absolute_error: 0.3174 - val_soft_acc: 0.7936\n",
      "Epoch 136/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3658 - mean_absolute_error: 0.3658 - soft_acc: 0.7300\n",
      "Epoch 00136: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4605 - mean_absolute_error: 0.4605 - soft_acc: 0.6028 - val_loss: 0.3253 - val_mean_absolute_error: 0.3253 - val_soft_acc: 0.7807\n",
      "Epoch 137/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3376 - mean_absolute_error: 0.3376 - soft_acc: 0.7300\n",
      "Epoch 00137: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4681 - mean_absolute_error: 0.4681 - soft_acc: 0.5961 - val_loss: 0.3451 - val_mean_absolute_error: 0.3451 - val_soft_acc: 0.7114\n",
      "Epoch 138/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.7600\n",
      "Epoch 00138: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4497 - mean_absolute_error: 0.4497 - soft_acc: 0.6389 - val_loss: 0.4134 - val_mean_absolute_error: 0.4134 - val_soft_acc: 0.6507\n",
      "Epoch 139/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4787 - mean_absolute_error: 0.4787 - soft_acc: 0.6400\n",
      "Epoch 00139: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4458 - mean_absolute_error: 0.4458 - soft_acc: 0.6094 - val_loss: 0.3686 - val_mean_absolute_error: 0.3686 - val_soft_acc: 0.7529\n",
      "Epoch 140/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4392 - mean_absolute_error: 0.4392 - soft_acc: 0.6600\n",
      "Epoch 00140: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3969 - mean_absolute_error: 0.3969 - soft_acc: 0.6928 - val_loss: 0.3339 - val_mean_absolute_error: 0.3339 - val_soft_acc: 0.7729\n",
      "Epoch 141/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4152 - mean_absolute_error: 0.4152 - soft_acc: 0.6600\n",
      "Epoch 00141: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4066 - mean_absolute_error: 0.4066 - soft_acc: 0.6911 - val_loss: 0.3247 - val_mean_absolute_error: 0.3247 - val_soft_acc: 0.7550\n",
      "Epoch 142/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4373 - mean_absolute_error: 0.4373 - soft_acc: 0.6500\n",
      "Epoch 00142: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3907 - mean_absolute_error: 0.3907 - soft_acc: 0.7217 - val_loss: 0.3251 - val_mean_absolute_error: 0.3251 - val_soft_acc: 0.7293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4270 - mean_absolute_error: 0.4270 - soft_acc: 0.7100\n",
      "Epoch 00143: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4152 - mean_absolute_error: 0.4152 - soft_acc: 0.6800 - val_loss: 0.3238 - val_mean_absolute_error: 0.3238 - val_soft_acc: 0.7550\n",
      "Epoch 144/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3755 - mean_absolute_error: 0.3755 - soft_acc: 0.7900\n",
      "Epoch 00144: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3863 - mean_absolute_error: 0.3863 - soft_acc: 0.7422 - val_loss: 0.3181 - val_mean_absolute_error: 0.3181 - val_soft_acc: 0.7679\n",
      "Epoch 145/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4374 - mean_absolute_error: 0.4374 - soft_acc: 0.6200\n",
      "Epoch 00145: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4090 - mean_absolute_error: 0.4090 - soft_acc: 0.6589 - val_loss: 0.3343 - val_mean_absolute_error: 0.3343 - val_soft_acc: 0.7907\n",
      "Epoch 146/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3711 - mean_absolute_error: 0.3711 - soft_acc: 0.7400\n",
      "Epoch 00146: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4092 - mean_absolute_error: 0.4092 - soft_acc: 0.6878 - val_loss: 0.3956 - val_mean_absolute_error: 0.3956 - val_soft_acc: 0.6350\n",
      "Epoch 147/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3950 - mean_absolute_error: 0.3950 - soft_acc: 0.7300\n",
      "Epoch 00147: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4185 - mean_absolute_error: 0.4185 - soft_acc: 0.6844 - val_loss: 0.3575 - val_mean_absolute_error: 0.3575 - val_soft_acc: 0.7221\n",
      "Epoch 148/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4311 - mean_absolute_error: 0.4311 - soft_acc: 0.7000\n",
      "Epoch 00148: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3918 - mean_absolute_error: 0.3918 - soft_acc: 0.7028 - val_loss: 0.3435 - val_mean_absolute_error: 0.3435 - val_soft_acc: 0.7679\n",
      "Epoch 149/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3682 - mean_absolute_error: 0.3682 - soft_acc: 0.6900\n",
      "Epoch 00149: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3857 - mean_absolute_error: 0.3857 - soft_acc: 0.6983 - val_loss: 0.4355 - val_mean_absolute_error: 0.4355 - val_soft_acc: 0.6229\n",
      "Epoch 150/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4598 - mean_absolute_error: 0.4598 - soft_acc: 0.5700\n",
      "Epoch 00150: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4552 - mean_absolute_error: 0.4552 - soft_acc: 0.6428 - val_loss: 0.4282 - val_mean_absolute_error: 0.4282 - val_soft_acc: 0.6971\n",
      "Epoch 151/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4309 - mean_absolute_error: 0.4309 - soft_acc: 0.6500\n",
      "Epoch 00151: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4312 - mean_absolute_error: 0.4312 - soft_acc: 0.6494 - val_loss: 0.3418 - val_mean_absolute_error: 0.3418 - val_soft_acc: 0.7707\n",
      "Epoch 152/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5029 - mean_absolute_error: 0.5029 - soft_acc: 0.6500\n",
      "Epoch 00152: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5090 - mean_absolute_error: 0.5090 - soft_acc: 0.5978 - val_loss: 0.3723 - val_mean_absolute_error: 0.3723 - val_soft_acc: 0.7379\n",
      "Epoch 153/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6509 - mean_absolute_error: 0.6509 - soft_acc: 0.4800\n",
      "Epoch 00153: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5578 - mean_absolute_error: 0.5578 - soft_acc: 0.6089 - val_loss: 0.3314 - val_mean_absolute_error: 0.3314 - val_soft_acc: 0.7343\n",
      "Epoch 154/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4861 - mean_absolute_error: 0.4861 - soft_acc: 0.5800\n",
      "Epoch 00154: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5516 - mean_absolute_error: 0.5516 - soft_acc: 0.5511 - val_loss: 0.4368 - val_mean_absolute_error: 0.4368 - val_soft_acc: 0.6314\n",
      "Epoch 155/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4997 - mean_absolute_error: 0.4997 - soft_acc: 0.5800\n",
      "Epoch 00155: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4850 - mean_absolute_error: 0.4850 - soft_acc: 0.6106 - val_loss: 0.5474 - val_mean_absolute_error: 0.5474 - val_soft_acc: 0.5429\n",
      "Epoch 156/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6609 - mean_absolute_error: 0.6609 - soft_acc: 0.5000\n",
      "Epoch 00156: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5543 - mean_absolute_error: 0.5543 - soft_acc: 0.5650 - val_loss: 0.4919 - val_mean_absolute_error: 0.4919 - val_soft_acc: 0.5529\n",
      "Epoch 157/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5432 - mean_absolute_error: 0.5432 - soft_acc: 0.5400\n",
      "Epoch 00157: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5511 - mean_absolute_error: 0.5511 - soft_acc: 0.5661 - val_loss: 0.3329 - val_mean_absolute_error: 0.3329 - val_soft_acc: 0.7479\n",
      "Epoch 158/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4025 - mean_absolute_error: 0.4025 - soft_acc: 0.6800\n",
      "Epoch 00158: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4592 - mean_absolute_error: 0.4592 - soft_acc: 0.6211 - val_loss: 0.3196 - val_mean_absolute_error: 0.3196 - val_soft_acc: 0.7600\n",
      "Epoch 159/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5563 - mean_absolute_error: 0.5563 - soft_acc: 0.5300\n",
      "Epoch 00159: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4536 - mean_absolute_error: 0.4536 - soft_acc: 0.6894 - val_loss: 0.3221 - val_mean_absolute_error: 0.3221 - val_soft_acc: 0.8243\n",
      "Epoch 160/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3942 - mean_absolute_error: 0.3942 - soft_acc: 0.6400\n",
      "Epoch 00160: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3979 - mean_absolute_error: 0.3979 - soft_acc: 0.6794 - val_loss: 0.3639 - val_mean_absolute_error: 0.3639 - val_soft_acc: 0.7171\n",
      "Epoch 161/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4230 - mean_absolute_error: 0.4230 - soft_acc: 0.6800\n",
      "Epoch 00161: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4178 - mean_absolute_error: 0.4178 - soft_acc: 0.6794 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.5064\n",
      "Epoch 162/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4242 - mean_absolute_error: 0.4242 - soft_acc: 0.7000\n",
      "Epoch 00162: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4363 - mean_absolute_error: 0.4363 - soft_acc: 0.6900 - val_loss: 0.3576 - val_mean_absolute_error: 0.3576 - val_soft_acc: 0.7836\n",
      "Epoch 163/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4487 - mean_absolute_error: 0.4487 - soft_acc: 0.6100\n",
      "Epoch 00163: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4048 - mean_absolute_error: 0.4048 - soft_acc: 0.7139 - val_loss: 0.4213 - val_mean_absolute_error: 0.4213 - val_soft_acc: 0.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4697 - mean_absolute_error: 0.4697 - soft_acc: 0.6500\n",
      "Epoch 00164: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4230 - mean_absolute_error: 0.4230 - soft_acc: 0.6622 - val_loss: 0.3859 - val_mean_absolute_error: 0.3859 - val_soft_acc: 0.6943\n",
      "Epoch 165/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3746 - mean_absolute_error: 0.3746 - soft_acc: 0.7600\n",
      "Epoch 00165: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4320 - mean_absolute_error: 0.4320 - soft_acc: 0.6906 - val_loss: 0.3902 - val_mean_absolute_error: 0.3902 - val_soft_acc: 0.6864\n",
      "Epoch 166/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4217 - mean_absolute_error: 0.4217 - soft_acc: 0.6900\n",
      "Epoch 00166: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4287 - mean_absolute_error: 0.4287 - soft_acc: 0.6717 - val_loss: 0.3739 - val_mean_absolute_error: 0.3739 - val_soft_acc: 0.7400\n",
      "Epoch 167/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3994 - mean_absolute_error: 0.3994 - soft_acc: 0.7400\n",
      "Epoch 00167: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4204 - mean_absolute_error: 0.4204 - soft_acc: 0.6489 - val_loss: 0.3167 - val_mean_absolute_error: 0.3167 - val_soft_acc: 0.7471\n",
      "Epoch 168/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3877 - mean_absolute_error: 0.3877 - soft_acc: 0.7100\n",
      "Epoch 00168: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4166 - mean_absolute_error: 0.4166 - soft_acc: 0.7000 - val_loss: 0.3462 - val_mean_absolute_error: 0.3462 - val_soft_acc: 0.7450\n",
      "Epoch 169/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5710 - mean_absolute_error: 0.5710 - soft_acc: 0.4500\n",
      "Epoch 00169: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5296 - mean_absolute_error: 0.5296 - soft_acc: 0.5411 - val_loss: 0.3206 - val_mean_absolute_error: 0.3206 - val_soft_acc: 0.7500\n",
      "Epoch 170/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4347 - mean_absolute_error: 0.4347 - soft_acc: 0.6600\n",
      "Epoch 00170: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5881 - mean_absolute_error: 0.5881 - soft_acc: 0.5422 - val_loss: 0.3505 - val_mean_absolute_error: 0.3505 - val_soft_acc: 0.7371\n",
      "Epoch 171/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3793 - mean_absolute_error: 0.3793 - soft_acc: 0.6900\n",
      "Epoch 00171: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4714 - mean_absolute_error: 0.4714 - soft_acc: 0.5683 - val_loss: 0.4572 - val_mean_absolute_error: 0.4572 - val_soft_acc: 0.6593\n",
      "Epoch 172/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4915 - mean_absolute_error: 0.4915 - soft_acc: 0.5600\n",
      "Epoch 00172: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4469 - mean_absolute_error: 0.4469 - soft_acc: 0.6511 - val_loss: 0.4466 - val_mean_absolute_error: 0.4466 - val_soft_acc: 0.6207\n",
      "Epoch 173/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4242 - mean_absolute_error: 0.4242 - soft_acc: 0.6500\n",
      "Epoch 00173: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4267 - mean_absolute_error: 0.4267 - soft_acc: 0.6606 - val_loss: 0.4067 - val_mean_absolute_error: 0.4067 - val_soft_acc: 0.6686\n",
      "Epoch 174/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3811 - mean_absolute_error: 0.3811 - soft_acc: 0.7300\n",
      "Epoch 00174: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4186 - mean_absolute_error: 0.4186 - soft_acc: 0.6828 - val_loss: 0.3576 - val_mean_absolute_error: 0.3576 - val_soft_acc: 0.7529\n",
      "Epoch 175/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4102 - mean_absolute_error: 0.4102 - soft_acc: 0.6800\n",
      "Epoch 00175: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4086 - mean_absolute_error: 0.4086 - soft_acc: 0.6822 - val_loss: 0.3316 - val_mean_absolute_error: 0.3316 - val_soft_acc: 0.7371\n",
      "Epoch 176/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4261 - mean_absolute_error: 0.4261 - soft_acc: 0.6900\n",
      "Epoch 00176: val_mean_absolute_error did not improve from 0.31311\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4250 - mean_absolute_error: 0.4250 - soft_acc: 0.6811 - val_loss: 0.3147 - val_mean_absolute_error: 0.3147 - val_soft_acc: 0.8086\n",
      "Epoch 177/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4389 - mean_absolute_error: 0.4389 - soft_acc: 0.6400\n",
      "Epoch 00177: val_mean_absolute_error improved from 0.31311 to 0.31177, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 98us/sample - loss: 0.4408 - mean_absolute_error: 0.4408 - soft_acc: 0.6644 - val_loss: 0.3118 - val_mean_absolute_error: 0.3118 - val_soft_acc: 0.7729\n",
      "Epoch 178/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4631 - mean_absolute_error: 0.4631 - soft_acc: 0.6100\n",
      "Epoch 00178: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4664 - mean_absolute_error: 0.4664 - soft_acc: 0.6500 - val_loss: 0.3701 - val_mean_absolute_error: 0.3701 - val_soft_acc: 0.7171\n",
      "Epoch 179/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4164 - mean_absolute_error: 0.4164 - soft_acc: 0.7500\n",
      "Epoch 00179: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4053 - mean_absolute_error: 0.4053 - soft_acc: 0.6783 - val_loss: 0.4373 - val_mean_absolute_error: 0.4373 - val_soft_acc: 0.6386\n",
      "Epoch 180/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4237 - mean_absolute_error: 0.4237 - soft_acc: 0.7400\n",
      "Epoch 00180: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4084 - mean_absolute_error: 0.4084 - soft_acc: 0.7061 - val_loss: 0.5308 - val_mean_absolute_error: 0.5308 - val_soft_acc: 0.5686\n",
      "Epoch 181/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5184 - mean_absolute_error: 0.5184 - soft_acc: 0.6000\n",
      "Epoch 00181: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4826 - mean_absolute_error: 0.4826 - soft_acc: 0.6117 - val_loss: 0.4004 - val_mean_absolute_error: 0.4004 - val_soft_acc: 0.7429\n",
      "Epoch 182/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4894 - mean_absolute_error: 0.4894 - soft_acc: 0.7400\n",
      "Epoch 00182: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4514 - mean_absolute_error: 0.4514 - soft_acc: 0.6306 - val_loss: 0.3816 - val_mean_absolute_error: 0.3816 - val_soft_acc: 0.6814\n",
      "Epoch 183/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3702 - mean_absolute_error: 0.3702 - soft_acc: 0.7200\n",
      "Epoch 00183: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4236 - mean_absolute_error: 0.4236 - soft_acc: 0.6789 - val_loss: 0.3769 - val_mean_absolute_error: 0.3769 - val_soft_acc: 0.7043\n",
      "Epoch 184/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3295 - mean_absolute_error: 0.3295 - soft_acc: 0.7600\n",
      "Epoch 00184: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3737 - mean_absolute_error: 0.3737 - soft_acc: 0.7178 - val_loss: 0.3830 - val_mean_absolute_error: 0.3830 - val_soft_acc: 0.7064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4316 - mean_absolute_error: 0.4316 - soft_acc: 0.6800\n",
      "Epoch 00185: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4033 - mean_absolute_error: 0.4033 - soft_acc: 0.6672 - val_loss: 0.5659 - val_mean_absolute_error: 0.5659 - val_soft_acc: 0.5279\n",
      "Epoch 186/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5474 - mean_absolute_error: 0.5474 - soft_acc: 0.5900\n",
      "Epoch 00186: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5110 - mean_absolute_error: 0.5110 - soft_acc: 0.5561 - val_loss: 0.4413 - val_mean_absolute_error: 0.4413 - val_soft_acc: 0.6621\n",
      "Epoch 187/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4545 - mean_absolute_error: 0.4545 - soft_acc: 0.6200\n",
      "Epoch 00187: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4397 - mean_absolute_error: 0.4397 - soft_acc: 0.6628 - val_loss: 0.4391 - val_mean_absolute_error: 0.4391 - val_soft_acc: 0.6700\n",
      "Epoch 188/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3706 - mean_absolute_error: 0.3706 - soft_acc: 0.7300\n",
      "Epoch 00188: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4027 - mean_absolute_error: 0.4027 - soft_acc: 0.7083 - val_loss: 0.4175 - val_mean_absolute_error: 0.4175 - val_soft_acc: 0.6771\n",
      "Epoch 189/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3598 - mean_absolute_error: 0.3598 - soft_acc: 0.7600\n",
      "Epoch 00189: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4061 - mean_absolute_error: 0.4061 - soft_acc: 0.6600 - val_loss: 0.4500 - val_mean_absolute_error: 0.4500 - val_soft_acc: 0.6136\n",
      "Epoch 190/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4859 - mean_absolute_error: 0.4859 - soft_acc: 0.6800\n",
      "Epoch 00190: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4429 - mean_absolute_error: 0.4429 - soft_acc: 0.6667 - val_loss: 0.3299 - val_mean_absolute_error: 0.3299 - val_soft_acc: 0.7957\n",
      "Epoch 191/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3967 - mean_absolute_error: 0.3967 - soft_acc: 0.6900\n",
      "Epoch 00191: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3860 - mean_absolute_error: 0.3860 - soft_acc: 0.7228 - val_loss: 0.4203 - val_mean_absolute_error: 0.4203 - val_soft_acc: 0.5950\n",
      "Epoch 192/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4234 - mean_absolute_error: 0.4234 - soft_acc: 0.6700\n",
      "Epoch 00192: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4227 - mean_absolute_error: 0.4227 - soft_acc: 0.6244 - val_loss: 0.3293 - val_mean_absolute_error: 0.3293 - val_soft_acc: 0.7471\n",
      "Epoch 193/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3946 - mean_absolute_error: 0.3946 - soft_acc: 0.6800\n",
      "Epoch 00193: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4059 - mean_absolute_error: 0.4059 - soft_acc: 0.7339 - val_loss: 0.3768 - val_mean_absolute_error: 0.3768 - val_soft_acc: 0.7021\n",
      "Epoch 194/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3660 - mean_absolute_error: 0.3660 - soft_acc: 0.7900\n",
      "Epoch 00194: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4116 - mean_absolute_error: 0.4116 - soft_acc: 0.6789 - val_loss: 0.3763 - val_mean_absolute_error: 0.3763 - val_soft_acc: 0.7457\n",
      "Epoch 195/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3845 - mean_absolute_error: 0.3845 - soft_acc: 0.6600\n",
      "Epoch 00195: val_mean_absolute_error did not improve from 0.31177\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4769 - mean_absolute_error: 0.4769 - soft_acc: 0.5967 - val_loss: 0.3134 - val_mean_absolute_error: 0.3134 - val_soft_acc: 0.7907\n",
      "Epoch 196/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4603 - mean_absolute_error: 0.4603 - soft_acc: 0.6700\n",
      "Epoch 00196: val_mean_absolute_error improved from 0.31177 to 0.31139, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.4158 - mean_absolute_error: 0.4158 - soft_acc: 0.7206 - val_loss: 0.3114 - val_mean_absolute_error: 0.3114 - val_soft_acc: 0.7343\n",
      "Epoch 197/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4873 - mean_absolute_error: 0.4873 - soft_acc: 0.6100\n",
      "Epoch 00197: val_mean_absolute_error improved from 0.31139 to 0.30913, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 96us/sample - loss: 0.4585 - mean_absolute_error: 0.4585 - soft_acc: 0.6411 - val_loss: 0.3091 - val_mean_absolute_error: 0.3091 - val_soft_acc: 0.7829\n",
      "Epoch 198/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6814 - mean_absolute_error: 0.6814 - soft_acc: 0.4400\n",
      "Epoch 00198: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5297 - mean_absolute_error: 0.5297 - soft_acc: 0.5828 - val_loss: 0.3164 - val_mean_absolute_error: 0.3164 - val_soft_acc: 0.7857\n",
      "Epoch 199/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5152 - mean_absolute_error: 0.5152 - soft_acc: 0.6000\n",
      "Epoch 00199: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.5259 - mean_absolute_error: 0.5259 - soft_acc: 0.5183 - val_loss: 0.5116 - val_mean_absolute_error: 0.5116 - val_soft_acc: 0.5964\n",
      "Epoch 200/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3966 - mean_absolute_error: 0.3966 - soft_acc: 0.6700\n",
      "Epoch 00200: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4038 - mean_absolute_error: 0.4038 - soft_acc: 0.6650 - val_loss: 0.4507 - val_mean_absolute_error: 0.4507 - val_soft_acc: 0.6436\n",
      "Epoch 201/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3849 - mean_absolute_error: 0.3849 - soft_acc: 0.7200\n",
      "Epoch 00201: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4001 - mean_absolute_error: 0.4001 - soft_acc: 0.6378 - val_loss: 0.4623 - val_mean_absolute_error: 0.4623 - val_soft_acc: 0.6236\n",
      "Epoch 202/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3544 - mean_absolute_error: 0.3544 - soft_acc: 0.8300\n",
      "Epoch 00202: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4116 - mean_absolute_error: 0.4116 - soft_acc: 0.7239 - val_loss: 0.5347 - val_mean_absolute_error: 0.5347 - val_soft_acc: 0.5686\n",
      "Epoch 203/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5493 - mean_absolute_error: 0.5493 - soft_acc: 0.6100\n",
      "Epoch 00203: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4395 - mean_absolute_error: 0.4395 - soft_acc: 0.6894 - val_loss: 0.4027 - val_mean_absolute_error: 0.4027 - val_soft_acc: 0.7071\n",
      "Epoch 204/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3709 - mean_absolute_error: 0.3709 - soft_acc: 0.7200\n",
      "Epoch 00204: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3978 - mean_absolute_error: 0.3978 - soft_acc: 0.6544 - val_loss: 0.3958 - val_mean_absolute_error: 0.3958 - val_soft_acc: 0.6736\n",
      "Epoch 205/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3687 - mean_absolute_error: 0.3687 - soft_acc: 0.7600\n",
      "Epoch 00205: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3926 - mean_absolute_error: 0.3926 - soft_acc: 0.7217 - val_loss: 0.4140 - val_mean_absolute_error: 0.4140 - val_soft_acc: 0.6486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3699 - mean_absolute_error: 0.3699 - soft_acc: 0.7200\n",
      "Epoch 00206: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3773 - mean_absolute_error: 0.3773 - soft_acc: 0.6833 - val_loss: 0.3587 - val_mean_absolute_error: 0.3587 - val_soft_acc: 0.7243\n",
      "Epoch 207/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4038 - mean_absolute_error: 0.4038 - soft_acc: 0.6400\n",
      "Epoch 00207: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3779 - mean_absolute_error: 0.3779 - soft_acc: 0.7178 - val_loss: 0.3477 - val_mean_absolute_error: 0.3477 - val_soft_acc: 0.7500\n",
      "Epoch 208/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3474 - mean_absolute_error: 0.3474 - soft_acc: 0.7400\n",
      "Epoch 00208: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3985 - mean_absolute_error: 0.3985 - soft_acc: 0.6989 - val_loss: 0.5096 - val_mean_absolute_error: 0.5096 - val_soft_acc: 0.5857\n",
      "Epoch 209/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4494 - mean_absolute_error: 0.4494 - soft_acc: 0.6300\n",
      "Epoch 00209: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4420 - mean_absolute_error: 0.4420 - soft_acc: 0.6561 - val_loss: 0.4605 - val_mean_absolute_error: 0.4605 - val_soft_acc: 0.6671\n",
      "Epoch 210/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4246 - mean_absolute_error: 0.4246 - soft_acc: 0.6800\n",
      "Epoch 00210: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3986 - mean_absolute_error: 0.3986 - soft_acc: 0.6783 - val_loss: 0.4604 - val_mean_absolute_error: 0.4604 - val_soft_acc: 0.5907\n",
      "Epoch 211/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4106 - mean_absolute_error: 0.4106 - soft_acc: 0.6900\n",
      "Epoch 00211: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3882 - mean_absolute_error: 0.3882 - soft_acc: 0.6989 - val_loss: 0.3235 - val_mean_absolute_error: 0.3235 - val_soft_acc: 0.8186\n",
      "Epoch 212/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4155 - mean_absolute_error: 0.4155 - soft_acc: 0.6900\n",
      "Epoch 00212: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4516 - mean_absolute_error: 0.4516 - soft_acc: 0.6411 - val_loss: 0.3140 - val_mean_absolute_error: 0.3140 - val_soft_acc: 0.7779\n",
      "Epoch 213/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4088 - mean_absolute_error: 0.4088 - soft_acc: 0.7300\n",
      "Epoch 00213: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4420 - mean_absolute_error: 0.4420 - soft_acc: 0.6717 - val_loss: 0.3349 - val_mean_absolute_error: 0.3349 - val_soft_acc: 0.7371\n",
      "Epoch 214/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3550 - mean_absolute_error: 0.3550 - soft_acc: 0.7000\n",
      "Epoch 00214: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5538 - mean_absolute_error: 0.5538 - soft_acc: 0.5789 - val_loss: 0.5036 - val_mean_absolute_error: 0.5036 - val_soft_acc: 0.6043\n",
      "Epoch 215/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4297 - mean_absolute_error: 0.4297 - soft_acc: 0.6700\n",
      "Epoch 00215: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4145 - mean_absolute_error: 0.4145 - soft_acc: 0.6794 - val_loss: 0.5921 - val_mean_absolute_error: 0.5921 - val_soft_acc: 0.5207\n",
      "Epoch 216/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4982 - mean_absolute_error: 0.4982 - soft_acc: 0.6800\n",
      "Epoch 00216: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4433 - mean_absolute_error: 0.4433 - soft_acc: 0.6606 - val_loss: 0.5461 - val_mean_absolute_error: 0.5461 - val_soft_acc: 0.4893\n",
      "Epoch 217/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4307 - mean_absolute_error: 0.4307 - soft_acc: 0.7200\n",
      "Epoch 00217: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4442 - mean_absolute_error: 0.4442 - soft_acc: 0.7056 - val_loss: 0.4677 - val_mean_absolute_error: 0.4677 - val_soft_acc: 0.5929\n",
      "Epoch 218/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4268 - mean_absolute_error: 0.4268 - soft_acc: 0.7000\n",
      "Epoch 00218: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4132 - mean_absolute_error: 0.4132 - soft_acc: 0.7017 - val_loss: 0.4349 - val_mean_absolute_error: 0.4349 - val_soft_acc: 0.6750\n",
      "Epoch 219/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3687 - mean_absolute_error: 0.3687 - soft_acc: 0.7200\n",
      "Epoch 00219: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4025 - mean_absolute_error: 0.4025 - soft_acc: 0.6933 - val_loss: 0.4421 - val_mean_absolute_error: 0.4421 - val_soft_acc: 0.5979\n",
      "Epoch 220/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3859 - mean_absolute_error: 0.3859 - soft_acc: 0.7000\n",
      "Epoch 00220: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4284 - mean_absolute_error: 0.4284 - soft_acc: 0.6211 - val_loss: 0.6071 - val_mean_absolute_error: 0.6071 - val_soft_acc: 0.4157\n",
      "Epoch 221/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5080 - mean_absolute_error: 0.5080 - soft_acc: 0.5600\n",
      "Epoch 00221: val_mean_absolute_error did not improve from 0.30913\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5599 - mean_absolute_error: 0.5599 - soft_acc: 0.5639 - val_loss: 0.3622 - val_mean_absolute_error: 0.3622 - val_soft_acc: 0.7429\n",
      "Epoch 222/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3822 - mean_absolute_error: 0.3822 - soft_acc: 0.7100\n",
      "Epoch 00222: val_mean_absolute_error improved from 0.30913 to 0.30909, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 97us/sample - loss: 0.4395 - mean_absolute_error: 0.4395 - soft_acc: 0.6072 - val_loss: 0.3091 - val_mean_absolute_error: 0.3091 - val_soft_acc: 0.7650\n",
      "Epoch 223/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5151 - mean_absolute_error: 0.5151 - soft_acc: 0.5600\n",
      "Epoch 00223: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4847 - mean_absolute_error: 0.4847 - soft_acc: 0.5867 - val_loss: 0.3260 - val_mean_absolute_error: 0.3260 - val_soft_acc: 0.7936\n",
      "Epoch 224/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5743 - mean_absolute_error: 0.5743 - soft_acc: 0.5600\n",
      "Epoch 00224: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4464 - mean_absolute_error: 0.4464 - soft_acc: 0.6561 - val_loss: 0.3417 - val_mean_absolute_error: 0.3417 - val_soft_acc: 0.7421\n",
      "Epoch 225/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4704 - mean_absolute_error: 0.4704 - soft_acc: 0.5700\n",
      "Epoch 00225: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4057 - mean_absolute_error: 0.4057 - soft_acc: 0.7050 - val_loss: 0.4211 - val_mean_absolute_error: 0.4211 - val_soft_acc: 0.6307\n",
      "Epoch 226/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3444 - mean_absolute_error: 0.3444 - soft_acc: 0.7700\n",
      "Epoch 00226: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4128 - mean_absolute_error: 0.4128 - soft_acc: 0.6844 - val_loss: 0.5583 - val_mean_absolute_error: 0.5583 - val_soft_acc: 0.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3922 - mean_absolute_error: 0.3922 - soft_acc: 0.7200\n",
      "Epoch 00227: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4046 - mean_absolute_error: 0.4046 - soft_acc: 0.6806 - val_loss: 0.4211 - val_mean_absolute_error: 0.4211 - val_soft_acc: 0.6593\n",
      "Epoch 228/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3427 - mean_absolute_error: 0.3427 - soft_acc: 0.7300\n",
      "Epoch 00228: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4107 - mean_absolute_error: 0.4107 - soft_acc: 0.6689 - val_loss: 0.4613 - val_mean_absolute_error: 0.4613 - val_soft_acc: 0.6057\n",
      "Epoch 229/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3350 - mean_absolute_error: 0.3350 - soft_acc: 0.7600\n",
      "Epoch 00229: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3870 - mean_absolute_error: 0.3870 - soft_acc: 0.7011 - val_loss: 0.3924 - val_mean_absolute_error: 0.3924 - val_soft_acc: 0.6436\n",
      "Epoch 230/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4056 - mean_absolute_error: 0.4056 - soft_acc: 0.7200\n",
      "Epoch 00230: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3892 - mean_absolute_error: 0.3892 - soft_acc: 0.6806 - val_loss: 0.3971 - val_mean_absolute_error: 0.3971 - val_soft_acc: 0.7100\n",
      "Epoch 231/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3384 - mean_absolute_error: 0.3384 - soft_acc: 0.7600\n",
      "Epoch 00231: val_mean_absolute_error did not improve from 0.30909\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3553 - mean_absolute_error: 0.3553 - soft_acc: 0.7361 - val_loss: 0.3100 - val_mean_absolute_error: 0.3100 - val_soft_acc: 0.8214\n",
      "Epoch 232/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4772 - mean_absolute_error: 0.4772 - soft_acc: 0.5800\n",
      "Epoch 00232: val_mean_absolute_error improved from 0.30909 to 0.30867, saving model to ./model_adr1/model_rank1.h5\n",
      "512/512 [==============================] - 0s 91us/sample - loss: 0.4806 - mean_absolute_error: 0.4806 - soft_acc: 0.6283 - val_loss: 0.3087 - val_mean_absolute_error: 0.3087 - val_soft_acc: 0.7879\n",
      "Epoch 233/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5502 - mean_absolute_error: 0.5502 - soft_acc: 0.5600\n",
      "Epoch 00233: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.5274 - mean_absolute_error: 0.5274 - soft_acc: 0.6167 - val_loss: 0.4446 - val_mean_absolute_error: 0.4446 - val_soft_acc: 0.6771\n",
      "Epoch 234/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3993 - mean_absolute_error: 0.3993 - soft_acc: 0.7500\n",
      "Epoch 00234: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4458 - mean_absolute_error: 0.4458 - soft_acc: 0.6167 - val_loss: 0.4727 - val_mean_absolute_error: 0.4727 - val_soft_acc: 0.5986\n",
      "Epoch 235/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4097 - mean_absolute_error: 0.4097 - soft_acc: 0.7100\n",
      "Epoch 00235: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4237 - mean_absolute_error: 0.4237 - soft_acc: 0.6528 - val_loss: 0.4873 - val_mean_absolute_error: 0.4873 - val_soft_acc: 0.5214\n",
      "Epoch 236/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4312 - mean_absolute_error: 0.4312 - soft_acc: 0.7000\n",
      "Epoch 00236: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3830 - mean_absolute_error: 0.3830 - soft_acc: 0.7094 - val_loss: 0.4313 - val_mean_absolute_error: 0.4313 - val_soft_acc: 0.6107\n",
      "Epoch 237/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3677 - mean_absolute_error: 0.3677 - soft_acc: 0.7700\n",
      "Epoch 00237: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3699 - mean_absolute_error: 0.3699 - soft_acc: 0.7256 - val_loss: 0.4263 - val_mean_absolute_error: 0.4263 - val_soft_acc: 0.6721\n",
      "Epoch 238/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3904 - mean_absolute_error: 0.3904 - soft_acc: 0.6900\n",
      "Epoch 00238: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3727 - mean_absolute_error: 0.3727 - soft_acc: 0.7489 - val_loss: 0.3726 - val_mean_absolute_error: 0.3726 - val_soft_acc: 0.6864\n",
      "Epoch 239/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3769 - mean_absolute_error: 0.3769 - soft_acc: 0.7000\n",
      "Epoch 00239: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3658 - mean_absolute_error: 0.3658 - soft_acc: 0.7483 - val_loss: 0.5362 - val_mean_absolute_error: 0.5362 - val_soft_acc: 0.5329\n",
      "Epoch 240/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3793 - mean_absolute_error: 0.3793 - soft_acc: 0.7300\n",
      "Epoch 00240: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3991 - mean_absolute_error: 0.3991 - soft_acc: 0.7183 - val_loss: 0.4855 - val_mean_absolute_error: 0.4855 - val_soft_acc: 0.5936\n",
      "Epoch 241/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3879 - mean_absolute_error: 0.3879 - soft_acc: 0.7600\n",
      "Epoch 00241: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4164 - mean_absolute_error: 0.4164 - soft_acc: 0.7489 - val_loss: 0.4926 - val_mean_absolute_error: 0.4926 - val_soft_acc: 0.5707\n",
      "Epoch 242/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4029 - mean_absolute_error: 0.4029 - soft_acc: 0.7200\n",
      "Epoch 00242: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3773 - mean_absolute_error: 0.3773 - soft_acc: 0.6972 - val_loss: 0.3825 - val_mean_absolute_error: 0.3825 - val_soft_acc: 0.6964\n",
      "Epoch 243/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3736 - mean_absolute_error: 0.3736 - soft_acc: 0.7300\n",
      "Epoch 00243: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3658 - mean_absolute_error: 0.3658 - soft_acc: 0.7728 - val_loss: 0.4659 - val_mean_absolute_error: 0.4659 - val_soft_acc: 0.6214\n",
      "Epoch 244/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3312 - mean_absolute_error: 0.3312 - soft_acc: 0.7700\n",
      "Epoch 00244: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3662 - mean_absolute_error: 0.3662 - soft_acc: 0.7639 - val_loss: 0.4551 - val_mean_absolute_error: 0.4551 - val_soft_acc: 0.6236\n",
      "Epoch 245/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3561 - mean_absolute_error: 0.3561 - soft_acc: 0.7200\n",
      "Epoch 00245: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.4045 - mean_absolute_error: 0.4045 - soft_acc: 0.7039 - val_loss: 0.4579 - val_mean_absolute_error: 0.4579 - val_soft_acc: 0.6750\n",
      "Epoch 246/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3107 - mean_absolute_error: 0.3107 - soft_acc: 0.8400\n",
      "Epoch 00246: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.3771 - mean_absolute_error: 0.3771 - soft_acc: 0.7594 - val_loss: 0.4345 - val_mean_absolute_error: 0.4345 - val_soft_acc: 0.6464\n",
      "Epoch 247/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3413 - mean_absolute_error: 0.3413 - soft_acc: 0.7600\n",
      "Epoch 00247: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3457 - mean_absolute_error: 0.3457 - soft_acc: 0.7494 - val_loss: 0.6031 - val_mean_absolute_error: 0.6031 - val_soft_acc: 0.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5297 - mean_absolute_error: 0.5297 - soft_acc: 0.5600\n",
      "Epoch 00248: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4354 - mean_absolute_error: 0.4354 - soft_acc: 0.6756 - val_loss: 0.5585 - val_mean_absolute_error: 0.5585 - val_soft_acc: 0.4921\n",
      "Epoch 249/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4451 - mean_absolute_error: 0.4451 - soft_acc: 0.6400\n",
      "Epoch 00249: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4096 - mean_absolute_error: 0.4096 - soft_acc: 0.6433 - val_loss: 0.5649 - val_mean_absolute_error: 0.5649 - val_soft_acc: 0.5357\n",
      "Epoch 250/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5338 - mean_absolute_error: 0.5338 - soft_acc: 0.5400\n",
      "Epoch 00250: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3867 - mean_absolute_error: 0.3867 - soft_acc: 0.7017 - val_loss: 0.3452 - val_mean_absolute_error: 0.3452 - val_soft_acc: 0.7500\n",
      "Epoch 251/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4113 - mean_absolute_error: 0.4113 - soft_acc: 0.7000\n",
      "Epoch 00251: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3982 - mean_absolute_error: 0.3982 - soft_acc: 0.6933 - val_loss: 0.3311 - val_mean_absolute_error: 0.3311 - val_soft_acc: 0.7779\n",
      "Epoch 252/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4391 - mean_absolute_error: 0.4391 - soft_acc: 0.6600\n",
      "Epoch 00252: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3961 - mean_absolute_error: 0.3961 - soft_acc: 0.6922 - val_loss: 0.3234 - val_mean_absolute_error: 0.3234 - val_soft_acc: 0.7621\n",
      "Epoch 253/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4365 - mean_absolute_error: 0.4365 - soft_acc: 0.6200\n",
      "Epoch 00253: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3780 - mean_absolute_error: 0.3780 - soft_acc: 0.7056 - val_loss: 0.4280 - val_mean_absolute_error: 0.4280 - val_soft_acc: 0.6514\n",
      "Epoch 254/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4075 - mean_absolute_error: 0.4075 - soft_acc: 0.6400\n",
      "Epoch 00254: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4343 - mean_absolute_error: 0.4343 - soft_acc: 0.6739 - val_loss: 0.4341 - val_mean_absolute_error: 0.4341 - val_soft_acc: 0.6671\n",
      "Epoch 255/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3414 - mean_absolute_error: 0.3414 - soft_acc: 0.7500\n",
      "Epoch 00255: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3799 - mean_absolute_error: 0.3799 - soft_acc: 0.7356 - val_loss: 0.6227 - val_mean_absolute_error: 0.6227 - val_soft_acc: 0.3879\n",
      "Epoch 256/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4596 - mean_absolute_error: 0.4596 - soft_acc: 0.6300\n",
      "Epoch 00256: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4663 - mean_absolute_error: 0.4663 - soft_acc: 0.6761 - val_loss: 0.3841 - val_mean_absolute_error: 0.3841 - val_soft_acc: 0.7200\n",
      "Epoch 257/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4087 - mean_absolute_error: 0.4087 - soft_acc: 0.6900\n",
      "Epoch 00257: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3860 - mean_absolute_error: 0.3860 - soft_acc: 0.7094 - val_loss: 0.4110 - val_mean_absolute_error: 0.4110 - val_soft_acc: 0.6971\n",
      "Epoch 258/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3575 - mean_absolute_error: 0.3575 - soft_acc: 0.7900\n",
      "Epoch 00258: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3671 - mean_absolute_error: 0.3671 - soft_acc: 0.7500 - val_loss: 0.4559 - val_mean_absolute_error: 0.4559 - val_soft_acc: 0.6364\n",
      "Epoch 259/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3300 - mean_absolute_error: 0.3300 - soft_acc: 0.7900\n",
      "Epoch 00259: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3642 - mean_absolute_error: 0.3642 - soft_acc: 0.7744 - val_loss: 0.5438 - val_mean_absolute_error: 0.5438 - val_soft_acc: 0.5614\n",
      "Epoch 260/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3473 - mean_absolute_error: 0.3473 - soft_acc: 0.7300\n",
      "Epoch 00260: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3720 - mean_absolute_error: 0.3720 - soft_acc: 0.7611 - val_loss: 0.5302 - val_mean_absolute_error: 0.5302 - val_soft_acc: 0.5150\n",
      "Epoch 261/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4075 - mean_absolute_error: 0.4075 - soft_acc: 0.7100\n",
      "Epoch 00261: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3767 - mean_absolute_error: 0.3767 - soft_acc: 0.7178 - val_loss: 0.4261 - val_mean_absolute_error: 0.4261 - val_soft_acc: 0.6436\n",
      "Epoch 262/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3772 - mean_absolute_error: 0.3772 - soft_acc: 0.7300\n",
      "Epoch 00262: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3654 - mean_absolute_error: 0.3654 - soft_acc: 0.7300 - val_loss: 0.7671 - val_mean_absolute_error: 0.7671 - val_soft_acc: 0.3557\n",
      "Epoch 263/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7565 - mean_absolute_error: 0.7565 - soft_acc: 0.3700\n",
      "Epoch 00263: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5916 - mean_absolute_error: 0.5916 - soft_acc: 0.5783 - val_loss: 0.5075 - val_mean_absolute_error: 0.5075 - val_soft_acc: 0.5736\n",
      "Epoch 264/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3671 - mean_absolute_error: 0.3671 - soft_acc: 0.7400\n",
      "Epoch 00264: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4206 - mean_absolute_error: 0.4206 - soft_acc: 0.6283 - val_loss: 0.4705 - val_mean_absolute_error: 0.4705 - val_soft_acc: 0.6214\n",
      "Epoch 265/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3466 - mean_absolute_error: 0.3466 - soft_acc: 0.7200\n",
      "Epoch 00265: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3866 - mean_absolute_error: 0.3866 - soft_acc: 0.7594 - val_loss: 0.5081 - val_mean_absolute_error: 0.5081 - val_soft_acc: 0.5914\n",
      "Epoch 266/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4079 - mean_absolute_error: 0.4079 - soft_acc: 0.6700\n",
      "Epoch 00266: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3802 - mean_absolute_error: 0.3802 - soft_acc: 0.7472 - val_loss: 0.4071 - val_mean_absolute_error: 0.4071 - val_soft_acc: 0.6436\n",
      "Epoch 267/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3502 - mean_absolute_error: 0.3502 - soft_acc: 0.7600\n",
      "Epoch 00267: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3480 - mean_absolute_error: 0.3480 - soft_acc: 0.7511 - val_loss: 0.3626 - val_mean_absolute_error: 0.3626 - val_soft_acc: 0.7321\n",
      "Epoch 268/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3873 - mean_absolute_error: 0.3873 - soft_acc: 0.7200\n",
      "Epoch 00268: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3695 - mean_absolute_error: 0.3695 - soft_acc: 0.7017 - val_loss: 0.3513 - val_mean_absolute_error: 0.3513 - val_soft_acc: 0.7271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4728 - mean_absolute_error: 0.4728 - soft_acc: 0.6700\n",
      "Epoch 00269: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4027 - mean_absolute_error: 0.4027 - soft_acc: 0.6683 - val_loss: 0.5653 - val_mean_absolute_error: 0.5653 - val_soft_acc: 0.4921\n",
      "Epoch 270/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3904 - mean_absolute_error: 0.3904 - soft_acc: 0.7000\n",
      "Epoch 00270: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4631 - mean_absolute_error: 0.4631 - soft_acc: 0.6706 - val_loss: 0.6819 - val_mean_absolute_error: 0.6819 - val_soft_acc: 0.4171\n",
      "Epoch 271/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.4516 - soft_acc: 0.6800\n",
      "Epoch 00271: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5268 - mean_absolute_error: 0.5268 - soft_acc: 0.5911 - val_loss: 0.3464 - val_mean_absolute_error: 0.3464 - val_soft_acc: 0.7500\n",
      "Epoch 272/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3720 - mean_absolute_error: 0.3720 - soft_acc: 0.7300\n",
      "Epoch 00272: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3937 - mean_absolute_error: 0.3937 - soft_acc: 0.7006 - val_loss: 0.4441 - val_mean_absolute_error: 0.4441 - val_soft_acc: 0.6207\n",
      "Epoch 273/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3581 - mean_absolute_error: 0.3581 - soft_acc: 0.7500\n",
      "Epoch 00273: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3566 - mean_absolute_error: 0.3566 - soft_acc: 0.6928 - val_loss: 0.6245 - val_mean_absolute_error: 0.6245 - val_soft_acc: 0.4164\n",
      "Epoch 274/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5282 - mean_absolute_error: 0.5282 - soft_acc: 0.6300\n",
      "Epoch 00274: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4605 - mean_absolute_error: 0.4605 - soft_acc: 0.6172 - val_loss: 0.5866 - val_mean_absolute_error: 0.5866 - val_soft_acc: 0.4671\n",
      "Epoch 275/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4590 - mean_absolute_error: 0.4590 - soft_acc: 0.6000\n",
      "Epoch 00275: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4549 - mean_absolute_error: 0.4549 - soft_acc: 0.6450 - val_loss: 0.3619 - val_mean_absolute_error: 0.3619 - val_soft_acc: 0.7071\n",
      "Epoch 276/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4165 - mean_absolute_error: 0.4165 - soft_acc: 0.7000\n",
      "Epoch 00276: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.4181 - mean_absolute_error: 0.4181 - soft_acc: 0.6567 - val_loss: 0.3129 - val_mean_absolute_error: 0.3129 - val_soft_acc: 0.7750\n",
      "Epoch 277/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5040 - mean_absolute_error: 0.5040 - soft_acc: 0.5200\n",
      "Epoch 00277: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4914 - mean_absolute_error: 0.4914 - soft_acc: 0.6111 - val_loss: 0.4111 - val_mean_absolute_error: 0.4111 - val_soft_acc: 0.7100\n",
      "Epoch 278/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3669 - mean_absolute_error: 0.3669 - soft_acc: 0.7700\n",
      "Epoch 00278: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4130 - mean_absolute_error: 0.4130 - soft_acc: 0.6561 - val_loss: 0.3950 - val_mean_absolute_error: 0.3950 - val_soft_acc: 0.6971\n",
      "Epoch 279/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4057 - mean_absolute_error: 0.4057 - soft_acc: 0.7100\n",
      "Epoch 00279: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4446 - mean_absolute_error: 0.4446 - soft_acc: 0.6878 - val_loss: 0.4330 - val_mean_absolute_error: 0.4330 - val_soft_acc: 0.6771\n",
      "Epoch 280/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3749 - mean_absolute_error: 0.3749 - soft_acc: 0.7300\n",
      "Epoch 00280: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4385 - mean_absolute_error: 0.4385 - soft_acc: 0.6089 - val_loss: 0.4545 - val_mean_absolute_error: 0.4545 - val_soft_acc: 0.6543\n",
      "Epoch 281/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3535 - mean_absolute_error: 0.3535 - soft_acc: 0.7700\n",
      "Epoch 00281: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3830 - mean_absolute_error: 0.3830 - soft_acc: 0.7161 - val_loss: 0.5346 - val_mean_absolute_error: 0.5346 - val_soft_acc: 0.5021\n",
      "Epoch 282/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3563 - mean_absolute_error: 0.3563 - soft_acc: 0.7700\n",
      "Epoch 00282: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3798 - mean_absolute_error: 0.3798 - soft_acc: 0.7422 - val_loss: 0.5562 - val_mean_absolute_error: 0.5562 - val_soft_acc: 0.5150\n",
      "Epoch 283/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2986 - mean_absolute_error: 0.2986 - soft_acc: 0.8100\n",
      "Epoch 00283: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3873 - mean_absolute_error: 0.3873 - soft_acc: 0.7267 - val_loss: 0.4831 - val_mean_absolute_error: 0.4831 - val_soft_acc: 0.6264\n",
      "Epoch 284/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3288 - mean_absolute_error: 0.3288 - soft_acc: 0.7700\n",
      "Epoch 00284: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3508 - mean_absolute_error: 0.3508 - soft_acc: 0.7739 - val_loss: 0.4180 - val_mean_absolute_error: 0.4180 - val_soft_acc: 0.6564\n",
      "Epoch 285/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3589 - mean_absolute_error: 0.3589 - soft_acc: 0.7100\n",
      "Epoch 00285: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3894 - mean_absolute_error: 0.3894 - soft_acc: 0.7272 - val_loss: 0.3709 - val_mean_absolute_error: 0.3709 - val_soft_acc: 0.6557\n",
      "Epoch 286/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3723 - mean_absolute_error: 0.3723 - soft_acc: 0.7100\n",
      "Epoch 00286: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4230 - mean_absolute_error: 0.4230 - soft_acc: 0.6778 - val_loss: 0.4199 - val_mean_absolute_error: 0.4199 - val_soft_acc: 0.7129\n",
      "Epoch 287/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3707 - mean_absolute_error: 0.3707 - soft_acc: 0.7700\n",
      "Epoch 00287: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3430 - mean_absolute_error: 0.3430 - soft_acc: 0.7717 - val_loss: 0.4419 - val_mean_absolute_error: 0.4419 - val_soft_acc: 0.5821\n",
      "Epoch 288/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3417 - mean_absolute_error: 0.3417 - soft_acc: 0.7500\n",
      "Epoch 00288: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3566 - mean_absolute_error: 0.3566 - soft_acc: 0.7678 - val_loss: 0.4155 - val_mean_absolute_error: 0.4155 - val_soft_acc: 0.7257\n",
      "Epoch 289/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3623 - mean_absolute_error: 0.3623 - soft_acc: 0.7300\n",
      "Epoch 00289: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3476 - mean_absolute_error: 0.3476 - soft_acc: 0.7433 - val_loss: 0.4699 - val_mean_absolute_error: 0.4699 - val_soft_acc: 0.6879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3938 - mean_absolute_error: 0.3938 - soft_acc: 0.6900\n",
      "Epoch 00290: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3743 - mean_absolute_error: 0.3743 - soft_acc: 0.7439 - val_loss: 0.5903 - val_mean_absolute_error: 0.5903 - val_soft_acc: 0.4543\n",
      "Epoch 291/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4070 - mean_absolute_error: 0.4070 - soft_acc: 0.6700\n",
      "Epoch 00291: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3977 - mean_absolute_error: 0.3977 - soft_acc: 0.6811 - val_loss: 0.6681 - val_mean_absolute_error: 0.6681 - val_soft_acc: 0.3836\n",
      "Epoch 292/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5354 - mean_absolute_error: 0.5354 - soft_acc: 0.5600\n",
      "Epoch 00292: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4645 - mean_absolute_error: 0.4645 - soft_acc: 0.6261 - val_loss: 0.6159 - val_mean_absolute_error: 0.6159 - val_soft_acc: 0.4214\n",
      "Epoch 293/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3828 - mean_absolute_error: 0.3828 - soft_acc: 0.7400\n",
      "Epoch 00293: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4755 - mean_absolute_error: 0.4755 - soft_acc: 0.6250 - val_loss: 0.4395 - val_mean_absolute_error: 0.4395 - val_soft_acc: 0.6464\n",
      "Epoch 294/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3440 - mean_absolute_error: 0.3440 - soft_acc: 0.7600\n",
      "Epoch 00294: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3665 - mean_absolute_error: 0.3665 - soft_acc: 0.7794 - val_loss: 0.3700 - val_mean_absolute_error: 0.3700 - val_soft_acc: 0.7479\n",
      "Epoch 295/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3758 - mean_absolute_error: 0.3758 - soft_acc: 0.6900\n",
      "Epoch 00295: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3895 - mean_absolute_error: 0.3895 - soft_acc: 0.7117 - val_loss: 0.3777 - val_mean_absolute_error: 0.3777 - val_soft_acc: 0.7271\n",
      "Epoch 296/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3831 - mean_absolute_error: 0.3831 - soft_acc: 0.7100\n",
      "Epoch 00296: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3763 - mean_absolute_error: 0.3763 - soft_acc: 0.7244 - val_loss: 0.3411 - val_mean_absolute_error: 0.3411 - val_soft_acc: 0.7371\n",
      "Epoch 297/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3890 - mean_absolute_error: 0.3890 - soft_acc: 0.7100\n",
      "Epoch 00297: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3909 - mean_absolute_error: 0.3909 - soft_acc: 0.6922 - val_loss: 0.3911 - val_mean_absolute_error: 0.3911 - val_soft_acc: 0.7071\n",
      "Epoch 298/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3498 - mean_absolute_error: 0.3498 - soft_acc: 0.7300\n",
      "Epoch 00298: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3632 - mean_absolute_error: 0.3632 - soft_acc: 0.7350 - val_loss: 0.3675 - val_mean_absolute_error: 0.3675 - val_soft_acc: 0.7014\n",
      "Epoch 299/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3496 - mean_absolute_error: 0.3496 - soft_acc: 0.7800\n",
      "Epoch 00299: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3755 - mean_absolute_error: 0.3755 - soft_acc: 0.7306 - val_loss: 0.4208 - val_mean_absolute_error: 0.4208 - val_soft_acc: 0.6971\n",
      "Epoch 300/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3552 - mean_absolute_error: 0.3552 - soft_acc: 0.7800\n",
      "Epoch 00300: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3865 - mean_absolute_error: 0.3865 - soft_acc: 0.7389 - val_loss: 0.4088 - val_mean_absolute_error: 0.4088 - val_soft_acc: 0.6714\n",
      "Epoch 301/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3543 - mean_absolute_error: 0.3543 - soft_acc: 0.7700\n",
      "Epoch 00301: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3517 - mean_absolute_error: 0.3517 - soft_acc: 0.7700 - val_loss: 0.3639 - val_mean_absolute_error: 0.3639 - val_soft_acc: 0.7914\n",
      "Epoch 302/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3706 - mean_absolute_error: 0.3706 - soft_acc: 0.7300\n",
      "Epoch 00302: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3612 - mean_absolute_error: 0.3612 - soft_acc: 0.7622 - val_loss: 0.3598 - val_mean_absolute_error: 0.3598 - val_soft_acc: 0.7786\n",
      "Epoch 303/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3487 - mean_absolute_error: 0.3487 - soft_acc: 0.7300\n",
      "Epoch 00303: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3640 - mean_absolute_error: 0.3640 - soft_acc: 0.7106 - val_loss: 0.3582 - val_mean_absolute_error: 0.3582 - val_soft_acc: 0.6936\n",
      "Epoch 304/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4025 - mean_absolute_error: 0.4025 - soft_acc: 0.7200\n",
      "Epoch 00304: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3724 - mean_absolute_error: 0.3724 - soft_acc: 0.7172 - val_loss: 0.3445 - val_mean_absolute_error: 0.3445 - val_soft_acc: 0.7450\n",
      "Epoch 305/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4508 - mean_absolute_error: 0.4508 - soft_acc: 0.6100\n",
      "Epoch 00305: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4098 - mean_absolute_error: 0.4098 - soft_acc: 0.6817 - val_loss: 0.3984 - val_mean_absolute_error: 0.3984 - val_soft_acc: 0.6893\n",
      "Epoch 306/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4043 - mean_absolute_error: 0.4043 - soft_acc: 0.7100\n",
      "Epoch 00306: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3705 - mean_absolute_error: 0.3705 - soft_acc: 0.7250 - val_loss: 0.4005 - val_mean_absolute_error: 0.4005 - val_soft_acc: 0.6686\n",
      "Epoch 307/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4076 - mean_absolute_error: 0.4076 - soft_acc: 0.7400\n",
      "Epoch 00307: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3827 - mean_absolute_error: 0.3827 - soft_acc: 0.7356 - val_loss: 0.3727 - val_mean_absolute_error: 0.3727 - val_soft_acc: 0.7500\n",
      "Epoch 308/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4023 - mean_absolute_error: 0.4023 - soft_acc: 0.7100\n",
      "Epoch 00308: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3867 - mean_absolute_error: 0.3867 - soft_acc: 0.7094 - val_loss: 0.4811 - val_mean_absolute_error: 0.4811 - val_soft_acc: 0.6114\n",
      "Epoch 309/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3603 - mean_absolute_error: 0.3603 - soft_acc: 0.7500\n",
      "Epoch 00309: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3707 - mean_absolute_error: 0.3707 - soft_acc: 0.7517 - val_loss: 0.3998 - val_mean_absolute_error: 0.3998 - val_soft_acc: 0.6714\n",
      "Epoch 310/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3977 - mean_absolute_error: 0.3977 - soft_acc: 0.6500\n",
      "Epoch 00310: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3723 - mean_absolute_error: 0.3723 - soft_acc: 0.7178 - val_loss: 0.4877 - val_mean_absolute_error: 0.4877 - val_soft_acc: 0.5886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3650 - mean_absolute_error: 0.3650 - soft_acc: 0.7500\n",
      "Epoch 00311: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3676 - mean_absolute_error: 0.3676 - soft_acc: 0.7356 - val_loss: 0.4460 - val_mean_absolute_error: 0.4460 - val_soft_acc: 0.6257\n",
      "Epoch 312/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3642 - mean_absolute_error: 0.3642 - soft_acc: 0.7100\n",
      "Epoch 00312: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4056 - mean_absolute_error: 0.4056 - soft_acc: 0.6606 - val_loss: 0.4168 - val_mean_absolute_error: 0.4168 - val_soft_acc: 0.7486\n",
      "Epoch 313/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4407 - mean_absolute_error: 0.4407 - soft_acc: 0.6300\n",
      "Epoch 00313: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4059 - mean_absolute_error: 0.4059 - soft_acc: 0.6511 - val_loss: 0.4035 - val_mean_absolute_error: 0.4035 - val_soft_acc: 0.6279\n",
      "Epoch 314/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3373 - mean_absolute_error: 0.3373 - soft_acc: 0.7200\n",
      "Epoch 00314: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3921 - mean_absolute_error: 0.3921 - soft_acc: 0.7117 - val_loss: 0.3794 - val_mean_absolute_error: 0.3794 - val_soft_acc: 0.6914\n",
      "Epoch 315/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3614 - mean_absolute_error: 0.3614 - soft_acc: 0.7800\n",
      "Epoch 00315: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4071 - mean_absolute_error: 0.4071 - soft_acc: 0.7061 - val_loss: 0.3240 - val_mean_absolute_error: 0.3240 - val_soft_acc: 0.7886\n",
      "Epoch 316/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4550 - mean_absolute_error: 0.4550 - soft_acc: 0.6500\n",
      "Epoch 00316: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4224 - mean_absolute_error: 0.4224 - soft_acc: 0.7106 - val_loss: 0.5943 - val_mean_absolute_error: 0.5943 - val_soft_acc: 0.4393\n",
      "Epoch 317/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3810 - mean_absolute_error: 0.3810 - soft_acc: 0.7100\n",
      "Epoch 00317: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4487 - mean_absolute_error: 0.4487 - soft_acc: 0.6461 - val_loss: 0.5409 - val_mean_absolute_error: 0.5409 - val_soft_acc: 0.5100\n",
      "Epoch 318/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3538 - mean_absolute_error: 0.3538 - soft_acc: 0.7500\n",
      "Epoch 00318: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3560 - mean_absolute_error: 0.3560 - soft_acc: 0.7894 - val_loss: 0.6374 - val_mean_absolute_error: 0.6374 - val_soft_acc: 0.4164\n",
      "Epoch 319/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4154 - mean_absolute_error: 0.4154 - soft_acc: 0.7000\n",
      "Epoch 00319: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3980 - mean_absolute_error: 0.3980 - soft_acc: 0.7294 - val_loss: 0.7136 - val_mean_absolute_error: 0.7136 - val_soft_acc: 0.3914\n",
      "Epoch 320/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5408 - mean_absolute_error: 0.5408 - soft_acc: 0.5800\n",
      "Epoch 00320: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4533 - mean_absolute_error: 0.4533 - soft_acc: 0.6589 - val_loss: 0.7929 - val_mean_absolute_error: 0.7929 - val_soft_acc: 0.3714\n",
      "Epoch 321/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6609 - mean_absolute_error: 0.6609 - soft_acc: 0.4900\n",
      "Epoch 00321: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5653 - mean_absolute_error: 0.5653 - soft_acc: 0.5667 - val_loss: 0.3932 - val_mean_absolute_error: 0.3932 - val_soft_acc: 0.7250\n",
      "Epoch 322/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5338 - mean_absolute_error: 0.5338 - soft_acc: 0.5600\n",
      "Epoch 00322: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4258 - mean_absolute_error: 0.4258 - soft_acc: 0.6900 - val_loss: 0.4877 - val_mean_absolute_error: 0.4877 - val_soft_acc: 0.6500\n",
      "Epoch 323/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3727 - mean_absolute_error: 0.3727 - soft_acc: 0.6800\n",
      "Epoch 00323: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3838 - mean_absolute_error: 0.3838 - soft_acc: 0.7356 - val_loss: 0.4467 - val_mean_absolute_error: 0.4467 - val_soft_acc: 0.6700\n",
      "Epoch 324/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3778 - mean_absolute_error: 0.3778 - soft_acc: 0.7300\n",
      "Epoch 00324: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4015 - mean_absolute_error: 0.4015 - soft_acc: 0.7544 - val_loss: 0.4826 - val_mean_absolute_error: 0.4826 - val_soft_acc: 0.5986\n",
      "Epoch 325/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3806 - mean_absolute_error: 0.3806 - soft_acc: 0.7400\n",
      "Epoch 00325: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3711 - mean_absolute_error: 0.3711 - soft_acc: 0.7572 - val_loss: 0.3845 - val_mean_absolute_error: 0.3845 - val_soft_acc: 0.7043\n",
      "Epoch 326/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4832 - mean_absolute_error: 0.4832 - soft_acc: 0.5700\n",
      "Epoch 00326: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4298 - mean_absolute_error: 0.4298 - soft_acc: 0.6728 - val_loss: 0.3219 - val_mean_absolute_error: 0.3219 - val_soft_acc: 0.7214\n",
      "Epoch 327/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6240 - mean_absolute_error: 0.6240 - soft_acc: 0.4900\n",
      "Epoch 00327: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5295 - mean_absolute_error: 0.5295 - soft_acc: 0.6300 - val_loss: 0.4723 - val_mean_absolute_error: 0.4723 - val_soft_acc: 0.6086\n",
      "Epoch 328/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4139 - mean_absolute_error: 0.4139 - soft_acc: 0.6900\n",
      "Epoch 00328: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3861 - mean_absolute_error: 0.3861 - soft_acc: 0.7200 - val_loss: 0.5531 - val_mean_absolute_error: 0.5531 - val_soft_acc: 0.5207\n",
      "Epoch 329/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3855 - mean_absolute_error: 0.3855 - soft_acc: 0.7300\n",
      "Epoch 00329: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3817 - mean_absolute_error: 0.3817 - soft_acc: 0.7128 - val_loss: 0.6889 - val_mean_absolute_error: 0.6889 - val_soft_acc: 0.4064\n",
      "Epoch 330/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4946 - mean_absolute_error: 0.4946 - soft_acc: 0.6300\n",
      "Epoch 00330: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4199 - mean_absolute_error: 0.4199 - soft_acc: 0.6600 - val_loss: 0.6088 - val_mean_absolute_error: 0.6088 - val_soft_acc: 0.3907\n",
      "Epoch 331/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3275 - mean_absolute_error: 0.3275 - soft_acc: 0.7700\n",
      "Epoch 00331: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3514 - mean_absolute_error: 0.3514 - soft_acc: 0.7467 - val_loss: 0.5547 - val_mean_absolute_error: 0.5547 - val_soft_acc: 0.4871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3809 - mean_absolute_error: 0.3809 - soft_acc: 0.7200\n",
      "Epoch 00332: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3568 - mean_absolute_error: 0.3568 - soft_acc: 0.7694 - val_loss: 0.4664 - val_mean_absolute_error: 0.4664 - val_soft_acc: 0.6293\n",
      "Epoch 333/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3652 - mean_absolute_error: 0.3652 - soft_acc: 0.7800\n",
      "Epoch 00333: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3644 - mean_absolute_error: 0.3644 - soft_acc: 0.7756 - val_loss: 0.5584 - val_mean_absolute_error: 0.5584 - val_soft_acc: 0.5386\n",
      "Epoch 334/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3360 - mean_absolute_error: 0.3360 - soft_acc: 0.8000\n",
      "Epoch 00334: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3782 - mean_absolute_error: 0.3782 - soft_acc: 0.7578 - val_loss: 0.4109 - val_mean_absolute_error: 0.4109 - val_soft_acc: 0.7050\n",
      "Epoch 335/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3533 - mean_absolute_error: 0.3533 - soft_acc: 0.7600\n",
      "Epoch 00335: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3517 - mean_absolute_error: 0.3517 - soft_acc: 0.7856 - val_loss: 0.3394 - val_mean_absolute_error: 0.3394 - val_soft_acc: 0.7757\n",
      "Epoch 336/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4712 - mean_absolute_error: 0.4712 - soft_acc: 0.6300\n",
      "Epoch 00336: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4230 - mean_absolute_error: 0.4230 - soft_acc: 0.6456 - val_loss: 0.4319 - val_mean_absolute_error: 0.4319 - val_soft_acc: 0.6336\n",
      "Epoch 337/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3682 - mean_absolute_error: 0.3682 - soft_acc: 0.7100\n",
      "Epoch 00337: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3511 - mean_absolute_error: 0.3511 - soft_acc: 0.7739 - val_loss: 0.4581 - val_mean_absolute_error: 0.4581 - val_soft_acc: 0.6164\n",
      "Epoch 338/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3419 - mean_absolute_error: 0.3419 - soft_acc: 0.7400\n",
      "Epoch 00338: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3617 - mean_absolute_error: 0.3617 - soft_acc: 0.7650 - val_loss: 0.5566 - val_mean_absolute_error: 0.5566 - val_soft_acc: 0.5029\n",
      "Epoch 339/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3426 - mean_absolute_error: 0.3426 - soft_acc: 0.8100\n",
      "Epoch 00339: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3377 - mean_absolute_error: 0.3377 - soft_acc: 0.7667 - val_loss: 0.5841 - val_mean_absolute_error: 0.5841 - val_soft_acc: 0.4543\n",
      "Epoch 340/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3879 - mean_absolute_error: 0.3879 - soft_acc: 0.7100\n",
      "Epoch 00340: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.3477 - mean_absolute_error: 0.3477 - soft_acc: 0.7667 - val_loss: 0.4273 - val_mean_absolute_error: 0.4273 - val_soft_acc: 0.6593\n",
      "Epoch 341/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4307 - mean_absolute_error: 0.4307 - soft_acc: 0.6700\n",
      "Epoch 00341: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3298 - mean_absolute_error: 0.3298 - soft_acc: 0.7900 - val_loss: 0.5751 - val_mean_absolute_error: 0.5751 - val_soft_acc: 0.4750\n",
      "Epoch 342/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3120 - mean_absolute_error: 0.3120 - soft_acc: 0.7700\n",
      "Epoch 00342: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3632 - mean_absolute_error: 0.3632 - soft_acc: 0.7144 - val_loss: 0.5985 - val_mean_absolute_error: 0.5985 - val_soft_acc: 0.4521\n",
      "Epoch 343/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3526 - mean_absolute_error: 0.3526 - soft_acc: 0.7400\n",
      "Epoch 00343: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3709 - mean_absolute_error: 0.3709 - soft_acc: 0.7344 - val_loss: 0.5339 - val_mean_absolute_error: 0.5339 - val_soft_acc: 0.5229\n",
      "Epoch 344/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3166 - mean_absolute_error: 0.3166 - soft_acc: 0.8000\n",
      "Epoch 00344: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3591 - mean_absolute_error: 0.3591 - soft_acc: 0.7461 - val_loss: 0.5000 - val_mean_absolute_error: 0.5000 - val_soft_acc: 0.5529\n",
      "Epoch 345/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3579 - mean_absolute_error: 0.3579 - soft_acc: 0.7300\n",
      "Epoch 00345: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3728 - mean_absolute_error: 0.3728 - soft_acc: 0.6733 - val_loss: 0.3726 - val_mean_absolute_error: 0.3726 - val_soft_acc: 0.6736\n",
      "Epoch 346/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5807 - mean_absolute_error: 0.5807 - soft_acc: 0.5300\n",
      "Epoch 00346: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4333 - mean_absolute_error: 0.4333 - soft_acc: 0.6328 - val_loss: 0.4232 - val_mean_absolute_error: 0.4232 - val_soft_acc: 0.6693\n",
      "Epoch 347/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3667 - mean_absolute_error: 0.3667 - soft_acc: 0.7100\n",
      "Epoch 00347: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3639 - mean_absolute_error: 0.3639 - soft_acc: 0.7456 - val_loss: 0.4116 - val_mean_absolute_error: 0.4116 - val_soft_acc: 0.6536\n",
      "Epoch 348/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3782 - mean_absolute_error: 0.3782 - soft_acc: 0.7200\n",
      "Epoch 00348: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3542 - mean_absolute_error: 0.3542 - soft_acc: 0.7550 - val_loss: 0.3862 - val_mean_absolute_error: 0.3862 - val_soft_acc: 0.7071\n",
      "Epoch 349/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3837 - mean_absolute_error: 0.3837 - soft_acc: 0.7100\n",
      "Epoch 00349: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3597 - mean_absolute_error: 0.3597 - soft_acc: 0.7589 - val_loss: 0.4545 - val_mean_absolute_error: 0.4545 - val_soft_acc: 0.5729\n",
      "Epoch 350/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3733 - mean_absolute_error: 0.3733 - soft_acc: 0.7900\n",
      "Epoch 00350: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3377 - mean_absolute_error: 0.3377 - soft_acc: 0.7872 - val_loss: 0.3570 - val_mean_absolute_error: 0.3570 - val_soft_acc: 0.7271\n",
      "Epoch 351/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4617 - mean_absolute_error: 0.4617 - soft_acc: 0.6000\n",
      "Epoch 00351: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3943 - mean_absolute_error: 0.3943 - soft_acc: 0.7156 - val_loss: 0.4646 - val_mean_absolute_error: 0.4646 - val_soft_acc: 0.5600\n",
      "Epoch 352/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3381 - mean_absolute_error: 0.3381 - soft_acc: 0.7400\n",
      "Epoch 00352: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3777 - mean_absolute_error: 0.3777 - soft_acc: 0.7017 - val_loss: 0.4929 - val_mean_absolute_error: 0.4929 - val_soft_acc: 0.5271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3011 - mean_absolute_error: 0.3011 - soft_acc: 0.8100\n",
      "Epoch 00353: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3689 - mean_absolute_error: 0.3689 - soft_acc: 0.7583 - val_loss: 0.6599 - val_mean_absolute_error: 0.6599 - val_soft_acc: 0.4450\n",
      "Epoch 354/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3865 - mean_absolute_error: 0.3865 - soft_acc: 0.7100\n",
      "Epoch 00354: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3629 - mean_absolute_error: 0.3629 - soft_acc: 0.7700 - val_loss: 0.5673 - val_mean_absolute_error: 0.5673 - val_soft_acc: 0.4929\n",
      "Epoch 355/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3607 - mean_absolute_error: 0.3607 - soft_acc: 0.7300\n",
      "Epoch 00355: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3482 - mean_absolute_error: 0.3482 - soft_acc: 0.7567 - val_loss: 0.6893 - val_mean_absolute_error: 0.6893 - val_soft_acc: 0.4814\n",
      "Epoch 356/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5076 - mean_absolute_error: 0.5076 - soft_acc: 0.5800\n",
      "Epoch 00356: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3650 - mean_absolute_error: 0.3650 - soft_acc: 0.7628 - val_loss: 0.5233 - val_mean_absolute_error: 0.5233 - val_soft_acc: 0.5100\n",
      "Epoch 357/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3509 - mean_absolute_error: 0.3509 - soft_acc: 0.7800\n",
      "Epoch 00357: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3211 - mean_absolute_error: 0.3211 - soft_acc: 0.7972 - val_loss: 0.3607 - val_mean_absolute_error: 0.3607 - val_soft_acc: 0.6964\n",
      "Epoch 358/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4832 - mean_absolute_error: 0.4832 - soft_acc: 0.6000\n",
      "Epoch 00358: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3846 - mean_absolute_error: 0.3846 - soft_acc: 0.6933 - val_loss: 0.4816 - val_mean_absolute_error: 0.4816 - val_soft_acc: 0.5807\n",
      "Epoch 359/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3466 - mean_absolute_error: 0.3466 - soft_acc: 0.7700\n",
      "Epoch 00359: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3558 - mean_absolute_error: 0.3558 - soft_acc: 0.7750 - val_loss: 0.8126 - val_mean_absolute_error: 0.8126 - val_soft_acc: 0.2950\n",
      "Epoch 360/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7041 - mean_absolute_error: 0.7041 - soft_acc: 0.4200\n",
      "Epoch 00360: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.6488 - mean_absolute_error: 0.6488 - soft_acc: 0.4478 - val_loss: 0.5695 - val_mean_absolute_error: 0.5695 - val_soft_acc: 0.4879\n",
      "Epoch 361/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2928 - mean_absolute_error: 0.2928 - soft_acc: 0.8000\n",
      "Epoch 00361: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4278 - mean_absolute_error: 0.4278 - soft_acc: 0.6800 - val_loss: 0.3729 - val_mean_absolute_error: 0.3729 - val_soft_acc: 0.6971\n",
      "Epoch 362/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5461 - mean_absolute_error: 0.5461 - soft_acc: 0.5200\n",
      "Epoch 00362: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4781 - mean_absolute_error: 0.4781 - soft_acc: 0.6556 - val_loss: 0.3303 - val_mean_absolute_error: 0.3303 - val_soft_acc: 0.7421\n",
      "Epoch 363/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5724 - mean_absolute_error: 0.5724 - soft_acc: 0.6000\n",
      "Epoch 00363: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5296 - mean_absolute_error: 0.5296 - soft_acc: 0.6089 - val_loss: 0.6015 - val_mean_absolute_error: 0.6015 - val_soft_acc: 0.4393\n",
      "Epoch 364/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3808 - mean_absolute_error: 0.3808 - soft_acc: 0.7400\n",
      "Epoch 00364: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4121 - mean_absolute_error: 0.4121 - soft_acc: 0.6811 - val_loss: 0.7600 - val_mean_absolute_error: 0.7600 - val_soft_acc: 0.3636\n",
      "Epoch 365/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5044 - mean_absolute_error: 0.5044 - soft_acc: 0.5800\n",
      "Epoch 00365: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4661 - mean_absolute_error: 0.4661 - soft_acc: 0.6422 - val_loss: 0.8153 - val_mean_absolute_error: 0.8153 - val_soft_acc: 0.4050\n",
      "Epoch 366/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4313 - mean_absolute_error: 0.4313 - soft_acc: 0.6200\n",
      "Epoch 00366: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4507 - mean_absolute_error: 0.4507 - soft_acc: 0.6572 - val_loss: 0.7610 - val_mean_absolute_error: 0.7610 - val_soft_acc: 0.3636\n",
      "Epoch 367/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5315 - mean_absolute_error: 0.5315 - soft_acc: 0.5500\n",
      "Epoch 00367: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4469 - mean_absolute_error: 0.4469 - soft_acc: 0.6733 - val_loss: 0.4559 - val_mean_absolute_error: 0.4559 - val_soft_acc: 0.6293\n",
      "Epoch 368/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4459 - mean_absolute_error: 0.4459 - soft_acc: 0.6800\n",
      "Epoch 00368: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4104 - mean_absolute_error: 0.4104 - soft_acc: 0.6994 - val_loss: 0.3603 - val_mean_absolute_error: 0.3603 - val_soft_acc: 0.7071\n",
      "Epoch 369/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5219 - mean_absolute_error: 0.5219 - soft_acc: 0.6000\n",
      "Epoch 00369: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4773 - mean_absolute_error: 0.4773 - soft_acc: 0.6550 - val_loss: 0.5322 - val_mean_absolute_error: 0.5322 - val_soft_acc: 0.5021\n",
      "Epoch 370/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3737 - mean_absolute_error: 0.3737 - soft_acc: 0.6700\n",
      "Epoch 00370: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3950 - mean_absolute_error: 0.3950 - soft_acc: 0.7189 - val_loss: 0.7714 - val_mean_absolute_error: 0.7714 - val_soft_acc: 0.3150\n",
      "Epoch 371/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4879 - mean_absolute_error: 0.4879 - soft_acc: 0.6000\n",
      "Epoch 00371: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4763 - mean_absolute_error: 0.4763 - soft_acc: 0.6467 - val_loss: 0.7234 - val_mean_absolute_error: 0.7234 - val_soft_acc: 0.4250\n",
      "Epoch 372/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4358 - mean_absolute_error: 0.4358 - soft_acc: 0.6400\n",
      "Epoch 00372: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4443 - mean_absolute_error: 0.4443 - soft_acc: 0.6422 - val_loss: 0.5854 - val_mean_absolute_error: 0.5854 - val_soft_acc: 0.4650\n",
      "Epoch 373/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3161 - mean_absolute_error: 0.3161 - soft_acc: 0.7600\n",
      "Epoch 00373: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3880 - mean_absolute_error: 0.3880 - soft_acc: 0.7072 - val_loss: 0.4742 - val_mean_absolute_error: 0.4742 - val_soft_acc: 0.6193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3824 - mean_absolute_error: 0.3824 - soft_acc: 0.7100\n",
      "Epoch 00374: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4160 - mean_absolute_error: 0.4160 - soft_acc: 0.6650 - val_loss: 0.4726 - val_mean_absolute_error: 0.4726 - val_soft_acc: 0.5371\n",
      "Epoch 375/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3722 - mean_absolute_error: 0.3722 - soft_acc: 0.7300\n",
      "Epoch 00375: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3301 - mean_absolute_error: 0.3301 - soft_acc: 0.7789 - val_loss: 0.5022 - val_mean_absolute_error: 0.5022 - val_soft_acc: 0.5686\n",
      "Epoch 376/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3653 - mean_absolute_error: 0.3653 - soft_acc: 0.7500\n",
      "Epoch 00376: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3573 - mean_absolute_error: 0.3573 - soft_acc: 0.7761 - val_loss: 0.5433 - val_mean_absolute_error: 0.5433 - val_soft_acc: 0.5179\n",
      "Epoch 377/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3860 - mean_absolute_error: 0.3860 - soft_acc: 0.7500\n",
      "Epoch 00377: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3451 - mean_absolute_error: 0.3451 - soft_acc: 0.8183 - val_loss: 0.5896 - val_mean_absolute_error: 0.5896 - val_soft_acc: 0.4650\n",
      "Epoch 378/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3272 - mean_absolute_error: 0.3272 - soft_acc: 0.7900\n",
      "Epoch 00378: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3548 - mean_absolute_error: 0.3548 - soft_acc: 0.7550 - val_loss: 0.9141 - val_mean_absolute_error: 0.9141 - val_soft_acc: 0.2529\n",
      "Epoch 379/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7198 - mean_absolute_error: 0.7198 - soft_acc: 0.4000\n",
      "Epoch 00379: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.5935 - mean_absolute_error: 0.5935 - soft_acc: 0.5083 - val_loss: 0.5566 - val_mean_absolute_error: 0.5566 - val_soft_acc: 0.4693\n",
      "Epoch 380/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3423 - mean_absolute_error: 0.3423 - soft_acc: 0.7500\n",
      "Epoch 00380: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3904 - mean_absolute_error: 0.3904 - soft_acc: 0.7028 - val_loss: 0.5490 - val_mean_absolute_error: 0.5490 - val_soft_acc: 0.5207\n",
      "Epoch 381/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3290 - mean_absolute_error: 0.3290 - soft_acc: 0.7700\n",
      "Epoch 00381: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3862 - mean_absolute_error: 0.3862 - soft_acc: 0.7306 - val_loss: 0.4994 - val_mean_absolute_error: 0.4994 - val_soft_acc: 0.5686\n",
      "Epoch 382/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3654 - mean_absolute_error: 0.3654 - soft_acc: 0.7300\n",
      "Epoch 00382: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3399 - mean_absolute_error: 0.3399 - soft_acc: 0.7094 - val_loss: 0.6194 - val_mean_absolute_error: 0.6194 - val_soft_acc: 0.4729\n",
      "Epoch 383/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3625 - mean_absolute_error: 0.3625 - soft_acc: 0.7600\n",
      "Epoch 00383: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3490 - mean_absolute_error: 0.3490 - soft_acc: 0.7561 - val_loss: 0.4907 - val_mean_absolute_error: 0.4907 - val_soft_acc: 0.6043\n",
      "Epoch 384/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3183 - mean_absolute_error: 0.3183 - soft_acc: 0.7900\n",
      "Epoch 00384: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3585 - mean_absolute_error: 0.3585 - soft_acc: 0.7756 - val_loss: 0.4459 - val_mean_absolute_error: 0.4459 - val_soft_acc: 0.6393\n",
      "Epoch 385/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4049 - mean_absolute_error: 0.4049 - soft_acc: 0.6400\n",
      "Epoch 00385: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3640 - mean_absolute_error: 0.3640 - soft_acc: 0.7256 - val_loss: 0.5307 - val_mean_absolute_error: 0.5307 - val_soft_acc: 0.4614\n",
      "Epoch 386/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3182 - mean_absolute_error: 0.3182 - soft_acc: 0.8100\n",
      "Epoch 00386: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3578 - mean_absolute_error: 0.3578 - soft_acc: 0.7656 - val_loss: 0.5226 - val_mean_absolute_error: 0.5226 - val_soft_acc: 0.5486\n",
      "Epoch 387/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3301 - mean_absolute_error: 0.3301 - soft_acc: 0.8000\n",
      "Epoch 00387: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3254 - mean_absolute_error: 0.3254 - soft_acc: 0.7800 - val_loss: 0.5869 - val_mean_absolute_error: 0.5869 - val_soft_acc: 0.4164\n",
      "Epoch 388/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3357 - mean_absolute_error: 0.3357 - soft_acc: 0.7900\n",
      "Epoch 00388: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3353 - mean_absolute_error: 0.3353 - soft_acc: 0.7956 - val_loss: 0.7330 - val_mean_absolute_error: 0.7330 - val_soft_acc: 0.4200\n",
      "Epoch 389/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4854 - mean_absolute_error: 0.4854 - soft_acc: 0.5600\n",
      "Epoch 00389: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4031 - mean_absolute_error: 0.4031 - soft_acc: 0.6850 - val_loss: 0.8560 - val_mean_absolute_error: 0.8560 - val_soft_acc: 0.3186\n",
      "Epoch 390/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6647 - mean_absolute_error: 0.6647 - soft_acc: 0.4700\n",
      "Epoch 00390: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5320 - mean_absolute_error: 0.5320 - soft_acc: 0.5967 - val_loss: 0.5804 - val_mean_absolute_error: 0.5804 - val_soft_acc: 0.4829\n",
      "Epoch 391/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3435 - mean_absolute_error: 0.3435 - soft_acc: 0.7800\n",
      "Epoch 00391: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3549 - mean_absolute_error: 0.3549 - soft_acc: 0.7683 - val_loss: 0.5074 - val_mean_absolute_error: 0.5074 - val_soft_acc: 0.5071\n",
      "Epoch 392/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3302 - mean_absolute_error: 0.3302 - soft_acc: 0.8000\n",
      "Epoch 00392: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3445 - mean_absolute_error: 0.3445 - soft_acc: 0.7806 - val_loss: 0.4278 - val_mean_absolute_error: 0.4278 - val_soft_acc: 0.6236\n",
      "Epoch 393/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3934 - mean_absolute_error: 0.3934 - soft_acc: 0.6900\n",
      "Epoch 00393: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3753 - mean_absolute_error: 0.3753 - soft_acc: 0.7239 - val_loss: 0.6034 - val_mean_absolute_error: 0.6034 - val_soft_acc: 0.4164\n",
      "Epoch 394/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3317 - mean_absolute_error: 0.3317 - soft_acc: 0.7800\n",
      "Epoch 00394: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3354 - mean_absolute_error: 0.3354 - soft_acc: 0.7661 - val_loss: 0.5868 - val_mean_absolute_error: 0.5868 - val_soft_acc: 0.4007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3113 - mean_absolute_error: 0.3113 - soft_acc: 0.8300\n",
      "Epoch 00395: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3367 - mean_absolute_error: 0.3367 - soft_acc: 0.7783 - val_loss: 0.6180 - val_mean_absolute_error: 0.6180 - val_soft_acc: 0.4164\n",
      "Epoch 396/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3409 - mean_absolute_error: 0.3409 - soft_acc: 0.7600\n",
      "Epoch 00396: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3722 - mean_absolute_error: 0.3722 - soft_acc: 0.7506 - val_loss: 0.5065 - val_mean_absolute_error: 0.5065 - val_soft_acc: 0.5507\n",
      "Epoch 397/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3869 - mean_absolute_error: 0.3869 - soft_acc: 0.8000\n",
      "Epoch 00397: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3586 - mean_absolute_error: 0.3586 - soft_acc: 0.7322 - val_loss: 0.6087 - val_mean_absolute_error: 0.6087 - val_soft_acc: 0.4471\n",
      "Epoch 398/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3035 - mean_absolute_error: 0.3035 - soft_acc: 0.8100\n",
      "Epoch 00398: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.3898 - mean_absolute_error: 0.3898 - soft_acc: 0.7222 - val_loss: 0.8629 - val_mean_absolute_error: 0.8629 - val_soft_acc: 0.2343\n",
      "Epoch 399/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5504 - mean_absolute_error: 0.5504 - soft_acc: 0.4900\n",
      "Epoch 00399: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.4951 - mean_absolute_error: 0.4951 - soft_acc: 0.6256 - val_loss: 0.6070 - val_mean_absolute_error: 0.6070 - val_soft_acc: 0.4036\n",
      "Epoch 400/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3246 - mean_absolute_error: 0.3246 - soft_acc: 0.7800\n",
      "Epoch 00400: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.3480 - mean_absolute_error: 0.3480 - soft_acc: 0.8017 - val_loss: 0.6809 - val_mean_absolute_error: 0.6809 - val_soft_acc: 0.3836\n",
      "Epoch 401/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4048 - mean_absolute_error: 0.4048 - soft_acc: 0.6900\n",
      "Epoch 00401: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.3701 - mean_absolute_error: 0.3701 - soft_acc: 0.7267 - val_loss: 0.6952 - val_mean_absolute_error: 0.6952 - val_soft_acc: 0.4171\n",
      "Epoch 402/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4655 - mean_absolute_error: 0.4655 - soft_acc: 0.6500\n",
      "Epoch 00402: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3902 - mean_absolute_error: 0.3902 - soft_acc: 0.7228 - val_loss: 0.6379 - val_mean_absolute_error: 0.6379 - val_soft_acc: 0.4500\n",
      "Epoch 403/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3049 - mean_absolute_error: 0.3049 - soft_acc: 0.8200\n",
      "Epoch 00403: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.3356 - mean_absolute_error: 0.3356 - soft_acc: 0.7528 - val_loss: 0.6199 - val_mean_absolute_error: 0.6199 - val_soft_acc: 0.4550\n",
      "Epoch 404/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3820 - mean_absolute_error: 0.3820 - soft_acc: 0.7400\n",
      "Epoch 00404: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3224 - mean_absolute_error: 0.3224 - soft_acc: 0.7728 - val_loss: 0.5419 - val_mean_absolute_error: 0.5419 - val_soft_acc: 0.4771\n",
      "Epoch 405/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3835 - mean_absolute_error: 0.3835 - soft_acc: 0.7600\n",
      "Epoch 00405: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3521 - mean_absolute_error: 0.3521 - soft_acc: 0.7372 - val_loss: 0.4912 - val_mean_absolute_error: 0.4912 - val_soft_acc: 0.5686\n",
      "Epoch 406/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3582 - mean_absolute_error: 0.3582 - soft_acc: 0.7500\n",
      "Epoch 00406: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3228 - mean_absolute_error: 0.3228 - soft_acc: 0.7900 - val_loss: 0.5593 - val_mean_absolute_error: 0.5593 - val_soft_acc: 0.4829\n",
      "Epoch 407/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3774 - mean_absolute_error: 0.3774 - soft_acc: 0.7100\n",
      "Epoch 00407: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3384 - mean_absolute_error: 0.3384 - soft_acc: 0.7583 - val_loss: 0.5268 - val_mean_absolute_error: 0.5268 - val_soft_acc: 0.5307\n",
      "Epoch 408/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2861 - mean_absolute_error: 0.2861 - soft_acc: 0.8400\n",
      "Epoch 00408: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3390 - mean_absolute_error: 0.3390 - soft_acc: 0.7700 - val_loss: 0.5199 - val_mean_absolute_error: 0.5199 - val_soft_acc: 0.5021\n",
      "Epoch 409/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3409 - mean_absolute_error: 0.3409 - soft_acc: 0.8100\n",
      "Epoch 00409: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3375 - mean_absolute_error: 0.3375 - soft_acc: 0.7700 - val_loss: 0.5565 - val_mean_absolute_error: 0.5565 - val_soft_acc: 0.4950\n",
      "Epoch 410/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4089 - mean_absolute_error: 0.4089 - soft_acc: 0.8000\n",
      "Epoch 00410: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3498 - mean_absolute_error: 0.3498 - soft_acc: 0.7756 - val_loss: 0.4644 - val_mean_absolute_error: 0.4644 - val_soft_acc: 0.5679\n",
      "Epoch 411/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3038 - mean_absolute_error: 0.3038 - soft_acc: 0.8100\n",
      "Epoch 00411: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3630 - mean_absolute_error: 0.3630 - soft_acc: 0.7539 - val_loss: 0.4077 - val_mean_absolute_error: 0.4077 - val_soft_acc: 0.6436\n",
      "Epoch 412/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3631 - mean_absolute_error: 0.3631 - soft_acc: 0.7100\n",
      "Epoch 00412: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3606 - mean_absolute_error: 0.3606 - soft_acc: 0.7489 - val_loss: 0.4129 - val_mean_absolute_error: 0.4129 - val_soft_acc: 0.6900\n",
      "Epoch 413/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3791 - mean_absolute_error: 0.3791 - soft_acc: 0.7000\n",
      "Epoch 00413: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3662 - mean_absolute_error: 0.3662 - soft_acc: 0.7094 - val_loss: 0.5224 - val_mean_absolute_error: 0.5224 - val_soft_acc: 0.5071\n",
      "Epoch 414/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3146 - mean_absolute_error: 0.3146 - soft_acc: 0.8000\n",
      "Epoch 00414: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3624 - mean_absolute_error: 0.3624 - soft_acc: 0.7744 - val_loss: 0.8027 - val_mean_absolute_error: 0.8027 - val_soft_acc: 0.3129\n",
      "Epoch 415/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5476 - mean_absolute_error: 0.5476 - soft_acc: 0.5100\n",
      "Epoch 00415: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5371 - mean_absolute_error: 0.5371 - soft_acc: 0.6039 - val_loss: 0.7234 - val_mean_absolute_error: 0.7234 - val_soft_acc: 0.3457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4514 - mean_absolute_error: 0.4514 - soft_acc: 0.7100\n",
      "Epoch 00416: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4088 - mean_absolute_error: 0.4088 - soft_acc: 0.6961 - val_loss: 0.8904 - val_mean_absolute_error: 0.8904 - val_soft_acc: 0.2679\n",
      "Epoch 417/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5295 - mean_absolute_error: 0.5295 - soft_acc: 0.5200\n",
      "Epoch 00417: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5575 - mean_absolute_error: 0.5575 - soft_acc: 0.5267 - val_loss: 0.5822 - val_mean_absolute_error: 0.5822 - val_soft_acc: 0.4957\n",
      "Epoch 418/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3434 - mean_absolute_error: 0.3434 - soft_acc: 0.8100\n",
      "Epoch 00418: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5081 - mean_absolute_error: 0.5081 - soft_acc: 0.5794 - val_loss: 0.4883 - val_mean_absolute_error: 0.4883 - val_soft_acc: 0.5400\n",
      "Epoch 419/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4944 - mean_absolute_error: 0.4944 - soft_acc: 0.5500\n",
      "Epoch 00419: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4104 - mean_absolute_error: 0.4104 - soft_acc: 0.7111 - val_loss: 0.5590 - val_mean_absolute_error: 0.5590 - val_soft_acc: 0.5157\n",
      "Epoch 420/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3637 - mean_absolute_error: 0.3637 - soft_acc: 0.7300\n",
      "Epoch 00420: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3653 - mean_absolute_error: 0.3653 - soft_acc: 0.7089 - val_loss: 0.4480 - val_mean_absolute_error: 0.4480 - val_soft_acc: 0.6086\n",
      "Epoch 421/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4608 - mean_absolute_error: 0.4608 - soft_acc: 0.6500\n",
      "Epoch 00421: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4602 - mean_absolute_error: 0.4602 - soft_acc: 0.6389 - val_loss: 0.5794 - val_mean_absolute_error: 0.5794 - val_soft_acc: 0.4771\n",
      "Epoch 422/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3849 - mean_absolute_error: 0.3849 - soft_acc: 0.6900\n",
      "Epoch 00422: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4089 - mean_absolute_error: 0.4089 - soft_acc: 0.7111 - val_loss: 0.5818 - val_mean_absolute_error: 0.5818 - val_soft_acc: 0.4236\n",
      "Epoch 423/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3180 - mean_absolute_error: 0.3180 - soft_acc: 0.8600\n",
      "Epoch 00423: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3448 - mean_absolute_error: 0.3448 - soft_acc: 0.7733 - val_loss: 0.5221 - val_mean_absolute_error: 0.5221 - val_soft_acc: 0.5357\n",
      "Epoch 424/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3334 - mean_absolute_error: 0.3334 - soft_acc: 0.7900\n",
      "Epoch 00424: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4025 - mean_absolute_error: 0.4025 - soft_acc: 0.7222 - val_loss: 0.4916 - val_mean_absolute_error: 0.4916 - val_soft_acc: 0.5400\n",
      "Epoch 425/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3753 - mean_absolute_error: 0.3753 - soft_acc: 0.6800\n",
      "Epoch 00425: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4005 - mean_absolute_error: 0.4005 - soft_acc: 0.7100 - val_loss: 0.5276 - val_mean_absolute_error: 0.5276 - val_soft_acc: 0.5000\n",
      "Epoch 426/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3052 - mean_absolute_error: 0.3052 - soft_acc: 0.7800\n",
      "Epoch 00426: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3377 - mean_absolute_error: 0.3377 - soft_acc: 0.7689 - val_loss: 0.4187 - val_mean_absolute_error: 0.4187 - val_soft_acc: 0.5850\n",
      "Epoch 427/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4339 - mean_absolute_error: 0.4339 - soft_acc: 0.6200\n",
      "Epoch 00427: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3594 - mean_absolute_error: 0.3594 - soft_acc: 0.6928 - val_loss: 0.6906 - val_mean_absolute_error: 0.6906 - val_soft_acc: 0.3657\n",
      "Epoch 428/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4091 - mean_absolute_error: 0.4091 - soft_acc: 0.6900\n",
      "Epoch 00428: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3559 - mean_absolute_error: 0.3559 - soft_acc: 0.7444 - val_loss: 0.5121 - val_mean_absolute_error: 0.5121 - val_soft_acc: 0.5843\n",
      "Epoch 429/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3438 - mean_absolute_error: 0.3438 - soft_acc: 0.7700\n",
      "Epoch 00429: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3300 - mean_absolute_error: 0.3300 - soft_acc: 0.7800 - val_loss: 0.6527 - val_mean_absolute_error: 0.6527 - val_soft_acc: 0.4014\n",
      "Epoch 430/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3765 - mean_absolute_error: 0.3765 - soft_acc: 0.7300\n",
      "Epoch 00430: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3776 - mean_absolute_error: 0.3776 - soft_acc: 0.7444 - val_loss: 0.5576 - val_mean_absolute_error: 0.5576 - val_soft_acc: 0.5414\n",
      "Epoch 431/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3453 - mean_absolute_error: 0.3453 - soft_acc: 0.7900\n",
      "Epoch 00431: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3274 - mean_absolute_error: 0.3274 - soft_acc: 0.8211 - val_loss: 0.5916 - val_mean_absolute_error: 0.5916 - val_soft_acc: 0.4264\n",
      "Epoch 432/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3518 - mean_absolute_error: 0.3518 - soft_acc: 0.7400\n",
      "Epoch 00432: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3299 - mean_absolute_error: 0.3299 - soft_acc: 0.7817 - val_loss: 0.4547 - val_mean_absolute_error: 0.4547 - val_soft_acc: 0.5986\n",
      "Epoch 433/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3014 - mean_absolute_error: 0.3014 - soft_acc: 0.8100\n",
      "Epoch 00433: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3297 - mean_absolute_error: 0.3297 - soft_acc: 0.7661 - val_loss: 0.5112 - val_mean_absolute_error: 0.5112 - val_soft_acc: 0.5329\n",
      "Epoch 434/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3072 - mean_absolute_error: 0.3072 - soft_acc: 0.8000\n",
      "Epoch 00434: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3114 - mean_absolute_error: 0.3114 - soft_acc: 0.8072 - val_loss: 0.6993 - val_mean_absolute_error: 0.6993 - val_soft_acc: 0.4457\n",
      "Epoch 435/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4511 - mean_absolute_error: 0.4511 - soft_acc: 0.6100\n",
      "Epoch 00435: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3998 - mean_absolute_error: 0.3998 - soft_acc: 0.6983 - val_loss: 0.6914 - val_mean_absolute_error: 0.6914 - val_soft_acc: 0.3379\n",
      "Epoch 436/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4405 - mean_absolute_error: 0.4405 - soft_acc: 0.6300\n",
      "Epoch 00436: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 55us/sample - loss: 0.3850 - mean_absolute_error: 0.3850 - soft_acc: 0.7128 - val_loss: 0.5806 - val_mean_absolute_error: 0.5806 - val_soft_acc: 0.4186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3471 - mean_absolute_error: 0.3471 - soft_acc: 0.8000\n",
      "Epoch 00437: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3716 - mean_absolute_error: 0.3716 - soft_acc: 0.7250 - val_loss: 0.5811 - val_mean_absolute_error: 0.5811 - val_soft_acc: 0.4879\n",
      "Epoch 438/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3062 - mean_absolute_error: 0.3062 - soft_acc: 0.8000\n",
      "Epoch 00438: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3301 - mean_absolute_error: 0.3301 - soft_acc: 0.7511 - val_loss: 0.5624 - val_mean_absolute_error: 0.5624 - val_soft_acc: 0.4593\n",
      "Epoch 439/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3198 - mean_absolute_error: 0.3198 - soft_acc: 0.7800\n",
      "Epoch 00439: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3207 - mean_absolute_error: 0.3207 - soft_acc: 0.7728 - val_loss: 0.5820 - val_mean_absolute_error: 0.5820 - val_soft_acc: 0.4957\n",
      "Epoch 440/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2979 - mean_absolute_error: 0.2979 - soft_acc: 0.8300\n",
      "Epoch 00440: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3217 - mean_absolute_error: 0.3217 - soft_acc: 0.7756 - val_loss: 0.5427 - val_mean_absolute_error: 0.5427 - val_soft_acc: 0.4929\n",
      "Epoch 441/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3008 - mean_absolute_error: 0.3008 - soft_acc: 0.7900\n",
      "Epoch 00441: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3247 - mean_absolute_error: 0.3247 - soft_acc: 0.7522 - val_loss: 0.4957 - val_mean_absolute_error: 0.4957 - val_soft_acc: 0.5636\n",
      "Epoch 442/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2735 - mean_absolute_error: 0.2735 - soft_acc: 0.8600\n",
      "Epoch 00442: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3264 - mean_absolute_error: 0.3264 - soft_acc: 0.8044 - val_loss: 0.3277 - val_mean_absolute_error: 0.3277 - val_soft_acc: 0.7450\n",
      "Epoch 443/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.7065 - mean_absolute_error: 0.7065 - soft_acc: 0.4100\n",
      "Epoch 00443: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4983 - mean_absolute_error: 0.4983 - soft_acc: 0.6400 - val_loss: 0.4531 - val_mean_absolute_error: 0.4531 - val_soft_acc: 0.5936\n",
      "Epoch 444/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3757 - mean_absolute_error: 0.3757 - soft_acc: 0.7400\n",
      "Epoch 00444: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3566 - mean_absolute_error: 0.3566 - soft_acc: 0.7728 - val_loss: 0.4150 - val_mean_absolute_error: 0.4150 - val_soft_acc: 0.6621\n",
      "Epoch 445/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5372 - mean_absolute_error: 0.5372 - soft_acc: 0.5400\n",
      "Epoch 00445: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4359 - mean_absolute_error: 0.4359 - soft_acc: 0.5978 - val_loss: 0.4280 - val_mean_absolute_error: 0.4280 - val_soft_acc: 0.6493\n",
      "Epoch 446/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3938 - mean_absolute_error: 0.3938 - soft_acc: 0.6900\n",
      "Epoch 00446: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3346 - mean_absolute_error: 0.3346 - soft_acc: 0.7817 - val_loss: 0.6377 - val_mean_absolute_error: 0.6377 - val_soft_acc: 0.4114\n",
      "Epoch 447/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2947 - mean_absolute_error: 0.2947 - soft_acc: 0.8400\n",
      "Epoch 00447: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.7806 - val_loss: 0.4871 - val_mean_absolute_error: 0.4871 - val_soft_acc: 0.5279\n",
      "Epoch 448/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3745 - mean_absolute_error: 0.3745 - soft_acc: 0.6800\n",
      "Epoch 00448: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3557 - mean_absolute_error: 0.3557 - soft_acc: 0.7261 - val_loss: 0.5502 - val_mean_absolute_error: 0.5502 - val_soft_acc: 0.4543\n",
      "Epoch 449/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3311 - mean_absolute_error: 0.3311 - soft_acc: 0.7900\n",
      "Epoch 00449: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3153 - mean_absolute_error: 0.3153 - soft_acc: 0.8056 - val_loss: 0.6633 - val_mean_absolute_error: 0.6633 - val_soft_acc: 0.3757\n",
      "Epoch 450/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3533 - mean_absolute_error: 0.3533 - soft_acc: 0.7400\n",
      "Epoch 00450: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3555 - mean_absolute_error: 0.3555 - soft_acc: 0.7622 - val_loss: 0.6198 - val_mean_absolute_error: 0.6198 - val_soft_acc: 0.4371\n",
      "Epoch 451/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3183 - mean_absolute_error: 0.3183 - soft_acc: 0.7800\n",
      "Epoch 00451: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3250 - mean_absolute_error: 0.3250 - soft_acc: 0.7717 - val_loss: 0.6136 - val_mean_absolute_error: 0.6136 - val_soft_acc: 0.4293\n",
      "Epoch 452/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2873 - mean_absolute_error: 0.2873 - soft_acc: 0.8600\n",
      "Epoch 00452: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3215 - mean_absolute_error: 0.3215 - soft_acc: 0.8161 - val_loss: 0.5418 - val_mean_absolute_error: 0.5418 - val_soft_acc: 0.4414\n",
      "Epoch 453/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3044 - mean_absolute_error: 0.3044 - soft_acc: 0.8400\n",
      "Epoch 00453: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3172 - mean_absolute_error: 0.3172 - soft_acc: 0.8228 - val_loss: 0.5916 - val_mean_absolute_error: 0.5916 - val_soft_acc: 0.4829\n",
      "Epoch 454/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2819 - mean_absolute_error: 0.2819 - soft_acc: 0.8300\n",
      "Epoch 00454: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3167 - mean_absolute_error: 0.3167 - soft_acc: 0.7694 - val_loss: 0.4957 - val_mean_absolute_error: 0.4957 - val_soft_acc: 0.5636\n",
      "Epoch 455/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2895 - mean_absolute_error: 0.2895 - soft_acc: 0.8700\n",
      "Epoch 00455: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3122 - mean_absolute_error: 0.3122 - soft_acc: 0.8244 - val_loss: 0.4658 - val_mean_absolute_error: 0.4658 - val_soft_acc: 0.5221\n",
      "Epoch 456/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2971 - mean_absolute_error: 0.2971 - soft_acc: 0.7900\n",
      "Epoch 00456: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3193 - mean_absolute_error: 0.3193 - soft_acc: 0.7956 - val_loss: 0.4581 - val_mean_absolute_error: 0.4581 - val_soft_acc: 0.6014\n",
      "Epoch 457/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3204 - mean_absolute_error: 0.3204 - soft_acc: 0.8100\n",
      "Epoch 00457: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3233 - mean_absolute_error: 0.3233 - soft_acc: 0.8000 - val_loss: 0.7559 - val_mean_absolute_error: 0.7559 - val_soft_acc: 0.3614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4296 - mean_absolute_error: 0.4296 - soft_acc: 0.7000\n",
      "Epoch 00458: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3871 - mean_absolute_error: 0.3871 - soft_acc: 0.7011 - val_loss: 0.7569 - val_mean_absolute_error: 0.7569 - val_soft_acc: 0.3664\n",
      "Epoch 459/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3859 - mean_absolute_error: 0.3859 - soft_acc: 0.7400\n",
      "Epoch 00459: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3655 - mean_absolute_error: 0.3655 - soft_acc: 0.7094 - val_loss: 0.6941 - val_mean_absolute_error: 0.6941 - val_soft_acc: 0.3250\n",
      "Epoch 460/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3061 - mean_absolute_error: 0.3061 - soft_acc: 0.8100\n",
      "Epoch 00460: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3647 - mean_absolute_error: 0.3647 - soft_acc: 0.7439 - val_loss: 0.6489 - val_mean_absolute_error: 0.6489 - val_soft_acc: 0.3757\n",
      "Epoch 461/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3222 - mean_absolute_error: 0.3222 - soft_acc: 0.7700\n",
      "Epoch 00461: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3470 - mean_absolute_error: 0.3470 - soft_acc: 0.7506 - val_loss: 0.5503 - val_mean_absolute_error: 0.5503 - val_soft_acc: 0.4871\n",
      "Epoch 462/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3352 - mean_absolute_error: 0.3352 - soft_acc: 0.7900\n",
      "Epoch 00462: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3314 - mean_absolute_error: 0.3314 - soft_acc: 0.7850 - val_loss: 0.5415 - val_mean_absolute_error: 0.5415 - val_soft_acc: 0.5129\n",
      "Epoch 463/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3283 - mean_absolute_error: 0.3283 - soft_acc: 0.7900\n",
      "Epoch 00463: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3119 - mean_absolute_error: 0.3119 - soft_acc: 0.7950 - val_loss: 0.6595 - val_mean_absolute_error: 0.6595 - val_soft_acc: 0.4064\n",
      "Epoch 464/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3125 - mean_absolute_error: 0.3125 - soft_acc: 0.8000\n",
      "Epoch 00464: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3503 - mean_absolute_error: 0.3503 - soft_acc: 0.7322 - val_loss: 0.5673 - val_mean_absolute_error: 0.5673 - val_soft_acc: 0.4671\n",
      "Epoch 465/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3303 - mean_absolute_error: 0.3303 - soft_acc: 0.8200\n",
      "Epoch 00465: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3720 - mean_absolute_error: 0.3720 - soft_acc: 0.7344 - val_loss: 0.5562 - val_mean_absolute_error: 0.5562 - val_soft_acc: 0.4900\n",
      "Epoch 466/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3440 - mean_absolute_error: 0.3440 - soft_acc: 0.7800\n",
      "Epoch 00466: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3237 - mean_absolute_error: 0.3237 - soft_acc: 0.7689 - val_loss: 0.6093 - val_mean_absolute_error: 0.6093 - val_soft_acc: 0.4086\n",
      "Epoch 467/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3130 - mean_absolute_error: 0.3130 - soft_acc: 0.8100\n",
      "Epoch 00467: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3074 - mean_absolute_error: 0.3074 - soft_acc: 0.8122 - val_loss: 0.5835 - val_mean_absolute_error: 0.5835 - val_soft_acc: 0.4186\n",
      "Epoch 468/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3340 - mean_absolute_error: 0.3340 - soft_acc: 0.7900\n",
      "Epoch 00468: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3436 - mean_absolute_error: 0.3436 - soft_acc: 0.7683 - val_loss: 0.6924 - val_mean_absolute_error: 0.6924 - val_soft_acc: 0.3557\n",
      "Epoch 469/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3847 - mean_absolute_error: 0.3847 - soft_acc: 0.7300\n",
      "Epoch 00469: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3717 - mean_absolute_error: 0.3717 - soft_acc: 0.7056 - val_loss: 0.6155 - val_mean_absolute_error: 0.6155 - val_soft_acc: 0.4243\n",
      "Epoch 470/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3367 - mean_absolute_error: 0.3367 - soft_acc: 0.7900\n",
      "Epoch 00470: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3833 - mean_absolute_error: 0.3833 - soft_acc: 0.6994 - val_loss: 0.7205 - val_mean_absolute_error: 0.7205 - val_soft_acc: 0.3664\n",
      "Epoch 471/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4217 - mean_absolute_error: 0.4217 - soft_acc: 0.7200\n",
      "Epoch 00471: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3683 - mean_absolute_error: 0.3683 - soft_acc: 0.7222 - val_loss: 0.7132 - val_mean_absolute_error: 0.7132 - val_soft_acc: 0.3357\n",
      "Epoch 472/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3971 - mean_absolute_error: 0.3971 - soft_acc: 0.6900\n",
      "Epoch 00472: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3478 - mean_absolute_error: 0.3478 - soft_acc: 0.7861 - val_loss: 0.5042 - val_mean_absolute_error: 0.5042 - val_soft_acc: 0.5357\n",
      "Epoch 473/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.8000\n",
      "Epoch 00473: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3823 - mean_absolute_error: 0.3823 - soft_acc: 0.7372 - val_loss: 0.4764 - val_mean_absolute_error: 0.4764 - val_soft_acc: 0.5071\n",
      "Epoch 474/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4002 - mean_absolute_error: 0.4002 - soft_acc: 0.6500\n",
      "Epoch 00474: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3649 - mean_absolute_error: 0.3649 - soft_acc: 0.7456 - val_loss: 0.5769 - val_mean_absolute_error: 0.5769 - val_soft_acc: 0.5057\n",
      "Epoch 475/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2958 - mean_absolute_error: 0.2958 - soft_acc: 0.8500\n",
      "Epoch 00475: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3416 - mean_absolute_error: 0.3416 - soft_acc: 0.7461 - val_loss: 0.6630 - val_mean_absolute_error: 0.6630 - val_soft_acc: 0.3786\n",
      "Epoch 476/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3900 - mean_absolute_error: 0.3900 - soft_acc: 0.7400\n",
      "Epoch 00476: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3584 - mean_absolute_error: 0.3584 - soft_acc: 0.7650 - val_loss: 0.7432 - val_mean_absolute_error: 0.7432 - val_soft_acc: 0.3614\n",
      "Epoch 477/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4409 - mean_absolute_error: 0.4409 - soft_acc: 0.6300\n",
      "Epoch 00477: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3587 - mean_absolute_error: 0.3587 - soft_acc: 0.7622 - val_loss: 0.7252 - val_mean_absolute_error: 0.7252 - val_soft_acc: 0.3536\n",
      "Epoch 478/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3676 - mean_absolute_error: 0.3676 - soft_acc: 0.7500\n",
      "Epoch 00478: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3510 - mean_absolute_error: 0.3510 - soft_acc: 0.7417 - val_loss: 0.6184 - val_mean_absolute_error: 0.6184 - val_soft_acc: 0.4679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3109 - mean_absolute_error: 0.3109 - soft_acc: 0.8300\n",
      "Epoch 00479: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3175 - mean_absolute_error: 0.3175 - soft_acc: 0.7950 - val_loss: 0.6646 - val_mean_absolute_error: 0.6646 - val_soft_acc: 0.3964\n",
      "Epoch 480/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3265 - mean_absolute_error: 0.3265 - soft_acc: 0.8000\n",
      "Epoch 00480: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3344 - mean_absolute_error: 0.3344 - soft_acc: 0.8150 - val_loss: 0.7245 - val_mean_absolute_error: 0.7245 - val_soft_acc: 0.2764\n",
      "Epoch 481/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3948 - mean_absolute_error: 0.3948 - soft_acc: 0.6900\n",
      "Epoch 00481: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3518 - mean_absolute_error: 0.3518 - soft_acc: 0.7383 - val_loss: 0.7733 - val_mean_absolute_error: 0.7733 - val_soft_acc: 0.3436\n",
      "Epoch 482/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4942 - mean_absolute_error: 0.4942 - soft_acc: 0.5400\n",
      "Epoch 00482: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3840 - mean_absolute_error: 0.3840 - soft_acc: 0.6839 - val_loss: 0.6862 - val_mean_absolute_error: 0.6862 - val_soft_acc: 0.3764\n",
      "Epoch 483/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3708 - mean_absolute_error: 0.3708 - soft_acc: 0.6900\n",
      "Epoch 00483: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3724 - mean_absolute_error: 0.3724 - soft_acc: 0.7250 - val_loss: 0.4755 - val_mean_absolute_error: 0.4755 - val_soft_acc: 0.5114\n",
      "Epoch 484/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3755 - mean_absolute_error: 0.3755 - soft_acc: 0.7400\n",
      "Epoch 00484: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4158 - mean_absolute_error: 0.4158 - soft_acc: 0.6883 - val_loss: 0.3965 - val_mean_absolute_error: 0.3965 - val_soft_acc: 0.5821\n",
      "Epoch 485/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4644 - mean_absolute_error: 0.4644 - soft_acc: 0.5700\n",
      "Epoch 00485: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4540 - mean_absolute_error: 0.4540 - soft_acc: 0.6106 - val_loss: 0.4368 - val_mean_absolute_error: 0.4368 - val_soft_acc: 0.6779\n",
      "Epoch 486/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4810 - mean_absolute_error: 0.4810 - soft_acc: 0.6100\n",
      "Epoch 00486: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4356 - mean_absolute_error: 0.4356 - soft_acc: 0.6661 - val_loss: 0.7329 - val_mean_absolute_error: 0.7329 - val_soft_acc: 0.3564\n",
      "Epoch 487/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3110 - mean_absolute_error: 0.3110 - soft_acc: 0.8300\n",
      "Epoch 00487: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3330 - mean_absolute_error: 0.3330 - soft_acc: 0.7694 - val_loss: 0.8360 - val_mean_absolute_error: 0.8360 - val_soft_acc: 0.2671\n",
      "Epoch 488/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4527 - mean_absolute_error: 0.4527 - soft_acc: 0.6300\n",
      "Epoch 00488: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3833 - mean_absolute_error: 0.3833 - soft_acc: 0.7100 - val_loss: 0.8593 - val_mean_absolute_error: 0.8593 - val_soft_acc: 0.2729\n",
      "Epoch 489/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5182 - mean_absolute_error: 0.5182 - soft_acc: 0.5300\n",
      "Epoch 00489: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 58us/sample - loss: 0.4455 - mean_absolute_error: 0.4455 - soft_acc: 0.6444 - val_loss: 0.7688 - val_mean_absolute_error: 0.7688 - val_soft_acc: 0.3286\n",
      "Epoch 490/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3875 - mean_absolute_error: 0.3875 - soft_acc: 0.6900\n",
      "Epoch 00490: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3687 - mean_absolute_error: 0.3687 - soft_acc: 0.7422 - val_loss: 0.5741 - val_mean_absolute_error: 0.5741 - val_soft_acc: 0.4286\n",
      "Epoch 491/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3924 - mean_absolute_error: 0.3924 - soft_acc: 0.6700\n",
      "Epoch 00491: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3513 - mean_absolute_error: 0.3513 - soft_acc: 0.7328 - val_loss: 0.4578 - val_mean_absolute_error: 0.4578 - val_soft_acc: 0.6193\n",
      "Epoch 492/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3804 - mean_absolute_error: 0.3804 - soft_acc: 0.7500\n",
      "Epoch 00492: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3532 - mean_absolute_error: 0.3532 - soft_acc: 0.7622 - val_loss: 0.4020 - val_mean_absolute_error: 0.4020 - val_soft_acc: 0.6207\n",
      "Epoch 493/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4372 - mean_absolute_error: 0.4372 - soft_acc: 0.6500\n",
      "Epoch 00493: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3823 - mean_absolute_error: 0.3823 - soft_acc: 0.7394 - val_loss: 0.4184 - val_mean_absolute_error: 0.4184 - val_soft_acc: 0.6264\n",
      "Epoch 494/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4289 - mean_absolute_error: 0.4289 - soft_acc: 0.6600\n",
      "Epoch 00494: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3770 - mean_absolute_error: 0.3770 - soft_acc: 0.6922 - val_loss: 0.4537 - val_mean_absolute_error: 0.4537 - val_soft_acc: 0.5400\n",
      "Epoch 495/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4158 - mean_absolute_error: 0.4158 - soft_acc: 0.6600\n",
      "Epoch 00495: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3729 - mean_absolute_error: 0.3729 - soft_acc: 0.7678 - val_loss: 0.3959 - val_mean_absolute_error: 0.3959 - val_soft_acc: 0.6593\n",
      "Epoch 496/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4876 - mean_absolute_error: 0.4876 - soft_acc: 0.5800\n",
      "Epoch 00496: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4150 - mean_absolute_error: 0.4150 - soft_acc: 0.7206 - val_loss: 0.3914 - val_mean_absolute_error: 0.3914 - val_soft_acc: 0.6336\n",
      "Epoch 497/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4712 - mean_absolute_error: 0.4712 - soft_acc: 0.6100\n",
      "Epoch 00497: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3636 - mean_absolute_error: 0.3636 - soft_acc: 0.7417 - val_loss: 0.4338 - val_mean_absolute_error: 0.4338 - val_soft_acc: 0.6064\n",
      "Epoch 498/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3040 - mean_absolute_error: 0.3040 - soft_acc: 0.7800\n",
      "Epoch 00498: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3671 - mean_absolute_error: 0.3671 - soft_acc: 0.7167 - val_loss: 0.4126 - val_mean_absolute_error: 0.4126 - val_soft_acc: 0.6136\n",
      "Epoch 499/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4477 - mean_absolute_error: 0.4477 - soft_acc: 0.5900\n",
      "Epoch 00499: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4135 - mean_absolute_error: 0.4135 - soft_acc: 0.6656 - val_loss: 0.3134 - val_mean_absolute_error: 0.3134 - val_soft_acc: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.8772 - mean_absolute_error: 0.8772 - soft_acc: 0.4000\n",
      "Epoch 00500: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.7061 - mean_absolute_error: 0.7061 - soft_acc: 0.4400 - val_loss: 0.8591 - val_mean_absolute_error: 0.8591 - val_soft_acc: 0.2550\n",
      "Epoch 501/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4659 - mean_absolute_error: 0.4659 - soft_acc: 0.5800\n",
      "Epoch 00501: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4873 - mean_absolute_error: 0.4873 - soft_acc: 0.6339 - val_loss: 1.0019 - val_mean_absolute_error: 1.0019 - val_soft_acc: 0.1593\n",
      "Epoch 502/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6458 - mean_absolute_error: 0.6458 - soft_acc: 0.4700\n",
      "Epoch 00502: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5337 - mean_absolute_error: 0.5337 - soft_acc: 0.5967 - val_loss: 0.7837 - val_mean_absolute_error: 0.7837 - val_soft_acc: 0.3286\n",
      "Epoch 503/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3336 - mean_absolute_error: 0.3336 - soft_acc: 0.7800\n",
      "Epoch 00503: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3937 - mean_absolute_error: 0.3937 - soft_acc: 0.7233 - val_loss: 0.6848 - val_mean_absolute_error: 0.6848 - val_soft_acc: 0.3129\n",
      "Epoch 504/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3624 - mean_absolute_error: 0.3624 - soft_acc: 0.7300\n",
      "Epoch 00504: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3376 - mean_absolute_error: 0.3376 - soft_acc: 0.7494 - val_loss: 0.6149 - val_mean_absolute_error: 0.6149 - val_soft_acc: 0.4143\n",
      "Epoch 505/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3278 - mean_absolute_error: 0.3278 - soft_acc: 0.7700\n",
      "Epoch 00505: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3428 - mean_absolute_error: 0.3428 - soft_acc: 0.7428 - val_loss: 0.6185 - val_mean_absolute_error: 0.6185 - val_soft_acc: 0.3729\n",
      "Epoch 506/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3111 - mean_absolute_error: 0.3111 - soft_acc: 0.8200\n",
      "Epoch 00506: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3327 - mean_absolute_error: 0.3327 - soft_acc: 0.8039 - val_loss: 0.4183 - val_mean_absolute_error: 0.4183 - val_soft_acc: 0.5650\n",
      "Epoch 507/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6085 - mean_absolute_error: 0.6085 - soft_acc: 0.5100\n",
      "Epoch 00507: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4496 - mean_absolute_error: 0.4496 - soft_acc: 0.6878 - val_loss: 0.3685 - val_mean_absolute_error: 0.3685 - val_soft_acc: 0.6486\n",
      "Epoch 508/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6079 - mean_absolute_error: 0.6079 - soft_acc: 0.4900\n",
      "Epoch 00508: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.6129 - mean_absolute_error: 0.6129 - soft_acc: 0.4944 - val_loss: 0.7085 - val_mean_absolute_error: 0.7085 - val_soft_acc: 0.3329\n",
      "Epoch 509/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4175 - mean_absolute_error: 0.4175 - soft_acc: 0.7000\n",
      "Epoch 00509: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4169 - mean_absolute_error: 0.4169 - soft_acc: 0.6750 - val_loss: 0.8435 - val_mean_absolute_error: 0.8435 - val_soft_acc: 0.2471\n",
      "Epoch 510/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5343 - mean_absolute_error: 0.5343 - soft_acc: 0.5100\n",
      "Epoch 00510: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4261 - mean_absolute_error: 0.4261 - soft_acc: 0.6578 - val_loss: 0.6718 - val_mean_absolute_error: 0.6718 - val_soft_acc: 0.3143\n",
      "Epoch 511/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3847 - mean_absolute_error: 0.3847 - soft_acc: 0.7000\n",
      "Epoch 00511: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3403 - mean_absolute_error: 0.3403 - soft_acc: 0.7806 - val_loss: 0.5424 - val_mean_absolute_error: 0.5424 - val_soft_acc: 0.5286\n",
      "Epoch 512/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3225 - mean_absolute_error: 0.3225 - soft_acc: 0.7800\n",
      "Epoch 00512: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3394 - mean_absolute_error: 0.3394 - soft_acc: 0.7544 - val_loss: 0.4138 - val_mean_absolute_error: 0.4138 - val_soft_acc: 0.6136\n",
      "Epoch 513/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4703 - mean_absolute_error: 0.4703 - soft_acc: 0.6100\n",
      "Epoch 00513: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3915 - mean_absolute_error: 0.3915 - soft_acc: 0.6928 - val_loss: 0.5608 - val_mean_absolute_error: 0.5608 - val_soft_acc: 0.5029\n",
      "Epoch 514/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3643 - mean_absolute_error: 0.3643 - soft_acc: 0.7300\n",
      "Epoch 00514: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3205 - mean_absolute_error: 0.3205 - soft_acc: 0.8106 - val_loss: 0.5175 - val_mean_absolute_error: 0.5175 - val_soft_acc: 0.5050\n",
      "Epoch 515/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3826 - mean_absolute_error: 0.3826 - soft_acc: 0.7400\n",
      "Epoch 00515: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3295 - mean_absolute_error: 0.3295 - soft_acc: 0.7822 - val_loss: 0.7271 - val_mean_absolute_error: 0.7271 - val_soft_acc: 0.3971\n",
      "Epoch 516/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3954 - mean_absolute_error: 0.3954 - soft_acc: 0.7300\n",
      "Epoch 00516: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3565 - mean_absolute_error: 0.3565 - soft_acc: 0.7278 - val_loss: 0.6956 - val_mean_absolute_error: 0.6956 - val_soft_acc: 0.3636\n",
      "Epoch 517/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4530 - mean_absolute_error: 0.4530 - soft_acc: 0.6900\n",
      "Epoch 00517: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3539 - mean_absolute_error: 0.3539 - soft_acc: 0.7706 - val_loss: 0.7478 - val_mean_absolute_error: 0.7478 - val_soft_acc: 0.3179\n",
      "Epoch 518/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4494 - mean_absolute_error: 0.4494 - soft_acc: 0.6500\n",
      "Epoch 00518: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4457 - mean_absolute_error: 0.4457 - soft_acc: 0.6500 - val_loss: 0.8315 - val_mean_absolute_error: 0.8315 - val_soft_acc: 0.3057\n",
      "Epoch 519/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5871 - mean_absolute_error: 0.5871 - soft_acc: 0.4900\n",
      "Epoch 00519: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5487 - mean_absolute_error: 0.5487 - soft_acc: 0.5583 - val_loss: 0.6239 - val_mean_absolute_error: 0.6239 - val_soft_acc: 0.3857\n",
      "Epoch 520/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3930 - mean_absolute_error: 0.3930 - soft_acc: 0.6600\n",
      "Epoch 00520: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3815 - mean_absolute_error: 0.3815 - soft_acc: 0.7189 - val_loss: 0.7577 - val_mean_absolute_error: 0.7577 - val_soft_acc: 0.3100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4724 - mean_absolute_error: 0.4724 - soft_acc: 0.5700\n",
      "Epoch 00521: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4551 - mean_absolute_error: 0.4551 - soft_acc: 0.6294 - val_loss: 0.5927 - val_mean_absolute_error: 0.5927 - val_soft_acc: 0.4393\n",
      "Epoch 522/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3000 - mean_absolute_error: 0.3000 - soft_acc: 0.8200\n",
      "Epoch 00522: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3914 - mean_absolute_error: 0.3914 - soft_acc: 0.7206 - val_loss: 0.4922 - val_mean_absolute_error: 0.4922 - val_soft_acc: 0.4736\n",
      "Epoch 523/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3312 - mean_absolute_error: 0.3312 - soft_acc: 0.7700\n",
      "Epoch 00523: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3507 - mean_absolute_error: 0.3507 - soft_acc: 0.7661 - val_loss: 0.4194 - val_mean_absolute_error: 0.4194 - val_soft_acc: 0.5721\n",
      "Epoch 524/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4182 - mean_absolute_error: 0.4182 - soft_acc: 0.6900\n",
      "Epoch 00524: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3733 - mean_absolute_error: 0.3733 - soft_acc: 0.7450 - val_loss: 0.5282 - val_mean_absolute_error: 0.5282 - val_soft_acc: 0.5179\n",
      "Epoch 525/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3075 - mean_absolute_error: 0.3075 - soft_acc: 0.8200\n",
      "Epoch 00525: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3332 - mean_absolute_error: 0.3332 - soft_acc: 0.7556 - val_loss: 0.5588 - val_mean_absolute_error: 0.5588 - val_soft_acc: 0.4464\n",
      "Epoch 526/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3401 - mean_absolute_error: 0.3401 - soft_acc: 0.7400\n",
      "Epoch 00526: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3468 - mean_absolute_error: 0.3468 - soft_acc: 0.7450 - val_loss: 0.5582 - val_mean_absolute_error: 0.5582 - val_soft_acc: 0.4821\n",
      "Epoch 527/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3427 - mean_absolute_error: 0.3427 - soft_acc: 0.8200\n",
      "Epoch 00527: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3701 - mean_absolute_error: 0.3701 - soft_acc: 0.7517 - val_loss: 0.6282 - val_mean_absolute_error: 0.6282 - val_soft_acc: 0.4014\n",
      "Epoch 528/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2990 - mean_absolute_error: 0.2990 - soft_acc: 0.8500\n",
      "Epoch 00528: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3124 - mean_absolute_error: 0.3124 - soft_acc: 0.7633 - val_loss: 0.7099 - val_mean_absolute_error: 0.7099 - val_soft_acc: 0.3329\n",
      "Epoch 529/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3770 - mean_absolute_error: 0.3770 - soft_acc: 0.6600\n",
      "Epoch 00529: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4152 - mean_absolute_error: 0.4152 - soft_acc: 0.6722 - val_loss: 0.6011 - val_mean_absolute_error: 0.6011 - val_soft_acc: 0.4521\n",
      "Epoch 530/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3614 - mean_absolute_error: 0.3614 - soft_acc: 0.7300\n",
      "Epoch 00530: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3413 - mean_absolute_error: 0.3413 - soft_acc: 0.7478 - val_loss: 0.7493 - val_mean_absolute_error: 0.7493 - val_soft_acc: 0.3386\n",
      "Epoch 531/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4361 - mean_absolute_error: 0.4361 - soft_acc: 0.6600\n",
      "Epoch 00531: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4467 - mean_absolute_error: 0.4467 - soft_acc: 0.6922 - val_loss: 0.7750 - val_mean_absolute_error: 0.7750 - val_soft_acc: 0.3543\n",
      "Epoch 532/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4585 - mean_absolute_error: 0.4585 - soft_acc: 0.6600\n",
      "Epoch 00532: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4573 - mean_absolute_error: 0.4573 - soft_acc: 0.6289 - val_loss: 0.5879 - val_mean_absolute_error: 0.5879 - val_soft_acc: 0.4364\n",
      "Epoch 533/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3110 - mean_absolute_error: 0.3110 - soft_acc: 0.8000\n",
      "Epoch 00533: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3555 - mean_absolute_error: 0.3555 - soft_acc: 0.7694 - val_loss: 0.7136 - val_mean_absolute_error: 0.7136 - val_soft_acc: 0.3407\n",
      "Epoch 534/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4135 - mean_absolute_error: 0.4135 - soft_acc: 0.7200\n",
      "Epoch 00534: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3881 - mean_absolute_error: 0.3881 - soft_acc: 0.7106 - val_loss: 0.6511 - val_mean_absolute_error: 0.6511 - val_soft_acc: 0.3629\n",
      "Epoch 535/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3395 - mean_absolute_error: 0.3395 - soft_acc: 0.7100\n",
      "Epoch 00535: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3575 - mean_absolute_error: 0.3575 - soft_acc: 0.7622 - val_loss: 0.7043 - val_mean_absolute_error: 0.7043 - val_soft_acc: 0.3150\n",
      "Epoch 536/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3143 - mean_absolute_error: 0.3143 - soft_acc: 0.7800\n",
      "Epoch 00536: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3532 - mean_absolute_error: 0.3532 - soft_acc: 0.7378 - val_loss: 0.6334 - val_mean_absolute_error: 0.6334 - val_soft_acc: 0.4143\n",
      "Epoch 537/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3029 - mean_absolute_error: 0.3029 - soft_acc: 0.8000\n",
      "Epoch 00537: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3250 - mean_absolute_error: 0.3250 - soft_acc: 0.7872 - val_loss: 0.7208 - val_mean_absolute_error: 0.7208 - val_soft_acc: 0.3386\n",
      "Epoch 538/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3446 - mean_absolute_error: 0.3446 - soft_acc: 0.7900\n",
      "Epoch 00538: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4152 - mean_absolute_error: 0.4152 - soft_acc: 0.6794 - val_loss: 0.5963 - val_mean_absolute_error: 0.5963 - val_soft_acc: 0.4343\n",
      "Epoch 539/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3004 - mean_absolute_error: 0.3004 - soft_acc: 0.8300\n",
      "Epoch 00539: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3141 - mean_absolute_error: 0.3141 - soft_acc: 0.7828 - val_loss: 0.5298 - val_mean_absolute_error: 0.5298 - val_soft_acc: 0.5357\n",
      "Epoch 540/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3892 - mean_absolute_error: 0.3892 - soft_acc: 0.7000\n",
      "Epoch 00540: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3340 - mean_absolute_error: 0.3340 - soft_acc: 0.8100 - val_loss: 0.5863 - val_mean_absolute_error: 0.5863 - val_soft_acc: 0.4621\n",
      "Epoch 541/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2502 - mean_absolute_error: 0.2502 - soft_acc: 0.9200\n",
      "Epoch 00541: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3122 - mean_absolute_error: 0.3122 - soft_acc: 0.8378 - val_loss: 0.6353 - val_mean_absolute_error: 0.6353 - val_soft_acc: 0.4221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3739 - mean_absolute_error: 0.3739 - soft_acc: 0.7600\n",
      "Epoch 00542: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - soft_acc: 0.7600 - val_loss: 0.5574 - val_mean_absolute_error: 0.5574 - val_soft_acc: 0.4414\n",
      "Epoch 543/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2806 - mean_absolute_error: 0.2806 - soft_acc: 0.8400\n",
      "Epoch 00543: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 51us/sample - loss: 0.3131 - mean_absolute_error: 0.3131 - soft_acc: 0.8000 - val_loss: 0.6533 - val_mean_absolute_error: 0.6533 - val_soft_acc: 0.4429\n",
      "Epoch 544/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3501 - mean_absolute_error: 0.3501 - soft_acc: 0.7800\n",
      "Epoch 00544: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3485 - mean_absolute_error: 0.3485 - soft_acc: 0.7428 - val_loss: 0.5145 - val_mean_absolute_error: 0.5145 - val_soft_acc: 0.5536\n",
      "Epoch 545/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2716 - mean_absolute_error: 0.2716 - soft_acc: 0.8700\n",
      "Epoch 00545: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3200 - mean_absolute_error: 0.3200 - soft_acc: 0.7822 - val_loss: 0.6066 - val_mean_absolute_error: 0.6066 - val_soft_acc: 0.4243\n",
      "Epoch 546/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3076 - mean_absolute_error: 0.3076 - soft_acc: 0.8300\n",
      "Epoch 00546: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3280 - mean_absolute_error: 0.3280 - soft_acc: 0.7872 - val_loss: 0.5090 - val_mean_absolute_error: 0.5090 - val_soft_acc: 0.5200\n",
      "Epoch 547/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3335 - mean_absolute_error: 0.3335 - soft_acc: 0.7500\n",
      "Epoch 00547: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3087 - mean_absolute_error: 0.3087 - soft_acc: 0.7861 - val_loss: 0.5224 - val_mean_absolute_error: 0.5224 - val_soft_acc: 0.5229\n",
      "Epoch 548/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3057 - mean_absolute_error: 0.3057 - soft_acc: 0.7600\n",
      "Epoch 00548: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3105 - mean_absolute_error: 0.3105 - soft_acc: 0.8089 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118 - val_soft_acc: 0.5200\n",
      "Epoch 549/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2879 - mean_absolute_error: 0.2879 - soft_acc: 0.8300\n",
      "Epoch 00549: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3104 - mean_absolute_error: 0.3104 - soft_acc: 0.8294 - val_loss: 0.5644 - val_mean_absolute_error: 0.5644 - val_soft_acc: 0.4593\n",
      "Epoch 550/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2436 - mean_absolute_error: 0.2436 - soft_acc: 0.8900\n",
      "Epoch 00550: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3034 - mean_absolute_error: 0.3034 - soft_acc: 0.7833 - val_loss: 0.3650 - val_mean_absolute_error: 0.3650 - val_soft_acc: 0.6257\n",
      "Epoch 551/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5120 - mean_absolute_error: 0.5120 - soft_acc: 0.5400\n",
      "Epoch 00551: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3964 - mean_absolute_error: 0.3964 - soft_acc: 0.6983 - val_loss: 0.3556 - val_mean_absolute_error: 0.3556 - val_soft_acc: 0.6407\n",
      "Epoch 552/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4648 - mean_absolute_error: 0.4648 - soft_acc: 0.6500\n",
      "Epoch 00552: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4003 - mean_absolute_error: 0.4003 - soft_acc: 0.7122 - val_loss: 0.3893 - val_mean_absolute_error: 0.3893 - val_soft_acc: 0.6671\n",
      "Epoch 553/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5385 - mean_absolute_error: 0.5385 - soft_acc: 0.5300\n",
      "Epoch 00553: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4287 - mean_absolute_error: 0.4287 - soft_acc: 0.6672 - val_loss: 0.3802 - val_mean_absolute_error: 0.3802 - val_soft_acc: 0.6414\n",
      "Epoch 554/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5937 - mean_absolute_error: 0.5937 - soft_acc: 0.4800\n",
      "Epoch 00554: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4698 - mean_absolute_error: 0.4698 - soft_acc: 0.6161 - val_loss: 0.5025 - val_mean_absolute_error: 0.5025 - val_soft_acc: 0.5457\n",
      "Epoch 555/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3793 - mean_absolute_error: 0.3793 - soft_acc: 0.7200\n",
      "Epoch 00555: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3750 - mean_absolute_error: 0.3750 - soft_acc: 0.7389 - val_loss: 0.4575 - val_mean_absolute_error: 0.4575 - val_soft_acc: 0.6043\n",
      "Epoch 556/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4516 - mean_absolute_error: 0.4516 - soft_acc: 0.6200\n",
      "Epoch 00556: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4090 - mean_absolute_error: 0.4090 - soft_acc: 0.7072 - val_loss: 0.5435 - val_mean_absolute_error: 0.5435 - val_soft_acc: 0.4921\n",
      "Epoch 557/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3447 - mean_absolute_error: 0.3447 - soft_acc: 0.7400\n",
      "Epoch 00557: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3843 - mean_absolute_error: 0.3843 - soft_acc: 0.7167 - val_loss: 0.6089 - val_mean_absolute_error: 0.6089 - val_soft_acc: 0.3729\n",
      "Epoch 558/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3087 - mean_absolute_error: 0.3087 - soft_acc: 0.8500\n",
      "Epoch 00558: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3205 - mean_absolute_error: 0.3205 - soft_acc: 0.7656 - val_loss: 0.5484 - val_mean_absolute_error: 0.5484 - val_soft_acc: 0.5000\n",
      "Epoch 559/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3148 - mean_absolute_error: 0.3148 - soft_acc: 0.7800\n",
      "Epoch 00559: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3234 - mean_absolute_error: 0.3234 - soft_acc: 0.7711 - val_loss: 0.5199 - val_mean_absolute_error: 0.5199 - val_soft_acc: 0.4843\n",
      "Epoch 560/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3202 - mean_absolute_error: 0.3202 - soft_acc: 0.7800\n",
      "Epoch 00560: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3379 - mean_absolute_error: 0.3379 - soft_acc: 0.7667 - val_loss: 0.4728 - val_mean_absolute_error: 0.4728 - val_soft_acc: 0.4964\n",
      "Epoch 561/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3700 - mean_absolute_error: 0.3700 - soft_acc: 0.7400\n",
      "Epoch 00561: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4098 - mean_absolute_error: 0.4098 - soft_acc: 0.7017 - val_loss: 0.4994 - val_mean_absolute_error: 0.4994 - val_soft_acc: 0.5586\n",
      "Epoch 562/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3329 - mean_absolute_error: 0.3329 - soft_acc: 0.8000\n",
      "Epoch 00562: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3435 - mean_absolute_error: 0.3435 - soft_acc: 0.7928 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.4993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3879 - mean_absolute_error: 0.3879 - soft_acc: 0.7300\n",
      "Epoch 00563: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3362 - mean_absolute_error: 0.3362 - soft_acc: 0.7633 - val_loss: 0.5640 - val_mean_absolute_error: 0.5640 - val_soft_acc: 0.4671\n",
      "Epoch 564/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2867 - mean_absolute_error: 0.2867 - soft_acc: 0.8300\n",
      "Epoch 00564: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3149 - mean_absolute_error: 0.3149 - soft_acc: 0.8094 - val_loss: 0.4838 - val_mean_absolute_error: 0.4838 - val_soft_acc: 0.5479\n",
      "Epoch 565/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3412 - mean_absolute_error: 0.3412 - soft_acc: 0.7500\n",
      "Epoch 00565: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3456 - mean_absolute_error: 0.3456 - soft_acc: 0.7772 - val_loss: 0.4853 - val_mean_absolute_error: 0.4853 - val_soft_acc: 0.5764\n",
      "Epoch 566/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6985 - mean_absolute_error: 0.6985 - soft_acc: 0.8300\n",
      "Epoch 00566: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4926 - mean_absolute_error: 0.4926 - soft_acc: 0.7856 - val_loss: 0.3389 - val_mean_absolute_error: 0.3389 - val_soft_acc: 0.7171\n",
      "Epoch 567/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4923 - mean_absolute_error: 0.4923 - soft_acc: 0.6100\n",
      "Epoch 00567: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4480 - mean_absolute_error: 0.4480 - soft_acc: 0.6494 - val_loss: 0.3925 - val_mean_absolute_error: 0.3925 - val_soft_acc: 0.6107\n",
      "Epoch 568/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4759 - mean_absolute_error: 0.4759 - soft_acc: 0.6000\n",
      "Epoch 00568: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3600 - mean_absolute_error: 0.3600 - soft_acc: 0.7450 - val_loss: 0.5046 - val_mean_absolute_error: 0.5046 - val_soft_acc: 0.5664\n",
      "Epoch 569/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3608 - mean_absolute_error: 0.3608 - soft_acc: 0.7500\n",
      "Epoch 00569: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3201 - mean_absolute_error: 0.3201 - soft_acc: 0.7967 - val_loss: 0.5643 - val_mean_absolute_error: 0.5643 - val_soft_acc: 0.4721\n",
      "Epoch 570/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3089 - mean_absolute_error: 0.3089 - soft_acc: 0.8100\n",
      "Epoch 00570: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3192 - mean_absolute_error: 0.3192 - soft_acc: 0.7683 - val_loss: 0.6995 - val_mean_absolute_error: 0.6995 - val_soft_acc: 0.2971\n",
      "Epoch 571/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3359 - mean_absolute_error: 0.3359 - soft_acc: 0.7400\n",
      "Epoch 00571: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3520 - mean_absolute_error: 0.3520 - soft_acc: 0.7761 - val_loss: 0.5254 - val_mean_absolute_error: 0.5254 - val_soft_acc: 0.5821\n",
      "Epoch 572/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2950 - mean_absolute_error: 0.2950 - soft_acc: 0.7900\n",
      "Epoch 00572: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3157 - mean_absolute_error: 0.3157 - soft_acc: 0.8089 - val_loss: 0.5128 - val_mean_absolute_error: 0.5128 - val_soft_acc: 0.5150\n",
      "Epoch 573/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3510 - mean_absolute_error: 0.3510 - soft_acc: 0.7200\n",
      "Epoch 00573: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3176 - mean_absolute_error: 0.3176 - soft_acc: 0.8039 - val_loss: 0.4121 - val_mean_absolute_error: 0.4121 - val_soft_acc: 0.6650\n",
      "Epoch 574/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3350 - mean_absolute_error: 0.3350 - soft_acc: 0.7500\n",
      "Epoch 00574: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3258 - mean_absolute_error: 0.3258 - soft_acc: 0.7872 - val_loss: 0.3505 - val_mean_absolute_error: 0.3505 - val_soft_acc: 0.7071\n",
      "Epoch 575/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4651 - mean_absolute_error: 0.4651 - soft_acc: 0.6500\n",
      "Epoch 00575: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4099 - mean_absolute_error: 0.4099 - soft_acc: 0.6928 - val_loss: 0.3524 - val_mean_absolute_error: 0.3524 - val_soft_acc: 0.7457\n",
      "Epoch 576/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5178 - mean_absolute_error: 0.5178 - soft_acc: 0.5100\n",
      "Epoch 00576: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3811 - mean_absolute_error: 0.3811 - soft_acc: 0.6911 - val_loss: 0.3674 - val_mean_absolute_error: 0.3674 - val_soft_acc: 0.6743\n",
      "Epoch 577/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4382 - mean_absolute_error: 0.4382 - soft_acc: 0.6200\n",
      "Epoch 00577: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3935 - mean_absolute_error: 0.3935 - soft_acc: 0.6889 - val_loss: 0.6881 - val_mean_absolute_error: 0.6881 - val_soft_acc: 0.3814\n",
      "Epoch 578/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4646 - mean_absolute_error: 0.4646 - soft_acc: 0.6500\n",
      "Epoch 00578: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3990 - mean_absolute_error: 0.3990 - soft_acc: 0.7061 - val_loss: 0.8001 - val_mean_absolute_error: 0.8001 - val_soft_acc: 0.2414\n",
      "Epoch 579/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4715 - mean_absolute_error: 0.4715 - soft_acc: 0.5800\n",
      "Epoch 00579: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3822 - mean_absolute_error: 0.3822 - soft_acc: 0.7228 - val_loss: 0.7981 - val_mean_absolute_error: 0.7981 - val_soft_acc: 0.3186\n",
      "Epoch 580/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4266 - mean_absolute_error: 0.4266 - soft_acc: 0.6800\n",
      "Epoch 00580: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3630 - mean_absolute_error: 0.3630 - soft_acc: 0.7706 - val_loss: 0.7684 - val_mean_absolute_error: 0.7684 - val_soft_acc: 0.3157\n",
      "Epoch 581/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4080 - mean_absolute_error: 0.4080 - soft_acc: 0.6500\n",
      "Epoch 00581: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3579 - mean_absolute_error: 0.3579 - soft_acc: 0.7261 - val_loss: 0.6613 - val_mean_absolute_error: 0.6613 - val_soft_acc: 0.3686\n",
      "Epoch 582/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2678 - mean_absolute_error: 0.2678 - soft_acc: 0.8600\n",
      "Epoch 00582: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3279 - mean_absolute_error: 0.3279 - soft_acc: 0.7300 - val_loss: 0.5831 - val_mean_absolute_error: 0.5831 - val_soft_acc: 0.4879\n",
      "Epoch 583/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3094 - mean_absolute_error: 0.3094 - soft_acc: 0.8200\n",
      "Epoch 00583: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3411 - mean_absolute_error: 0.3411 - soft_acc: 0.7683 - val_loss: 0.4803 - val_mean_absolute_error: 0.4803 - val_soft_acc: 0.5479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3847 - mean_absolute_error: 0.3847 - soft_acc: 0.7500\n",
      "Epoch 00584: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3660 - mean_absolute_error: 0.3660 - soft_acc: 0.6983 - val_loss: 0.5417 - val_mean_absolute_error: 0.5417 - val_soft_acc: 0.5336\n",
      "Epoch 585/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3117 - mean_absolute_error: 0.3117 - soft_acc: 0.7800\n",
      "Epoch 00585: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3262 - mean_absolute_error: 0.3262 - soft_acc: 0.7628 - val_loss: 0.6806 - val_mean_absolute_error: 0.6806 - val_soft_acc: 0.3843\n",
      "Epoch 586/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3851 - mean_absolute_error: 0.3851 - soft_acc: 0.7700\n",
      "Epoch 00586: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3321 - mean_absolute_error: 0.3321 - soft_acc: 0.8217 - val_loss: 0.5862 - val_mean_absolute_error: 0.5862 - val_soft_acc: 0.4929\n",
      "Epoch 587/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3598 - mean_absolute_error: 0.3598 - soft_acc: 0.7400\n",
      "Epoch 00587: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3436 - mean_absolute_error: 0.3436 - soft_acc: 0.8033 - val_loss: 0.4708 - val_mean_absolute_error: 0.4708 - val_soft_acc: 0.5757\n",
      "Epoch 588/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4197 - mean_absolute_error: 0.4197 - soft_acc: 0.6700\n",
      "Epoch 00588: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3334 - mean_absolute_error: 0.3334 - soft_acc: 0.7817 - val_loss: 0.6184 - val_mean_absolute_error: 0.6184 - val_soft_acc: 0.4343\n",
      "Epoch 589/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3109 - mean_absolute_error: 0.3109 - soft_acc: 0.8200\n",
      "Epoch 00589: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3138 - mean_absolute_error: 0.3138 - soft_acc: 0.8194 - val_loss: 0.6322 - val_mean_absolute_error: 0.6322 - val_soft_acc: 0.4014\n",
      "Epoch 590/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3706 - mean_absolute_error: 0.3706 - soft_acc: 0.7200\n",
      "Epoch 00590: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3202 - mean_absolute_error: 0.3202 - soft_acc: 0.8128 - val_loss: 0.5501 - val_mean_absolute_error: 0.5501 - val_soft_acc: 0.4950\n",
      "Epoch 591/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2826 - mean_absolute_error: 0.2826 - soft_acc: 0.8400\n",
      "Epoch 00591: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3123 - mean_absolute_error: 0.3123 - soft_acc: 0.8178 - val_loss: 0.6212 - val_mean_absolute_error: 0.6212 - val_soft_acc: 0.4143\n",
      "Epoch 592/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3083 - mean_absolute_error: 0.3083 - soft_acc: 0.8400\n",
      "Epoch 00592: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3137 - mean_absolute_error: 0.3137 - soft_acc: 0.8033 - val_loss: 0.5552 - val_mean_absolute_error: 0.5552 - val_soft_acc: 0.4614\n",
      "Epoch 593/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2704 - mean_absolute_error: 0.2704 - soft_acc: 0.8800\n",
      "Epoch 00593: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3499 - mean_absolute_error: 0.3499 - soft_acc: 0.7722 - val_loss: 0.4589 - val_mean_absolute_error: 0.4589 - val_soft_acc: 0.5807\n",
      "Epoch 594/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4460 - mean_absolute_error: 0.4460 - soft_acc: 0.6600\n",
      "Epoch 00594: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3303 - mean_absolute_error: 0.3303 - soft_acc: 0.7922 - val_loss: 0.6129 - val_mean_absolute_error: 0.6129 - val_soft_acc: 0.4600\n",
      "Epoch 595/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2761 - mean_absolute_error: 0.2761 - soft_acc: 0.8400\n",
      "Epoch 00595: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3107 - mean_absolute_error: 0.3107 - soft_acc: 0.8244 - val_loss: 0.6990 - val_mean_absolute_error: 0.6990 - val_soft_acc: 0.3486\n",
      "Epoch 596/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3727 - mean_absolute_error: 0.3727 - soft_acc: 0.7300\n",
      "Epoch 00596: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3294 - mean_absolute_error: 0.3294 - soft_acc: 0.7944 - val_loss: 0.5908 - val_mean_absolute_error: 0.5908 - val_soft_acc: 0.4650\n",
      "Epoch 597/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3083 - mean_absolute_error: 0.3083 - soft_acc: 0.8200\n",
      "Epoch 00597: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3500 - mean_absolute_error: 0.3500 - soft_acc: 0.7761 - val_loss: 0.4796 - val_mean_absolute_error: 0.4796 - val_soft_acc: 0.5529\n",
      "Epoch 598/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4025 - mean_absolute_error: 0.4025 - soft_acc: 0.6900\n",
      "Epoch 00598: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3411 - mean_absolute_error: 0.3411 - soft_acc: 0.7378 - val_loss: 0.6525 - val_mean_absolute_error: 0.6525 - val_soft_acc: 0.3786\n",
      "Epoch 599/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3201 - mean_absolute_error: 0.3201 - soft_acc: 0.8100\n",
      "Epoch 00599: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3169 - mean_absolute_error: 0.3169 - soft_acc: 0.7983 - val_loss: 0.6125 - val_mean_absolute_error: 0.6125 - val_soft_acc: 0.4136\n",
      "Epoch 600/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3086 - mean_absolute_error: 0.3086 - soft_acc: 0.8100\n",
      "Epoch 00600: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3164 - mean_absolute_error: 0.3164 - soft_acc: 0.7817 - val_loss: 0.5225 - val_mean_absolute_error: 0.5225 - val_soft_acc: 0.5357\n",
      "Epoch 601/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3264 - mean_absolute_error: 0.3264 - soft_acc: 0.8000\n",
      "Epoch 00601: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3370 - mean_absolute_error: 0.3370 - soft_acc: 0.7722 - val_loss: 0.4471 - val_mean_absolute_error: 0.4471 - val_soft_acc: 0.5214\n",
      "Epoch 602/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4127 - mean_absolute_error: 0.4127 - soft_acc: 0.6900\n",
      "Epoch 00602: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3402 - mean_absolute_error: 0.3402 - soft_acc: 0.7722 - val_loss: 0.5201 - val_mean_absolute_error: 0.5201 - val_soft_acc: 0.4714\n",
      "Epoch 603/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3151 - mean_absolute_error: 0.3151 - soft_acc: 0.7700\n",
      "Epoch 00603: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3173 - mean_absolute_error: 0.3173 - soft_acc: 0.7811 - val_loss: 0.5909 - val_mean_absolute_error: 0.5909 - val_soft_acc: 0.4364\n",
      "Epoch 604/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3012 - mean_absolute_error: 0.3012 - soft_acc: 0.8300\n",
      "Epoch 00604: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3206 - mean_absolute_error: 0.3206 - soft_acc: 0.7906 - val_loss: 0.5037 - val_mean_absolute_error: 0.5037 - val_soft_acc: 0.5407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3624 - mean_absolute_error: 0.3624 - soft_acc: 0.7500\n",
      "Epoch 00605: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3261 - mean_absolute_error: 0.3261 - soft_acc: 0.7933 - val_loss: 0.5392 - val_mean_absolute_error: 0.5392 - val_soft_acc: 0.4486\n",
      "Epoch 606/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3279 - mean_absolute_error: 0.3279 - soft_acc: 0.8200\n",
      "Epoch 00606: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3418 - mean_absolute_error: 0.3418 - soft_acc: 0.7822 - val_loss: 0.5804 - val_mean_absolute_error: 0.5804 - val_soft_acc: 0.4493\n",
      "Epoch 607/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2701 - mean_absolute_error: 0.2701 - soft_acc: 0.8200\n",
      "Epoch 00607: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3344 - mean_absolute_error: 0.3344 - soft_acc: 0.7772 - val_loss: 0.5621 - val_mean_absolute_error: 0.5621 - val_soft_acc: 0.4543\n",
      "Epoch 608/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2711 - mean_absolute_error: 0.2711 - soft_acc: 0.8900\n",
      "Epoch 00608: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3077 - mean_absolute_error: 0.3077 - soft_acc: 0.8189 - val_loss: 0.6923 - val_mean_absolute_error: 0.6923 - val_soft_acc: 0.3793\n",
      "Epoch 609/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3888 - mean_absolute_error: 0.3888 - soft_acc: 0.6500\n",
      "Epoch 00609: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3539 - mean_absolute_error: 0.3539 - soft_acc: 0.7522 - val_loss: 0.7544 - val_mean_absolute_error: 0.7544 - val_soft_acc: 0.3157\n",
      "Epoch 610/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4328 - mean_absolute_error: 0.4328 - soft_acc: 0.6700\n",
      "Epoch 00610: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3532 - mean_absolute_error: 0.3532 - soft_acc: 0.7206 - val_loss: 0.6777 - val_mean_absolute_error: 0.6777 - val_soft_acc: 0.3921\n",
      "Epoch 611/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2970 - mean_absolute_error: 0.2970 - soft_acc: 0.8200\n",
      "Epoch 00611: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3133 - mean_absolute_error: 0.3133 - soft_acc: 0.8350 - val_loss: 0.4578 - val_mean_absolute_error: 0.4578 - val_soft_acc: 0.5529\n",
      "Epoch 612/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4372 - mean_absolute_error: 0.4372 - soft_acc: 0.6500\n",
      "Epoch 00612: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4004 - mean_absolute_error: 0.4004 - soft_acc: 0.7022 - val_loss: 0.4701 - val_mean_absolute_error: 0.4701 - val_soft_acc: 0.5479\n",
      "Epoch 613/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4148 - mean_absolute_error: 0.4148 - soft_acc: 0.6100\n",
      "Epoch 00613: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3642 - mean_absolute_error: 0.3642 - soft_acc: 0.7561 - val_loss: 0.5545 - val_mean_absolute_error: 0.5545 - val_soft_acc: 0.4464\n",
      "Epoch 614/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3662 - mean_absolute_error: 0.3662 - soft_acc: 0.7700\n",
      "Epoch 00614: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3102 - mean_absolute_error: 0.3102 - soft_acc: 0.8244 - val_loss: 0.6901 - val_mean_absolute_error: 0.6901 - val_soft_acc: 0.3307\n",
      "Epoch 615/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3014 - mean_absolute_error: 0.3014 - soft_acc: 0.8300\n",
      "Epoch 00615: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3156 - mean_absolute_error: 0.3156 - soft_acc: 0.7850 - val_loss: 0.6529 - val_mean_absolute_error: 0.6529 - val_soft_acc: 0.3764\n",
      "Epoch 616/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2882 - mean_absolute_error: 0.2882 - soft_acc: 0.8700\n",
      "Epoch 00616: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3347 - mean_absolute_error: 0.3347 - soft_acc: 0.7683 - val_loss: 0.3989 - val_mean_absolute_error: 0.3989 - val_soft_acc: 0.6879\n",
      "Epoch 617/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4618 - mean_absolute_error: 0.4618 - soft_acc: 0.5900\n",
      "Epoch 00617: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4282 - mean_absolute_error: 0.4282 - soft_acc: 0.7067 - val_loss: 0.3312 - val_mean_absolute_error: 0.3312 - val_soft_acc: 0.8064\n",
      "Epoch 618/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5556 - mean_absolute_error: 0.5556 - soft_acc: 0.5200\n",
      "Epoch 00618: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4617 - mean_absolute_error: 0.4617 - soft_acc: 0.6644 - val_loss: 0.5713 - val_mean_absolute_error: 0.5713 - val_soft_acc: 0.5264\n",
      "Epoch 619/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3078 - mean_absolute_error: 0.3078 - soft_acc: 0.8300\n",
      "Epoch 00619: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3076 - mean_absolute_error: 0.3076 - soft_acc: 0.7928 - val_loss: 0.5862 - val_mean_absolute_error: 0.5862 - val_soft_acc: 0.4621\n",
      "Epoch 620/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3181 - mean_absolute_error: 0.3181 - soft_acc: 0.7800\n",
      "Epoch 00620: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3344 - mean_absolute_error: 0.3344 - soft_acc: 0.7806 - val_loss: 0.5187 - val_mean_absolute_error: 0.5187 - val_soft_acc: 0.5357\n",
      "Epoch 621/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3562 - mean_absolute_error: 0.3562 - soft_acc: 0.7200\n",
      "Epoch 00621: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3291 - mean_absolute_error: 0.3291 - soft_acc: 0.7839 - val_loss: 0.6736 - val_mean_absolute_error: 0.6736 - val_soft_acc: 0.3229\n",
      "Epoch 622/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3284 - mean_absolute_error: 0.3284 - soft_acc: 0.7900\n",
      "Epoch 00622: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3090 - mean_absolute_error: 0.3090 - soft_acc: 0.7928 - val_loss: 0.5672 - val_mean_absolute_error: 0.5672 - val_soft_acc: 0.4721\n",
      "Epoch 623/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3026 - mean_absolute_error: 0.3026 - soft_acc: 0.8300\n",
      "Epoch 00623: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3168 - mean_absolute_error: 0.3168 - soft_acc: 0.7744 - val_loss: 0.7031 - val_mean_absolute_error: 0.7031 - val_soft_acc: 0.3764\n",
      "Epoch 624/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3781 - mean_absolute_error: 0.3781 - soft_acc: 0.7100\n",
      "Epoch 00624: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4156 - mean_absolute_error: 0.4156 - soft_acc: 0.6856 - val_loss: 0.8210 - val_mean_absolute_error: 0.8210 - val_soft_acc: 0.3086\n",
      "Epoch 625/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5191 - mean_absolute_error: 0.5191 - soft_acc: 0.4900\n",
      "Epoch 00625: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4127 - mean_absolute_error: 0.4127 - soft_acc: 0.6867 - val_loss: 0.7896 - val_mean_absolute_error: 0.7896 - val_soft_acc: 0.2850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4157 - mean_absolute_error: 0.4157 - soft_acc: 0.6600\n",
      "Epoch 00626: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3791 - mean_absolute_error: 0.3791 - soft_acc: 0.7150 - val_loss: 0.8284 - val_mean_absolute_error: 0.8284 - val_soft_acc: 0.2571\n",
      "Epoch 627/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4483 - mean_absolute_error: 0.4483 - soft_acc: 0.5700\n",
      "Epoch 00627: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4029 - mean_absolute_error: 0.4029 - soft_acc: 0.6883 - val_loss: 0.8657 - val_mean_absolute_error: 0.8657 - val_soft_acc: 0.2807\n",
      "Epoch 628/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5267 - mean_absolute_error: 0.5267 - soft_acc: 0.5400\n",
      "Epoch 00628: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4410 - mean_absolute_error: 0.4410 - soft_acc: 0.6744 - val_loss: 0.7363 - val_mean_absolute_error: 0.7363 - val_soft_acc: 0.3129\n",
      "Epoch 629/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3426 - mean_absolute_error: 0.3426 - soft_acc: 0.7700\n",
      "Epoch 00629: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3328 - mean_absolute_error: 0.3328 - soft_acc: 0.7883 - val_loss: 0.8110 - val_mean_absolute_error: 0.8110 - val_soft_acc: 0.3443\n",
      "Epoch 630/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4106 - mean_absolute_error: 0.4106 - soft_acc: 0.7200\n",
      "Epoch 00630: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4381 - mean_absolute_error: 0.4381 - soft_acc: 0.6717 - val_loss: 0.8230 - val_mean_absolute_error: 0.8230 - val_soft_acc: 0.2829\n",
      "Epoch 631/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3849 - mean_absolute_error: 0.3849 - soft_acc: 0.7000\n",
      "Epoch 00631: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3744 - mean_absolute_error: 0.3744 - soft_acc: 0.7333 - val_loss: 0.7802 - val_mean_absolute_error: 0.7802 - val_soft_acc: 0.3236\n",
      "Epoch 632/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3352 - mean_absolute_error: 0.3352 - soft_acc: 0.7900\n",
      "Epoch 00632: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - soft_acc: 0.7967 - val_loss: 0.9579 - val_mean_absolute_error: 0.9579 - val_soft_acc: 0.1893\n",
      "Epoch 633/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5505 - mean_absolute_error: 0.5505 - soft_acc: 0.5000\n",
      "Epoch 00633: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.5028 - mean_absolute_error: 0.5028 - soft_acc: 0.5700 - val_loss: 0.7852 - val_mean_absolute_error: 0.7852 - val_soft_acc: 0.2850\n",
      "Epoch 634/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3566 - mean_absolute_error: 0.3566 - soft_acc: 0.7200\n",
      "Epoch 00634: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3669 - mean_absolute_error: 0.3669 - soft_acc: 0.7300 - val_loss: 0.8005 - val_mean_absolute_error: 0.8005 - val_soft_acc: 0.2800\n",
      "Epoch 635/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3640 - mean_absolute_error: 0.3640 - soft_acc: 0.7600\n",
      "Epoch 00635: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3698 - mean_absolute_error: 0.3698 - soft_acc: 0.7578 - val_loss: 0.5169 - val_mean_absolute_error: 0.5169 - val_soft_acc: 0.5229\n",
      "Epoch 636/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3438 - mean_absolute_error: 0.3438 - soft_acc: 0.7400\n",
      "Epoch 00636: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3165 - mean_absolute_error: 0.3165 - soft_acc: 0.7572 - val_loss: 0.4932 - val_mean_absolute_error: 0.4932 - val_soft_acc: 0.5636\n",
      "Epoch 637/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3526 - mean_absolute_error: 0.3526 - soft_acc: 0.7300\n",
      "Epoch 00637: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3576 - mean_absolute_error: 0.3576 - soft_acc: 0.7272 - val_loss: 0.5206 - val_mean_absolute_error: 0.5206 - val_soft_acc: 0.5486\n",
      "Epoch 638/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3067 - mean_absolute_error: 0.3067 - soft_acc: 0.8400\n",
      "Epoch 00638: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3582 - mean_absolute_error: 0.3582 - soft_acc: 0.7494 - val_loss: 0.6367 - val_mean_absolute_error: 0.6367 - val_soft_acc: 0.4193\n",
      "Epoch 639/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3059 - mean_absolute_error: 0.3059 - soft_acc: 0.8100\n",
      "Epoch 00639: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3555 - mean_absolute_error: 0.3555 - soft_acc: 0.7550 - val_loss: 0.7129 - val_mean_absolute_error: 0.7129 - val_soft_acc: 0.3821\n",
      "Epoch 640/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3588 - mean_absolute_error: 0.3588 - soft_acc: 0.7800\n",
      "Epoch 00640: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3631 - mean_absolute_error: 0.3631 - soft_acc: 0.7556 - val_loss: 0.7099 - val_mean_absolute_error: 0.7099 - val_soft_acc: 0.3129\n",
      "Epoch 641/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3315 - mean_absolute_error: 0.3315 - soft_acc: 0.8100\n",
      "Epoch 00641: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3004 - mean_absolute_error: 0.3004 - soft_acc: 0.8439 - val_loss: 0.7634 - val_mean_absolute_error: 0.7634 - val_soft_acc: 0.3107\n",
      "Epoch 642/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3546 - mean_absolute_error: 0.3546 - soft_acc: 0.8000\n",
      "Epoch 00642: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3525 - mean_absolute_error: 0.3525 - soft_acc: 0.7689 - val_loss: 0.6721 - val_mean_absolute_error: 0.6721 - val_soft_acc: 0.2764\n",
      "Epoch 643/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2562 - mean_absolute_error: 0.2562 - soft_acc: 0.9000\n",
      "Epoch 00643: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3140 - mean_absolute_error: 0.3140 - soft_acc: 0.8150 - val_loss: 0.6062 - val_mean_absolute_error: 0.6062 - val_soft_acc: 0.4471\n",
      "Epoch 644/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2842 - mean_absolute_error: 0.2842 - soft_acc: 0.8300\n",
      "Epoch 00644: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3075 - mean_absolute_error: 0.3075 - soft_acc: 0.7944 - val_loss: 0.6078 - val_mean_absolute_error: 0.6078 - val_soft_acc: 0.4521\n",
      "Epoch 645/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3085 - mean_absolute_error: 0.3085 - soft_acc: 0.7800\n",
      "Epoch 00645: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3120 - mean_absolute_error: 0.3120 - soft_acc: 0.8278 - val_loss: 0.5951 - val_mean_absolute_error: 0.5951 - val_soft_acc: 0.4186\n",
      "Epoch 646/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3617 - mean_absolute_error: 0.3617 - soft_acc: 0.7700\n",
      "Epoch 00646: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3076 - mean_absolute_error: 0.3076 - soft_acc: 0.8117 - val_loss: 0.7477 - val_mean_absolute_error: 0.7477 - val_soft_acc: 0.2950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3818 - mean_absolute_error: 0.3818 - soft_acc: 0.7100\n",
      "Epoch 00647: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3188 - mean_absolute_error: 0.3188 - soft_acc: 0.8094 - val_loss: 0.8121 - val_mean_absolute_error: 0.8121 - val_soft_acc: 0.2593\n",
      "Epoch 648/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4286 - mean_absolute_error: 0.4286 - soft_acc: 0.6300\n",
      "Epoch 00648: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3420 - mean_absolute_error: 0.3420 - soft_acc: 0.7944 - val_loss: 0.6987 - val_mean_absolute_error: 0.6987 - val_soft_acc: 0.3129\n",
      "Epoch 649/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2867 - mean_absolute_error: 0.2867 - soft_acc: 0.8300\n",
      "Epoch 00649: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3329 - mean_absolute_error: 0.3329 - soft_acc: 0.7367 - val_loss: 0.4867 - val_mean_absolute_error: 0.4867 - val_soft_acc: 0.5171\n",
      "Epoch 650/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3897 - mean_absolute_error: 0.3897 - soft_acc: 0.6900\n",
      "Epoch 00650: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4099 - mean_absolute_error: 0.4099 - soft_acc: 0.6956 - val_loss: 0.4692 - val_mean_absolute_error: 0.4692 - val_soft_acc: 0.5607\n",
      "Epoch 651/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3854 - mean_absolute_error: 0.3854 - soft_acc: 0.6800\n",
      "Epoch 00651: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3605 - mean_absolute_error: 0.3605 - soft_acc: 0.7644 - val_loss: 0.4393 - val_mean_absolute_error: 0.4393 - val_soft_acc: 0.6243\n",
      "Epoch 652/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4143 - mean_absolute_error: 0.4143 - soft_acc: 0.6800\n",
      "Epoch 00652: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3376 - mean_absolute_error: 0.3376 - soft_acc: 0.7978 - val_loss: 0.6553 - val_mean_absolute_error: 0.6553 - val_soft_acc: 0.3736\n",
      "Epoch 653/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2978 - mean_absolute_error: 0.2978 - soft_acc: 0.8400\n",
      "Epoch 00653: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3498 - mean_absolute_error: 0.3498 - soft_acc: 0.7256 - val_loss: 0.6879 - val_mean_absolute_error: 0.6879 - val_soft_acc: 0.3693\n",
      "Epoch 654/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3473 - mean_absolute_error: 0.3473 - soft_acc: 0.7000\n",
      "Epoch 00654: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3639 - mean_absolute_error: 0.3639 - soft_acc: 0.7333 - val_loss: 0.8010 - val_mean_absolute_error: 0.8010 - val_soft_acc: 0.3107\n",
      "Epoch 655/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4797 - mean_absolute_error: 0.4797 - soft_acc: 0.5900\n",
      "Epoch 00655: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4457 - mean_absolute_error: 0.4457 - soft_acc: 0.6967 - val_loss: 0.6001 - val_mean_absolute_error: 0.6001 - val_soft_acc: 0.3807\n",
      "Epoch 656/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3283 - mean_absolute_error: 0.3283 - soft_acc: 0.8400\n",
      "Epoch 00656: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4300 - mean_absolute_error: 0.4300 - soft_acc: 0.6622 - val_loss: 0.5652 - val_mean_absolute_error: 0.5652 - val_soft_acc: 0.4850\n",
      "Epoch 657/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3384 - mean_absolute_error: 0.3384 - soft_acc: 0.7600\n",
      "Epoch 00657: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3661 - mean_absolute_error: 0.3661 - soft_acc: 0.6744 - val_loss: 0.6230 - val_mean_absolute_error: 0.6230 - val_soft_acc: 0.3993\n",
      "Epoch 658/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3564 - mean_absolute_error: 0.3564 - soft_acc: 0.7500\n",
      "Epoch 00658: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3308 - mean_absolute_error: 0.3308 - soft_acc: 0.7861 - val_loss: 0.6993 - val_mean_absolute_error: 0.6993 - val_soft_acc: 0.3486\n",
      "Epoch 659/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3116 - mean_absolute_error: 0.3116 - soft_acc: 0.7800\n",
      "Epoch 00659: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3139 - mean_absolute_error: 0.3139 - soft_acc: 0.8056 - val_loss: 0.6977 - val_mean_absolute_error: 0.6977 - val_soft_acc: 0.2950\n",
      "Epoch 660/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3146 - mean_absolute_error: 0.3146 - soft_acc: 0.8100\n",
      "Epoch 00660: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3087 - mean_absolute_error: 0.3087 - soft_acc: 0.8033 - val_loss: 0.5341 - val_mean_absolute_error: 0.5341 - val_soft_acc: 0.4871\n",
      "Epoch 661/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3531 - mean_absolute_error: 0.3531 - soft_acc: 0.7500\n",
      "Epoch 00661: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3149 - mean_absolute_error: 0.3149 - soft_acc: 0.8233 - val_loss: 0.5189 - val_mean_absolute_error: 0.5189 - val_soft_acc: 0.4893\n",
      "Epoch 662/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3637 - mean_absolute_error: 0.3637 - soft_acc: 0.7600\n",
      "Epoch 00662: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3079 - mean_absolute_error: 0.3079 - soft_acc: 0.8083 - val_loss: 0.4893 - val_mean_absolute_error: 0.4893 - val_soft_acc: 0.5043\n",
      "Epoch 663/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3217 - mean_absolute_error: 0.3217 - soft_acc: 0.8000\n",
      "Epoch 00663: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2990 - mean_absolute_error: 0.2990 - soft_acc: 0.8183 - val_loss: 0.7060 - val_mean_absolute_error: 0.7060 - val_soft_acc: 0.3050\n",
      "Epoch 664/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3857 - mean_absolute_error: 0.3857 - soft_acc: 0.7300\n",
      "Epoch 00664: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3722 - mean_absolute_error: 0.3722 - soft_acc: 0.7006 - val_loss: 0.6816 - val_mean_absolute_error: 0.6816 - val_soft_acc: 0.3429\n",
      "Epoch 665/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3517 - mean_absolute_error: 0.3517 - soft_acc: 0.7400\n",
      "Epoch 00665: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3510 - mean_absolute_error: 0.3510 - soft_acc: 0.7494 - val_loss: 0.5030 - val_mean_absolute_error: 0.5030 - val_soft_acc: 0.5664\n",
      "Epoch 666/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3390 - mean_absolute_error: 0.3390 - soft_acc: 0.7900\n",
      "Epoch 00666: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3285 - mean_absolute_error: 0.3285 - soft_acc: 0.7344 - val_loss: 0.4265 - val_mean_absolute_error: 0.4265 - val_soft_acc: 0.5907\n",
      "Epoch 667/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4157 - mean_absolute_error: 0.4157 - soft_acc: 0.7200\n",
      "Epoch 00667: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3493 - mean_absolute_error: 0.3493 - soft_acc: 0.7756 - val_loss: 0.5644 - val_mean_absolute_error: 0.5644 - val_soft_acc: 0.4850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2848 - mean_absolute_error: 0.2848 - soft_acc: 0.8100\n",
      "Epoch 00668: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3153 - mean_absolute_error: 0.3153 - soft_acc: 0.8111 - val_loss: 0.7237 - val_mean_absolute_error: 0.7237 - val_soft_acc: 0.3207\n",
      "Epoch 669/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2974 - mean_absolute_error: 0.2974 - soft_acc: 0.9000\n",
      "Epoch 00669: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2883 - mean_absolute_error: 0.2883 - soft_acc: 0.8506 - val_loss: 0.6049 - val_mean_absolute_error: 0.6049 - val_soft_acc: 0.3936\n",
      "Epoch 670/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2941 - mean_absolute_error: 0.2941 - soft_acc: 0.8200\n",
      "Epoch 00670: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3049 - mean_absolute_error: 0.3049 - soft_acc: 0.8311 - val_loss: 0.6651 - val_mean_absolute_error: 0.6651 - val_soft_acc: 0.3457\n",
      "Epoch 671/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3159 - mean_absolute_error: 0.3159 - soft_acc: 0.8200\n",
      "Epoch 00671: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2990 - mean_absolute_error: 0.2990 - soft_acc: 0.7978 - val_loss: 0.7628 - val_mean_absolute_error: 0.7628 - val_soft_acc: 0.3207\n",
      "Epoch 672/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3984 - mean_absolute_error: 0.3984 - soft_acc: 0.7000\n",
      "Epoch 00672: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3436 - mean_absolute_error: 0.3436 - soft_acc: 0.7944 - val_loss: 0.6794 - val_mean_absolute_error: 0.6794 - val_soft_acc: 0.3279\n",
      "Epoch 673/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3357 - mean_absolute_error: 0.3357 - soft_acc: 0.8000\n",
      "Epoch 00673: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3145 - mean_absolute_error: 0.3145 - soft_acc: 0.8244 - val_loss: 0.6173 - val_mean_absolute_error: 0.6173 - val_soft_acc: 0.3857\n",
      "Epoch 674/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2957 - mean_absolute_error: 0.2957 - soft_acc: 0.8400\n",
      "Epoch 00674: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2998 - mean_absolute_error: 0.2998 - soft_acc: 0.7939 - val_loss: 0.4563 - val_mean_absolute_error: 0.4563 - val_soft_acc: 0.5193\n",
      "Epoch 675/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4208 - mean_absolute_error: 0.4208 - soft_acc: 0.6700\n",
      "Epoch 00675: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3112 - mean_absolute_error: 0.3112 - soft_acc: 0.8044 - val_loss: 0.4981 - val_mean_absolute_error: 0.4981 - val_soft_acc: 0.4814\n",
      "Epoch 676/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3418 - mean_absolute_error: 0.3418 - soft_acc: 0.7400\n",
      "Epoch 00676: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3189 - mean_absolute_error: 0.3189 - soft_acc: 0.8011 - val_loss: 0.5610 - val_mean_absolute_error: 0.5610 - val_soft_acc: 0.4000\n",
      "Epoch 677/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3250 - mean_absolute_error: 0.3250 - soft_acc: 0.7800\n",
      "Epoch 00677: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3332 - mean_absolute_error: 0.3332 - soft_acc: 0.7789 - val_loss: 0.7867 - val_mean_absolute_error: 0.7867 - val_soft_acc: 0.2643\n",
      "Epoch 678/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4212 - mean_absolute_error: 0.4212 - soft_acc: 0.6300\n",
      "Epoch 00678: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3866 - mean_absolute_error: 0.3866 - soft_acc: 0.7017 - val_loss: 0.7954 - val_mean_absolute_error: 0.7954 - val_soft_acc: 0.2721\n",
      "Epoch 679/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4138 - mean_absolute_error: 0.4138 - soft_acc: 0.6600\n",
      "Epoch 00679: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3447 - mean_absolute_error: 0.3447 - soft_acc: 0.7750 - val_loss: 0.6286 - val_mean_absolute_error: 0.6286 - val_soft_acc: 0.4093\n",
      "Epoch 680/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2840 - mean_absolute_error: 0.2840 - soft_acc: 0.8200\n",
      "Epoch 00680: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3056 - mean_absolute_error: 0.3056 - soft_acc: 0.8017 - val_loss: 0.6177 - val_mean_absolute_error: 0.6177 - val_soft_acc: 0.4321\n",
      "Epoch 681/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2885 - mean_absolute_error: 0.2885 - soft_acc: 0.8700\n",
      "Epoch 00681: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2804 - mean_absolute_error: 0.2804 - soft_acc: 0.8522 - val_loss: 0.4846 - val_mean_absolute_error: 0.4846 - val_soft_acc: 0.5636\n",
      "Epoch 682/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3243 - mean_absolute_error: 0.3243 - soft_acc: 0.7700\n",
      "Epoch 00682: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3197 - mean_absolute_error: 0.3197 - soft_acc: 0.8094 - val_loss: 0.6338 - val_mean_absolute_error: 0.6338 - val_soft_acc: 0.4143\n",
      "Epoch 683/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3154 - mean_absolute_error: 0.3154 - soft_acc: 0.8000\n",
      "Epoch 00683: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3088 - mean_absolute_error: 0.3088 - soft_acc: 0.8022 - val_loss: 0.5570 - val_mean_absolute_error: 0.5570 - val_soft_acc: 0.4900\n",
      "Epoch 684/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2696 - mean_absolute_error: 0.2696 - soft_acc: 0.8500\n",
      "Epoch 00684: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3073 - mean_absolute_error: 0.3073 - soft_acc: 0.7656 - val_loss: 0.5206 - val_mean_absolute_error: 0.5206 - val_soft_acc: 0.5486\n",
      "Epoch 685/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3469 - mean_absolute_error: 0.3469 - soft_acc: 0.7600\n",
      "Epoch 00685: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3337 - mean_absolute_error: 0.3337 - soft_acc: 0.7694 - val_loss: 0.6083 - val_mean_absolute_error: 0.6083 - val_soft_acc: 0.4036\n",
      "Epoch 686/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2829 - mean_absolute_error: 0.2829 - soft_acc: 0.8400\n",
      "Epoch 00686: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3562 - mean_absolute_error: 0.3562 - soft_acc: 0.7367 - val_loss: 0.8182 - val_mean_absolute_error: 0.8182 - val_soft_acc: 0.2800\n",
      "Epoch 687/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4253 - mean_absolute_error: 0.4253 - soft_acc: 0.6300\n",
      "Epoch 00687: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4247 - mean_absolute_error: 0.4247 - soft_acc: 0.6683 - val_loss: 0.9091 - val_mean_absolute_error: 0.9091 - val_soft_acc: 0.1707\n",
      "Epoch 688/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5492 - mean_absolute_error: 0.5492 - soft_acc: 0.4500\n",
      "Epoch 00688: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4604 - mean_absolute_error: 0.4604 - soft_acc: 0.6339 - val_loss: 0.8500 - val_mean_absolute_error: 0.8500 - val_soft_acc: 0.2521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4958 - mean_absolute_error: 0.4958 - soft_acc: 0.6200\n",
      "Epoch 00689: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3734 - mean_absolute_error: 0.3734 - soft_acc: 0.7233 - val_loss: 0.8633 - val_mean_absolute_error: 0.8633 - val_soft_acc: 0.3064\n",
      "Epoch 690/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4231 - mean_absolute_error: 0.4231 - soft_acc: 0.6900\n",
      "Epoch 00690: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3885 - mean_absolute_error: 0.3885 - soft_acc: 0.7517 - val_loss: 0.8204 - val_mean_absolute_error: 0.8204 - val_soft_acc: 0.3057\n",
      "Epoch 691/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4102 - mean_absolute_error: 0.4102 - soft_acc: 0.6500\n",
      "Epoch 00691: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3785 - mean_absolute_error: 0.3785 - soft_acc: 0.7022 - val_loss: 0.6860 - val_mean_absolute_error: 0.6860 - val_soft_acc: 0.3129\n",
      "Epoch 692/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2948 - mean_absolute_error: 0.2948 - soft_acc: 0.8200\n",
      "Epoch 00692: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 0.3473 - mean_absolute_error: 0.3473 - soft_acc: 0.7878 - val_loss: 0.6737 - val_mean_absolute_error: 0.6737 - val_soft_acc: 0.3207\n",
      "Epoch 693/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2819 - mean_absolute_error: 0.2819 - soft_acc: 0.8700\n",
      "Epoch 00693: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3186 - mean_absolute_error: 0.3186 - soft_acc: 0.8006 - val_loss: 0.6907 - val_mean_absolute_error: 0.6907 - val_soft_acc: 0.3464\n",
      "Epoch 694/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2764 - mean_absolute_error: 0.2764 - soft_acc: 0.8400\n",
      "Epoch 00694: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3016 - mean_absolute_error: 0.3016 - soft_acc: 0.7650 - val_loss: 0.6331 - val_mean_absolute_error: 0.6331 - val_soft_acc: 0.3379\n",
      "Epoch 695/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3143 - mean_absolute_error: 0.3143 - soft_acc: 0.7900\n",
      "Epoch 00695: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3323 - mean_absolute_error: 0.3323 - soft_acc: 0.7722 - val_loss: 0.5785 - val_mean_absolute_error: 0.5785 - val_soft_acc: 0.4750\n",
      "Epoch 696/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3534 - mean_absolute_error: 0.3534 - soft_acc: 0.7500\n",
      "Epoch 00696: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3654 - mean_absolute_error: 0.3654 - soft_acc: 0.7456 - val_loss: 0.5364 - val_mean_absolute_error: 0.5364 - val_soft_acc: 0.5129\n",
      "Epoch 697/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3410 - mean_absolute_error: 0.3410 - soft_acc: 0.7300\n",
      "Epoch 00697: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3617 - mean_absolute_error: 0.3617 - soft_acc: 0.7489 - val_loss: 0.4496 - val_mean_absolute_error: 0.4496 - val_soft_acc: 0.5857\n",
      "Epoch 698/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3932 - mean_absolute_error: 0.3932 - soft_acc: 0.6800\n",
      "Epoch 00698: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3285 - mean_absolute_error: 0.3285 - soft_acc: 0.7472 - val_loss: 0.5561 - val_mean_absolute_error: 0.5561 - val_soft_acc: 0.5157\n",
      "Epoch 699/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3088 - mean_absolute_error: 0.3088 - soft_acc: 0.7800\n",
      "Epoch 00699: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3161 - mean_absolute_error: 0.3161 - soft_acc: 0.8161 - val_loss: 0.6340 - val_mean_absolute_error: 0.6340 - val_soft_acc: 0.3607\n",
      "Epoch 700/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3001 - mean_absolute_error: 0.3001 - soft_acc: 0.7900\n",
      "Epoch 00700: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3054 - mean_absolute_error: 0.3054 - soft_acc: 0.8056 - val_loss: 0.6985 - val_mean_absolute_error: 0.6985 - val_soft_acc: 0.3257\n",
      "Epoch 701/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2921 - mean_absolute_error: 0.2921 - soft_acc: 0.8300\n",
      "Epoch 00701: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3274 - mean_absolute_error: 0.3274 - soft_acc: 0.7978 - val_loss: 0.9147 - val_mean_absolute_error: 0.9147 - val_soft_acc: 0.2121\n",
      "Epoch 702/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6100 - mean_absolute_error: 0.6100 - soft_acc: 0.4600\n",
      "Epoch 00702: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5138 - mean_absolute_error: 0.5138 - soft_acc: 0.6267 - val_loss: 0.5219 - val_mean_absolute_error: 0.5219 - val_soft_acc: 0.4614\n",
      "Epoch 703/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3919 - mean_absolute_error: 0.3919 - soft_acc: 0.6800\n",
      "Epoch 00703: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3511 - mean_absolute_error: 0.3511 - soft_acc: 0.7294 - val_loss: 0.5530 - val_mean_absolute_error: 0.5530 - val_soft_acc: 0.5079\n",
      "Epoch 704/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3672 - mean_absolute_error: 0.3672 - soft_acc: 0.7600\n",
      "Epoch 00704: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3606 - mean_absolute_error: 0.3606 - soft_acc: 0.6983 - val_loss: 0.6651 - val_mean_absolute_error: 0.6651 - val_soft_acc: 0.3436\n",
      "Epoch 705/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3127 - mean_absolute_error: 0.3127 - soft_acc: 0.8300\n",
      "Epoch 00705: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3536 - mean_absolute_error: 0.3536 - soft_acc: 0.7572 - val_loss: 0.6351 - val_mean_absolute_error: 0.6351 - val_soft_acc: 0.3707\n",
      "Epoch 706/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3131 - mean_absolute_error: 0.3131 - soft_acc: 0.7800\n",
      "Epoch 00706: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3532 - mean_absolute_error: 0.3532 - soft_acc: 0.7761 - val_loss: 0.5863 - val_mean_absolute_error: 0.5863 - val_soft_acc: 0.4650\n",
      "Epoch 707/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3378 - mean_absolute_error: 0.3378 - soft_acc: 0.7300\n",
      "Epoch 00707: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3038 - mean_absolute_error: 0.3038 - soft_acc: 0.8356 - val_loss: 0.7012 - val_mean_absolute_error: 0.7012 - val_soft_acc: 0.3079\n",
      "Epoch 708/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4022 - mean_absolute_error: 0.4022 - soft_acc: 0.6900\n",
      "Epoch 00708: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3598 - mean_absolute_error: 0.3598 - soft_acc: 0.7417 - val_loss: 0.7845 - val_mean_absolute_error: 0.7845 - val_soft_acc: 0.2771\n",
      "Epoch 709/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4808 - mean_absolute_error: 0.4808 - soft_acc: 0.6100\n",
      "Epoch 00709: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3689 - mean_absolute_error: 0.3689 - soft_acc: 0.7150 - val_loss: 0.7060 - val_mean_absolute_error: 0.7060 - val_soft_acc: 0.3157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 710/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3007 - mean_absolute_error: 0.3007 - soft_acc: 0.8300\n",
      "Epoch 00710: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3318 - mean_absolute_error: 0.3318 - soft_acc: 0.7328 - val_loss: 0.4571 - val_mean_absolute_error: 0.4571 - val_soft_acc: 0.5964\n",
      "Epoch 711/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3526 - mean_absolute_error: 0.3526 - soft_acc: 0.7600\n",
      "Epoch 00711: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3759 - mean_absolute_error: 0.3759 - soft_acc: 0.7406 - val_loss: 0.5372 - val_mean_absolute_error: 0.5372 - val_soft_acc: 0.4514\n",
      "Epoch 712/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2805 - mean_absolute_error: 0.2805 - soft_acc: 0.8400\n",
      "Epoch 00712: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3046 - mean_absolute_error: 0.3046 - soft_acc: 0.8361 - val_loss: 0.5687 - val_mean_absolute_error: 0.5687 - val_soft_acc: 0.4750\n",
      "Epoch 713/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2816 - mean_absolute_error: 0.2816 - soft_acc: 0.8700\n",
      "Epoch 00713: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3073 - mean_absolute_error: 0.3073 - soft_acc: 0.8328 - val_loss: 0.6303 - val_mean_absolute_error: 0.6303 - val_soft_acc: 0.3964\n",
      "Epoch 714/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3311 - mean_absolute_error: 0.3311 - soft_acc: 0.8000\n",
      "Epoch 00714: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3106 - mean_absolute_error: 0.3106 - soft_acc: 0.8189 - val_loss: 0.7077 - val_mean_absolute_error: 0.7077 - val_soft_acc: 0.3079\n",
      "Epoch 715/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3394 - mean_absolute_error: 0.3394 - soft_acc: 0.8000\n",
      "Epoch 00715: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3149 - mean_absolute_error: 0.3149 - soft_acc: 0.7761 - val_loss: 0.6555 - val_mean_absolute_error: 0.6555 - val_soft_acc: 0.3457\n",
      "Epoch 716/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2616 - mean_absolute_error: 0.2616 - soft_acc: 0.8500\n",
      "Epoch 00716: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2893 - mean_absolute_error: 0.2893 - soft_acc: 0.8044 - val_loss: 0.5081 - val_mean_absolute_error: 0.5081 - val_soft_acc: 0.5536\n",
      "Epoch 717/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3280 - mean_absolute_error: 0.3280 - soft_acc: 0.8000\n",
      "Epoch 00717: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3308 - mean_absolute_error: 0.3308 - soft_acc: 0.7594 - val_loss: 0.6323 - val_mean_absolute_error: 0.6323 - val_soft_acc: 0.3557\n",
      "Epoch 718/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2946 - mean_absolute_error: 0.2946 - soft_acc: 0.8000\n",
      "Epoch 00718: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2986 - mean_absolute_error: 0.2986 - soft_acc: 0.8356 - val_loss: 0.6254 - val_mean_absolute_error: 0.6254 - val_soft_acc: 0.3400\n",
      "Epoch 719/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2559 - mean_absolute_error: 0.2559 - soft_acc: 0.8500\n",
      "Epoch 00719: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3040 - mean_absolute_error: 0.3040 - soft_acc: 0.7828 - val_loss: 0.7471 - val_mean_absolute_error: 0.7471 - val_soft_acc: 0.2771\n",
      "Epoch 720/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3263 - mean_absolute_error: 0.3263 - soft_acc: 0.8000\n",
      "Epoch 00720: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3756 - mean_absolute_error: 0.3756 - soft_acc: 0.7256 - val_loss: 0.8074 - val_mean_absolute_error: 0.8074 - val_soft_acc: 0.3829\n",
      "Epoch 721/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4350 - mean_absolute_error: 0.4350 - soft_acc: 0.6100\n",
      "Epoch 00721: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3708 - mean_absolute_error: 0.3708 - soft_acc: 0.6906 - val_loss: 0.8696 - val_mean_absolute_error: 0.8696 - val_soft_acc: 0.3114\n",
      "Epoch 722/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5517 - mean_absolute_error: 0.5517 - soft_acc: 0.4600\n",
      "Epoch 00722: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4209 - mean_absolute_error: 0.4209 - soft_acc: 0.6372 - val_loss: 0.7181 - val_mean_absolute_error: 0.7181 - val_soft_acc: 0.2900\n",
      "Epoch 723/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2860 - mean_absolute_error: 0.2860 - soft_acc: 0.8300\n",
      "Epoch 00723: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3237 - mean_absolute_error: 0.3237 - soft_acc: 0.7889 - val_loss: 0.6389 - val_mean_absolute_error: 0.6389 - val_soft_acc: 0.3764\n",
      "Epoch 724/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2749 - mean_absolute_error: 0.2749 - soft_acc: 0.8200\n",
      "Epoch 00724: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2942 - mean_absolute_error: 0.2942 - soft_acc: 0.8350 - val_loss: 0.5694 - val_mean_absolute_error: 0.5694 - val_soft_acc: 0.4929\n",
      "Epoch 725/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3470 - mean_absolute_error: 0.3470 - soft_acc: 0.8000\n",
      "Epoch 00725: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3878 - mean_absolute_error: 0.3878 - soft_acc: 0.7028 - val_loss: 0.4408 - val_mean_absolute_error: 0.4408 - val_soft_acc: 0.6371\n",
      "Epoch 726/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.5939 - mean_absolute_error: 0.5939 - soft_acc: 0.4500\n",
      "Epoch 00726: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4342 - mean_absolute_error: 0.4342 - soft_acc: 0.6944 - val_loss: 0.4232 - val_mean_absolute_error: 0.4232 - val_soft_acc: 0.6493\n",
      "Epoch 727/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.6097 - mean_absolute_error: 0.6097 - soft_acc: 0.4900\n",
      "Epoch 00727: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4540 - mean_absolute_error: 0.4540 - soft_acc: 0.6489 - val_loss: 0.5114 - val_mean_absolute_error: 0.5114 - val_soft_acc: 0.5564\n",
      "Epoch 728/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4235 - mean_absolute_error: 0.4235 - soft_acc: 0.6700\n",
      "Epoch 00728: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 48us/sample - loss: 0.4058 - mean_absolute_error: 0.4058 - soft_acc: 0.6917 - val_loss: 0.6209 - val_mean_absolute_error: 0.6209 - val_soft_acc: 0.4379\n",
      "Epoch 729/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.3795 - mean_absolute_error: 0.3795 - soft_acc: 0.7600\n",
      "Epoch 00729: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3442 - mean_absolute_error: 0.3442 - soft_acc: 0.7756 - val_loss: 0.7578 - val_mean_absolute_error: 0.7578 - val_soft_acc: 0.3493\n",
      "Epoch 730/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2928 - mean_absolute_error: 0.2928 - soft_acc: 0.8100\n",
      "Epoch 00730: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3211 - mean_absolute_error: 0.3211 - soft_acc: 0.7783 - val_loss: 0.7751 - val_mean_absolute_error: 0.7751 - val_soft_acc: 0.3029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.2820 - mean_absolute_error: 0.2820 - soft_acc: 0.8400\n",
      "Epoch 00731: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2969 - mean_absolute_error: 0.2969 - soft_acc: 0.8156 - val_loss: 0.8398 - val_mean_absolute_error: 0.8398 - val_soft_acc: 0.2829\n",
      "Epoch 732/3000\n",
      "100/512 [====>.........................] - ETA: 0s - loss: 0.4877 - mean_absolute_error: 0.4877 - soft_acc: 0.5600\n",
      "Epoch 00732: val_mean_absolute_error did not improve from 0.30867\n",
      "512/512 [==============================] - 0s 893us/sample - loss: 0.3542 - mean_absolute_error: 0.3542 - soft_acc: 0.7250 - val_loss: 0.6264 - val_mean_absolute_error: 0.6264 - val_soft_acc: 0.3964\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./model_adr1/\"\n",
    "#先預測 rank\n",
    "import tensorflow.keras.backend as KB\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# This returns a tensor\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256,input_shape=(73,),activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024,activation='relu',kernel_initializer='normal'))\n",
    "# model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(units=256,activation='relu',kernel_initializer='normal'))\n",
    "#model.add(Dense(units=64,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(units=1,activation='linear',kernel_initializer='normal'))\n",
    "es = EarlyStopping(monitor='val_loss',patience=500,restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+'model_rank1.h5', \n",
    "                                                monitor='val_mean_absolute_error', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                mode='min')\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mae',soft_acc])\n",
    "train_history = model.fit(X, Y,validation_split=0.2, epochs=3000, batch_size=100,callbacks=[es,checkpoint])  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "now = 'adr_predict_dnn'\n",
    "#plot_model(model, to_file='./static/model'+now+'.png',show_shapes=True)\n",
    "# summarize history for accuracy\n",
    "plt.plot(train_history.history['soft_acc'])\n",
    "plt.plot(train_history.history['val_soft_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./model_adr1/model_rank_acurracy1.png')\n",
    "plt.show()\n",
    "# summarize history for loss \n",
    "plt.plot(train_history.history['loss']) \n",
    "plt.plot(train_history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./model_adr1/model_rank_loss1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 4., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 7., 0., 0., 4., 0., 2., 0., 0., 0., 0., 0., 2., 4.,\n",
       "       4., 0., 0., 0., 4., 0., 0., 2., 0., 0., 0., 0., 6., 0., 9., 4., 0.,\n",
       "       0., 5., 0., 0., 6., 6., 0., 0., 9., 0., 5., 4., 1., 0., 0., 4., 0.,\n",
       "       9., 8., 0., 0., 0., 4., 9., 5., 9., 8., 0., 0., 7., 6., 1., 9., 9.,\n",
       "       0., 5., 0., 9., 4., 1., 9., 0., 0., 0., 8., 8., 9., 0., 0., 0., 1.,\n",
       "       9., 0., 0., 1., 0., 0., 8., 4., 0., 0., 2., 0., 0., 7., 9., 0., 3.,\n",
       "       7., 0., 0., 0., 0., 0., 4., 0., 0., 0., 6., 8., 0., 0., 9., 0., 0.,\n",
       "       3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 6., 0., 0.])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = np.reshape(Y_predict,(Y_predict.shape[0],))\n",
    "Y_predict = transfer_label(Y_predict)\n",
    "Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  label\n",
       "0     2017-04-01      0\n",
       "1     2017-04-02      0\n",
       "2     2017-04-03      0\n",
       "3     2017-04-04      0\n",
       "4     2017-04-05      4\n",
       "..           ...    ...\n",
       "148   2017-08-27      0\n",
       "149   2017-08-28      0\n",
       "150   2017-08-29      6\n",
       "151   2017-08-30      0\n",
       "152   2017-08-31      0\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nolabel = pd.read_csv('./test_nolabel.csv')\n",
    "test_label = pd.DataFrame()\n",
    "test_label['arrival_date'] = test_nolabel['arrival_date']\n",
    "test_label['label'] = Y_predict.astype('int64')\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label.to_csv('./test_label_dnn_2_time.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use\n",
    "test_data['booking_total_revenue'] = Y_predict*(test_data['stays_in_week_nights']+test_data['stays_in_weekend_nights']+1)\n",
    "test_data = combine_arrival_date(test_data)\n",
    "test_data = test_data.groupby('arrival_date').sum()\n",
    "test_data = test_data['booking_total_revenue']\n",
    "test_data = test_data.values\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `去跑revenue rank 預測`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "not_use,not_use2,not_use3,X_preprocess,test_preprocess = pre_adr_model(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X_preprocess.groupby('arrival_date').sum()\n",
    "test_X_tmp = test_preprocess.groupby('arrival_date').sum()\n",
    "#leadtime 先保留\n",
    "X_tmp.drop(['ID','agent','adr','booking_total_revenue'],axis=1,inplace=True)\n",
    "test_X_tmp.drop(['ID','agent'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>...</th>\n",
       "      <th>assigned_room_type_K</th>\n",
       "      <th>deposit_type_No Deposit</th>\n",
       "      <th>deposit_type_Non Refund</th>\n",
       "      <th>deposit_type_Refundable</th>\n",
       "      <th>customer_type_Contract</th>\n",
       "      <th>customer_type_Group</th>\n",
       "      <th>customer_type_Transient</th>\n",
       "      <th>customer_type_Transient-Party</th>\n",
       "      <th>assigned_room_type_P</th>\n",
       "      <th>reserved_room_type_P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>19600</td>\n",
       "      <td>2781</td>\n",
       "      <td>38</td>\n",
       "      <td>276</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>2518</td>\n",
       "      <td>972</td>\n",
       "      <td>55</td>\n",
       "      <td>150</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-03</th>\n",
       "      <td>2419</td>\n",
       "      <td>999</td>\n",
       "      <td>37</td>\n",
       "      <td>123</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-04</th>\n",
       "      <td>11415</td>\n",
       "      <td>1836</td>\n",
       "      <td>129</td>\n",
       "      <td>202</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-05</th>\n",
       "      <td>2789</td>\n",
       "      <td>1036</td>\n",
       "      <td>86</td>\n",
       "      <td>140</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-27</th>\n",
       "      <td>15621</td>\n",
       "      <td>2067</td>\n",
       "      <td>167</td>\n",
       "      <td>263</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-28</th>\n",
       "      <td>3520</td>\n",
       "      <td>871</td>\n",
       "      <td>33</td>\n",
       "      <td>223</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-29</th>\n",
       "      <td>5347</td>\n",
       "      <td>1690</td>\n",
       "      <td>31</td>\n",
       "      <td>333</td>\n",
       "      <td>215</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-30</th>\n",
       "      <td>18026</td>\n",
       "      <td>1833</td>\n",
       "      <td>80</td>\n",
       "      <td>398</td>\n",
       "      <td>246</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>10375</td>\n",
       "      <td>2145</td>\n",
       "      <td>114</td>\n",
       "      <td>357</td>\n",
       "      <td>310</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lead_time  arrival_date_week_number  stays_in_weekend_nights  \\\n",
       "arrival_date                                                                 \n",
       "2015-07-01        19600                      2781                       38   \n",
       "2015-07-02         2518                       972                       55   \n",
       "2015-07-03         2419                       999                       37   \n",
       "2015-07-04        11415                      1836                      129   \n",
       "2015-07-05         2789                      1036                       86   \n",
       "...                 ...                       ...                      ...   \n",
       "2017-03-27        15621                      2067                      167   \n",
       "2017-03-28         3520                       871                       33   \n",
       "2017-03-29         5347                      1690                       31   \n",
       "2017-03-30        18026                      1833                       80   \n",
       "2017-03-31        10375                      2145                      114   \n",
       "\n",
       "              stays_in_week_nights  adults  children  babies  \\\n",
       "arrival_date                                                   \n",
       "2015-07-01                     276     186         2       0   \n",
       "2015-07-02                     150      71         2       0   \n",
       "2015-07-03                     123      74         3       0   \n",
       "2015-07-04                     202     135         5       2   \n",
       "2015-07-05                     140      72         8       0   \n",
       "...                            ...     ...       ...     ...   \n",
       "2017-03-27                     263     296         0       0   \n",
       "2017-03-28                     223     120         3       1   \n",
       "2017-03-29                     333     215         7       2   \n",
       "2017-03-30                     398     246         5       3   \n",
       "2017-03-31                     357     310         9       0   \n",
       "\n",
       "              is_repeated_guest  previous_cancellations  \\\n",
       "arrival_date                                              \n",
       "2015-07-01                    1                       0   \n",
       "2015-07-02                    0                       0   \n",
       "2015-07-03                    0                       0   \n",
       "2015-07-04                    0                      23   \n",
       "2015-07-05                    0                       0   \n",
       "...                         ...                     ...   \n",
       "2017-03-27                    9                       1   \n",
       "2017-03-28                    7                       1   \n",
       "2017-03-29                   17                       2   \n",
       "2017-03-30                    6                       1   \n",
       "2017-03-31                    3                       0   \n",
       "\n",
       "              previous_bookings_not_canceled  ...  assigned_room_type_K  \\\n",
       "arrival_date                                  ...                         \n",
       "2015-07-01                                 9  ...                   0.0   \n",
       "2015-07-02                                 0  ...                   0.0   \n",
       "2015-07-03                                 0  ...                   0.0   \n",
       "2015-07-04                                 0  ...                   0.0   \n",
       "2015-07-05                                 0  ...                   0.0   \n",
       "...                                      ...  ...                   ...   \n",
       "2017-03-27                                18  ...                   0.0   \n",
       "2017-03-28                                43  ...                   0.0   \n",
       "2017-03-29                                72  ...                   2.0   \n",
       "2017-03-30                                39  ...                   2.0   \n",
       "2017-03-31                                 4  ...                   0.0   \n",
       "\n",
       "              deposit_type_No Deposit  deposit_type_Non Refund  \\\n",
       "arrival_date                                                     \n",
       "2015-07-01                      103.0                      0.0   \n",
       "2015-07-02                       36.0                      0.0   \n",
       "2015-07-03                       37.0                      0.0   \n",
       "2015-07-04                       45.0                     23.0   \n",
       "2015-07-05                       37.0                      0.0   \n",
       "...                               ...                      ...   \n",
       "2017-03-27                      114.0                     45.0   \n",
       "2017-03-28                       67.0                      0.0   \n",
       "2017-03-29                      130.0                      0.0   \n",
       "2017-03-30                      124.0                     17.0   \n",
       "2017-03-31                      130.0                     35.0   \n",
       "\n",
       "              deposit_type_Refundable  customer_type_Contract  \\\n",
       "arrival_date                                                    \n",
       "2015-07-01                        0.0                     6.0   \n",
       "2015-07-02                        0.0                    13.0   \n",
       "2015-07-03                        0.0                     6.0   \n",
       "2015-07-04                        0.0                     7.0   \n",
       "2015-07-05                        0.0                     9.0   \n",
       "...                               ...                     ...   \n",
       "2017-03-27                        0.0                     0.0   \n",
       "2017-03-28                        0.0                     0.0   \n",
       "2017-03-29                        0.0                     0.0   \n",
       "2017-03-30                        0.0                     3.0   \n",
       "2017-03-31                        0.0                     4.0   \n",
       "\n",
       "              customer_type_Group  customer_type_Transient  \\\n",
       "arrival_date                                                 \n",
       "2015-07-01                    0.0                     97.0   \n",
       "2015-07-02                    0.0                     20.0   \n",
       "2015-07-03                    0.0                     22.0   \n",
       "2015-07-04                    0.0                     26.0   \n",
       "2015-07-05                    1.0                     27.0   \n",
       "...                           ...                      ...   \n",
       "2017-03-27                    2.0                    112.0   \n",
       "2017-03-28                    1.0                     64.0   \n",
       "2017-03-29                    3.0                    125.0   \n",
       "2017-03-30                    0.0                    119.0   \n",
       "2017-03-31                    1.0                    158.0   \n",
       "\n",
       "              customer_type_Transient-Party  assigned_room_type_P  \\\n",
       "arrival_date                                                        \n",
       "2015-07-01                              0.0                     0   \n",
       "2015-07-02                              3.0                     0   \n",
       "2015-07-03                              9.0                     0   \n",
       "2015-07-04                             35.0                     0   \n",
       "2015-07-05                              0.0                     0   \n",
       "...                                     ...                   ...   \n",
       "2017-03-27                             45.0                     0   \n",
       "2017-03-28                              2.0                     0   \n",
       "2017-03-29                              2.0                     0   \n",
       "2017-03-30                             19.0                     0   \n",
       "2017-03-31                              2.0                     0   \n",
       "\n",
       "              reserved_room_type_P  \n",
       "arrival_date                        \n",
       "2015-07-01                       0  \n",
       "2015-07-02                       0  \n",
       "2015-07-03                       0  \n",
       "2015-07-04                       0  \n",
       "2015-07-05                       0  \n",
       "...                            ...  \n",
       "2017-03-27                       0  \n",
       "2017-03-28                       0  \n",
       "2017-03-29                       0  \n",
       "2017-03-30                       0  \n",
       "2017-03-31                       0  \n",
       "\n",
       "[640 rows x 72 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = X_tmp.valuesX = X_tmp.values\n",
    "test_X = test_X_tmp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 72)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 72)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train_label.drop(['arrival_date'],axis=1).values\n",
    "Y = np.reshape(Y,(Y.shape[0],))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 72)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_OneHot = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TrainOneHot = to_categorical(Y_train) \n",
    "Y_TestOneHot = to_categorical(Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 10)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TrainOneHot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/3000\n",
      "512/512 [==============================] - 0s 919us/sample - loss: 1871.7993 - mean_absolute_error: 1871.7993 - soft_acc: 0.0000e+00 - val_loss: 340.6542 - val_mean_absolute_error: 340.6542 - val_soft_acc: 0.0000e+00\n",
      "Epoch 2/3000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 262.6454 - mean_absolute_error: 262.6454 - soft_acc: 0.0033 - val_loss: 140.5340 - val_mean_absolute_error: 140.5340 - val_soft_acc: 0.0000e+00\n",
      "Epoch 3/3000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 92.8451 - mean_absolute_error: 92.8451 - soft_acc: 0.0133 - val_loss: 11.2670 - val_mean_absolute_error: 11.2670 - val_soft_acc: 0.0607\n",
      "Epoch 4/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 118.7212 - mean_absolute_error: 118.7212 - soft_acc: 0.0050 - val_loss: 92.0567 - val_mean_absolute_error: 92.0567 - val_soft_acc: 0.0000e+00\n",
      "Epoch 5/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 92.6126 - mean_absolute_error: 92.6126 - soft_acc: 0.0017 - val_loss: 21.5145 - val_mean_absolute_error: 21.5145 - val_soft_acc: 0.0000e+00\n",
      "Epoch 6/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 41.1843 - mean_absolute_error: 41.1843 - soft_acc: 0.0200 - val_loss: 66.7485 - val_mean_absolute_error: 66.7485 - val_soft_acc: 0.0000e+00\n",
      "Epoch 7/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 122.4911 - mean_absolute_error: 122.4911 - soft_acc: 0.0033 - val_loss: 16.1756 - val_mean_absolute_error: 16.1756 - val_soft_acc: 0.0150\n",
      "Epoch 8/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 48.7958 - mean_absolute_error: 48.7958 - soft_acc: 0.0183 - val_loss: 40.4469 - val_mean_absolute_error: 40.4469 - val_soft_acc: 0.0279\n",
      "Epoch 9/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 45.5891 - mean_absolute_error: 45.5891 - soft_acc: 0.0133 - val_loss: 49.9750 - val_mean_absolute_error: 49.9750 - val_soft_acc: 0.0000e+00\n",
      "Epoch 10/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 75.6062 - mean_absolute_error: 75.6062 - soft_acc: 0.0100 - val_loss: 74.0088 - val_mean_absolute_error: 74.0088 - val_soft_acc: 0.0000e+00\n",
      "Epoch 11/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 59.7806 - mean_absolute_error: 59.7806 - soft_acc: 0.0233 - val_loss: 6.8549 - val_mean_absolute_error: 6.8549 - val_soft_acc: 0.0657\n",
      "Epoch 12/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 64.0655 - mean_absolute_error: 64.0655 - soft_acc: 0.0100 - val_loss: 52.7525 - val_mean_absolute_error: 52.7525 - val_soft_acc: 0.0000e+00\n",
      "Epoch 13/3000\n",
      "512/512 [==============================] - 0s 49us/sample - loss: 58.1719 - mean_absolute_error: 58.1719 - soft_acc: 0.0083 - val_loss: 12.8182 - val_mean_absolute_error: 12.8182 - val_soft_acc: 0.0179\n",
      "Epoch 14/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 72.8659 - mean_absolute_error: 72.8659 - soft_acc: 0.0133 - val_loss: 124.1538 - val_mean_absolute_error: 124.1538 - val_soft_acc: 0.0000e+00\n",
      "Epoch 15/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 152.2792 - mean_absolute_error: 152.2792 - soft_acc: 0.0000e+00 - val_loss: 130.2121 - val_mean_absolute_error: 130.2121 - val_soft_acc: 0.0000e+00\n",
      "Epoch 16/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 125.8881 - mean_absolute_error: 125.8881 - soft_acc: 0.0000e+00 - val_loss: 37.2041 - val_mean_absolute_error: 37.2041 - val_soft_acc: 0.0050\n",
      "Epoch 17/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 37.1311 - mean_absolute_error: 37.1311 - soft_acc: 0.0183 - val_loss: 25.0286 - val_mean_absolute_error: 25.0286 - val_soft_acc: 0.0100\n",
      "Epoch 18/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 27.3403 - mean_absolute_error: 27.3403 - soft_acc: 0.0083 - val_loss: 26.3056 - val_mean_absolute_error: 26.3056 - val_soft_acc: 0.0179\n",
      "Epoch 19/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 48.1830 - mean_absolute_error: 48.1830 - soft_acc: 0.0067 - val_loss: 18.4393 - val_mean_absolute_error: 18.4393 - val_soft_acc: 0.0229\n",
      "Epoch 20/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 38.5580 - mean_absolute_error: 38.5580 - soft_acc: 0.0339 - val_loss: 31.8100 - val_mean_absolute_error: 31.8100 - val_soft_acc: 0.0000e+00\n",
      "Epoch 21/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 59.1181 - mean_absolute_error: 59.1181 - soft_acc: 0.0033 - val_loss: 55.4855 - val_mean_absolute_error: 55.4855 - val_soft_acc: 0.0050\n",
      "Epoch 22/3000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 53.7682 - mean_absolute_error: 53.7682 - soft_acc: 0.0289 - val_loss: 22.7470 - val_mean_absolute_error: 22.7470 - val_soft_acc: 0.0000e+00\n",
      "Epoch 23/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 36.7538 - mean_absolute_error: 36.7538 - soft_acc: 0.0167 - val_loss: 7.1926 - val_mean_absolute_error: 7.1926 - val_soft_acc: 0.0579\n",
      "Epoch 24/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 11.0159 - mean_absolute_error: 11.0159 - soft_acc: 0.0772 - val_loss: 20.7140 - val_mean_absolute_error: 20.7140 - val_soft_acc: 0.0050\n",
      "Epoch 25/3000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 36.9432 - mean_absolute_error: 36.9432 - soft_acc: 0.0283 - val_loss: 9.0110 - val_mean_absolute_error: 9.0110 - val_soft_acc: 0.0557\n",
      "Epoch 26/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 38.5830 - mean_absolute_error: 38.5830 - soft_acc: 0.0117 - val_loss: 39.2145 - val_mean_absolute_error: 39.2145 - val_soft_acc: 0.0000e+00\n",
      "Epoch 27/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 52.4005 - mean_absolute_error: 52.4005 - soft_acc: 0.0183 - val_loss: 19.6425 - val_mean_absolute_error: 19.6425 - val_soft_acc: 0.0050\n",
      "Epoch 28/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 28.2949 - mean_absolute_error: 28.2949 - soft_acc: 0.0183 - val_loss: 10.8419 - val_mean_absolute_error: 10.8419 - val_soft_acc: 0.0936\n",
      "Epoch 29/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 10.6471 - mean_absolute_error: 10.6471 - soft_acc: 0.0500 - val_loss: 4.7975 - val_mean_absolute_error: 4.7975 - val_soft_acc: 0.0507\n",
      "Epoch 30/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 8.5075 - mean_absolute_error: 8.5075 - soft_acc: 0.0650 - val_loss: 10.4731 - val_mean_absolute_error: 10.4731 - val_soft_acc: 0.0350\n",
      "Epoch 31/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 11.1941 - mean_absolute_error: 11.1941 - soft_acc: 0.0667 - val_loss: 4.0486 - val_mean_absolute_error: 4.0486 - val_soft_acc: 0.1443\n",
      "Epoch 32/3000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 7.5718 - mean_absolute_error: 7.5718 - soft_acc: 0.0706 - val_loss: 1.9655 - val_mean_absolute_error: 1.9655 - val_soft_acc: 0.1864\n",
      "Epoch 33/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 6.5197 - mean_absolute_error: 6.5197 - soft_acc: 0.0750 - val_loss: 5.3535 - val_mean_absolute_error: 5.3535 - val_soft_acc: 0.0857\n",
      "Epoch 34/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 17.2230 - mean_absolute_error: 17.2230 - soft_acc: 0.0533 - val_loss: 20.4941 - val_mean_absolute_error: 20.4941 - val_soft_acc: 0.0000e+00\n",
      "Epoch 35/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 18.7848 - mean_absolute_error: 18.7848 - soft_acc: 0.0606 - val_loss: 19.8365 - val_mean_absolute_error: 19.8365 - val_soft_acc: 0.0179\n",
      "Epoch 36/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 21.3188 - mean_absolute_error: 21.3188 - soft_acc: 0.0200 - val_loss: 14.4604 - val_mean_absolute_error: 14.4604 - val_soft_acc: 0.0200\n",
      "Epoch 37/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 17.1163 - mean_absolute_error: 17.1163 - soft_acc: 0.0467 - val_loss: 4.3465 - val_mean_absolute_error: 4.3465 - val_soft_acc: 0.0957\n",
      "Epoch 38/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 12.2230 - mean_absolute_error: 12.2230 - soft_acc: 0.0767 - val_loss: 8.6446 - val_mean_absolute_error: 8.6446 - val_soft_acc: 0.0200\n",
      "Epoch 39/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 24.6017 - mean_absolute_error: 24.6017 - soft_acc: 0.0422 - val_loss: 14.2774 - val_mean_absolute_error: 14.2774 - val_soft_acc: 0.0279\n",
      "Epoch 40/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 17.9154 - mean_absolute_error: 17.9154 - soft_acc: 0.0250 - val_loss: 9.9839 - val_mean_absolute_error: 9.9839 - val_soft_acc: 0.0279\n",
      "Epoch 41/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 19.3501 - mean_absolute_error: 19.3501 - soft_acc: 0.0167 - val_loss: 18.6005 - val_mean_absolute_error: 18.6005 - val_soft_acc: 0.0000e+00\n",
      "Epoch 42/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 28.2750 - mean_absolute_error: 28.2750 - soft_acc: 0.0183 - val_loss: 14.1080 - val_mean_absolute_error: 14.1080 - val_soft_acc: 0.0050\n",
      "Epoch 43/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 15.3101 - mean_absolute_error: 15.3101 - soft_acc: 0.0450 - val_loss: 20.7593 - val_mean_absolute_error: 20.7593 - val_soft_acc: 0.0229\n",
      "Epoch 44/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 14.9536 - mean_absolute_error: 14.9536 - soft_acc: 0.0433 - val_loss: 8.9569 - val_mean_absolute_error: 8.9569 - val_soft_acc: 0.0000e+00\n",
      "Epoch 45/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 10.6407 - mean_absolute_error: 10.6407 - soft_acc: 0.0639 - val_loss: 5.3547 - val_mean_absolute_error: 5.3547 - val_soft_acc: 0.0629\n",
      "Epoch 46/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 3.9365 - mean_absolute_error: 3.9365 - soft_acc: 0.1239 - val_loss: 8.8333 - val_mean_absolute_error: 8.8333 - val_soft_acc: 0.0100\n",
      "Epoch 47/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 7.5745 - mean_absolute_error: 7.5745 - soft_acc: 0.0717 - val_loss: 2.0361 - val_mean_absolute_error: 2.0361 - val_soft_acc: 0.2150\n",
      "Epoch 48/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 4.2057 - mean_absolute_error: 4.2057 - soft_acc: 0.1339 - val_loss: 1.8348 - val_mean_absolute_error: 1.8348 - val_soft_acc: 0.1479\n",
      "Epoch 49/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 3.2061 - mean_absolute_error: 3.2061 - soft_acc: 0.1789 - val_loss: 5.0623 - val_mean_absolute_error: 5.0623 - val_soft_acc: 0.0607\n",
      "Epoch 50/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 5.5128 - mean_absolute_error: 5.5128 - soft_acc: 0.1139 - val_loss: 7.7500 - val_mean_absolute_error: 7.7500 - val_soft_acc: 0.0229\n",
      "Epoch 51/3000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 9.2345 - mean_absolute_error: 9.2345 - soft_acc: 0.0700 - val_loss: 1.6387 - val_mean_absolute_error: 1.6387 - val_soft_acc: 0.1714\n",
      "Epoch 52/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 5.4636 - mean_absolute_error: 5.4636 - soft_acc: 0.1228 - val_loss: 7.3352 - val_mean_absolute_error: 7.3352 - val_soft_acc: 0.0329\n",
      "Epoch 53/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 8.7699 - mean_absolute_error: 8.7699 - soft_acc: 0.0783 - val_loss: 7.3938 - val_mean_absolute_error: 7.3938 - val_soft_acc: 0.0629\n",
      "Epoch 54/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 17.2894 - mean_absolute_error: 17.2894 - soft_acc: 0.0589 - val_loss: 2.8722 - val_mean_absolute_error: 2.8722 - val_soft_acc: 0.1571\n",
      "Epoch 55/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 10.2518 - mean_absolute_error: 10.2518 - soft_acc: 0.0756 - val_loss: 4.9951 - val_mean_absolute_error: 4.9951 - val_soft_acc: 0.0986\n",
      "Epoch 56/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 9.2710 - mean_absolute_error: 9.2710 - soft_acc: 0.0806 - val_loss: 8.3235 - val_mean_absolute_error: 8.3235 - val_soft_acc: 0.0229\n",
      "Epoch 57/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 6.9188 - mean_absolute_error: 6.9188 - soft_acc: 0.0817 - val_loss: 6.5048 - val_mean_absolute_error: 6.5048 - val_soft_acc: 0.0100\n",
      "Epoch 58/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 8.4009 - mean_absolute_error: 8.4009 - soft_acc: 0.0783 - val_loss: 3.6927 - val_mean_absolute_error: 3.6927 - val_soft_acc: 0.1007\n",
      "Epoch 59/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 12.3744 - mean_absolute_error: 12.3744 - soft_acc: 0.0383 - val_loss: 12.9946 - val_mean_absolute_error: 12.9946 - val_soft_acc: 0.0050\n",
      "Epoch 60/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 14.2627 - mean_absolute_error: 14.2627 - soft_acc: 0.0317 - val_loss: 9.6456 - val_mean_absolute_error: 9.6456 - val_soft_acc: 0.0557\n",
      "Epoch 61/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 11.9767 - mean_absolute_error: 11.9767 - soft_acc: 0.0706 - val_loss: 9.3099 - val_mean_absolute_error: 9.3099 - val_soft_acc: 0.0200\n",
      "Epoch 62/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 11.3640 - mean_absolute_error: 11.3640 - soft_acc: 0.0533 - val_loss: 10.2948 - val_mean_absolute_error: 10.2948 - val_soft_acc: 0.0100\n",
      "Epoch 63/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 15.8344 - mean_absolute_error: 15.8344 - soft_acc: 0.02 - 0s 42us/sample - loss: 12.3664 - mean_absolute_error: 12.3664 - soft_acc: 0.0400 - val_loss: 6.4191 - val_mean_absolute_error: 6.4191 - val_soft_acc: 0.0379\n",
      "Epoch 64/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 4.8008 - mean_absolute_error: 4.8008 - soft_acc: 0.1711 - val_loss: 2.7155 - val_mean_absolute_error: 2.7155 - val_soft_acc: 0.1464\n",
      "Epoch 65/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 3.4876 - mean_absolute_error: 3.4876 - soft_acc: 0.1672 - val_loss: 6.0804 - val_mean_absolute_error: 6.0804 - val_soft_acc: 0.0657\n",
      "Epoch 66/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 5.9902 - mean_absolute_error: 5.9902 - soft_acc: 0.1033 - val_loss: 2.8333 - val_mean_absolute_error: 2.8333 - val_soft_acc: 0.1543\n",
      "Epoch 67/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 6.2291 - mean_absolute_error: 6.2291 - soft_acc: 0.1650 - val_loss: 2.4878 - val_mean_absolute_error: 2.4878 - val_soft_acc: 0.2507\n",
      "Epoch 68/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 3.1567 - mean_absolute_error: 3.1567 - soft_acc: 0.1600 - val_loss: 3.2406 - val_mean_absolute_error: 3.2406 - val_soft_acc: 0.1464\n",
      "Epoch 69/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 8.6866 - mean_absolute_error: 8.6866 - soft_acc: 0.0839 - val_loss: 3.1204 - val_mean_absolute_error: 3.1204 - val_soft_acc: 0.1693\n",
      "Epoch 70/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 12.7451 - mean_absolute_error: 12.7451 - soft_acc: 0.0800 - val_loss: 12.8875 - val_mean_absolute_error: 12.8875 - val_soft_acc: 0.0150\n",
      "Epoch 71/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 16.9001 - mean_absolute_error: 16.9001 - soft_acc: 0.0233 - val_loss: 2.0677 - val_mean_absolute_error: 2.0677 - val_soft_acc: 0.1614\n",
      "Epoch 72/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 8.9414 - mean_absolute_error: 8.9414 - soft_acc: 0.0872 - val_loss: 1.9190 - val_mean_absolute_error: 1.9190 - val_soft_acc: 0.2357\n",
      "Epoch 73/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 4.8055 - mean_absolute_error: 4.8055 - soft_acc: 0.1167 - val_loss: 4.4681 - val_mean_absolute_error: 4.4681 - val_soft_acc: 0.1143\n",
      "Epoch 74/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 6.8786 - mean_absolute_error: 6.8786 - soft_acc: 0.0950 - val_loss: 8.3262 - val_mean_absolute_error: 8.3262 - val_soft_acc: 0.0607\n",
      "Epoch 75/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 9.9443 - mean_absolute_error: 9.9443 - soft_acc: 0.0717 - val_loss: 5.2267 - val_mean_absolute_error: 5.2267 - val_soft_acc: 0.0629\n",
      "Epoch 76/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 4.2912 - mean_absolute_error: 4.2912 - soft_acc: 0.1117 - val_loss: 7.5996 - val_mean_absolute_error: 7.5996 - val_soft_acc: 0.0379\n",
      "Epoch 77/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 10.1230 - mean_absolute_error: 10.1230 - soft_acc: 0.0706 - val_loss: 5.6097 - val_mean_absolute_error: 5.6097 - val_soft_acc: 0.0636\n",
      "Epoch 78/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 10.3729 - mean_absolute_error: 10.3729 - soft_acc: 0.0783 - val_loss: 3.8007 - val_mean_absolute_error: 3.8007 - val_soft_acc: 0.0707\n",
      "Epoch 79/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 6.2561 - mean_absolute_error: 6.2561 - soft_acc: 0.0706 - val_loss: 3.7255 - val_mean_absolute_error: 3.7255 - val_soft_acc: 0.0986\n",
      "Epoch 80/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 3.8760 - mean_absolute_error: 3.8760 - soft_acc: 0.1661 - val_loss: 1.6081 - val_mean_absolute_error: 1.6081 - val_soft_acc: 0.1586\n",
      "Epoch 81/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 4.1624 - mean_absolute_error: 4.1624 - soft_acc: 0.1350 - val_loss: 3.4608 - val_mean_absolute_error: 3.4608 - val_soft_acc: 0.1900\n",
      "Epoch 82/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 4.7708 - mean_absolute_error: 4.7708 - soft_acc: 0.1422 - val_loss: 1.3032 - val_mean_absolute_error: 1.3031 - val_soft_acc: 0.3036\n",
      "Epoch 83/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 4.8255 - mean_absolute_error: 4.8255 - soft_acc: 0.1672 - val_loss: 2.6208 - val_mean_absolute_error: 2.6208 - val_soft_acc: 0.1314\n",
      "Epoch 84/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 3.6322 - mean_absolute_error: 3.6322 - soft_acc: 0.1389 - val_loss: 1.8787 - val_mean_absolute_error: 1.8787 - val_soft_acc: 0.1693\n",
      "Epoch 85/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 3.6696 - mean_absolute_error: 3.6696 - soft_acc: 0.1622 - val_loss: 1.6670 - val_mean_absolute_error: 1.6670 - val_soft_acc: 0.3336\n",
      "Epoch 86/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 4.5201 - mean_absolute_error: 4.5201 - soft_acc: 0.1133 - val_loss: 3.3456 - val_mean_absolute_error: 3.3456 - val_soft_acc: 0.2043\n",
      "Epoch 87/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.8984 - mean_absolute_error: 1.8984 - soft_acc: 0.2506 - val_loss: 1.4071 - val_mean_absolute_error: 1.4071 - val_soft_acc: 0.2571\n",
      "Epoch 88/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 2.2199 - mean_absolute_error: 2.2199 - soft_acc: 0.2189 - val_loss: 1.1817 - val_mean_absolute_error: 1.1817 - val_soft_acc: 0.3157\n",
      "Epoch 89/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 1.6890 - mean_absolute_error: 1.6890 - soft_acc: 0.2661 - val_loss: 1.0317 - val_mean_absolute_error: 1.0317 - val_soft_acc: 0.3257\n",
      "Epoch 90/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 1.6377 - mean_absolute_error: 1.6377 - soft_acc: 0.21 - 0s 39us/sample - loss: 1.9034 - mean_absolute_error: 1.9034 - soft_acc: 0.2161 - val_loss: 2.1634 - val_mean_absolute_error: 2.1634 - val_soft_acc: 0.1714\n",
      "Epoch 91/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 2.4547 - mean_absolute_error: 2.4547 - soft_acc: 0.2267 - val_loss: 3.3198 - val_mean_absolute_error: 3.3198 - val_soft_acc: 0.0629\n",
      "Epoch 92/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 5.1322 - mean_absolute_error: 5.1322 - soft_acc: 0.1261 - val_loss: 3.2745 - val_mean_absolute_error: 3.2745 - val_soft_acc: 0.1393\n",
      "Epoch 93/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 6.1250 - mean_absolute_error: 6.1250 - soft_acc: 0.1322 - val_loss: 8.1789 - val_mean_absolute_error: 8.1789 - val_soft_acc: 0.0150\n",
      "Epoch 94/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 9.4938 - mean_absolute_error: 9.4938 - soft_acc: 0.0900 - val_loss: 3.3374 - val_mean_absolute_error: 3.3374 - val_soft_acc: 0.1286\n",
      "Epoch 95/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 5.2458 - mean_absolute_error: 5.2458 - soft_acc: 0.1539 - val_loss: 3.4995 - val_mean_absolute_error: 3.4995 - val_soft_acc: 0.1393\n",
      "Epoch 96/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 5.6983 - mean_absolute_error: 5.6983 - soft_acc: 0.1411 - val_loss: 6.5273 - val_mean_absolute_error: 6.5273 - val_soft_acc: 0.0250\n",
      "Epoch 97/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 6.9112 - mean_absolute_error: 6.9112 - soft_acc: 0.0911 - val_loss: 4.2225 - val_mean_absolute_error: 4.2225 - val_soft_acc: 0.1193\n",
      "Epoch 98/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 6.3606 - mean_absolute_error: 6.3606 - soft_acc: 0.0922 - val_loss: 2.6110 - val_mean_absolute_error: 2.6110 - val_soft_acc: 0.1336\n",
      "Epoch 99/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 5.1482 - mean_absolute_error: 5.1482 - soft_acc: 0.1033 - val_loss: 7.1826 - val_mean_absolute_error: 7.1826 - val_soft_acc: 0.0886\n",
      "Epoch 100/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 10.3496 - mean_absolute_error: 10.3496 - soft_acc: 0.0672 - val_loss: 4.2572 - val_mean_absolute_error: 4.2572 - val_soft_acc: 0.0629\n",
      "Epoch 101/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 6.0040 - mean_absolute_error: 6.0040 - soft_acc: 0.0939 - val_loss: 7.1999 - val_mean_absolute_error: 7.1999 - val_soft_acc: 0.0786\n",
      "Epoch 102/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 5.5136 - mean_absolute_error: 5.5136 - soft_acc: 0.1228 - val_loss: 6.6346 - val_mean_absolute_error: 6.6346 - val_soft_acc: 0.0279\n",
      "Epoch 103/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 5.7744 - mean_absolute_error: 5.7744 - soft_acc: 0.1361 - val_loss: 3.7162 - val_mean_absolute_error: 3.7162 - val_soft_acc: 0.1036\n",
      "Epoch 104/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 4.0078 - mean_absolute_error: 4.0078 - soft_acc: 0.1678 - val_loss: 2.9491 - val_mean_absolute_error: 2.9491 - val_soft_acc: 0.1114\n",
      "Epoch 105/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 3.5585 - mean_absolute_error: 3.5585 - soft_acc: 0.1700 - val_loss: 1.8864 - val_mean_absolute_error: 1.8864 - val_soft_acc: 0.2350\n",
      "Epoch 106/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 2.3515 - mean_absolute_error: 2.3515 - soft_acc: 0.23 - 0s 22us/sample - loss: 2.0226 - mean_absolute_error: 2.0226 - soft_acc: 0.2594 - val_loss: 0.9683 - val_mean_absolute_error: 0.9683 - val_soft_acc: 0.4629\n",
      "Epoch 107/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 1.8548 - mean_absolute_error: 1.8548 - soft_acc: 0.2517 - val_loss: 1.2069 - val_mean_absolute_error: 1.2069 - val_soft_acc: 0.2850\n",
      "Epoch 108/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 1.6427 - mean_absolute_error: 1.6427 - soft_acc: 0.3272 - val_loss: 1.6872 - val_mean_absolute_error: 1.6872 - val_soft_acc: 0.2471\n",
      "Epoch 109/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 2.4865 - mean_absolute_error: 2.4865 - soft_acc: 0.1683 - val_loss: 1.2298 - val_mean_absolute_error: 1.2298 - val_soft_acc: 0.2600\n",
      "Epoch 110/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 2.4805 - mean_absolute_error: 2.4805 - soft_acc: 0.2339 - val_loss: 1.2189 - val_mean_absolute_error: 1.2189 - val_soft_acc: 0.4271\n",
      "Epoch 111/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 2.0154 - mean_absolute_error: 2.0154 - soft_acc: 0.2678 - val_loss: 1.8679 - val_mean_absolute_error: 1.8679 - val_soft_acc: 0.1107\n",
      "Epoch 112/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 2.2760 - mean_absolute_error: 2.2760 - soft_acc: 0.2161 - val_loss: 1.8475 - val_mean_absolute_error: 1.8475 - val_soft_acc: 0.1636\n",
      "Epoch 113/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 3.3768 - mean_absolute_error: 3.3768 - soft_acc: 0.2039 - val_loss: 3.2206 - val_mean_absolute_error: 3.2206 - val_soft_acc: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 3.0211 - mean_absolute_error: 3.0211 - soft_acc: 0.1694 - val_loss: 2.0136 - val_mean_absolute_error: 2.0136 - val_soft_acc: 0.1850\n",
      "Epoch 115/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 2.4101 - mean_absolute_error: 2.4101 - soft_acc: 0.1828 - val_loss: 1.7084 - val_mean_absolute_error: 1.7084 - val_soft_acc: 0.1893\n",
      "Epoch 116/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 2.1478 - mean_absolute_error: 2.1478 - soft_acc: 0.2544 - val_loss: 1.2092 - val_mean_absolute_error: 1.2092 - val_soft_acc: 0.3200\n",
      "Epoch 117/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 2.5201 - mean_absolute_error: 2.5201 - soft_acc: 0.2022 - val_loss: 1.4796 - val_mean_absolute_error: 1.4796 - val_soft_acc: 0.2829\n",
      "Epoch 118/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 2.7031 - mean_absolute_error: 2.7031 - soft_acc: 0.2111 - val_loss: 1.2979 - val_mean_absolute_error: 1.2979 - val_soft_acc: 0.2850\n",
      "Epoch 119/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 2.2091 - mean_absolute_error: 2.2091 - soft_acc: 0.3011 - val_loss: 1.1256 - val_mean_absolute_error: 1.1256 - val_soft_acc: 0.3671\n",
      "Epoch 120/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 2.5115 - mean_absolute_error: 2.5115 - soft_acc: 0.2339 - val_loss: 1.8260 - val_mean_absolute_error: 1.8260 - val_soft_acc: 0.2293\n",
      "Epoch 121/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 2.3347 - mean_absolute_error: 2.3347 - soft_acc: 0.2478 - val_loss: 0.9285 - val_mean_absolute_error: 0.9285 - val_soft_acc: 0.4464\n",
      "Epoch 122/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 2.5443 - mean_absolute_error: 2.5443 - soft_acc: 0.2311 - val_loss: 2.5478 - val_mean_absolute_error: 2.5478 - val_soft_acc: 0.0650\n",
      "Epoch 123/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 3.5644 - mean_absolute_error: 3.5644 - soft_acc: 0.2644 - val_loss: 2.3369 - val_mean_absolute_error: 2.3369 - val_soft_acc: 0.0857\n",
      "Epoch 124/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 2.6521 - mean_absolute_error: 2.6521 - soft_acc: 0.1733 - val_loss: 2.2818 - val_mean_absolute_error: 2.2818 - val_soft_acc: 0.1436\n",
      "Epoch 125/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 3.3493 - mean_absolute_error: 3.3493 - soft_acc: 0.1728 - val_loss: 2.7059 - val_mean_absolute_error: 2.7059 - val_soft_acc: 0.1114\n",
      "Epoch 126/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 2.7571 - mean_absolute_error: 2.7571 - soft_acc: 0.1800 - val_loss: 1.9386 - val_mean_absolute_error: 1.9386 - val_soft_acc: 0.0700\n",
      "Epoch 127/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 2.6175 - mean_absolute_error: 2.6175 - soft_acc: 0.2294 - val_loss: 0.8303 - val_mean_absolute_error: 0.8303 - val_soft_acc: 0.4600\n",
      "Epoch 128/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.4564 - mean_absolute_error: 1.4564 - soft_acc: 0.3272 - val_loss: 0.7963 - val_mean_absolute_error: 0.7963 - val_soft_acc: 0.4114\n",
      "Epoch 129/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 1.0382 - mean_absolute_error: 1.0382 - soft_acc: 0.3600 - val_loss: 0.7762 - val_mean_absolute_error: 0.7762 - val_soft_acc: 0.4571\n",
      "Epoch 130/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 1.7292 - mean_absolute_error: 1.7292 - soft_acc: 0.2872 - val_loss: 1.6162 - val_mean_absolute_error: 1.6162 - val_soft_acc: 0.2929\n",
      "Epoch 131/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 2.0346 - mean_absolute_error: 2.0346 - soft_acc: 0.23 - 0s 33us/sample - loss: 2.1339 - mean_absolute_error: 2.1339 - soft_acc: 0.2589 - val_loss: 0.9422 - val_mean_absolute_error: 0.9422 - val_soft_acc: 0.3686\n",
      "Epoch 132/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.4352 - mean_absolute_error: 1.4352 - soft_acc: 0.3028 - val_loss: 1.6766 - val_mean_absolute_error: 1.6766 - val_soft_acc: 0.1364\n",
      "Epoch 133/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 3.1979 - mean_absolute_error: 3.1979 - soft_acc: 0.1622 - val_loss: 1.8542 - val_mean_absolute_error: 1.8542 - val_soft_acc: 0.1179\n",
      "Epoch 134/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 2.9414 - mean_absolute_error: 2.9414 - soft_acc: 0.2217 - val_loss: 3.1074 - val_mean_absolute_error: 3.1074 - val_soft_acc: 0.0629\n",
      "Epoch 135/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 3.7262 - mean_absolute_error: 3.7262 - soft_acc: 0.1794 - val_loss: 2.8782 - val_mean_absolute_error: 2.8782 - val_soft_acc: 0.1164\n",
      "Epoch 136/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 3.2700 - mean_absolute_error: 3.2700 - soft_acc: 0.1878 - val_loss: 3.3310 - val_mean_absolute_error: 3.3310 - val_soft_acc: 0.1343\n",
      "Epoch 137/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 2.6749 - mean_absolute_error: 2.6749 - soft_acc: 0.1900 - val_loss: 0.7890 - val_mean_absolute_error: 0.7890 - val_soft_acc: 0.3479\n",
      "Epoch 138/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.2926 - mean_absolute_error: 1.2926 - soft_acc: 0.4206 - val_loss: 1.3032 - val_mean_absolute_error: 1.3032 - val_soft_acc: 0.1871\n",
      "Epoch 139/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 1.1355 - mean_absolute_error: 1.1355 - soft_acc: 0.3922 - val_loss: 2.2605 - val_mean_absolute_error: 2.2605 - val_soft_acc: 0.1557\n",
      "Epoch 140/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 3.5422 - mean_absolute_error: 3.5422 - soft_acc: 0.1761 - val_loss: 1.0444 - val_mean_absolute_error: 1.0444 - val_soft_acc: 0.3671\n",
      "Epoch 141/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 2.1156 - mean_absolute_error: 2.1156 - soft_acc: 0.3039 - val_loss: 1.5942 - val_mean_absolute_error: 1.5942 - val_soft_acc: 0.3336\n",
      "Epoch 142/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 2.8169 - mean_absolute_error: 2.8169 - soft_acc: 0.2661 - val_loss: 1.4131 - val_mean_absolute_error: 1.4131 - val_soft_acc: 0.2900\n",
      "Epoch 143/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 1.9209 - mean_absolute_error: 1.9209 - soft_acc: 0.2861 - val_loss: 2.1342 - val_mean_absolute_error: 2.1342 - val_soft_acc: 0.1964\n",
      "Epoch 144/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 2.0061 - mean_absolute_error: 2.0061 - soft_acc: 0.2506 - val_loss: 0.8312 - val_mean_absolute_error: 0.8312 - val_soft_acc: 0.4321\n",
      "Epoch 145/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.6074 - mean_absolute_error: 1.6074 - soft_acc: 0.2439 - val_loss: 1.0028 - val_mean_absolute_error: 1.0028 - val_soft_acc: 0.4264\n",
      "Epoch 146/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 1.4407 - mean_absolute_error: 1.4407 - soft_acc: 0.3550 - val_loss: 1.2342 - val_mean_absolute_error: 1.2342 - val_soft_acc: 0.3664\n",
      "Epoch 147/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 1.2249 - mean_absolute_error: 1.2249 - soft_acc: 0.3611 - val_loss: 0.6600 - val_mean_absolute_error: 0.6600 - val_soft_acc: 0.4564\n",
      "Epoch 148/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.7811 - mean_absolute_error: 0.7811 - soft_acc: 0.4761 - val_loss: 0.7139 - val_mean_absolute_error: 0.7139 - val_soft_acc: 0.4793\n",
      "Epoch 149/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 1.2474 - mean_absolute_error: 1.2474 - soft_acc: 0.3478 - val_loss: 1.6672 - val_mean_absolute_error: 1.6672 - val_soft_acc: 0.1436\n",
      "Epoch 150/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 2.9833 - mean_absolute_error: 2.9833 - soft_acc: 0.1967 - val_loss: 1.3547 - val_mean_absolute_error: 1.3547 - val_soft_acc: 0.2921\n",
      "Epoch 151/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 2.1949 - mean_absolute_error: 2.1949 - soft_acc: 0.2039 - val_loss: 1.3996 - val_mean_absolute_error: 1.3996 - val_soft_acc: 0.1943\n",
      "Epoch 152/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 2.3952 - mean_absolute_error: 2.3952 - soft_acc: 0.2372 - val_loss: 2.6427 - val_mean_absolute_error: 2.6427 - val_soft_acc: 0.0429\n",
      "Epoch 153/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 3.7932 - mean_absolute_error: 3.7932 - soft_acc: 0.1172 - val_loss: 1.0880 - val_mean_absolute_error: 1.0880 - val_soft_acc: 0.3636\n",
      "Epoch 154/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 3.1345 - mean_absolute_error: 3.1345 - soft_acc: 0.1750 - val_loss: 1.3941 - val_mean_absolute_error: 1.3941 - val_soft_acc: 0.3657\n",
      "Epoch 155/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 2.0529 - mean_absolute_error: 2.0529 - soft_acc: 0.3011 - val_loss: 1.5824 - val_mean_absolute_error: 1.5824 - val_soft_acc: 0.3279\n",
      "Epoch 156/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 1.8431 - mean_absolute_error: 1.8431 - soft_acc: 0.3467 - val_loss: 1.1380 - val_mean_absolute_error: 1.1380 - val_soft_acc: 0.3971\n",
      "Epoch 157/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 1.1329 - mean_absolute_error: 1.1329 - soft_acc: 0.4256 - val_loss: 0.8369 - val_mean_absolute_error: 0.8369 - val_soft_acc: 0.4186\n",
      "Epoch 158/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 1.3045 - mean_absolute_error: 1.3045 - soft_acc: 0.4056 - val_loss: 1.1703 - val_mean_absolute_error: 1.1703 - val_soft_acc: 0.4400\n",
      "Epoch 159/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.2341 - mean_absolute_error: 1.2341 - soft_acc: 0.2856 - val_loss: 1.0541 - val_mean_absolute_error: 1.0541 - val_soft_acc: 0.3543\n",
      "Epoch 160/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.2624 - mean_absolute_error: 1.2624 - soft_acc: 0.3744 - val_loss: 1.2198 - val_mean_absolute_error: 1.2198 - val_soft_acc: 0.2550\n",
      "Epoch 161/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 1.6759 - mean_absolute_error: 1.6759 - soft_acc: 0.27 - 0s 42us/sample - loss: 1.3808 - mean_absolute_error: 1.3808 - soft_acc: 0.3078 - val_loss: 0.8504 - val_mean_absolute_error: 0.8504 - val_soft_acc: 0.4414\n",
      "Epoch 162/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 1.0086 - mean_absolute_error: 1.0086 - soft_acc: 0.3883 - val_loss: 1.1950 - val_mean_absolute_error: 1.1950 - val_soft_acc: 0.2736\n",
      "Epoch 163/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.6480 - mean_absolute_error: 1.6480 - soft_acc: 0.2894 - val_loss: 2.3167 - val_mean_absolute_error: 2.3167 - val_soft_acc: 0.1129\n",
      "Epoch 164/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 3.0896 - mean_absolute_error: 3.0896 - soft_acc: 0.1744 - val_loss: 2.4953 - val_mean_absolute_error: 2.4953 - val_soft_acc: 0.1464\n",
      "Epoch 165/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 4.7516 - mean_absolute_error: 4.7516 - soft_acc: 0.1256 - val_loss: 2.7024 - val_mean_absolute_error: 2.7024 - val_soft_acc: 0.1814\n",
      "Epoch 166/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 3.0803 - mean_absolute_error: 3.0803 - soft_acc: 0.2206 - val_loss: 1.0905 - val_mean_absolute_error: 1.0905 - val_soft_acc: 0.3786\n",
      "Epoch 167/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 2.0119 - mean_absolute_error: 2.0119 - soft_acc: 0.2728 - val_loss: 1.3500 - val_mean_absolute_error: 1.3500 - val_soft_acc: 0.2929\n",
      "Epoch 168/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 2.1850 - mean_absolute_error: 2.1850 - soft_acc: 0.2722 - val_loss: 1.0326 - val_mean_absolute_error: 1.0326 - val_soft_acc: 0.3864\n",
      "Epoch 169/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 2.1834 - mean_absolute_error: 2.1834 - soft_acc: 0.21 - 0s 35us/sample - loss: 1.3382 - mean_absolute_error: 1.3382 - soft_acc: 0.4211 - val_loss: 0.5826 - val_mean_absolute_error: 0.5826 - val_soft_acc: 0.5650\n",
      "Epoch 170/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.7424 - mean_absolute_error: 0.7424 - soft_acc: 0.5156 - val_loss: 0.8871 - val_mean_absolute_error: 0.8871 - val_soft_acc: 0.4314\n",
      "Epoch 171/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.9574 - mean_absolute_error: 0.9574 - soft_acc: 0.4600 - val_loss: 0.6421 - val_mean_absolute_error: 0.6421 - val_soft_acc: 0.5050\n",
      "Epoch 172/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.8731 - mean_absolute_error: 0.8731 - soft_acc: 0.4494 - val_loss: 1.1139 - val_mean_absolute_error: 1.1139 - val_soft_acc: 0.4214\n",
      "Epoch 173/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 1.3773 - mean_absolute_error: 1.3773 - soft_acc: 0.3467 - val_loss: 1.1598 - val_mean_absolute_error: 1.1598 - val_soft_acc: 0.2993\n",
      "Epoch 174/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 1.5019 - mean_absolute_error: 1.5019 - soft_acc: 0.3250 - val_loss: 0.9767 - val_mean_absolute_error: 0.9767 - val_soft_acc: 0.4450\n",
      "Epoch 175/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.8675 - mean_absolute_error: 1.8675 - soft_acc: 0.2528 - val_loss: 1.0102 - val_mean_absolute_error: 1.0102 - val_soft_acc: 0.3386\n",
      "Epoch 176/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 1.0791 - mean_absolute_error: 1.0791 - soft_acc: 0.33 - 0s 35us/sample - loss: 1.3549 - mean_absolute_error: 1.3549 - soft_acc: 0.3722 - val_loss: 0.8140 - val_mean_absolute_error: 0.8140 - val_soft_acc: 0.3571\n",
      "Epoch 177/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 1.4790 - mean_absolute_error: 1.4790 - soft_acc: 0.3122 - val_loss: 1.3736 - val_mean_absolute_error: 1.3736 - val_soft_acc: 0.1714\n",
      "Epoch 178/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.2942 - mean_absolute_error: 1.2942 - soft_acc: 0.3906 - val_loss: 1.4865 - val_mean_absolute_error: 1.4865 - val_soft_acc: 0.1336\n",
      "Epoch 179/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 1.9153 - mean_absolute_error: 1.9153 - soft_acc: 0.2911 - val_loss: 0.8771 - val_mean_absolute_error: 0.8771 - val_soft_acc: 0.3664\n",
      "Epoch 180/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.2354 - mean_absolute_error: 1.2354 - soft_acc: 0.4011 - val_loss: 0.7381 - val_mean_absolute_error: 0.7381 - val_soft_acc: 0.5043\n",
      "Epoch 181/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6630 - mean_absolute_error: 0.6630 - soft_acc: 0.5467 - val_loss: 1.2409 - val_mean_absolute_error: 1.2409 - val_soft_acc: 0.2671\n",
      "Epoch 182/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 1.9846 - mean_absolute_error: 1.9846 - soft_acc: 0.3017 - val_loss: 0.7597 - val_mean_absolute_error: 0.7597 - val_soft_acc: 0.4171\n",
      "Epoch 183/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.6349 - mean_absolute_error: 0.6349 - soft_acc: 0.47 - 0s 46us/sample - loss: 1.7726 - mean_absolute_error: 1.7726 - soft_acc: 0.2906 - val_loss: 1.1102 - val_mean_absolute_error: 1.1102 - val_soft_acc: 0.2971\n",
      "Epoch 184/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 1.9687 - mean_absolute_error: 1.9687 - soft_acc: 0.2578 - val_loss: 0.9685 - val_mean_absolute_error: 0.9685 - val_soft_acc: 0.5493\n",
      "Epoch 185/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.8943 - mean_absolute_error: 1.8943 - soft_acc: 0.3200 - val_loss: 0.9416 - val_mean_absolute_error: 0.9416 - val_soft_acc: 0.3057\n",
      "Epoch 186/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 1.1334 - mean_absolute_error: 1.1334 - soft_acc: 0.4828 - val_loss: 0.9246 - val_mean_absolute_error: 0.9246 - val_soft_acc: 0.3129\n",
      "Epoch 187/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 1.1421 - mean_absolute_error: 1.1421 - soft_acc: 0.3906 - val_loss: 0.9616 - val_mean_absolute_error: 0.9616 - val_soft_acc: 0.3893\n",
      "Epoch 188/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 1.3478 - mean_absolute_error: 1.3478 - soft_acc: 0.3683 - val_loss: 0.8157 - val_mean_absolute_error: 0.8157 - val_soft_acc: 0.3250\n",
      "Epoch 189/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 38us/sample - loss: 0.8078 - mean_absolute_error: 0.8078 - soft_acc: 0.4506 - val_loss: 0.9280 - val_mean_absolute_error: 0.9280 - val_soft_acc: 0.3257\n",
      "Epoch 190/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.8924 - mean_absolute_error: 0.8924 - soft_acc: 0.4317 - val_loss: 0.8475 - val_mean_absolute_error: 0.8475 - val_soft_acc: 0.5086\n",
      "Epoch 191/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 1.0816 - mean_absolute_error: 1.0816 - soft_acc: 0.4028 - val_loss: 0.8516 - val_mean_absolute_error: 0.8516 - val_soft_acc: 0.3050\n",
      "Epoch 192/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.8031 - mean_absolute_error: 0.8031 - soft_acc: 0.4833 - val_loss: 0.7607 - val_mean_absolute_error: 0.7607 - val_soft_acc: 0.4486\n",
      "Epoch 193/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.9005 - mean_absolute_error: 0.9005 - soft_acc: 0.4606 - val_loss: 0.7658 - val_mean_absolute_error: 0.7658 - val_soft_acc: 0.3514\n",
      "Epoch 194/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.9542 - mean_absolute_error: 0.9542 - soft_acc: 0.4428 - val_loss: 0.7650 - val_mean_absolute_error: 0.7650 - val_soft_acc: 0.5514\n",
      "Epoch 195/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.9911 - mean_absolute_error: 0.9911 - soft_acc: 0.4328 - val_loss: 1.0038 - val_mean_absolute_error: 1.0038 - val_soft_acc: 0.4314\n",
      "Epoch 196/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.2217 - mean_absolute_error: 1.2217 - soft_acc: 0.3228 - val_loss: 0.6896 - val_mean_absolute_error: 0.6896 - val_soft_acc: 0.3471\n",
      "Epoch 197/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.4644 - mean_absolute_error: 1.4644 - soft_acc: 0.3222 - val_loss: 1.0696 - val_mean_absolute_error: 1.0696 - val_soft_acc: 0.3943\n",
      "Epoch 198/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 1.4026 - mean_absolute_error: 1.4026 - soft_acc: 0.3461 - val_loss: 1.0231 - val_mean_absolute_error: 1.0231 - val_soft_acc: 0.3029\n",
      "Epoch 199/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 1.0482 - mean_absolute_error: 1.0482 - soft_acc: 0.4244 - val_loss: 0.8024 - val_mean_absolute_error: 0.8024 - val_soft_acc: 0.4164\n",
      "Epoch 200/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.0459 - mean_absolute_error: 1.0459 - soft_acc: 0.4022 - val_loss: 0.8238 - val_mean_absolute_error: 0.8238 - val_soft_acc: 0.4343\n",
      "Epoch 201/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 1.1898 - mean_absolute_error: 1.1898 - soft_acc: 0.3450 - val_loss: 1.4590 - val_mean_absolute_error: 1.4590 - val_soft_acc: 0.2829\n",
      "Epoch 202/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.0639 - mean_absolute_error: 1.0639 - soft_acc: 0.4244 - val_loss: 1.2314 - val_mean_absolute_error: 1.2314 - val_soft_acc: 0.2136\n",
      "Epoch 203/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 1.5874 - mean_absolute_error: 1.5874 - soft_acc: 0.3117 - val_loss: 1.0919 - val_mean_absolute_error: 1.0919 - val_soft_acc: 0.2650\n",
      "Epoch 204/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.2727 - mean_absolute_error: 1.2727 - soft_acc: 0.4039 - val_loss: 0.8347 - val_mean_absolute_error: 0.8347 - val_soft_acc: 0.4371\n",
      "Epoch 205/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 1.4355 - mean_absolute_error: 1.4355 - soft_acc: 0.3417 - val_loss: 1.6439 - val_mean_absolute_error: 1.6439 - val_soft_acc: 0.2493\n",
      "Epoch 206/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.3505 - mean_absolute_error: 1.3505 - soft_acc: 0.3683 - val_loss: 0.7447 - val_mean_absolute_error: 0.7447 - val_soft_acc: 0.4293\n",
      "Epoch 207/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.7208 - mean_absolute_error: 0.7208 - soft_acc: 0.4461 - val_loss: 0.6154 - val_mean_absolute_error: 0.6154 - val_soft_acc: 0.5257\n",
      "Epoch 208/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.5777 - mean_absolute_error: 0.5777 - soft_acc: 0.5172 - val_loss: 0.5697 - val_mean_absolute_error: 0.5697 - val_soft_acc: 0.5457\n",
      "Epoch 209/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5414 - mean_absolute_error: 0.5414 - soft_acc: 0.6044 - val_loss: 0.5996 - val_mean_absolute_error: 0.5996 - val_soft_acc: 0.5000\n",
      "Epoch 210/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.7748 - mean_absolute_error: 0.7748 - soft_acc: 0.4806 - val_loss: 0.6488 - val_mean_absolute_error: 0.6488 - val_soft_acc: 0.5021\n",
      "Epoch 211/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.7359 - mean_absolute_error: 0.7359 - soft_acc: 0.5228 - val_loss: 0.8303 - val_mean_absolute_error: 0.8303 - val_soft_acc: 0.3179\n",
      "Epoch 212/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 1.2900 - mean_absolute_error: 1.2900 - soft_acc: 0.4022 - val_loss: 0.8612 - val_mean_absolute_error: 0.8612 - val_soft_acc: 0.3614\n",
      "Epoch 213/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.9998 - mean_absolute_error: 0.9998 - soft_acc: 0.4750 - val_loss: 0.7462 - val_mean_absolute_error: 0.7462 - val_soft_acc: 0.3586\n",
      "Epoch 214/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6754 - mean_absolute_error: 0.6754 - soft_acc: 0.5317 - val_loss: 0.7251 - val_mean_absolute_error: 0.7251 - val_soft_acc: 0.4007\n",
      "Epoch 215/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.8358 - mean_absolute_error: 0.8358 - soft_acc: 0.4767 - val_loss: 0.8141 - val_mean_absolute_error: 0.8141 - val_soft_acc: 0.4300\n",
      "Epoch 216/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.7181 - mean_absolute_error: 0.7181 - soft_acc: 0.4828 - val_loss: 0.9919 - val_mean_absolute_error: 0.9919 - val_soft_acc: 0.3307\n",
      "Epoch 217/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.8212 - mean_absolute_error: 0.8212 - soft_acc: 0.4433 - val_loss: 1.1057 - val_mean_absolute_error: 1.1057 - val_soft_acc: 0.2750\n",
      "Epoch 218/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 1.7724 - mean_absolute_error: 1.7724 - soft_acc: 0.2806 - val_loss: 0.8513 - val_mean_absolute_error: 0.8513 - val_soft_acc: 0.4393\n",
      "Epoch 219/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.7831 - mean_absolute_error: 0.7831 - soft_acc: 0.4567 - val_loss: 0.8228 - val_mean_absolute_error: 0.8228 - val_soft_acc: 0.4707\n",
      "Epoch 220/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.8549 - mean_absolute_error: 0.8549 - soft_acc: 0.4606 - val_loss: 0.8221 - val_mean_absolute_error: 0.8221 - val_soft_acc: 0.3250\n",
      "Epoch 221/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.7685 - mean_absolute_error: 0.7685 - soft_acc: 0.4489 - val_loss: 0.9606 - val_mean_absolute_error: 0.9606 - val_soft_acc: 0.2629\n",
      "Epoch 222/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.5539 - mean_absolute_error: 1.5539 - soft_acc: 0.2733 - val_loss: 0.8243 - val_mean_absolute_error: 0.8243 - val_soft_acc: 0.2850\n",
      "Epoch 223/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 1.1827 - mean_absolute_error: 1.1827 - soft_acc: 0.3900 - val_loss: 0.7543 - val_mean_absolute_error: 0.7543 - val_soft_acc: 0.3893\n",
      "Epoch 224/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 1.1969 - mean_absolute_error: 1.1969 - soft_acc: 0.3839 - val_loss: 1.0891 - val_mean_absolute_error: 1.0891 - val_soft_acc: 0.2471\n",
      "Epoch 225/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.5618 - mean_absolute_error: 1.5618 - soft_acc: 0.3494 - val_loss: 0.9053 - val_mean_absolute_error: 0.9053 - val_soft_acc: 0.3807\n",
      "Epoch 226/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.9525 - mean_absolute_error: 0.9525 - soft_acc: 0.4211 - val_loss: 0.8034 - val_mean_absolute_error: 0.8034 - val_soft_acc: 0.3936\n",
      "Epoch 227/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.8052 - mean_absolute_error: 0.8052 - soft_acc: 0.4778 - val_loss: 0.7326 - val_mean_absolute_error: 0.7326 - val_soft_acc: 0.4443\n",
      "Epoch 228/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6552 - mean_absolute_error: 0.6552 - soft_acc: 0.5583 - val_loss: 0.7028 - val_mean_absolute_error: 0.7028 - val_soft_acc: 0.5336\n",
      "Epoch 229/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7956 - mean_absolute_error: 0.7956 - soft_acc: 0.4889 - val_loss: 0.6274 - val_mean_absolute_error: 0.6274 - val_soft_acc: 0.4843\n",
      "Epoch 230/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.7650 - mean_absolute_error: 0.7650 - soft_acc: 0.5228 - val_loss: 0.7272 - val_mean_absolute_error: 0.7272 - val_soft_acc: 0.4336\n",
      "Epoch 231/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.5459 - mean_absolute_error: 0.5459 - soft_acc: 0.6067 - val_loss: 0.7514 - val_mean_absolute_error: 0.7514 - val_soft_acc: 0.4057\n",
      "Epoch 232/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5056 - mean_absolute_error: 0.5056 - soft_acc: 0.6239 - val_loss: 0.7817 - val_mean_absolute_error: 0.7817 - val_soft_acc: 0.4286\n",
      "Epoch 233/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.5636 - mean_absolute_error: 0.5636 - soft_acc: 0.6106 - val_loss: 0.7505 - val_mean_absolute_error: 0.7505 - val_soft_acc: 0.4907\n",
      "Epoch 234/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.8441 - mean_absolute_error: 0.8441 - soft_acc: 0.4228 - val_loss: 0.7688 - val_mean_absolute_error: 0.7688 - val_soft_acc: 0.3457\n",
      "Epoch 235/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6519 - mean_absolute_error: 0.6519 - soft_acc: 0.5317 - val_loss: 0.7580 - val_mean_absolute_error: 0.7580 - val_soft_acc: 0.5007\n",
      "Epoch 236/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5078 - mean_absolute_error: 0.5078 - soft_acc: 0.6317 - val_loss: 0.6175 - val_mean_absolute_error: 0.6175 - val_soft_acc: 0.5000\n",
      "Epoch 237/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5916 - mean_absolute_error: 0.5916 - soft_acc: 0.5656 - val_loss: 0.6082 - val_mean_absolute_error: 0.6082 - val_soft_acc: 0.5021\n",
      "Epoch 238/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5584 - mean_absolute_error: 0.5584 - soft_acc: 0.5606 - val_loss: 0.7220 - val_mean_absolute_error: 0.7220 - val_soft_acc: 0.5436\n",
      "Epoch 239/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5320 - mean_absolute_error: 0.5320 - soft_acc: 0.5856 - val_loss: 0.7546 - val_mean_absolute_error: 0.7546 - val_soft_acc: 0.3914\n",
      "Epoch 240/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5043 - mean_absolute_error: 0.5043 - soft_acc: 0.6483 - val_loss: 0.7113 - val_mean_absolute_error: 0.7113 - val_soft_acc: 0.3829\n",
      "Epoch 241/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5020 - mean_absolute_error: 0.5020 - soft_acc: 0.6272 - val_loss: 0.7250 - val_mean_absolute_error: 0.7250 - val_soft_acc: 0.4750\n",
      "Epoch 242/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5883 - mean_absolute_error: 0.5883 - soft_acc: 0.5789 - val_loss: 0.7243 - val_mean_absolute_error: 0.7243 - val_soft_acc: 0.4779\n",
      "Epoch 243/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5778 - mean_absolute_error: 0.5778 - soft_acc: 0.6272 - val_loss: 0.5754 - val_mean_absolute_error: 0.5754 - val_soft_acc: 0.5429\n",
      "Epoch 244/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5549 - mean_absolute_error: 0.5549 - soft_acc: 0.5556 - val_loss: 0.6711 - val_mean_absolute_error: 0.6711 - val_soft_acc: 0.4979\n",
      "Epoch 245/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.7413 - mean_absolute_error: 0.7413 - soft_acc: 0.5322 - val_loss: 0.5528 - val_mean_absolute_error: 0.5528 - val_soft_acc: 0.5471\n",
      "Epoch 246/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5622 - mean_absolute_error: 0.5622 - soft_acc: 0.5978 - val_loss: 0.5728 - val_mean_absolute_error: 0.5728 - val_soft_acc: 0.5250\n",
      "Epoch 247/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6271 - mean_absolute_error: 0.6271 - soft_acc: 0.5756 - val_loss: 0.6222 - val_mean_absolute_error: 0.6222 - val_soft_acc: 0.5536\n",
      "Epoch 248/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5184 - mean_absolute_error: 0.5184 - soft_acc: 0.6811 - val_loss: 0.6762 - val_mean_absolute_error: 0.6762 - val_soft_acc: 0.4464\n",
      "Epoch 249/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4726 - mean_absolute_error: 0.4726 - soft_acc: 0.6411 - val_loss: 0.6504 - val_mean_absolute_error: 0.6504 - val_soft_acc: 0.4236\n",
      "Epoch 250/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.6041 - mean_absolute_error: 0.6041 - soft_acc: 0.5778 - val_loss: 0.6735 - val_mean_absolute_error: 0.6735 - val_soft_acc: 0.4821\n",
      "Epoch 251/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6900 - mean_absolute_error: 0.6900 - soft_acc: 0.5206 - val_loss: 0.6310 - val_mean_absolute_error: 0.6310 - val_soft_acc: 0.4257\n",
      "Epoch 252/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5954 - mean_absolute_error: 0.5954 - soft_acc: 0.5617 - val_loss: 0.5878 - val_mean_absolute_error: 0.5878 - val_soft_acc: 0.5071\n",
      "Epoch 253/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5258 - mean_absolute_error: 0.5258 - soft_acc: 0.6328 - val_loss: 0.5725 - val_mean_absolute_error: 0.5725 - val_soft_acc: 0.5271\n",
      "Epoch 254/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4597 - mean_absolute_error: 0.4597 - soft_acc: 0.6494 - val_loss: 0.6120 - val_mean_absolute_error: 0.6120 - val_soft_acc: 0.5536\n",
      "Epoch 255/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5787 - mean_absolute_error: 0.5787 - soft_acc: 0.5961 - val_loss: 0.6352 - val_mean_absolute_error: 0.6352 - val_soft_acc: 0.4793\n",
      "Epoch 256/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.6874 - mean_absolute_error: 0.6874 - soft_acc: 0.5239 - val_loss: 0.5800 - val_mean_absolute_error: 0.5800 - val_soft_acc: 0.5021\n",
      "Epoch 257/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.7799 - mean_absolute_error: 0.7799 - soft_acc: 0.5794 - val_loss: 0.6035 - val_mean_absolute_error: 0.6035 - val_soft_acc: 0.5479\n",
      "Epoch 258/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5299 - mean_absolute_error: 0.5299 - soft_acc: 0.5978 - val_loss: 0.7372 - val_mean_absolute_error: 0.7372 - val_soft_acc: 0.4243\n",
      "Epoch 259/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4548 - mean_absolute_error: 0.4548 - soft_acc: 0.5956 - val_loss: 0.6860 - val_mean_absolute_error: 0.6860 - val_soft_acc: 0.4879\n",
      "Epoch 260/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.6309 - mean_absolute_error: 0.6309 - soft_acc: 0.5939 - val_loss: 0.6863 - val_mean_absolute_error: 0.6863 - val_soft_acc: 0.3936\n",
      "Epoch 261/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.8212 - mean_absolute_error: 0.8212 - soft_acc: 0.4528 - val_loss: 0.6468 - val_mean_absolute_error: 0.6468 - val_soft_acc: 0.5129\n",
      "Epoch 262/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.6615 - mean_absolute_error: 0.6615 - soft_acc: 0.5800 - val_loss: 0.8286 - val_mean_absolute_error: 0.8286 - val_soft_acc: 0.3664\n",
      "Epoch 263/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.7226 - mean_absolute_error: 0.7226 - soft_acc: 0.4844 - val_loss: 0.6518 - val_mean_absolute_error: 0.6518 - val_soft_acc: 0.4871\n",
      "Epoch 264/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.7739 - mean_absolute_error: 0.7739 - soft_acc: 0.5244 - val_loss: 0.6841 - val_mean_absolute_error: 0.6841 - val_soft_acc: 0.4900\n",
      "Epoch 265/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 0.6351 - mean_absolute_error: 0.6351 - soft_acc: 0.5867 - val_loss: 0.5935 - val_mean_absolute_error: 0.5935 - val_soft_acc: 0.5764\n",
      "Epoch 266/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5918 - mean_absolute_error: 0.5918 - soft_acc: 0.5589 - val_loss: 0.6841 - val_mean_absolute_error: 0.6841 - val_soft_acc: 0.4600\n",
      "Epoch 267/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.6170 - mean_absolute_error: 0.6170 - soft_acc: 0.5672 - val_loss: 0.6869 - val_mean_absolute_error: 0.6869 - val_soft_acc: 0.4771\n",
      "Epoch 268/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.7440 - mean_absolute_error: 0.7440 - soft_acc: 0.5300 - val_loss: 0.5615 - val_mean_absolute_error: 0.5615 - val_soft_acc: 0.5529\n",
      "Epoch 269/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6644 - mean_absolute_error: 0.6644 - soft_acc: 0.5322 - val_loss: 0.6564 - val_mean_absolute_error: 0.6564 - val_soft_acc: 0.4829\n",
      "Epoch 270/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.7050 - mean_absolute_error: 0.7050 - soft_acc: 0.5633 - val_loss: 0.9274 - val_mean_absolute_error: 0.9274 - val_soft_acc: 0.3579\n",
      "Epoch 271/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.9453 - mean_absolute_error: 0.9453 - soft_acc: 0.3989 - val_loss: 0.8908 - val_mean_absolute_error: 0.8908 - val_soft_acc: 0.4679\n",
      "Epoch 272/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.9544 - mean_absolute_error: 0.9544 - soft_acc: 0.4744 - val_loss: 0.6664 - val_mean_absolute_error: 0.6664 - val_soft_acc: 0.3679\n",
      "Epoch 273/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.7793 - mean_absolute_error: 1.7793 - soft_acc: 0.3867 - val_loss: 0.8058 - val_mean_absolute_error: 0.8058 - val_soft_acc: 0.5029\n",
      "Epoch 274/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.7692 - mean_absolute_error: 0.7692 - soft_acc: 0.4756 - val_loss: 0.6087 - val_mean_absolute_error: 0.6087 - val_soft_acc: 0.4614\n",
      "Epoch 275/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.7398 - mean_absolute_error: 0.7398 - soft_acc: 0.5122 - val_loss: 0.6810 - val_mean_absolute_error: 0.6810 - val_soft_acc: 0.4057\n",
      "Epoch 276/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.6961 - mean_absolute_error: 0.6961 - soft_acc: 0.5128 - val_loss: 0.7574 - val_mean_absolute_error: 0.7574 - val_soft_acc: 0.4979\n",
      "Epoch 277/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7292 - mean_absolute_error: 0.7292 - soft_acc: 0.5161 - val_loss: 0.5344 - val_mean_absolute_error: 0.5344 - val_soft_acc: 0.5679\n",
      "Epoch 278/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6554 - mean_absolute_error: 0.6554 - soft_acc: 0.5500 - val_loss: 0.7502 - val_mean_absolute_error: 0.7502 - val_soft_acc: 0.4457\n",
      "Epoch 279/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 1.0300 - mean_absolute_error: 1.0300 - soft_acc: 0.4211 - val_loss: 0.5383 - val_mean_absolute_error: 0.5383 - val_soft_acc: 0.5964\n",
      "Epoch 280/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.7134 - mean_absolute_error: 0.7134 - soft_acc: 0.5350 - val_loss: 0.6582 - val_mean_absolute_error: 0.6582 - val_soft_acc: 0.5871\n",
      "Epoch 281/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6482 - mean_absolute_error: 0.6482 - soft_acc: 0.5339 - val_loss: 0.6103 - val_mean_absolute_error: 0.6103 - val_soft_acc: 0.4714\n",
      "Epoch 282/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.5192 - mean_absolute_error: 0.5192 - soft_acc: 0.6028 - val_loss: 0.8420 - val_mean_absolute_error: 0.8420 - val_soft_acc: 0.2950\n",
      "Epoch 283/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.8824 - mean_absolute_error: 0.8824 - soft_acc: 0.4444 - val_loss: 1.1072 - val_mean_absolute_error: 1.1072 - val_soft_acc: 0.4257\n",
      "Epoch 284/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.8840 - mean_absolute_error: 0.8840 - soft_acc: 0.4661 - val_loss: 0.8578 - val_mean_absolute_error: 0.8578 - val_soft_acc: 0.4279\n",
      "Epoch 285/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.7734 - mean_absolute_error: 0.7734 - soft_acc: 0.5050 - val_loss: 0.7328 - val_mean_absolute_error: 0.7328 - val_soft_acc: 0.5257\n",
      "Epoch 286/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.9557 - mean_absolute_error: 0.9557 - soft_acc: 0.4611 - val_loss: 0.6766 - val_mean_absolute_error: 0.6766 - val_soft_acc: 0.4214\n",
      "Epoch 287/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5630 - mean_absolute_error: 0.5630 - soft_acc: 0.5783 - val_loss: 0.6389 - val_mean_absolute_error: 0.6389 - val_soft_acc: 0.4336\n",
      "Epoch 288/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.7152 - mean_absolute_error: 0.7152 - soft_acc: 0.5400 - val_loss: 0.6955 - val_mean_absolute_error: 0.6955 - val_soft_acc: 0.4186\n",
      "Epoch 289/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7770 - mean_absolute_error: 0.7770 - soft_acc: 0.5461 - val_loss: 0.6385 - val_mean_absolute_error: 0.6385 - val_soft_acc: 0.4850\n",
      "Epoch 290/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.6189 - mean_absolute_error: 0.6189 - soft_acc: 0.5328 - val_loss: 0.8827 - val_mean_absolute_error: 0.8827 - val_soft_acc: 0.3643\n",
      "Epoch 291/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.7828 - mean_absolute_error: 0.7828 - soft_acc: 0.4489 - val_loss: 0.6520 - val_mean_absolute_error: 0.6520 - val_soft_acc: 0.4493\n",
      "Epoch 292/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5295 - mean_absolute_error: 0.5295 - soft_acc: 0.6272 - val_loss: 0.5512 - val_mean_absolute_error: 0.5512 - val_soft_acc: 0.5479\n",
      "Epoch 293/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4419 - mean_absolute_error: 0.4419 - soft_acc: 0.6556 - val_loss: 0.7656 - val_mean_absolute_error: 0.7656 - val_soft_acc: 0.4164\n",
      "Epoch 294/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.6051 - mean_absolute_error: 0.6051 - soft_acc: 0.5533 - val_loss: 0.6736 - val_mean_absolute_error: 0.6736 - val_soft_acc: 0.4693\n",
      "Epoch 295/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.9661 - mean_absolute_error: 0.9661 - soft_acc: 0.4650 - val_loss: 0.6421 - val_mean_absolute_error: 0.6421 - val_soft_acc: 0.4743\n",
      "Epoch 296/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.6270 - mean_absolute_error: 0.6270 - soft_acc: 0.5839 - val_loss: 0.7313 - val_mean_absolute_error: 0.7313 - val_soft_acc: 0.4350\n",
      "Epoch 297/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6837 - mean_absolute_error: 0.6837 - soft_acc: 0.4500 - val_loss: 0.6794 - val_mean_absolute_error: 0.6794 - val_soft_acc: 0.4314\n",
      "Epoch 298/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.7195 - mean_absolute_error: 0.7195 - soft_acc: 0.5272 - val_loss: 0.8282 - val_mean_absolute_error: 0.8282 - val_soft_acc: 0.3686\n",
      "Epoch 299/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.6943 - mean_absolute_error: 0.6943 - soft_acc: 0.5678 - val_loss: 0.7199 - val_mean_absolute_error: 0.7199 - val_soft_acc: 0.4550\n",
      "Epoch 300/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.6557 - mean_absolute_error: 0.6557 - soft_acc: 0.5478 - val_loss: 0.7444 - val_mean_absolute_error: 0.7444 - val_soft_acc: 0.3836\n",
      "Epoch 301/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.7638 - mean_absolute_error: 0.7638 - soft_acc: 0.4367 - val_loss: 0.6453 - val_mean_absolute_error: 0.6453 - val_soft_acc: 0.5229\n",
      "Epoch 302/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4944 - mean_absolute_error: 0.4944 - soft_acc: 0.5972 - val_loss: 0.6137 - val_mean_absolute_error: 0.6137 - val_soft_acc: 0.5686\n",
      "Epoch 303/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5665 - mean_absolute_error: 0.5665 - soft_acc: 0.5944 - val_loss: 0.6504 - val_mean_absolute_error: 0.6504 - val_soft_acc: 0.5386\n",
      "Epoch 304/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5707 - mean_absolute_error: 0.5707 - soft_acc: 0.6239 - val_loss: 0.6653 - val_mean_absolute_error: 0.6653 - val_soft_acc: 0.5357\n",
      "Epoch 305/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5302 - mean_absolute_error: 0.5302 - soft_acc: 0.6261 - val_loss: 0.5905 - val_mean_absolute_error: 0.5905 - val_soft_acc: 0.5457\n",
      "Epoch 306/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.6178 - mean_absolute_error: 0.6178 - soft_acc: 0.6139 - val_loss: 0.7276 - val_mean_absolute_error: 0.7276 - val_soft_acc: 0.4414\n",
      "Epoch 307/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5245 - mean_absolute_error: 0.5245 - soft_acc: 0.6289 - val_loss: 0.6103 - val_mean_absolute_error: 0.6103 - val_soft_acc: 0.5379\n",
      "Epoch 308/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4211 - mean_absolute_error: 0.4211 - soft_acc: 0.7039 - val_loss: 0.6113 - val_mean_absolute_error: 0.6113 - val_soft_acc: 0.5557\n",
      "Epoch 309/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4965 - mean_absolute_error: 0.4965 - soft_acc: 0.6572 - val_loss: 0.6859 - val_mean_absolute_error: 0.6859 - val_soft_acc: 0.5129\n",
      "Epoch 310/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5551 - mean_absolute_error: 0.5551 - soft_acc: 0.5489 - val_loss: 0.5940 - val_mean_absolute_error: 0.5940 - val_soft_acc: 0.4843\n",
      "Epoch 311/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.5221 - mean_absolute_error: 0.5221 - soft_acc: 0.6194 - val_loss: 0.6101 - val_mean_absolute_error: 0.6101 - val_soft_acc: 0.5814\n",
      "Epoch 312/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5440 - mean_absolute_error: 0.5440 - soft_acc: 0.6450 - val_loss: 0.5676 - val_mean_absolute_error: 0.5676 - val_soft_acc: 0.4686\n",
      "Epoch 313/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4454 - mean_absolute_error: 0.4454 - soft_acc: 0.6233 - val_loss: 0.5973 - val_mean_absolute_error: 0.5973 - val_soft_acc: 0.5050\n",
      "Epoch 314/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5005 - mean_absolute_error: 0.5005 - soft_acc: 0.6150 - val_loss: 0.5614 - val_mean_absolute_error: 0.5614 - val_soft_acc: 0.5807\n",
      "Epoch 315/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6277 - mean_absolute_error: 0.6277 - soft_acc: 0.6056 - val_loss: 0.7808 - val_mean_absolute_error: 0.7808 - val_soft_acc: 0.3886\n",
      "Epoch 316/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.8276 - mean_absolute_error: 0.8276 - soft_acc: 0.4928 - val_loss: 0.6476 - val_mean_absolute_error: 0.6476 - val_soft_acc: 0.4714\n",
      "Epoch 317/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5592 - mean_absolute_error: 0.5592 - soft_acc: 0.5489 - val_loss: 0.6221 - val_mean_absolute_error: 0.6221 - val_soft_acc: 0.4257\n",
      "Epoch 318/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5160 - mean_absolute_error: 0.5160 - soft_acc: 0.6706 - val_loss: 0.6540 - val_mean_absolute_error: 0.6540 - val_soft_acc: 0.4686\n",
      "Epoch 319/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4466 - mean_absolute_error: 0.4466 - soft_acc: 0.6711 - val_loss: 0.7532 - val_mean_absolute_error: 0.7532 - val_soft_acc: 0.4871\n",
      "Epoch 320/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5742 - mean_absolute_error: 0.5742 - soft_acc: 0.6144 - val_loss: 0.7388 - val_mean_absolute_error: 0.7388 - val_soft_acc: 0.4571\n",
      "Epoch 321/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.6624 - mean_absolute_error: 0.6624 - soft_acc: 0.5089 - val_loss: 0.5430 - val_mean_absolute_error: 0.5430 - val_soft_acc: 0.6371\n",
      "Epoch 322/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5375 - mean_absolute_error: 0.5375 - soft_acc: 0.5694 - val_loss: 0.6890 - val_mean_absolute_error: 0.6890 - val_soft_acc: 0.4164\n",
      "Epoch 323/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5640 - mean_absolute_error: 0.5640 - soft_acc: 0.6111 - val_loss: 0.7603 - val_mean_absolute_error: 0.7603 - val_soft_acc: 0.4729\n",
      "Epoch 324/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.8026 - mean_absolute_error: 0.8026 - soft_acc: 0.5406 - val_loss: 0.6995 - val_mean_absolute_error: 0.6995 - val_soft_acc: 0.4593\n",
      "Epoch 325/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.5689 - mean_absolute_error: 0.5689 - soft_acc: 0.5539 - val_loss: 0.6401 - val_mean_absolute_error: 0.6401 - val_soft_acc: 0.5257\n",
      "Epoch 326/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4733 - mean_absolute_error: 0.4733 - soft_acc: 0.6322 - val_loss: 0.6259 - val_mean_absolute_error: 0.6259 - val_soft_acc: 0.5079\n",
      "Epoch 327/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4361 - mean_absolute_error: 0.4361 - soft_acc: 0.6172 - val_loss: 0.5775 - val_mean_absolute_error: 0.5775 - val_soft_acc: 0.5736\n",
      "Epoch 328/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5756 - mean_absolute_error: 0.5756 - soft_acc: 0.5939 - val_loss: 0.6571 - val_mean_absolute_error: 0.6571 - val_soft_acc: 0.5107\n",
      "Epoch 329/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.5934 - mean_absolute_error: 0.5934 - soft_acc: 0.5917 - val_loss: 0.5745 - val_mean_absolute_error: 0.5745 - val_soft_acc: 0.6321\n",
      "Epoch 330/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5451 - mean_absolute_error: 0.5451 - soft_acc: 0.5889 - val_loss: 0.5974 - val_mean_absolute_error: 0.5974 - val_soft_acc: 0.5150\n",
      "Epoch 331/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.5000 - mean_absolute_error: 0.5000 - soft_acc: 0.6500 - val_loss: 0.6440 - val_mean_absolute_error: 0.6440 - val_soft_acc: 0.4236\n",
      "Epoch 332/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5406 - mean_absolute_error: 0.5406 - soft_acc: 0.5728 - val_loss: 0.7832 - val_mean_absolute_error: 0.7832 - val_soft_acc: 0.5057\n",
      "Epoch 333/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.9679 - mean_absolute_error: 0.9679 - soft_acc: 0.4750 - val_loss: 0.6405 - val_mean_absolute_error: 0.6405 - val_soft_acc: 0.4464\n",
      "Epoch 334/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.6554 - mean_absolute_error: 0.6554 - soft_acc: 0.5217 - val_loss: 0.6829 - val_mean_absolute_error: 0.6829 - val_soft_acc: 0.4907\n",
      "Epoch 335/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4895 - mean_absolute_error: 0.4895 - soft_acc: 0.6056 - val_loss: 0.5734 - val_mean_absolute_error: 0.5734 - val_soft_acc: 0.6200\n",
      "Epoch 336/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5001 - mean_absolute_error: 0.5001 - soft_acc: 0.6533 - val_loss: 0.6657 - val_mean_absolute_error: 0.6657 - val_soft_acc: 0.4671\n",
      "Epoch 337/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4874 - mean_absolute_error: 0.4874 - soft_acc: 0.5911 - val_loss: 2.1959 - val_mean_absolute_error: 2.1959 - val_soft_acc: 0.2621\n",
      "Epoch 338/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.9528 - mean_absolute_error: 0.9528 - soft_acc: 0.6278 - val_loss: 0.6540 - val_mean_absolute_error: 0.6540 - val_soft_acc: 0.5029\n",
      "Epoch 339/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4654 - mean_absolute_error: 0.4654 - soft_acc: 0.6611 - val_loss: 0.7066 - val_mean_absolute_error: 0.7066 - val_soft_acc: 0.4621\n",
      "Epoch 340/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4411 - mean_absolute_error: 0.4411 - soft_acc: 0.6972 - val_loss: 0.6734 - val_mean_absolute_error: 0.6734 - val_soft_acc: 0.4386\n",
      "Epoch 341/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5738 - mean_absolute_error: 0.5738 - soft_acc: 0.5706 - val_loss: 0.5566 - val_mean_absolute_error: 0.5566 - val_soft_acc: 0.5836\n",
      "Epoch 342/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5078 - mean_absolute_error: 0.5078 - soft_acc: 0.6872 - val_loss: 0.8481 - val_mean_absolute_error: 0.8481 - val_soft_acc: 0.4071\n",
      "Epoch 343/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.6299 - mean_absolute_error: 0.6299 - soft_acc: 0.5828 - val_loss: 0.5485 - val_mean_absolute_error: 0.5485 - val_soft_acc: 0.4964\n",
      "Epoch 344/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4865 - mean_absolute_error: 0.4865 - soft_acc: 0.6056 - val_loss: 0.5848 - val_mean_absolute_error: 0.5848 - val_soft_acc: 0.5429\n",
      "Epoch 345/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4945 - mean_absolute_error: 0.4945 - soft_acc: 0.6789 - val_loss: 0.7679 - val_mean_absolute_error: 0.7679 - val_soft_acc: 0.4271\n",
      "Epoch 346/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.5760 - mean_absolute_error: 0.5760 - soft_acc: 0.6006 - val_loss: 0.8214 - val_mean_absolute_error: 0.8214 - val_soft_acc: 0.3300\n",
      "Epoch 347/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.7002 - mean_absolute_error: 0.7002 - soft_acc: 0.5467 - val_loss: 1.0811 - val_mean_absolute_error: 1.0811 - val_soft_acc: 0.2321\n",
      "Epoch 348/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.9533 - mean_absolute_error: 0.9533 - soft_acc: 0.4372 - val_loss: 0.6008 - val_mean_absolute_error: 0.6008 - val_soft_acc: 0.5586\n",
      "Epoch 349/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4774 - mean_absolute_error: 0.4774 - soft_acc: 0.6856 - val_loss: 0.7275 - val_mean_absolute_error: 0.7275 - val_soft_acc: 0.3957\n",
      "Epoch 350/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5122 - mean_absolute_error: 0.5122 - soft_acc: 0.6433 - val_loss: 0.6670 - val_mean_absolute_error: 0.6670 - val_soft_acc: 0.4950\n",
      "Epoch 351/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4609 - mean_absolute_error: 0.4609 - soft_acc: 0.6800 - val_loss: 0.6519 - val_mean_absolute_error: 0.6519 - val_soft_acc: 0.5029\n",
      "Epoch 352/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5364 - mean_absolute_error: 0.5364 - soft_acc: 0.5683 - val_loss: 0.5912 - val_mean_absolute_error: 0.5912 - val_soft_acc: 0.5786\n",
      "Epoch 353/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4247 - mean_absolute_error: 0.4247 - soft_acc: 0.6894 - val_loss: 0.6190 - val_mean_absolute_error: 0.6190 - val_soft_acc: 0.5043\n",
      "Epoch 354/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.4196 - mean_absolute_error: 0.4196 - soft_acc: 0.7067 - val_loss: 0.7856 - val_mean_absolute_error: 0.7856 - val_soft_acc: 0.4700\n",
      "Epoch 355/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.5536 - mean_absolute_error: 0.5536 - soft_acc: 0.6039 - val_loss: 0.6319 - val_mean_absolute_error: 0.6319 - val_soft_acc: 0.5843\n",
      "Epoch 356/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3725 - mean_absolute_error: 0.3725 - soft_acc: 0.7544 - val_loss: 0.6330 - val_mean_absolute_error: 0.6330 - val_soft_acc: 0.5329\n",
      "Epoch 357/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3993 - mean_absolute_error: 0.3993 - soft_acc: 0.7256 - val_loss: 0.6989 - val_mean_absolute_error: 0.6989 - val_soft_acc: 0.5050\n",
      "Epoch 358/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3710 - mean_absolute_error: 0.3710 - soft_acc: 0.7333 - val_loss: 0.6167 - val_mean_absolute_error: 0.6167 - val_soft_acc: 0.5421\n",
      "Epoch 359/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4068 - mean_absolute_error: 0.4068 - soft_acc: 0.7356 - val_loss: 0.5910 - val_mean_absolute_error: 0.5910 - val_soft_acc: 0.5450\n",
      "Epoch 360/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4327 - mean_absolute_error: 0.4327 - soft_acc: 0.7256 - val_loss: 0.6703 - val_mean_absolute_error: 0.6703 - val_soft_acc: 0.5257\n",
      "Epoch 361/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.5440 - mean_absolute_error: 0.5440 - soft_acc: 0.6194 - val_loss: 0.6500 - val_mean_absolute_error: 0.6500 - val_soft_acc: 0.5329\n",
      "Epoch 362/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4648 - mean_absolute_error: 0.4648 - soft_acc: 0.6806 - val_loss: 0.5724 - val_mean_absolute_error: 0.5724 - val_soft_acc: 0.5600\n",
      "Epoch 363/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4118 - mean_absolute_error: 0.4118 - soft_acc: 0.7044 - val_loss: 0.6480 - val_mean_absolute_error: 0.6480 - val_soft_acc: 0.4179\n",
      "Epoch 364/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.5017 - mean_absolute_error: 0.5017 - soft_acc: 0.6372 - val_loss: 0.5969 - val_mean_absolute_error: 0.5969 - val_soft_acc: 0.5350\n",
      "Epoch 365/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5392 - mean_absolute_error: 0.5392 - soft_acc: 0.6389 - val_loss: 0.5994 - val_mean_absolute_error: 0.5994 - val_soft_acc: 0.5350\n",
      "Epoch 366/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4059 - mean_absolute_error: 0.4059 - soft_acc: 0.7183 - val_loss: 0.6031 - val_mean_absolute_error: 0.6031 - val_soft_acc: 0.5993\n",
      "Epoch 367/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3836 - mean_absolute_error: 0.3836 - soft_acc: 0.7317 - val_loss: 0.5575 - val_mean_absolute_error: 0.5575 - val_soft_acc: 0.6143\n",
      "Epoch 368/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4264 - mean_absolute_error: 0.4264 - soft_acc: 0.6750 - val_loss: 0.5632 - val_mean_absolute_error: 0.5632 - val_soft_acc: 0.5964\n",
      "Epoch 369/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.4387 - mean_absolute_error: 0.4387 - soft_acc: 0.7011 - val_loss: 0.5303 - val_mean_absolute_error: 0.5303 - val_soft_acc: 0.5879\n",
      "Epoch 370/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3768 - mean_absolute_error: 0.3768 - soft_acc: 0.7383 - val_loss: 0.8352 - val_mean_absolute_error: 0.8352 - val_soft_acc: 0.4221\n",
      "Epoch 371/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.8897 - mean_absolute_error: 0.8897 - soft_acc: 0.4956 - val_loss: 0.6530 - val_mean_absolute_error: 0.6530 - val_soft_acc: 0.4443\n",
      "Epoch 372/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.9182 - mean_absolute_error: 0.9182 - soft_acc: 0.4489 - val_loss: 0.8174 - val_mean_absolute_error: 0.8174 - val_soft_acc: 0.4043\n",
      "Epoch 373/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.9344 - mean_absolute_error: 0.9344 - soft_acc: 0.4456 - val_loss: 0.6814 - val_mean_absolute_error: 0.6814 - val_soft_acc: 0.4621\n",
      "Epoch 374/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5969 - mean_absolute_error: 0.5969 - soft_acc: 0.5844 - val_loss: 0.5624 - val_mean_absolute_error: 0.5624 - val_soft_acc: 0.5907\n",
      "Epoch 375/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4949 - mean_absolute_error: 0.4949 - soft_acc: 0.5867 - val_loss: 0.7672 - val_mean_absolute_error: 0.7672 - val_soft_acc: 0.3664\n",
      "Epoch 376/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.6741 - mean_absolute_error: 0.6741 - soft_acc: 0.5422 - val_loss: 0.7674 - val_mean_absolute_error: 0.7674 - val_soft_acc: 0.3786\n",
      "Epoch 377/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.6371 - mean_absolute_error: 0.6371 - soft_acc: 0.5639 - val_loss: 0.6891 - val_mean_absolute_error: 0.6891 - val_soft_acc: 0.4214\n",
      "Epoch 378/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4781 - mean_absolute_error: 0.4781 - soft_acc: 0.6567 - val_loss: 0.7286 - val_mean_absolute_error: 0.7286 - val_soft_acc: 0.3629\n",
      "Epoch 379/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5409 - mean_absolute_error: 0.5409 - soft_acc: 0.6472 - val_loss: 0.6879 - val_mean_absolute_error: 0.6879 - val_soft_acc: 0.5186\n",
      "Epoch 380/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5445 - mean_absolute_error: 0.5445 - soft_acc: 0.6261 - val_loss: 0.6036 - val_mean_absolute_error: 0.6036 - val_soft_acc: 0.5843\n",
      "Epoch 381/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4224 - mean_absolute_error: 0.4224 - soft_acc: 0.7089 - val_loss: 0.5834 - val_mean_absolute_error: 0.5834 - val_soft_acc: 0.5121\n",
      "Epoch 382/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4364 - mean_absolute_error: 0.4364 - soft_acc: 0.6700 - val_loss: 0.5984 - val_mean_absolute_error: 0.5984 - val_soft_acc: 0.4950\n",
      "Epoch 383/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5187 - mean_absolute_error: 0.5187 - soft_acc: 0.6533 - val_loss: 0.6108 - val_mean_absolute_error: 0.6108 - val_soft_acc: 0.5307\n",
      "Epoch 384/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.5432 - mean_absolute_error: 0.5432 - soft_acc: 0.6111 - val_loss: 0.6477 - val_mean_absolute_error: 0.6477 - val_soft_acc: 0.4543\n",
      "Epoch 385/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5557 - mean_absolute_error: 0.5557 - soft_acc: 0.6117 - val_loss: 0.5879 - val_mean_absolute_error: 0.5879 - val_soft_acc: 0.5150\n",
      "Epoch 386/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4225 - mean_absolute_error: 0.4225 - soft_acc: 0.6911 - val_loss: 0.6033 - val_mean_absolute_error: 0.6033 - val_soft_acc: 0.5279\n",
      "Epoch 387/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4136 - mean_absolute_error: 0.4136 - soft_acc: 0.6994 - val_loss: 0.6743 - val_mean_absolute_error: 0.6743 - val_soft_acc: 0.4721\n",
      "Epoch 388/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5356 - mean_absolute_error: 0.5356 - soft_acc: 0.6239 - val_loss: 0.7779 - val_mean_absolute_error: 0.7779 - val_soft_acc: 0.4064\n",
      "Epoch 389/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5435 - mean_absolute_error: 0.5435 - soft_acc: 0.5761 - val_loss: 0.7687 - val_mean_absolute_error: 0.7687 - val_soft_acc: 0.4450\n",
      "Epoch 390/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.6170 - mean_absolute_error: 0.6170 - soft_acc: 0.6083 - val_loss: 0.9504 - val_mean_absolute_error: 0.9504 - val_soft_acc: 0.3100\n",
      "Epoch 391/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6981 - mean_absolute_error: 0.6981 - soft_acc: 0.5439 - val_loss: 0.7130 - val_mean_absolute_error: 0.7130 - val_soft_acc: 0.5200\n",
      "Epoch 392/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.8319 - mean_absolute_error: 0.8319 - soft_acc: 0.5472 - val_loss: 0.5675 - val_mean_absolute_error: 0.5675 - val_soft_acc: 0.5271\n",
      "Epoch 393/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5250 - mean_absolute_error: 0.5250 - soft_acc: 0.6756 - val_loss: 0.6658 - val_mean_absolute_error: 0.6658 - val_soft_acc: 0.5543\n",
      "Epoch 394/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.7035 - mean_absolute_error: 0.7035 - soft_acc: 0.5261 - val_loss: 0.8998 - val_mean_absolute_error: 0.8998 - val_soft_acc: 0.3229\n",
      "Epoch 395/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.7469 - mean_absolute_error: 0.7469 - soft_acc: 0.5339 - val_loss: 0.9324 - val_mean_absolute_error: 0.9324 - val_soft_acc: 0.4021\n",
      "Epoch 396/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.6016 - mean_absolute_error: 0.6016 - soft_acc: 0.5817 - val_loss: 0.6719 - val_mean_absolute_error: 0.6719 - val_soft_acc: 0.4286\n",
      "Epoch 397/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.7530 - mean_absolute_error: 0.7530 - soft_acc: 0.5072 - val_loss: 0.6850 - val_mean_absolute_error: 0.6850 - val_soft_acc: 0.4907\n",
      "Epoch 398/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.6514 - mean_absolute_error: 0.6514 - soft_acc: 0.5533 - val_loss: 0.7098 - val_mean_absolute_error: 0.7098 - val_soft_acc: 0.3957\n",
      "Epoch 399/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.6936 - mean_absolute_error: 0.6936 - soft_acc: 0.5506 - val_loss: 0.8695 - val_mean_absolute_error: 0.8695 - val_soft_acc: 0.2979\n",
      "Epoch 400/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6755 - mean_absolute_error: 0.6755 - soft_acc: 0.5450 - val_loss: 0.6564 - val_mean_absolute_error: 0.6564 - val_soft_acc: 0.5257\n",
      "Epoch 401/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4737 - mean_absolute_error: 0.4737 - soft_acc: 0.6461 - val_loss: 0.5545 - val_mean_absolute_error: 0.5545 - val_soft_acc: 0.4864\n",
      "Epoch 402/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4150 - mean_absolute_error: 0.4150 - soft_acc: 0.7100 - val_loss: 0.5096 - val_mean_absolute_error: 0.5096 - val_soft_acc: 0.6314\n",
      "Epoch 403/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4266 - mean_absolute_error: 0.4266 - soft_acc: 0.6894 - val_loss: 0.4863 - val_mean_absolute_error: 0.4863 - val_soft_acc: 0.7229\n",
      "Epoch 404/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4173 - mean_absolute_error: 0.4173 - soft_acc: 0.7211 - val_loss: 0.5216 - val_mean_absolute_error: 0.5216 - val_soft_acc: 0.5707\n",
      "Epoch 405/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4161 - mean_absolute_error: 0.4161 - soft_acc: 0.6928 - val_loss: 0.6794 - val_mean_absolute_error: 0.6794 - val_soft_acc: 0.4264\n",
      "Epoch 406/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4330 - mean_absolute_error: 0.4330 - soft_acc: 0.6367 - val_loss: 0.6418 - val_mean_absolute_error: 0.6418 - val_soft_acc: 0.5207\n",
      "Epoch 407/3000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.4169 - mean_absolute_error: 0.4169 - soft_acc: 0.6983 - val_loss: 0.6944 - val_mean_absolute_error: 0.6944 - val_soft_acc: 0.4800\n",
      "Epoch 408/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4144 - mean_absolute_error: 0.4144 - soft_acc: 0.7389 - val_loss: 0.6291 - val_mean_absolute_error: 0.6291 - val_soft_acc: 0.5307\n",
      "Epoch 409/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3831 - mean_absolute_error: 0.3831 - soft_acc: 0.7367 - val_loss: 0.5919 - val_mean_absolute_error: 0.5919 - val_soft_acc: 0.4979\n",
      "Epoch 410/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3652 - mean_absolute_error: 0.3652 - soft_acc: 0.7667 - val_loss: 0.6470 - val_mean_absolute_error: 0.6470 - val_soft_acc: 0.4950\n",
      "Epoch 411/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4101 - mean_absolute_error: 0.4101 - soft_acc: 0.6967 - val_loss: 0.5517 - val_mean_absolute_error: 0.5517 - val_soft_acc: 0.5179\n",
      "Epoch 412/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4447 - mean_absolute_error: 0.4447 - soft_acc: 0.6728 - val_loss: 0.5849 - val_mean_absolute_error: 0.5849 - val_soft_acc: 0.5021\n",
      "Epoch 413/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5427 - mean_absolute_error: 0.5427 - soft_acc: 0.6017 - val_loss: 0.5843 - val_mean_absolute_error: 0.5843 - val_soft_acc: 0.4921\n",
      "Epoch 414/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.5765 - mean_absolute_error: 0.5765 - soft_acc: 0.6133 - val_loss: 0.5692 - val_mean_absolute_error: 0.5692 - val_soft_acc: 0.5586\n",
      "Epoch 415/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5190 - mean_absolute_error: 0.5190 - soft_acc: 0.5956 - val_loss: 0.5473 - val_mean_absolute_error: 0.5473 - val_soft_acc: 0.5629\n",
      "Epoch 416/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4265 - mean_absolute_error: 0.4265 - soft_acc: 0.6683 - val_loss: 0.7220 - val_mean_absolute_error: 0.7220 - val_soft_acc: 0.3957\n",
      "Epoch 417/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 40us/sample - loss: 0.7192 - mean_absolute_error: 0.7192 - soft_acc: 0.5700 - val_loss: 0.5942 - val_mean_absolute_error: 0.5942 - val_soft_acc: 0.5021\n",
      "Epoch 418/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4990 - mean_absolute_error: 0.4990 - soft_acc: 0.6711 - val_loss: 0.6274 - val_mean_absolute_error: 0.6274 - val_soft_acc: 0.4900\n",
      "Epoch 419/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5465 - mean_absolute_error: 0.5465 - soft_acc: 0.6417 - val_loss: 0.6540 - val_mean_absolute_error: 0.6540 - val_soft_acc: 0.5057\n",
      "Epoch 420/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.4679 - mean_absolute_error: 0.4679 - soft_acc: 0.6472 - val_loss: 0.6430 - val_mean_absolute_error: 0.6430 - val_soft_acc: 0.5021\n",
      "Epoch 421/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4564 - mean_absolute_error: 0.4564 - soft_acc: 0.6694 - val_loss: 0.6838 - val_mean_absolute_error: 0.6838 - val_soft_acc: 0.5329\n",
      "Epoch 422/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.5435 - mean_absolute_error: 0.5435 - soft_acc: 0.6078 - val_loss: 0.8501 - val_mean_absolute_error: 0.8501 - val_soft_acc: 0.3636\n",
      "Epoch 423/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.6418 - mean_absolute_error: 0.6418 - soft_acc: 0.5761 - val_loss: 0.7962 - val_mean_absolute_error: 0.7962 - val_soft_acc: 0.4214\n",
      "Epoch 424/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5084 - mean_absolute_error: 0.5084 - soft_acc: 0.6133 - val_loss: 0.6660 - val_mean_absolute_error: 0.6660 - val_soft_acc: 0.4464\n",
      "Epoch 425/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4260 - mean_absolute_error: 0.4260 - soft_acc: 0.7256 - val_loss: 0.6102 - val_mean_absolute_error: 0.6102 - val_soft_acc: 0.6043\n",
      "Epoch 426/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3869 - mean_absolute_error: 0.3869 - soft_acc: 0.7339 - val_loss: 0.6174 - val_mean_absolute_error: 0.6174 - val_soft_acc: 0.4893\n",
      "Epoch 427/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4227 - mean_absolute_error: 0.4227 - soft_acc: 0.6967 - val_loss: 0.6076 - val_mean_absolute_error: 0.6076 - val_soft_acc: 0.5279\n",
      "Epoch 428/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4865 - mean_absolute_error: 0.4865 - soft_acc: 0.6528 - val_loss: 0.5628 - val_mean_absolute_error: 0.5628 - val_soft_acc: 0.5836\n",
      "Epoch 429/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4218 - mean_absolute_error: 0.4218 - soft_acc: 0.6844 - val_loss: 0.5398 - val_mean_absolute_error: 0.5398 - val_soft_acc: 0.5629\n",
      "Epoch 430/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3697 - mean_absolute_error: 0.3697 - soft_acc: 0.7378 - val_loss: 0.5488 - val_mean_absolute_error: 0.5488 - val_soft_acc: 0.5529\n",
      "Epoch 431/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3793 - mean_absolute_error: 0.3793 - soft_acc: 0.7217 - val_loss: 0.5874 - val_mean_absolute_error: 0.5874 - val_soft_acc: 0.6093\n",
      "Epoch 432/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3948 - mean_absolute_error: 0.3948 - soft_acc: 0.6906 - val_loss: 0.6411 - val_mean_absolute_error: 0.6411 - val_soft_acc: 0.4871\n",
      "Epoch 433/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4889 - mean_absolute_error: 0.4889 - soft_acc: 0.5922 - val_loss: 0.6439 - val_mean_absolute_error: 0.6439 - val_soft_acc: 0.4900\n",
      "Epoch 434/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4114 - mean_absolute_error: 0.4114 - soft_acc: 0.7044 - val_loss: 0.5502 - val_mean_absolute_error: 0.5502 - val_soft_acc: 0.5657\n",
      "Epoch 435/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3911 - mean_absolute_error: 0.3911 - soft_acc: 0.7100 - val_loss: 0.6842 - val_mean_absolute_error: 0.6842 - val_soft_acc: 0.4421\n",
      "Epoch 436/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4919 - mean_absolute_error: 0.4919 - soft_acc: 0.6267 - val_loss: 0.7396 - val_mean_absolute_error: 0.7396 - val_soft_acc: 0.4343\n",
      "Epoch 437/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4538 - mean_absolute_error: 0.4538 - soft_acc: 0.6256 - val_loss: 0.6478 - val_mean_absolute_error: 0.6478 - val_soft_acc: 0.5050\n",
      "Epoch 438/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5259 - mean_absolute_error: 0.5259 - soft_acc: 0.5794 - val_loss: 0.6319 - val_mean_absolute_error: 0.6319 - val_soft_acc: 0.5507\n",
      "Epoch 439/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4526 - mean_absolute_error: 0.4526 - soft_acc: 0.6917 - val_loss: 0.5858 - val_mean_absolute_error: 0.5858 - val_soft_acc: 0.4714\n",
      "Epoch 440/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4990 - mean_absolute_error: 0.4990 - soft_acc: 0.6050 - val_loss: 0.5573 - val_mean_absolute_error: 0.5573 - val_soft_acc: 0.5236\n",
      "Epoch 441/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4464 - mean_absolute_error: 0.4464 - soft_acc: 0.6472 - val_loss: 0.5040 - val_mean_absolute_error: 0.5040 - val_soft_acc: 0.6386\n",
      "Epoch 442/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3850 - mean_absolute_error: 0.3850 - soft_acc: 0.7250 - val_loss: 0.5387 - val_mean_absolute_error: 0.5387 - val_soft_acc: 0.5221\n",
      "Epoch 443/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3603 - mean_absolute_error: 0.3603 - soft_acc: 0.7500 - val_loss: 0.5817 - val_mean_absolute_error: 0.5817 - val_soft_acc: 0.6321\n",
      "Epoch 444/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3753 - mean_absolute_error: 0.3753 - soft_acc: 0.7494 - val_loss: 0.6310 - val_mean_absolute_error: 0.6310 - val_soft_acc: 0.4229\n",
      "Epoch 445/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3969 - mean_absolute_error: 0.3969 - soft_acc: 0.7078 - val_loss: 0.5300 - val_mean_absolute_error: 0.5300 - val_soft_acc: 0.5786\n",
      "Epoch 446/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4387 - mean_absolute_error: 0.4387 - soft_acc: 0.6311 - val_loss: 0.5521 - val_mean_absolute_error: 0.5521 - val_soft_acc: 0.6193\n",
      "Epoch 447/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.5168 - mean_absolute_error: 0.5168 - soft_acc: 0.6367 - val_loss: 0.5239 - val_mean_absolute_error: 0.5239 - val_soft_acc: 0.5957\n",
      "Epoch 448/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4589 - mean_absolute_error: 0.4589 - soft_acc: 0.6594 - val_loss: 0.5127 - val_mean_absolute_error: 0.5127 - val_soft_acc: 0.6421\n",
      "Epoch 449/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4175 - mean_absolute_error: 0.4175 - soft_acc: 0.7344 - val_loss: 0.5926 - val_mean_absolute_error: 0.5926 - val_soft_acc: 0.5757\n",
      "Epoch 450/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3724 - mean_absolute_error: 0.3724 - soft_acc: 0.7244 - val_loss: 0.5353 - val_mean_absolute_error: 0.5353 - val_soft_acc: 0.5807\n",
      "Epoch 451/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3886 - mean_absolute_error: 0.3886 - soft_acc: 0.6978 - val_loss: 0.5357 - val_mean_absolute_error: 0.5357 - val_soft_acc: 0.5836\n",
      "Epoch 452/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3720 - mean_absolute_error: 0.3720 - soft_acc: 0.6989 - val_loss: 0.5593 - val_mean_absolute_error: 0.5593 - val_soft_acc: 0.5400\n",
      "Epoch 453/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4786 - mean_absolute_error: 0.4786 - soft_acc: 0.6494 - val_loss: 0.4911 - val_mean_absolute_error: 0.4911 - val_soft_acc: 0.6414\n",
      "Epoch 454/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3859 - mean_absolute_error: 0.3859 - soft_acc: 0.7222 - val_loss: 0.4848 - val_mean_absolute_error: 0.4848 - val_soft_acc: 0.6157\n",
      "Epoch 455/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3302 - mean_absolute_error: 0.3302 - soft_acc: 0.7711 - val_loss: 0.7009 - val_mean_absolute_error: 0.7009 - val_soft_acc: 0.4214\n",
      "Epoch 456/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4381 - mean_absolute_error: 0.4381 - soft_acc: 0.7067 - val_loss: 0.5067 - val_mean_absolute_error: 0.5067 - val_soft_acc: 0.6286\n",
      "Epoch 457/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4090 - mean_absolute_error: 0.4090 - soft_acc: 0.7172 - val_loss: 0.5062 - val_mean_absolute_error: 0.5062 - val_soft_acc: 0.6621\n",
      "Epoch 458/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3656 - mean_absolute_error: 0.3656 - soft_acc: 0.7189 - val_loss: 0.5634 - val_mean_absolute_error: 0.5634 - val_soft_acc: 0.5607\n",
      "Epoch 459/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4851 - mean_absolute_error: 0.4851 - soft_acc: 0.6667 - val_loss: 0.6893 - val_mean_absolute_error: 0.6893 - val_soft_acc: 0.4721\n",
      "Epoch 460/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.7576 - mean_absolute_error: 0.7576 - soft_acc: 0.5033 - val_loss: 0.6751 - val_mean_absolute_error: 0.6751 - val_soft_acc: 0.5307\n",
      "Epoch 461/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3824 - mean_absolute_error: 0.3824 - soft_acc: 0.7211 - val_loss: 0.6341 - val_mean_absolute_error: 0.6341 - val_soft_acc: 0.4843\n",
      "Epoch 462/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.6066 - mean_absolute_error: 0.6066 - soft_acc: 0.5944 - val_loss: 0.5749 - val_mean_absolute_error: 0.5749 - val_soft_acc: 0.6271\n",
      "Epoch 463/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4979 - mean_absolute_error: 0.4979 - soft_acc: 0.6628 - val_loss: 0.5509 - val_mean_absolute_error: 0.5509 - val_soft_acc: 0.5529\n",
      "Epoch 464/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4440 - mean_absolute_error: 0.4440 - soft_acc: 0.7189 - val_loss: 0.4717 - val_mean_absolute_error: 0.4717 - val_soft_acc: 0.6307\n",
      "Epoch 465/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3840 - mean_absolute_error: 0.3840 - soft_acc: 0.7489 - val_loss: 0.5015 - val_mean_absolute_error: 0.5015 - val_soft_acc: 0.6700\n",
      "Epoch 466/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3934 - mean_absolute_error: 0.3934 - soft_acc: 0.7389 - val_loss: 0.5350 - val_mean_absolute_error: 0.5350 - val_soft_acc: 0.5857\n",
      "Epoch 467/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3624 - mean_absolute_error: 0.3624 - soft_acc: 0.7444 - val_loss: 0.5378 - val_mean_absolute_error: 0.5378 - val_soft_acc: 0.6271\n",
      "Epoch 468/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3529 - mean_absolute_error: 0.3529 - soft_acc: 0.7650 - val_loss: 0.5410 - val_mean_absolute_error: 0.5410 - val_soft_acc: 0.5914\n",
      "Epoch 469/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3885 - mean_absolute_error: 0.3885 - soft_acc: 0.7278 - val_loss: 0.5745 - val_mean_absolute_error: 0.5745 - val_soft_acc: 0.5271\n",
      "Epoch 470/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3794 - mean_absolute_error: 0.3794 - soft_acc: 0.6983 - val_loss: 0.7094 - val_mean_absolute_error: 0.7094 - val_soft_acc: 0.4800\n",
      "Epoch 471/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4365 - mean_absolute_error: 0.4365 - soft_acc: 0.6678 - val_loss: 0.5825 - val_mean_absolute_error: 0.5825 - val_soft_acc: 0.5071\n",
      "Epoch 472/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4487 - mean_absolute_error: 0.4487 - soft_acc: 0.6772 - val_loss: 0.5548 - val_mean_absolute_error: 0.5548 - val_soft_acc: 0.5864\n",
      "Epoch 473/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4756 - mean_absolute_error: 0.4756 - soft_acc: 0.6650 - val_loss: 0.5849 - val_mean_absolute_error: 0.5849 - val_soft_acc: 0.5279\n",
      "Epoch 474/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3665 - mean_absolute_error: 0.3665 - soft_acc: 0.7506 - val_loss: 0.7642 - val_mean_absolute_error: 0.7642 - val_soft_acc: 0.4214\n",
      "Epoch 475/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4827 - mean_absolute_error: 0.4827 - soft_acc: 0.6722 - val_loss: 0.6541 - val_mean_absolute_error: 0.6541 - val_soft_acc: 0.5300\n",
      "Epoch 476/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4024 - mean_absolute_error: 0.4024 - soft_acc: 0.7217 - val_loss: 0.5838 - val_mean_absolute_error: 0.5838 - val_soft_acc: 0.5786\n",
      "Epoch 477/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4833 - mean_absolute_error: 0.4833 - soft_acc: 0.6594 - val_loss: 0.5963 - val_mean_absolute_error: 0.5963 - val_soft_acc: 0.5229\n",
      "Epoch 478/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3745 - mean_absolute_error: 0.3745 - soft_acc: 0.7394 - val_loss: 0.5931 - val_mean_absolute_error: 0.5931 - val_soft_acc: 0.5421\n",
      "Epoch 479/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3463 - mean_absolute_error: 0.3463 - soft_acc: 0.7322 - val_loss: 0.5812 - val_mean_absolute_error: 0.5812 - val_soft_acc: 0.5279\n",
      "Epoch 480/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3757 - mean_absolute_error: 0.3757 - soft_acc: 0.7489 - val_loss: 0.6043 - val_mean_absolute_error: 0.6043 - val_soft_acc: 0.5964\n",
      "Epoch 481/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3587 - mean_absolute_error: 0.3587 - soft_acc: 0.7550 - val_loss: 0.5507 - val_mean_absolute_error: 0.5507 - val_soft_acc: 0.6171\n",
      "Epoch 482/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3478 - mean_absolute_error: 0.3478 - soft_acc: 0.7872 - val_loss: 0.6131 - val_mean_absolute_error: 0.6131 - val_soft_acc: 0.5786\n",
      "Epoch 483/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3353 - mean_absolute_error: 0.3353 - soft_acc: 0.7806 - val_loss: 0.6629 - val_mean_absolute_error: 0.6629 - val_soft_acc: 0.5357\n",
      "Epoch 484/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3384 - mean_absolute_error: 0.3384 - soft_acc: 0.7372 - val_loss: 0.5899 - val_mean_absolute_error: 0.5899 - val_soft_acc: 0.5457\n",
      "Epoch 485/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3788 - mean_absolute_error: 0.3788 - soft_acc: 0.7300 - val_loss: 0.6521 - val_mean_absolute_error: 0.6521 - val_soft_acc: 0.5836\n",
      "Epoch 486/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3591 - mean_absolute_error: 0.3591 - soft_acc: 0.7639 - val_loss: 0.6117 - val_mean_absolute_error: 0.6117 - val_soft_acc: 0.4943\n",
      "Epoch 487/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.6466 - mean_absolute_error: 0.6466 - soft_acc: 0.5511 - val_loss: 0.5938 - val_mean_absolute_error: 0.5938 - val_soft_acc: 0.4921\n",
      "Epoch 488/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.6615 - mean_absolute_error: 0.6615 - soft_acc: 0.5106 - val_loss: 0.5861 - val_mean_absolute_error: 0.5861 - val_soft_acc: 0.5636\n",
      "Epoch 489/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5306 - mean_absolute_error: 0.5306 - soft_acc: 0.6100 - val_loss: 0.6004 - val_mean_absolute_error: 0.6004 - val_soft_acc: 0.5436\n",
      "Epoch 490/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5017 - mean_absolute_error: 0.5017 - soft_acc: 0.6450 - val_loss: 0.8610 - val_mean_absolute_error: 0.8610 - val_soft_acc: 0.3707\n",
      "Epoch 491/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4819 - mean_absolute_error: 0.4819 - soft_acc: 0.6889 - val_loss: 0.8535 - val_mean_absolute_error: 0.8535 - val_soft_acc: 0.4221\n",
      "Epoch 492/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5057 - mean_absolute_error: 0.5057 - soft_acc: 0.6889 - val_loss: 0.6235 - val_mean_absolute_error: 0.6235 - val_soft_acc: 0.5629\n",
      "Epoch 493/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3939 - mean_absolute_error: 0.3939 - soft_acc: 0.6728 - val_loss: 0.6266 - val_mean_absolute_error: 0.6266 - val_soft_acc: 0.5607\n",
      "Epoch 494/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4402 - mean_absolute_error: 0.4402 - soft_acc: 0.7089 - val_loss: 0.6384 - val_mean_absolute_error: 0.6384 - val_soft_acc: 0.4286\n",
      "Epoch 495/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3909 - mean_absolute_error: 0.3909 - soft_acc: 0.6906 - val_loss: 0.5462 - val_mean_absolute_error: 0.5462 - val_soft_acc: 0.5400\n",
      "Epoch 496/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3474 - mean_absolute_error: 0.3474 - soft_acc: 0.7817 - val_loss: 0.7011 - val_mean_absolute_error: 0.7011 - val_soft_acc: 0.4643\n",
      "Epoch 497/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4504 - mean_absolute_error: 0.4504 - soft_acc: 0.6767 - val_loss: 0.6357 - val_mean_absolute_error: 0.6357 - val_soft_acc: 0.5307\n",
      "Epoch 498/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4196 - mean_absolute_error: 0.4196 - soft_acc: 0.6578 - val_loss: 0.6075 - val_mean_absolute_error: 0.6075 - val_soft_acc: 0.5507\n",
      "Epoch 499/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.6845 - mean_absolute_error: 0.6845 - soft_acc: 0.6172 - val_loss: 0.8160 - val_mean_absolute_error: 0.8160 - val_soft_acc: 0.3757\n",
      "Epoch 500/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.6075 - mean_absolute_error: 0.6075 - soft_acc: 0.5311 - val_loss: 0.7376 - val_mean_absolute_error: 0.7376 - val_soft_acc: 0.4036\n",
      "Epoch 501/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.4918 - mean_absolute_error: 0.4918 - soft_acc: 0.6156 - val_loss: 0.6888 - val_mean_absolute_error: 0.6888 - val_soft_acc: 0.4979\n",
      "Epoch 502/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4087 - mean_absolute_error: 0.4087 - soft_acc: 0.7200 - val_loss: 0.5626 - val_mean_absolute_error: 0.5626 - val_soft_acc: 0.5150\n",
      "Epoch 503/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4272 - mean_absolute_error: 0.4272 - soft_acc: 0.6878 - val_loss: 0.5465 - val_mean_absolute_error: 0.5465 - val_soft_acc: 0.6014\n",
      "Epoch 504/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3671 - mean_absolute_error: 0.3671 - soft_acc: 0.7289 - val_loss: 0.5334 - val_mean_absolute_error: 0.5334 - val_soft_acc: 0.5707\n",
      "Epoch 505/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3426 - mean_absolute_error: 0.3426 - soft_acc: 0.7517 - val_loss: 0.6918 - val_mean_absolute_error: 0.6918 - val_soft_acc: 0.4850\n",
      "Epoch 506/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4229 - mean_absolute_error: 0.4229 - soft_acc: 0.7206 - val_loss: 0.7599 - val_mean_absolute_error: 0.7599 - val_soft_acc: 0.3471\n",
      "Epoch 507/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5103 - mean_absolute_error: 0.5103 - soft_acc: 0.6817 - val_loss: 0.7399 - val_mean_absolute_error: 0.7399 - val_soft_acc: 0.4857\n",
      "Epoch 508/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4013 - mean_absolute_error: 0.4013 - soft_acc: 0.7222 - val_loss: 0.7000 - val_mean_absolute_error: 0.7000 - val_soft_acc: 0.5286\n",
      "Epoch 509/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4274 - mean_absolute_error: 0.4274 - soft_acc: 0.6967 - val_loss: 0.5231 - val_mean_absolute_error: 0.5231 - val_soft_acc: 0.5479\n",
      "Epoch 510/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4142 - mean_absolute_error: 0.4142 - soft_acc: 0.7089 - val_loss: 0.5512 - val_mean_absolute_error: 0.5512 - val_soft_acc: 0.4921\n",
      "Epoch 511/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3505 - mean_absolute_error: 0.3505 - soft_acc: 0.7722 - val_loss: 0.5584 - val_mean_absolute_error: 0.5584 - val_soft_acc: 0.5379\n",
      "Epoch 512/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3417 - mean_absolute_error: 0.3417 - soft_acc: 0.7411 - val_loss: 0.5783 - val_mean_absolute_error: 0.5783 - val_soft_acc: 0.5171\n",
      "Epoch 513/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3639 - mean_absolute_error: 0.3639 - soft_acc: 0.7467 - val_loss: 0.5979 - val_mean_absolute_error: 0.5979 - val_soft_acc: 0.5457\n",
      "Epoch 514/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4197 - mean_absolute_error: 0.4197 - soft_acc: 0.7156 - val_loss: 0.5976 - val_mean_absolute_error: 0.5976 - val_soft_acc: 0.5607\n",
      "Epoch 515/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4538 - mean_absolute_error: 0.4538 - soft_acc: 0.6828 - val_loss: 0.5858 - val_mean_absolute_error: 0.5858 - val_soft_acc: 0.5300\n",
      "Epoch 516/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3532 - mean_absolute_error: 0.3532 - soft_acc: 0.7444 - val_loss: 0.6091 - val_mean_absolute_error: 0.6091 - val_soft_acc: 0.5071\n",
      "Epoch 517/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3522 - mean_absolute_error: 0.3522 - soft_acc: 0.7722 - val_loss: 0.6631 - val_mean_absolute_error: 0.6631 - val_soft_acc: 0.4800\n",
      "Epoch 518/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3621 - mean_absolute_error: 0.3621 - soft_acc: 0.7556 - val_loss: 0.6924 - val_mean_absolute_error: 0.6924 - val_soft_acc: 0.3721\n",
      "Epoch 519/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4790 - mean_absolute_error: 0.4790 - soft_acc: 0.6511 - val_loss: 0.8070 - val_mean_absolute_error: 0.8070 - val_soft_acc: 0.3736\n",
      "Epoch 520/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.5242 - mean_absolute_error: 0.5242 - soft_acc: 0.6494 - val_loss: 0.6527 - val_mean_absolute_error: 0.6527 - val_soft_acc: 0.4721\n",
      "Epoch 521/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4441 - mean_absolute_error: 0.4441 - soft_acc: 0.7361 - val_loss: 0.6887 - val_mean_absolute_error: 0.6887 - val_soft_acc: 0.4650\n",
      "Epoch 522/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.4945 - mean_absolute_error: 0.4945 - soft_acc: 0.6411 - val_loss: 0.6652 - val_mean_absolute_error: 0.6652 - val_soft_acc: 0.4771\n",
      "Epoch 523/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5278 - mean_absolute_error: 0.5278 - soft_acc: 0.6450 - val_loss: 0.6115 - val_mean_absolute_error: 0.6115 - val_soft_acc: 0.5507\n",
      "Epoch 524/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4542 - mean_absolute_error: 0.4542 - soft_acc: 0.7078 - val_loss: 0.6391 - val_mean_absolute_error: 0.6391 - val_soft_acc: 0.5329\n",
      "Epoch 525/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4174 - mean_absolute_error: 0.4174 - soft_acc: 0.6450 - val_loss: 0.6885 - val_mean_absolute_error: 0.6885 - val_soft_acc: 0.4593\n",
      "Epoch 526/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4593 - mean_absolute_error: 0.4593 - soft_acc: 0.6161 - val_loss: 0.5776 - val_mean_absolute_error: 0.5776 - val_soft_acc: 0.5329\n",
      "Epoch 527/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4482 - mean_absolute_error: 0.4482 - soft_acc: 0.6600 - val_loss: 0.5237 - val_mean_absolute_error: 0.5237 - val_soft_acc: 0.5657\n",
      "Epoch 528/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3742 - mean_absolute_error: 0.3742 - soft_acc: 0.7522 - val_loss: 0.6019 - val_mean_absolute_error: 0.6019 - val_soft_acc: 0.4921\n",
      "Epoch 529/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4816 - mean_absolute_error: 0.4816 - soft_acc: 0.6617 - val_loss: 0.5667 - val_mean_absolute_error: 0.5667 - val_soft_acc: 0.5300\n",
      "Epoch 530/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4983 - mean_absolute_error: 0.4983 - soft_acc: 0.6006 - val_loss: 0.5567 - val_mean_absolute_error: 0.5567 - val_soft_acc: 0.5707\n",
      "Epoch 531/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.5076 - mean_absolute_error: 0.5076 - soft_acc: 0.5950 - val_loss: 0.5848 - val_mean_absolute_error: 0.5848 - val_soft_acc: 0.6064\n",
      "Epoch 532/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4370 - mean_absolute_error: 0.4370 - soft_acc: 0.6689 - val_loss: 0.7683 - val_mean_absolute_error: 0.7683 - val_soft_acc: 0.4214\n",
      "Epoch 533/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4584 - mean_absolute_error: 0.4584 - soft_acc: 0.6572 - val_loss: 0.7711 - val_mean_absolute_error: 0.7711 - val_soft_acc: 0.3886\n",
      "Epoch 534/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.5867 - mean_absolute_error: 0.5867 - soft_acc: 0.5556 - val_loss: 0.6829 - val_mean_absolute_error: 0.6829 - val_soft_acc: 0.5543\n",
      "Epoch 535/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5707 - mean_absolute_error: 0.5707 - soft_acc: 0.5828 - val_loss: 0.8252 - val_mean_absolute_error: 0.8252 - val_soft_acc: 0.4171\n",
      "Epoch 536/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.5869 - mean_absolute_error: 0.5869 - soft_acc: 0.5550 - val_loss: 0.6512 - val_mean_absolute_error: 0.6512 - val_soft_acc: 0.4157\n",
      "Epoch 537/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4845 - mean_absolute_error: 0.4845 - soft_acc: 0.6850 - val_loss: 0.5853 - val_mean_absolute_error: 0.5853 - val_soft_acc: 0.5121\n",
      "Epoch 538/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5375 - mean_absolute_error: 0.5375 - soft_acc: 0.6178 - val_loss: 0.8035 - val_mean_absolute_error: 0.8035 - val_soft_acc: 0.4164\n",
      "Epoch 539/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5842 - mean_absolute_error: 0.5842 - soft_acc: 0.6161 - val_loss: 0.8437 - val_mean_absolute_error: 0.8437 - val_soft_acc: 0.3686\n",
      "Epoch 540/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5171 - mean_absolute_error: 0.5171 - soft_acc: 0.6933 - val_loss: 0.5718 - val_mean_absolute_error: 0.5718 - val_soft_acc: 0.5171\n",
      "Epoch 541/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5331 - mean_absolute_error: 0.5331 - soft_acc: 0.6139 - val_loss: 0.6483 - val_mean_absolute_error: 0.6483 - val_soft_acc: 0.5150\n",
      "Epoch 542/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.8694 - mean_absolute_error: 0.8694 - soft_acc: 0.4633 - val_loss: 1.0744 - val_mean_absolute_error: 1.0744 - val_soft_acc: 0.2750\n",
      "Epoch 543/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 1.1677 - mean_absolute_error: 1.1677 - soft_acc: 0.4150 - val_loss: 1.0325 - val_mean_absolute_error: 1.0325 - val_soft_acc: 0.3336\n",
      "Epoch 544/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 1.3975 - mean_absolute_error: 1.3975 - soft_acc: 0.3550 - val_loss: 1.0031 - val_mean_absolute_error: 1.0031 - val_soft_acc: 0.3714\n",
      "Epoch 545/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 1.0096 - mean_absolute_error: 1.0096 - soft_acc: 0.4522 - val_loss: 0.9324 - val_mean_absolute_error: 0.9324 - val_soft_acc: 0.2679\n",
      "Epoch 546/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 1.3848 - mean_absolute_error: 1.3848 - soft_acc: 0.2828 - val_loss: 1.4067 - val_mean_absolute_error: 1.4067 - val_soft_acc: 0.2857\n",
      "Epoch 547/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.5928 - mean_absolute_error: 1.5928 - soft_acc: 0.3472 - val_loss: 1.7114 - val_mean_absolute_error: 1.7114 - val_soft_acc: 0.2293\n",
      "Epoch 548/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 1.4078 - mean_absolute_error: 1.4078 - soft_acc: 0.4072 - val_loss: 1.2590 - val_mean_absolute_error: 1.2590 - val_soft_acc: 0.2750\n",
      "Epoch 549/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.9111 - mean_absolute_error: 0.9111 - soft_acc: 0.4444 - val_loss: 1.0172 - val_mean_absolute_error: 1.0172 - val_soft_acc: 0.3407\n",
      "Epoch 550/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.8847 - mean_absolute_error: 0.8847 - soft_acc: 0.4828 - val_loss: 0.7572 - val_mean_absolute_error: 0.7572 - val_soft_acc: 0.4521\n",
      "Epoch 551/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.8172 - mean_absolute_error: 0.8172 - soft_acc: 0.5078 - val_loss: 0.8107 - val_mean_absolute_error: 0.8107 - val_soft_acc: 0.3129\n",
      "Epoch 552/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.7635 - mean_absolute_error: 0.7635 - soft_acc: 0.4844 - val_loss: 0.9140 - val_mean_absolute_error: 0.9140 - val_soft_acc: 0.3686\n",
      "Epoch 553/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.8739 - mean_absolute_error: 0.8739 - soft_acc: 0.4389 - val_loss: 0.8233 - val_mean_absolute_error: 0.8233 - val_soft_acc: 0.4300\n",
      "Epoch 554/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.7399 - mean_absolute_error: 0.7399 - soft_acc: 0.5406 - val_loss: 0.7844 - val_mean_absolute_error: 0.7844 - val_soft_acc: 0.3329\n",
      "Epoch 555/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.7890 - mean_absolute_error: 0.7890 - soft_acc: 0.4117 - val_loss: 0.7478 - val_mean_absolute_error: 0.7478 - val_soft_acc: 0.4529\n",
      "Epoch 556/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.8689 - mean_absolute_error: 0.8689 - soft_acc: 0.4717 - val_loss: 0.8371 - val_mean_absolute_error: 0.8371 - val_soft_acc: 0.3329\n",
      "Epoch 557/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.9536 - mean_absolute_error: 0.9536 - soft_acc: 0.3839 - val_loss: 0.7848 - val_mean_absolute_error: 0.7848 - val_soft_acc: 0.4250\n",
      "Epoch 558/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.7855 - mean_absolute_error: 0.7855 - soft_acc: 0.4689 - val_loss: 0.7603 - val_mean_absolute_error: 0.7603 - val_soft_acc: 0.3579\n",
      "Epoch 559/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4965 - mean_absolute_error: 0.4965 - soft_acc: 0.6250 - val_loss: 0.6525 - val_mean_absolute_error: 0.6525 - val_soft_acc: 0.4264\n",
      "Epoch 560/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.4463 - mean_absolute_error: 0.4463 - soft_acc: 0.6722 - val_loss: 0.6123 - val_mean_absolute_error: 0.6123 - val_soft_acc: 0.4950\n",
      "Epoch 561/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5564 - mean_absolute_error: 0.5564 - soft_acc: 0.6089 - val_loss: 0.5589 - val_mean_absolute_error: 0.5589 - val_soft_acc: 0.4871\n",
      "Epoch 562/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6199 - mean_absolute_error: 0.6199 - soft_acc: 0.5678 - val_loss: 0.6665 - val_mean_absolute_error: 0.6665 - val_soft_acc: 0.5279\n",
      "Epoch 563/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 1.1085 - mean_absolute_error: 1.1085 - soft_acc: 0.4661 - val_loss: 0.4965 - val_mean_absolute_error: 0.4965 - val_soft_acc: 0.5779\n",
      "Epoch 564/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.6475 - mean_absolute_error: 0.6475 - soft_acc: 0.5283 - val_loss: 0.5159 - val_mean_absolute_error: 0.5159 - val_soft_acc: 0.5629\n",
      "Epoch 565/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.6675 - mean_absolute_error: 0.6675 - soft_acc: 0.5544 - val_loss: 0.5256 - val_mean_absolute_error: 0.5256 - val_soft_acc: 0.5479\n",
      "Epoch 566/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.4467 - mean_absolute_error: 0.4467 - soft_acc: 0.6644 - val_loss: 0.5728 - val_mean_absolute_error: 0.5728 - val_soft_acc: 0.5479\n",
      "Epoch 567/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3955 - mean_absolute_error: 0.3955 - soft_acc: 0.7333 - val_loss: 0.4989 - val_mean_absolute_error: 0.4989 - val_soft_acc: 0.5343\n",
      "Epoch 568/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4936 - mean_absolute_error: 0.4936 - soft_acc: 0.6967 - val_loss: 0.5072 - val_mean_absolute_error: 0.5072 - val_soft_acc: 0.5807\n",
      "Epoch 569/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3680 - mean_absolute_error: 0.3680 - soft_acc: 0.7811 - val_loss: 0.4963 - val_mean_absolute_error: 0.4963 - val_soft_acc: 0.6007\n",
      "Epoch 570/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3596 - mean_absolute_error: 0.3596 - soft_acc: 0.7672 - val_loss: 0.5184 - val_mean_absolute_error: 0.5184 - val_soft_acc: 0.5579\n",
      "Epoch 571/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3688 - mean_absolute_error: 0.3688 - soft_acc: 0.7344 - val_loss: 0.5896 - val_mean_absolute_error: 0.5896 - val_soft_acc: 0.5300\n",
      "Epoch 572/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3894 - mean_absolute_error: 0.3894 - soft_acc: 0.7350 - val_loss: 0.6577 - val_mean_absolute_error: 0.6577 - val_soft_acc: 0.4543\n",
      "Epoch 573/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4239 - mean_absolute_error: 0.4239 - soft_acc: 0.6744 - val_loss: 0.5285 - val_mean_absolute_error: 0.5285 - val_soft_acc: 0.6221\n",
      "Epoch 574/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4395 - mean_absolute_error: 0.4395 - soft_acc: 0.6572 - val_loss: 0.5161 - val_mean_absolute_error: 0.5161 - val_soft_acc: 0.5600\n",
      "Epoch 575/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4487 - mean_absolute_error: 0.4487 - soft_acc: 0.6933 - val_loss: 0.5339 - val_mean_absolute_error: 0.5339 - val_soft_acc: 0.6014\n",
      "Epoch 576/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5231 - mean_absolute_error: 0.5231 - soft_acc: 0.6344 - val_loss: 0.5351 - val_mean_absolute_error: 0.5351 - val_soft_acc: 0.5586\n",
      "Epoch 577/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4920 - mean_absolute_error: 0.4920 - soft_acc: 0.6600 - val_loss: 0.5677 - val_mean_absolute_error: 0.5677 - val_soft_acc: 0.4764\n",
      "Epoch 578/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4647 - mean_absolute_error: 0.4647 - soft_acc: 0.6661 - val_loss: 0.5666 - val_mean_absolute_error: 0.5666 - val_soft_acc: 0.6093\n",
      "Epoch 579/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6867 - mean_absolute_error: 0.6867 - soft_acc: 0.5356 - val_loss: 0.7317 - val_mean_absolute_error: 0.7317 - val_soft_acc: 0.3350\n",
      "Epoch 580/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5958 - mean_absolute_error: 0.5958 - soft_acc: 0.4933 - val_loss: 0.5755 - val_mean_absolute_error: 0.5755 - val_soft_acc: 0.5843\n",
      "Epoch 581/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.4865 - mean_absolute_error: 0.4865 - soft_acc: 0.6661 - val_loss: 0.5776 - val_mean_absolute_error: 0.5776 - val_soft_acc: 0.5386\n",
      "Epoch 582/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4139 - mean_absolute_error: 0.4139 - soft_acc: 0.7133 - val_loss: 0.5276 - val_mean_absolute_error: 0.5276 - val_soft_acc: 0.6421\n",
      "Epoch 583/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4218 - mean_absolute_error: 0.4218 - soft_acc: 0.6900 - val_loss: 0.5100 - val_mean_absolute_error: 0.5100 - val_soft_acc: 0.6500\n",
      "Epoch 584/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4181 - mean_absolute_error: 0.4181 - soft_acc: 0.7128 - val_loss: 0.5998 - val_mean_absolute_error: 0.5998 - val_soft_acc: 0.5200\n",
      "Epoch 585/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4356 - mean_absolute_error: 0.4356 - soft_acc: 0.6644 - val_loss: 0.6418 - val_mean_absolute_error: 0.6418 - val_soft_acc: 0.5021\n",
      "Epoch 586/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4841 - mean_absolute_error: 0.4841 - soft_acc: 0.6844 - val_loss: 0.5394 - val_mean_absolute_error: 0.5394 - val_soft_acc: 0.5893\n",
      "Epoch 587/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4233 - mean_absolute_error: 0.4233 - soft_acc: 0.6928 - val_loss: 0.5653 - val_mean_absolute_error: 0.5653 - val_soft_acc: 0.6121\n",
      "Epoch 588/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4316 - mean_absolute_error: 0.4316 - soft_acc: 0.6861 - val_loss: 0.5321 - val_mean_absolute_error: 0.5321 - val_soft_acc: 0.6093\n",
      "Epoch 589/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3505 - mean_absolute_error: 0.3505 - soft_acc: 0.7428 - val_loss: 0.5570 - val_mean_absolute_error: 0.5570 - val_soft_acc: 0.5014\n",
      "Epoch 590/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3752 - mean_absolute_error: 0.3752 - soft_acc: 0.7483 - val_loss: 0.4895 - val_mean_absolute_error: 0.4895 - val_soft_acc: 0.5779\n",
      "Epoch 591/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3739 - mean_absolute_error: 0.3739 - soft_acc: 0.7767 - val_loss: 0.4942 - val_mean_absolute_error: 0.4942 - val_soft_acc: 0.6164\n",
      "Epoch 592/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4179 - mean_absolute_error: 0.4179 - soft_acc: 0.6967 - val_loss: 0.4766 - val_mean_absolute_error: 0.4766 - val_soft_acc: 0.5957\n",
      "Epoch 593/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4002 - mean_absolute_error: 0.4002 - soft_acc: 0.6856 - val_loss: 0.5013 - val_mean_absolute_error: 0.5013 - val_soft_acc: 0.5500\n",
      "Epoch 594/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3825 - mean_absolute_error: 0.3825 - soft_acc: 0.7311 - val_loss: 0.5574 - val_mean_absolute_error: 0.5574 - val_soft_acc: 0.5021\n",
      "Epoch 595/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3718 - mean_absolute_error: 0.3718 - soft_acc: 0.7778 - val_loss: 0.5632 - val_mean_absolute_error: 0.5632 - val_soft_acc: 0.5279\n",
      "Epoch 596/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4254 - mean_absolute_error: 0.4254 - soft_acc: 0.6706 - val_loss: 0.6170 - val_mean_absolute_error: 0.6170 - val_soft_acc: 0.5021\n",
      "Epoch 597/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5487 - mean_absolute_error: 0.5487 - soft_acc: 0.6217 - val_loss: 0.6455 - val_mean_absolute_error: 0.6455 - val_soft_acc: 0.4771\n",
      "Epoch 598/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4853 - mean_absolute_error: 0.4853 - soft_acc: 0.6372 - val_loss: 0.7188 - val_mean_absolute_error: 0.7188 - val_soft_acc: 0.4036\n",
      "Epoch 599/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.7034 - mean_absolute_error: 0.7034 - soft_acc: 0.5111 - val_loss: 0.5897 - val_mean_absolute_error: 0.5897 - val_soft_acc: 0.5429\n",
      "Epoch 600/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5605 - mean_absolute_error: 0.5605 - soft_acc: 0.6150 - val_loss: 0.6472 - val_mean_absolute_error: 0.6472 - val_soft_acc: 0.4814\n",
      "Epoch 601/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4372 - mean_absolute_error: 0.4372 - soft_acc: 0.6967 - val_loss: 0.9016 - val_mean_absolute_error: 0.9016 - val_soft_acc: 0.4371\n",
      "Epoch 602/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4940 - mean_absolute_error: 0.4940 - soft_acc: 0.6800 - val_loss: 0.7630 - val_mean_absolute_error: 0.7630 - val_soft_acc: 0.4321\n",
      "Epoch 603/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.5650 - mean_absolute_error: 0.5650 - soft_acc: 0.6161 - val_loss: 0.9307 - val_mean_absolute_error: 0.9307 - val_soft_acc: 0.4229\n",
      "Epoch 604/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.8668 - mean_absolute_error: 0.8668 - soft_acc: 0.4794 - val_loss: 0.5962 - val_mean_absolute_error: 0.5962 - val_soft_acc: 0.4464\n",
      "Epoch 605/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5683 - mean_absolute_error: 0.5683 - soft_acc: 0.5878 - val_loss: 0.5460 - val_mean_absolute_error: 0.5460 - val_soft_acc: 0.6043\n",
      "Epoch 606/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5544 - mean_absolute_error: 0.5544 - soft_acc: 0.5511 - val_loss: 0.5441 - val_mean_absolute_error: 0.5441 - val_soft_acc: 0.5657\n",
      "Epoch 607/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4798 - mean_absolute_error: 0.4798 - soft_acc: 0.6283 - val_loss: 0.5202 - val_mean_absolute_error: 0.5202 - val_soft_acc: 0.6014\n",
      "Epoch 608/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5062 - mean_absolute_error: 0.5062 - soft_acc: 0.6378 - val_loss: 0.5627 - val_mean_absolute_error: 0.5627 - val_soft_acc: 0.5607\n",
      "Epoch 609/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.6016 - mean_absolute_error: 0.6016 - soft_acc: 0.5989 - val_loss: 0.5434 - val_mean_absolute_error: 0.5434 - val_soft_acc: 0.5736\n",
      "Epoch 610/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4069 - mean_absolute_error: 0.4069 - soft_acc: 0.7389 - val_loss: 0.6037 - val_mean_absolute_error: 0.6037 - val_soft_acc: 0.5336\n",
      "Epoch 611/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.6319 - mean_absolute_error: 0.6319 - soft_acc: 0.5872 - val_loss: 0.5615 - val_mean_absolute_error: 0.5615 - val_soft_acc: 0.5507\n",
      "Epoch 612/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5326 - mean_absolute_error: 0.5326 - soft_acc: 0.6178 - val_loss: 0.7168 - val_mean_absolute_error: 0.7168 - val_soft_acc: 0.4114\n",
      "Epoch 613/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.7341 - mean_absolute_error: 0.7341 - soft_acc: 0.4167 - val_loss: 0.7202 - val_mean_absolute_error: 0.7202 - val_soft_acc: 0.5850\n",
      "Epoch 614/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.6748 - mean_absolute_error: 0.6748 - soft_acc: 0.5917 - val_loss: 0.6327 - val_mean_absolute_error: 0.6327 - val_soft_acc: 0.4750\n",
      "Epoch 615/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4740 - mean_absolute_error: 0.4740 - soft_acc: 0.6417 - val_loss: 0.6461 - val_mean_absolute_error: 0.6461 - val_soft_acc: 0.5229\n",
      "Epoch 616/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4247 - mean_absolute_error: 0.4247 - soft_acc: 0.6567 - val_loss: 0.6484 - val_mean_absolute_error: 0.6484 - val_soft_acc: 0.5436\n",
      "Epoch 617/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.5174 - mean_absolute_error: 0.5174 - soft_acc: 0.58 - 0s 24us/sample - loss: 0.4485 - mean_absolute_error: 0.4485 - soft_acc: 0.6861 - val_loss: 0.6060 - val_mean_absolute_error: 0.6060 - val_soft_acc: 0.4943\n",
      "Epoch 618/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3973 - mean_absolute_error: 0.3973 - soft_acc: 0.6783 - val_loss: 0.6553 - val_mean_absolute_error: 0.6553 - val_soft_acc: 0.5379\n",
      "Epoch 619/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3888 - mean_absolute_error: 0.3888 - soft_acc: 0.7272 - val_loss: 0.5919 - val_mean_absolute_error: 0.5919 - val_soft_acc: 0.4921\n",
      "Epoch 620/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5080 - mean_absolute_error: 0.5080 - soft_acc: 0.5811 - val_loss: 0.5869 - val_mean_absolute_error: 0.5869 - val_soft_acc: 0.5557\n",
      "Epoch 621/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4074 - mean_absolute_error: 0.4074 - soft_acc: 0.7044 - val_loss: 0.5792 - val_mean_absolute_error: 0.5792 - val_soft_acc: 0.5207\n",
      "Epoch 622/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4000 - mean_absolute_error: 0.4000 - soft_acc: 0.7344 - val_loss: 0.6178 - val_mean_absolute_error: 0.6178 - val_soft_acc: 0.4893\n",
      "Epoch 623/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3590 - mean_absolute_error: 0.3590 - soft_acc: 0.7478 - val_loss: 0.6105 - val_mean_absolute_error: 0.6105 - val_soft_acc: 0.5664\n",
      "Epoch 624/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3778 - mean_absolute_error: 0.3778 - soft_acc: 0.7011 - val_loss: 0.5860 - val_mean_absolute_error: 0.5860 - val_soft_acc: 0.4921\n",
      "Epoch 625/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3755 - mean_absolute_error: 0.3755 - soft_acc: 0.7333 - val_loss: 0.5942 - val_mean_absolute_error: 0.5942 - val_soft_acc: 0.5150\n",
      "Epoch 626/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3820 - mean_absolute_error: 0.3820 - soft_acc: 0.7228 - val_loss: 0.5422 - val_mean_absolute_error: 0.5422 - val_soft_acc: 0.5786\n",
      "Epoch 627/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5962 - mean_absolute_error: 0.5962 - soft_acc: 0.5022 - val_loss: 0.5937 - val_mean_absolute_error: 0.5937 - val_soft_acc: 0.5100\n",
      "Epoch 628/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.5436 - mean_absolute_error: 0.5436 - soft_acc: 0.5822 - val_loss: 0.7478 - val_mean_absolute_error: 0.7478 - val_soft_acc: 0.4164\n",
      "Epoch 629/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5102 - mean_absolute_error: 0.5102 - soft_acc: 0.6161 - val_loss: 0.6233 - val_mean_absolute_error: 0.6233 - val_soft_acc: 0.4950\n",
      "Epoch 630/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4779 - mean_absolute_error: 0.4779 - soft_acc: 0.6750 - val_loss: 0.5140 - val_mean_absolute_error: 0.5140 - val_soft_acc: 0.5529\n",
      "Epoch 631/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3877 - mean_absolute_error: 0.3877 - soft_acc: 0.7000 - val_loss: 0.5070 - val_mean_absolute_error: 0.5070 - val_soft_acc: 0.5557\n",
      "Epoch 632/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3735 - mean_absolute_error: 0.3735 - soft_acc: 0.7111 - val_loss: 0.5043 - val_mean_absolute_error: 0.5043 - val_soft_acc: 0.5736\n",
      "Epoch 633/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3865 - mean_absolute_error: 0.3865 - soft_acc: 0.7328 - val_loss: 0.5426 - val_mean_absolute_error: 0.5426 - val_soft_acc: 0.5329\n",
      "Epoch 634/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4010 - mean_absolute_error: 0.4010 - soft_acc: 0.7117 - val_loss: 0.5563 - val_mean_absolute_error: 0.5563 - val_soft_acc: 0.5507\n",
      "Epoch 635/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3696 - mean_absolute_error: 0.3696 - soft_acc: 0.7600 - val_loss: 0.5636 - val_mean_absolute_error: 0.5636 - val_soft_acc: 0.5814\n",
      "Epoch 636/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3569 - mean_absolute_error: 0.3569 - soft_acc: 0.7811 - val_loss: 0.5222 - val_mean_absolute_error: 0.5222 - val_soft_acc: 0.5043\n",
      "Epoch 637/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.5023 - mean_absolute_error: 0.5023 - soft_acc: 0.6706 - val_loss: 0.5558 - val_mean_absolute_error: 0.5558 - val_soft_acc: 0.5407\n",
      "Epoch 638/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4385 - mean_absolute_error: 0.4385 - soft_acc: 0.7172 - val_loss: 0.6421 - val_mean_absolute_error: 0.6421 - val_soft_acc: 0.5050\n",
      "Epoch 639/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3568 - mean_absolute_error: 0.3568 - soft_acc: 0.7622 - val_loss: 0.6039 - val_mean_absolute_error: 0.6039 - val_soft_acc: 0.5150\n",
      "Epoch 640/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4269 - mean_absolute_error: 0.4269 - soft_acc: 0.6978 - val_loss: 0.6697 - val_mean_absolute_error: 0.6697 - val_soft_acc: 0.4979\n",
      "Epoch 641/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4530 - mean_absolute_error: 0.4530 - soft_acc: 0.6867 - val_loss: 0.5828 - val_mean_absolute_error: 0.5828 - val_soft_acc: 0.4743\n",
      "Epoch 642/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3572 - mean_absolute_error: 0.3572 - soft_acc: 0.7528 - val_loss: 0.5346 - val_mean_absolute_error: 0.5346 - val_soft_acc: 0.5836\n",
      "Epoch 643/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3888 - mean_absolute_error: 0.3888 - soft_acc: 0.7233 - val_loss: 0.5786 - val_mean_absolute_error: 0.5786 - val_soft_acc: 0.5329\n",
      "Epoch 644/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4287 - mean_absolute_error: 0.4287 - soft_acc: 0.7122 - val_loss: 0.5368 - val_mean_absolute_error: 0.5368 - val_soft_acc: 0.6064\n",
      "Epoch 645/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3986 - mean_absolute_error: 0.3986 - soft_acc: 0.7339 - val_loss: 0.6058 - val_mean_absolute_error: 0.6058 - val_soft_acc: 0.4764\n",
      "Epoch 646/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3815 - mean_absolute_error: 0.3815 - soft_acc: 0.7161 - val_loss: 0.5480 - val_mean_absolute_error: 0.5480 - val_soft_acc: 0.4914\n",
      "Epoch 647/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3582 - mean_absolute_error: 0.3582 - soft_acc: 0.7978 - val_loss: 0.5448 - val_mean_absolute_error: 0.5448 - val_soft_acc: 0.5557\n",
      "Epoch 648/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4039 - mean_absolute_error: 0.4039 - soft_acc: 0.7400 - val_loss: 0.5843 - val_mean_absolute_error: 0.5843 - val_soft_acc: 0.5636\n",
      "Epoch 649/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4148 - mean_absolute_error: 0.4148 - soft_acc: 0.6844 - val_loss: 0.5624 - val_mean_absolute_error: 0.5624 - val_soft_acc: 0.5507\n",
      "Epoch 650/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3799 - mean_absolute_error: 0.3799 - soft_acc: 0.7711 - val_loss: 0.5558 - val_mean_absolute_error: 0.5558 - val_soft_acc: 0.5350\n",
      "Epoch 651/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.4159 - mean_absolute_error: 0.4159 - soft_acc: 0.6922 - val_loss: 0.5602 - val_mean_absolute_error: 0.5602 - val_soft_acc: 0.5836\n",
      "Epoch 652/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4547 - mean_absolute_error: 0.4547 - soft_acc: 0.6878 - val_loss: 0.6451 - val_mean_absolute_error: 0.6451 - val_soft_acc: 0.5564\n",
      "Epoch 653/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3944 - mean_absolute_error: 0.3944 - soft_acc: 0.7333 - val_loss: 0.5417 - val_mean_absolute_error: 0.5417 - val_soft_acc: 0.5679\n",
      "Epoch 654/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3596 - mean_absolute_error: 0.3596 - soft_acc: 0.76 - 0s 38us/sample - loss: 0.4311 - mean_absolute_error: 0.4311 - soft_acc: 0.7222 - val_loss: 0.7388 - val_mean_absolute_error: 0.7388 - val_soft_acc: 0.4500\n",
      "Epoch 655/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.6038 - mean_absolute_error: 0.6038 - soft_acc: 0.5400 - val_loss: 0.9203 - val_mean_absolute_error: 0.9203 - val_soft_acc: 0.3843\n",
      "Epoch 656/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.8066 - mean_absolute_error: 0.8066 - soft_acc: 0.4172 - val_loss: 0.5342 - val_mean_absolute_error: 0.5342 - val_soft_acc: 0.5936\n",
      "Epoch 657/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5538 - mean_absolute_error: 0.5538 - soft_acc: 0.6239 - val_loss: 0.6534 - val_mean_absolute_error: 0.6534 - val_soft_acc: 0.4950\n",
      "Epoch 658/3000\n",
      "512/512 [==============================] - 0s 10us/sample - loss: 0.4732 - mean_absolute_error: 0.4732 - soft_acc: 0.6600 - val_loss: 0.5605 - val_mean_absolute_error: 0.5605 - val_soft_acc: 0.5529\n",
      "Epoch 659/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4299 - mean_absolute_error: 0.4299 - soft_acc: 0.6433 - val_loss: 0.5448 - val_mean_absolute_error: 0.5448 - val_soft_acc: 0.5529\n",
      "Epoch 660/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4280 - mean_absolute_error: 0.4280 - soft_acc: 0.7172 - val_loss: 0.5797 - val_mean_absolute_error: 0.5797 - val_soft_acc: 0.5157\n",
      "Epoch 661/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3808 - mean_absolute_error: 0.3808 - soft_acc: 0.7472 - val_loss: 0.6248 - val_mean_absolute_error: 0.6248 - val_soft_acc: 0.5229\n",
      "Epoch 662/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4490 - mean_absolute_error: 0.4490 - soft_acc: 0.6778 - val_loss: 0.5165 - val_mean_absolute_error: 0.5165 - val_soft_acc: 0.6143\n",
      "Epoch 663/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5222 - mean_absolute_error: 0.5222 - soft_acc: 0.6328 - val_loss: 3.1884 - val_mean_absolute_error: 3.1884 - val_soft_acc: 0.2936\n",
      "Epoch 664/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 2.4489 - mean_absolute_error: 2.4489 - soft_acc: 0.3494 - val_loss: 0.6821 - val_mean_absolute_error: 0.6821 - val_soft_acc: 0.4643\n",
      "Epoch 665/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.8323 - mean_absolute_error: 0.8323 - soft_acc: 0.4506 - val_loss: 0.6985 - val_mean_absolute_error: 0.6985 - val_soft_acc: 0.5464\n",
      "Epoch 666/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.9356 - mean_absolute_error: 0.9356 - soft_acc: 0.4622 - val_loss: 1.4457 - val_mean_absolute_error: 1.4457 - val_soft_acc: 0.1664\n",
      "Epoch 667/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 2.1286 - mean_absolute_error: 2.1286 - soft_acc: 0.2211 - val_loss: 2.0486 - val_mean_absolute_error: 2.0486 - val_soft_acc: 0.1214\n",
      "Epoch 668/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 2.8354 - mean_absolute_error: 2.8354 - soft_acc: 0.1822 - val_loss: 1.7590 - val_mean_absolute_error: 1.7590 - val_soft_acc: 0.2329\n",
      "Epoch 669/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 2.3657 - mean_absolute_error: 2.3657 - soft_acc: 0.2906 - val_loss: 0.9643 - val_mean_absolute_error: 0.9643 - val_soft_acc: 0.3129\n",
      "Epoch 670/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 1.1688 - mean_absolute_error: 1.1688 - soft_acc: 0.3856 - val_loss: 0.6701 - val_mean_absolute_error: 0.6701 - val_soft_acc: 0.4057\n",
      "Epoch 671/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.7446 - mean_absolute_error: 0.7446 - soft_acc: 0.5211 - val_loss: 0.5423 - val_mean_absolute_error: 0.5423 - val_soft_acc: 0.5450\n",
      "Epoch 672/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6240 - mean_absolute_error: 0.6240 - soft_acc: 0.5511 - val_loss: 0.4665 - val_mean_absolute_error: 0.4665 - val_soft_acc: 0.6721\n",
      "Epoch 673/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4680 - mean_absolute_error: 0.4680 - soft_acc: 0.6767 - val_loss: 0.4793 - val_mean_absolute_error: 0.4793 - val_soft_acc: 0.6029\n",
      "Epoch 674/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4370 - mean_absolute_error: 0.4370 - soft_acc: 0.6739 - val_loss: 0.6069 - val_mean_absolute_error: 0.6069 - val_soft_acc: 0.5529\n",
      "Epoch 675/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4888 - mean_absolute_error: 0.4888 - soft_acc: 0.6406 - val_loss: 0.6198 - val_mean_absolute_error: 0.6198 - val_soft_acc: 0.5586\n",
      "Epoch 676/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4558 - mean_absolute_error: 0.4558 - soft_acc: 0.6833 - val_loss: 0.4968 - val_mean_absolute_error: 0.4968 - val_soft_acc: 0.6500\n",
      "Epoch 677/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4008 - mean_absolute_error: 0.4008 - soft_acc: 0.6967 - val_loss: 0.4443 - val_mean_absolute_error: 0.4443 - val_soft_acc: 0.6564\n",
      "Epoch 678/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3610 - mean_absolute_error: 0.3610 - soft_acc: 0.7672 - val_loss: 0.4394 - val_mean_absolute_error: 0.4394 - val_soft_acc: 0.6771\n",
      "Epoch 679/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3786 - mean_absolute_error: 0.3786 - soft_acc: 0.7161 - val_loss: 0.4386 - val_mean_absolute_error: 0.4386 - val_soft_acc: 0.6136\n",
      "Epoch 680/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3978 - mean_absolute_error: 0.3978 - soft_acc: 0.7406 - val_loss: 0.4352 - val_mean_absolute_error: 0.4352 - val_soft_acc: 0.6693\n",
      "Epoch 681/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3853 - mean_absolute_error: 0.3853 - soft_acc: 0.7083 - val_loss: 0.6689 - val_mean_absolute_error: 0.6689 - val_soft_acc: 0.5186\n",
      "Epoch 682/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.7287 - mean_absolute_error: 0.7287 - soft_acc: 0.5567 - val_loss: 0.7528 - val_mean_absolute_error: 0.7528 - val_soft_acc: 0.4021\n",
      "Epoch 683/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.7690 - mean_absolute_error: 0.7690 - soft_acc: 0.4656 - val_loss: 0.5750 - val_mean_absolute_error: 0.5750 - val_soft_acc: 0.5964\n",
      "Epoch 684/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5849 - mean_absolute_error: 0.5849 - soft_acc: 0.5883 - val_loss: 0.6327 - val_mean_absolute_error: 0.6327 - val_soft_acc: 0.5000\n",
      "Epoch 685/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7528 - mean_absolute_error: 0.7528 - soft_acc: 0.5489 - val_loss: 0.5217 - val_mean_absolute_error: 0.5217 - val_soft_acc: 0.6414\n",
      "Epoch 686/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5928 - mean_absolute_error: 0.5928 - soft_acc: 0.5950 - val_loss: 0.4824 - val_mean_absolute_error: 0.4824 - val_soft_acc: 0.5829\n",
      "Epoch 687/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4152 - mean_absolute_error: 0.4152 - soft_acc: 0.6911 - val_loss: 0.6745 - val_mean_absolute_error: 0.6745 - val_soft_acc: 0.4850\n",
      "Epoch 688/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6342 - mean_absolute_error: 0.6342 - soft_acc: 0.5756 - val_loss: 0.4527 - val_mean_absolute_error: 0.4527 - val_soft_acc: 0.6750\n",
      "Epoch 689/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4843 - mean_absolute_error: 0.4843 - soft_acc: 0.6444 - val_loss: 0.4481 - val_mean_absolute_error: 0.4481 - val_soft_acc: 0.6793\n",
      "Epoch 690/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3890 - mean_absolute_error: 0.3890 - soft_acc: 0.7006 - val_loss: 0.5267 - val_mean_absolute_error: 0.5267 - val_soft_acc: 0.5600\n",
      "Epoch 691/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4959 - mean_absolute_error: 0.4959 - soft_acc: 0.6139 - val_loss: 0.4640 - val_mean_absolute_error: 0.4640 - val_soft_acc: 0.6414\n",
      "Epoch 692/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.5097 - mean_absolute_error: 0.5097 - soft_acc: 0.5933 - val_loss: 0.4969 - val_mean_absolute_error: 0.4969 - val_soft_acc: 0.6543\n",
      "Epoch 693/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5868 - mean_absolute_error: 0.5868 - soft_acc: 0.6328 - val_loss: 0.4688 - val_mean_absolute_error: 0.4688 - val_soft_acc: 0.6279\n",
      "Epoch 694/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4449 - mean_absolute_error: 0.4449 - soft_acc: 0.6661 - val_loss: 0.4359 - val_mean_absolute_error: 0.4359 - val_soft_acc: 0.6871\n",
      "Epoch 695/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3977 - mean_absolute_error: 0.3977 - soft_acc: 0.7117 - val_loss: 0.4832 - val_mean_absolute_error: 0.4832 - val_soft_acc: 0.5957\n",
      "Epoch 696/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.5274 - mean_absolute_error: 0.5274 - soft_acc: 0.6372 - val_loss: 0.4814 - val_mean_absolute_error: 0.4814 - val_soft_acc: 0.6214\n",
      "Epoch 697/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.5390 - mean_absolute_error: 0.5390 - soft_acc: 0.6167 - val_loss: 0.5769 - val_mean_absolute_error: 0.5769 - val_soft_acc: 0.5807\n",
      "Epoch 698/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.7926 - mean_absolute_error: 0.7926 - soft_acc: 0.4294 - val_loss: 0.6959 - val_mean_absolute_error: 0.6959 - val_soft_acc: 0.3907\n",
      "Epoch 699/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7144 - mean_absolute_error: 0.7144 - soft_acc: 0.5167 - val_loss: 0.5892 - val_mean_absolute_error: 0.5892 - val_soft_acc: 0.5050\n",
      "Epoch 700/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.6605 - mean_absolute_error: 0.6605 - soft_acc: 0.5439 - val_loss: 0.5547 - val_mean_absolute_error: 0.5547 - val_soft_acc: 0.6036\n",
      "Epoch 701/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.6058 - mean_absolute_error: 0.6058 - soft_acc: 0.5017 - val_loss: 0.5022 - val_mean_absolute_error: 0.5022 - val_soft_acc: 0.6186\n",
      "Epoch 702/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4939 - mean_absolute_error: 0.4939 - soft_acc: 0.6528 - val_loss: 0.5294 - val_mean_absolute_error: 0.5294 - val_soft_acc: 0.6114\n",
      "Epoch 703/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4635 - mean_absolute_error: 0.4635 - soft_acc: 0.6317 - val_loss: 0.4682 - val_mean_absolute_error: 0.4682 - val_soft_acc: 0.6514\n",
      "Epoch 704/3000\n",
      "512/512 [==============================] - 0s 60us/sample - loss: 0.4382 - mean_absolute_error: 0.4382 - soft_acc: 0.6694 - val_loss: 0.4834 - val_mean_absolute_error: 0.4834 - val_soft_acc: 0.6364\n",
      "Epoch 705/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4107 - mean_absolute_error: 0.4107 - soft_acc: 0.6983 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732 - val_soft_acc: 0.6207\n",
      "Epoch 706/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3909 - mean_absolute_error: 0.3909 - soft_acc: 0.7183 - val_loss: 0.4462 - val_mean_absolute_error: 0.4462 - val_soft_acc: 0.6979\n",
      "Epoch 707/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3408 - mean_absolute_error: 0.3408 - soft_acc: 0.7389 - val_loss: 0.4927 - val_mean_absolute_error: 0.4927 - val_soft_acc: 0.6264\n",
      "Epoch 708/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4555 - mean_absolute_error: 0.4555 - soft_acc: 0.6467 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.6214\n",
      "Epoch 709/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4349 - mean_absolute_error: 0.4349 - soft_acc: 0.6900 - val_loss: 0.5825 - val_mean_absolute_error: 0.5825 - val_soft_acc: 0.5429\n",
      "Epoch 710/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4704 - mean_absolute_error: 0.4704 - soft_acc: 0.6767 - val_loss: 0.6229 - val_mean_absolute_error: 0.6229 - val_soft_acc: 0.5100\n",
      "Epoch 711/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.6182 - mean_absolute_error: 0.6182 - soft_acc: 0.5344 - val_loss: 0.5540 - val_mean_absolute_error: 0.5540 - val_soft_acc: 0.5507\n",
      "Epoch 712/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4835 - mean_absolute_error: 0.4835 - soft_acc: 0.6667 - val_loss: 0.5490 - val_mean_absolute_error: 0.5490 - val_soft_acc: 0.5229\n",
      "Epoch 713/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5796 - mean_absolute_error: 0.5796 - soft_acc: 0.5694 - val_loss: 0.5451 - val_mean_absolute_error: 0.5451 - val_soft_acc: 0.5479\n",
      "Epoch 714/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4976 - mean_absolute_error: 0.4976 - soft_acc: 0.6583 - val_loss: 0.5924 - val_mean_absolute_error: 0.5924 - val_soft_acc: 0.5379\n",
      "Epoch 715/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5201 - mean_absolute_error: 0.5201 - soft_acc: 0.6311 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827 - val_soft_acc: 0.6036\n",
      "Epoch 716/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.4306 - mean_absolute_error: 0.4306 - soft_acc: 0.6828 - val_loss: 0.5182 - val_mean_absolute_error: 0.5182 - val_soft_acc: 0.6214\n",
      "Epoch 717/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4300 - mean_absolute_error: 0.4300 - soft_acc: 0.7156 - val_loss: 0.4968 - val_mean_absolute_error: 0.4968 - val_soft_acc: 0.5729\n",
      "Epoch 718/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4077 - mean_absolute_error: 0.4077 - soft_acc: 0.6822 - val_loss: 0.5751 - val_mean_absolute_error: 0.5751 - val_soft_acc: 0.5093\n",
      "Epoch 719/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3908 - mean_absolute_error: 0.3908 - soft_acc: 0.7267 - val_loss: 0.5987 - val_mean_absolute_error: 0.5987 - val_soft_acc: 0.5864\n",
      "Epoch 720/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3820 - mean_absolute_error: 0.3820 - soft_acc: 0.6922 - val_loss: 0.5530 - val_mean_absolute_error: 0.5530 - val_soft_acc: 0.5479\n",
      "Epoch 721/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3844 - mean_absolute_error: 0.3844 - soft_acc: 0.7333 - val_loss: 0.5196 - val_mean_absolute_error: 0.5196 - val_soft_acc: 0.5550\n",
      "Epoch 722/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3284 - mean_absolute_error: 0.3284 - soft_acc: 0.7700 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.5957\n",
      "Epoch 723/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3556 - mean_absolute_error: 0.3556 - soft_acc: 0.7361 - val_loss: 0.4754 - val_mean_absolute_error: 0.4754 - val_soft_acc: 0.6086\n",
      "Epoch 724/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3826 - mean_absolute_error: 0.3826 - soft_acc: 0.7122 - val_loss: 0.5215 - val_mean_absolute_error: 0.5215 - val_soft_acc: 0.5957\n",
      "Epoch 725/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3556 - mean_absolute_error: 0.3556 - soft_acc: 0.7828 - val_loss: 0.5561 - val_mean_absolute_error: 0.5561 - val_soft_acc: 0.5836\n",
      "Epoch 726/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3732 - mean_absolute_error: 0.3732 - soft_acc: 0.7228 - val_loss: 0.5013 - val_mean_absolute_error: 0.5013 - val_soft_acc: 0.5857\n",
      "Epoch 727/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3422 - mean_absolute_error: 0.3422 - soft_acc: 0.7272 - val_loss: 0.4878 - val_mean_absolute_error: 0.4878 - val_soft_acc: 0.6086\n",
      "Epoch 728/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3366 - mean_absolute_error: 0.3366 - soft_acc: 0.7089 - val_loss: 0.4961 - val_mean_absolute_error: 0.4961 - val_soft_acc: 0.6086\n",
      "Epoch 729/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3374 - mean_absolute_error: 0.3374 - soft_acc: 0.8033 - val_loss: 0.5359 - val_mean_absolute_error: 0.5359 - val_soft_acc: 0.6014\n",
      "Epoch 730/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3442 - mean_absolute_error: 0.3442 - soft_acc: 0.7839 - val_loss: 0.5094 - val_mean_absolute_error: 0.5094 - val_soft_acc: 0.6064\n",
      "Epoch 731/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3518 - mean_absolute_error: 0.3518 - soft_acc: 0.7611 - val_loss: 0.4972 - val_mean_absolute_error: 0.4972 - val_soft_acc: 0.5986\n",
      "Epoch 732/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3729 - mean_absolute_error: 0.3729 - soft_acc: 0.7522 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732 - val_soft_acc: 0.6850\n",
      "Epoch 733/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4012 - mean_absolute_error: 0.4012 - soft_acc: 0.6733 - val_loss: 0.5242 - val_mean_absolute_error: 0.5242 - val_soft_acc: 0.6700\n",
      "Epoch 734/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4994 - mean_absolute_error: 0.4994 - soft_acc: 0.6217 - val_loss: 0.5077 - val_mean_absolute_error: 0.5077 - val_soft_acc: 0.5679\n",
      "Epoch 735/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4308 - mean_absolute_error: 0.4308 - soft_acc: 0.6422 - val_loss: 0.6453 - val_mean_absolute_error: 0.6453 - val_soft_acc: 0.4771\n",
      "Epoch 736/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4165 - mean_absolute_error: 0.4165 - soft_acc: 0.6889 - val_loss: 0.6259 - val_mean_absolute_error: 0.6259 - val_soft_acc: 0.5179\n",
      "Epoch 737/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4928 - mean_absolute_error: 0.4928 - soft_acc: 0.5794 - val_loss: 0.5527 - val_mean_absolute_error: 0.5527 - val_soft_acc: 0.5964\n",
      "Epoch 738/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4888 - mean_absolute_error: 0.4888 - soft_acc: 0.6494 - val_loss: 0.5110 - val_mean_absolute_error: 0.5110 - val_soft_acc: 0.6086\n",
      "Epoch 739/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4364 - mean_absolute_error: 0.4364 - soft_acc: 0.6828 - val_loss: 0.5237 - val_mean_absolute_error: 0.5237 - val_soft_acc: 0.5600\n",
      "Epoch 740/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4067 - mean_absolute_error: 0.4067 - soft_acc: 0.7183 - val_loss: 0.5262 - val_mean_absolute_error: 0.5262 - val_soft_acc: 0.5421\n",
      "Epoch 741/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3651 - mean_absolute_error: 0.3651 - soft_acc: 0.7794 - val_loss: 0.5945 - val_mean_absolute_error: 0.5945 - val_soft_acc: 0.5764\n",
      "Epoch 742/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3684 - mean_absolute_error: 0.3684 - soft_acc: 0.7206 - val_loss: 0.5899 - val_mean_absolute_error: 0.5899 - val_soft_acc: 0.5743\n",
      "Epoch 743/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.4244 - mean_absolute_error: 0.4244 - soft_acc: 0.6828 - val_loss: 0.5386 - val_mean_absolute_error: 0.5386 - val_soft_acc: 0.5271\n",
      "Epoch 744/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3988 - mean_absolute_error: 0.3988 - soft_acc: 0.7267 - val_loss: 0.4852 - val_mean_absolute_error: 0.4852 - val_soft_acc: 0.5936\n",
      "Epoch 745/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3984 - mean_absolute_error: 0.3984 - soft_acc: 0.7206 - val_loss: 0.5068 - val_mean_absolute_error: 0.5068 - val_soft_acc: 0.5807\n",
      "Epoch 746/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3615 - mean_absolute_error: 0.3615 - soft_acc: 0.7400 - val_loss: 0.5197 - val_mean_absolute_error: 0.5197 - val_soft_acc: 0.5707\n",
      "Epoch 747/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3344 - mean_absolute_error: 0.3344 - soft_acc: 0.7889 - val_loss: 0.4998 - val_mean_absolute_error: 0.4998 - val_soft_acc: 0.6143\n",
      "Epoch 748/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4100 - mean_absolute_error: 0.4100 - soft_acc: 0.6906 - val_loss: 0.4885 - val_mean_absolute_error: 0.4885 - val_soft_acc: 0.5729\n",
      "Epoch 749/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4055 - mean_absolute_error: 0.4055 - soft_acc: 0.7467 - val_loss: 0.5552 - val_mean_absolute_error: 0.5552 - val_soft_acc: 0.6550\n",
      "Epoch 750/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.4333 - mean_absolute_error: 0.4333 - soft_acc: 0.7267 - val_loss: 0.4977 - val_mean_absolute_error: 0.4977 - val_soft_acc: 0.6036\n",
      "Epoch 751/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3386 - mean_absolute_error: 0.3386 - soft_acc: 0.8044 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.5629\n",
      "Epoch 752/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3390 - mean_absolute_error: 0.3390 - soft_acc: 0.7428 - val_loss: 0.4656 - val_mean_absolute_error: 0.4656 - val_soft_acc: 0.5957\n",
      "Epoch 753/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.7806 - val_loss: 0.5043 - val_mean_absolute_error: 0.5043 - val_soft_acc: 0.5679\n",
      "Epoch 754/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4071 - mean_absolute_error: 0.4071 - soft_acc: 0.7078 - val_loss: 0.4917 - val_mean_absolute_error: 0.4917 - val_soft_acc: 0.6600\n",
      "Epoch 755/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3839 - mean_absolute_error: 0.3839 - soft_acc: 0.6933 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.6164\n",
      "Epoch 756/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3563 - mean_absolute_error: 0.3563 - soft_acc: 0.7944 - val_loss: 0.4993 - val_mean_absolute_error: 0.4993 - val_soft_acc: 0.5557\n",
      "Epoch 757/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3336 - mean_absolute_error: 0.3336 - soft_acc: 0.7939 - val_loss: 0.5305 - val_mean_absolute_error: 0.5305 - val_soft_acc: 0.5321\n",
      "Epoch 758/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3555 - mean_absolute_error: 0.3555 - soft_acc: 0.7450 - val_loss: 0.5647 - val_mean_absolute_error: 0.5647 - val_soft_acc: 0.4329\n",
      "Epoch 759/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3438 - mean_absolute_error: 0.3438 - soft_acc: 0.7656 - val_loss: 0.5631 - val_mean_absolute_error: 0.5631 - val_soft_acc: 0.5507\n",
      "Epoch 760/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3312 - mean_absolute_error: 0.3312 - soft_acc: 0.7372 - val_loss: 0.5704 - val_mean_absolute_error: 0.5704 - val_soft_acc: 0.5507\n",
      "Epoch 761/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4174 - mean_absolute_error: 0.4174 - soft_acc: 0.7278 - val_loss: 0.5327 - val_mean_absolute_error: 0.5327 - val_soft_acc: 0.5200\n",
      "Epoch 762/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4004 - mean_absolute_error: 0.4004 - soft_acc: 0.7389 - val_loss: 0.4981 - val_mean_absolute_error: 0.4981 - val_soft_acc: 0.6043\n",
      "Epoch 763/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3811 - mean_absolute_error: 0.3811 - soft_acc: 0.6889 - val_loss: 0.5032 - val_mean_absolute_error: 0.5032 - val_soft_acc: 0.5550\n",
      "Epoch 764/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3117 - mean_absolute_error: 0.3117 - soft_acc: 0.8144 - val_loss: 0.4912 - val_mean_absolute_error: 0.4912 - val_soft_acc: 0.5779\n",
      "Epoch 765/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3163 - mean_absolute_error: 0.3163 - soft_acc: 0.7900 - val_loss: 0.5021 - val_mean_absolute_error: 0.5021 - val_soft_acc: 0.5986\n",
      "Epoch 766/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3984 - mean_absolute_error: 0.3984 - soft_acc: 0.7061 - val_loss: 0.5287 - val_mean_absolute_error: 0.5287 - val_soft_acc: 0.6086\n",
      "Epoch 767/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4022 - mean_absolute_error: 0.4022 - soft_acc: 0.7128 - val_loss: 0.4988 - val_mean_absolute_error: 0.4988 - val_soft_acc: 0.6343\n",
      "Epoch 768/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4460 - mean_absolute_error: 0.4460 - soft_acc: 0.7044 - val_loss: 0.5013 - val_mean_absolute_error: 0.5013 - val_soft_acc: 0.6036\n",
      "Epoch 769/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3708 - mean_absolute_error: 0.3708 - soft_acc: 0.7589 - val_loss: 0.5203 - val_mean_absolute_error: 0.5203 - val_soft_acc: 0.5400\n",
      "Epoch 770/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3970 - mean_absolute_error: 0.3970 - soft_acc: 0.7489 - val_loss: 0.5059 - val_mean_absolute_error: 0.5059 - val_soft_acc: 0.5857\n",
      "Epoch 771/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3383 - mean_absolute_error: 0.3383 - soft_acc: 0.8017 - val_loss: 0.4920 - val_mean_absolute_error: 0.4920 - val_soft_acc: 0.6136\n",
      "Epoch 772/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3291 - mean_absolute_error: 0.3291 - soft_acc: 0.7689 - val_loss: 0.5142 - val_mean_absolute_error: 0.5142 - val_soft_acc: 0.5757\n",
      "Epoch 773/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3632 - mean_absolute_error: 0.3632 - soft_acc: 0.8033 - val_loss: 0.4756 - val_mean_absolute_error: 0.4756 - val_soft_acc: 0.5950\n",
      "Epoch 774/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3618 - mean_absolute_error: 0.3618 - soft_acc: 0.7294 - val_loss: 0.5076 - val_mean_absolute_error: 0.5076 - val_soft_acc: 0.5571\n",
      "Epoch 775/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3374 - mean_absolute_error: 0.3374 - soft_acc: 0.7739 - val_loss: 0.5130 - val_mean_absolute_error: 0.5130 - val_soft_acc: 0.5807\n",
      "Epoch 776/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4163 - mean_absolute_error: 0.4163 - soft_acc: 0.6950 - val_loss: 0.4791 - val_mean_absolute_error: 0.4791 - val_soft_acc: 0.6214\n",
      "Epoch 777/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3704 - mean_absolute_error: 0.3704 - soft_acc: 0.7139 - val_loss: 0.5140 - val_mean_absolute_error: 0.5140 - val_soft_acc: 0.6086\n",
      "Epoch 778/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3705 - mean_absolute_error: 0.3705 - soft_acc: 0.7611 - val_loss: 0.5413 - val_mean_absolute_error: 0.5413 - val_soft_acc: 0.6014\n",
      "Epoch 779/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3692 - mean_absolute_error: 0.3692 - soft_acc: 0.7389 - val_loss: 0.5792 - val_mean_absolute_error: 0.5792 - val_soft_acc: 0.5764\n",
      "Epoch 780/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3282 - mean_absolute_error: 0.3282 - soft_acc: 0.7783 - val_loss: 0.5026 - val_mean_absolute_error: 0.5026 - val_soft_acc: 0.5986\n",
      "Epoch 781/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3404 - mean_absolute_error: 0.3404 - soft_acc: 0.7156 - val_loss: 0.4983 - val_mean_absolute_error: 0.4983 - val_soft_acc: 0.5907\n",
      "Epoch 782/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3306 - mean_absolute_error: 0.3306 - soft_acc: 0.7833 - val_loss: 0.4864 - val_mean_absolute_error: 0.4864 - val_soft_acc: 0.6471\n",
      "Epoch 783/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3221 - mean_absolute_error: 0.3221 - soft_acc: 0.7750 - val_loss: 0.4741 - val_mean_absolute_error: 0.4741 - val_soft_acc: 0.6514\n",
      "Epoch 784/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3368 - mean_absolute_error: 0.3368 - soft_acc: 0.7500 - val_loss: 0.5049 - val_mean_absolute_error: 0.5049 - val_soft_acc: 0.5607\n",
      "Epoch 785/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3344 - mean_absolute_error: 0.3344 - soft_acc: 0.7650 - val_loss: 0.5292 - val_mean_absolute_error: 0.5292 - val_soft_acc: 0.5400\n",
      "Epoch 786/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3484 - mean_absolute_error: 0.3484 - soft_acc: 0.7722 - val_loss: 0.5407 - val_mean_absolute_error: 0.5407 - val_soft_acc: 0.5993\n",
      "Epoch 787/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3929 - mean_absolute_error: 0.3929 - soft_acc: 0.7356 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.6243\n",
      "Epoch 788/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3608 - mean_absolute_error: 0.3608 - soft_acc: 0.6961 - val_loss: 0.5174 - val_mean_absolute_error: 0.5174 - val_soft_acc: 0.5579\n",
      "Epoch 789/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4026 - mean_absolute_error: 0.4026 - soft_acc: 0.6856 - val_loss: 0.5299 - val_mean_absolute_error: 0.5299 - val_soft_acc: 0.5300\n",
      "Epoch 790/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4100 - mean_absolute_error: 0.4100 - soft_acc: 0.6928 - val_loss: 0.5062 - val_mean_absolute_error: 0.5062 - val_soft_acc: 0.6443\n",
      "Epoch 791/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.4840 - mean_absolute_error: 0.4840 - soft_acc: 0.5978 - val_loss: 0.5587 - val_mean_absolute_error: 0.5587 - val_soft_acc: 0.5736\n",
      "Epoch 792/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4675 - mean_absolute_error: 0.4675 - soft_acc: 0.6550 - val_loss: 0.6399 - val_mean_absolute_error: 0.6399 - val_soft_acc: 0.5079\n",
      "Epoch 793/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4385 - mean_absolute_error: 0.4385 - soft_acc: 0.6656 - val_loss: 0.6236 - val_mean_absolute_error: 0.6236 - val_soft_acc: 0.4407\n",
      "Epoch 794/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4844 - mean_absolute_error: 0.4844 - soft_acc: 0.5967 - val_loss: 0.5190 - val_mean_absolute_error: 0.5190 - val_soft_acc: 0.5221\n",
      "Epoch 795/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3624 - mean_absolute_error: 0.3624 - soft_acc: 0.7417 - val_loss: 0.4955 - val_mean_absolute_error: 0.4955 - val_soft_acc: 0.5779\n",
      "Epoch 796/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4302 - mean_absolute_error: 0.4302 - soft_acc: 0.7061 - val_loss: 0.5024 - val_mean_absolute_error: 0.5024 - val_soft_acc: 0.6193\n",
      "Epoch 797/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4296 - mean_absolute_error: 0.4296 - soft_acc: 0.7039 - val_loss: 0.5034 - val_mean_absolute_error: 0.5034 - val_soft_acc: 0.6214\n",
      "Epoch 798/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3647 - mean_absolute_error: 0.3647 - soft_acc: 0.7172 - val_loss: 0.5473 - val_mean_absolute_error: 0.5473 - val_soft_acc: 0.5986\n",
      "Epoch 799/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3423 - mean_absolute_error: 0.3423 - soft_acc: 0.7761 - val_loss: 0.5011 - val_mean_absolute_error: 0.5011 - val_soft_acc: 0.6471\n",
      "Epoch 800/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3120 - mean_absolute_error: 0.3120 - soft_acc: 0.7900 - val_loss: 0.4742 - val_mean_absolute_error: 0.4742 - val_soft_acc: 0.6314\n",
      "Epoch 801/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3476 - mean_absolute_error: 0.3476 - soft_acc: 0.7617 - val_loss: 0.4756 - val_mean_absolute_error: 0.4756 - val_soft_acc: 0.6136\n",
      "Epoch 802/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3170 - mean_absolute_error: 0.3170 - soft_acc: 0.7328 - val_loss: 0.4793 - val_mean_absolute_error: 0.4793 - val_soft_acc: 0.6321\n",
      "Epoch 803/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3283 - mean_absolute_error: 0.3283 - soft_acc: 0.7922 - val_loss: 0.5073 - val_mean_absolute_error: 0.5073 - val_soft_acc: 0.5729\n",
      "Epoch 804/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5374 - mean_absolute_error: 0.5374 - soft_acc: 0.6117 - val_loss: 0.6048 - val_mean_absolute_error: 0.6048 - val_soft_acc: 0.4950\n",
      "Epoch 805/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4865 - mean_absolute_error: 0.4865 - soft_acc: 0.6556 - val_loss: 0.5811 - val_mean_absolute_error: 0.5811 - val_soft_acc: 0.4879\n",
      "Epoch 806/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.5082 - mean_absolute_error: 0.5082 - soft_acc: 0.6072 - val_loss: 0.5580 - val_mean_absolute_error: 0.5580 - val_soft_acc: 0.5529\n",
      "Epoch 807/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4699 - mean_absolute_error: 0.4699 - soft_acc: 0.6700 - val_loss: 0.7749 - val_mean_absolute_error: 0.7749 - val_soft_acc: 0.3429\n",
      "Epoch 808/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.7184 - mean_absolute_error: 0.7184 - soft_acc: 0.5528 - val_loss: 0.7131 - val_mean_absolute_error: 0.7131 - val_soft_acc: 0.3936\n",
      "Epoch 809/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5551 - mean_absolute_error: 0.5551 - soft_acc: 0.6344 - val_loss: 0.9904 - val_mean_absolute_error: 0.9904 - val_soft_acc: 0.3364\n",
      "Epoch 810/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.9952 - mean_absolute_error: 0.9952 - soft_acc: 0.3789 - val_loss: 0.7019 - val_mean_absolute_error: 0.7019 - val_soft_acc: 0.4650\n",
      "Epoch 811/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.8678 - mean_absolute_error: 0.8678 - soft_acc: 0.4689 - val_loss: 0.5510 - val_mean_absolute_error: 0.5510 - val_soft_acc: 0.5886\n",
      "Epoch 812/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.6438 - mean_absolute_error: 0.6438 - soft_acc: 0.5689 - val_loss: 0.6807 - val_mean_absolute_error: 0.6807 - val_soft_acc: 0.4650\n",
      "Epoch 813/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.5878 - mean_absolute_error: 0.5878 - soft_acc: 0.6189 - val_loss: 0.6114 - val_mean_absolute_error: 0.6114 - val_soft_acc: 0.5000\n",
      "Epoch 814/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4943 - mean_absolute_error: 0.4943 - soft_acc: 0.6050 - val_loss: 0.6663 - val_mean_absolute_error: 0.6663 - val_soft_acc: 0.4800\n",
      "Epoch 815/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.5285 - mean_absolute_error: 0.5285 - soft_acc: 0.6750 - val_loss: 0.6374 - val_mean_absolute_error: 0.6374 - val_soft_acc: 0.4793\n",
      "Epoch 816/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4711 - mean_absolute_error: 0.4711 - soft_acc: 0.6317 - val_loss: 0.4983 - val_mean_absolute_error: 0.4983 - val_soft_acc: 0.6093\n",
      "Epoch 817/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3531 - mean_absolute_error: 0.3531 - soft_acc: 0.7772 - val_loss: 0.4802 - val_mean_absolute_error: 0.4802 - val_soft_acc: 0.5729\n",
      "Epoch 818/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3428 - mean_absolute_error: 0.3428 - soft_acc: 0.7911 - val_loss: 0.4838 - val_mean_absolute_error: 0.4838 - val_soft_acc: 0.6550\n",
      "Epoch 819/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4327 - mean_absolute_error: 0.4327 - soft_acc: 0.6956 - val_loss: 0.4793 - val_mean_absolute_error: 0.4793 - val_soft_acc: 0.6157\n",
      "Epoch 820/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4658 - mean_absolute_error: 0.4658 - soft_acc: 0.6594 - val_loss: 0.4902 - val_mean_absolute_error: 0.4902 - val_soft_acc: 0.6343\n",
      "Epoch 821/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3957 - mean_absolute_error: 0.3957 - soft_acc: 0.7050 - val_loss: 0.4806 - val_mean_absolute_error: 0.4806 - val_soft_acc: 0.6443\n",
      "Epoch 822/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3828 - mean_absolute_error: 0.3828 - soft_acc: 0.7061 - val_loss: 0.4793 - val_mean_absolute_error: 0.4793 - val_soft_acc: 0.6036\n",
      "Epoch 823/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3538 - mean_absolute_error: 0.3538 - soft_acc: 0.7544 - val_loss: 0.4587 - val_mean_absolute_error: 0.4587 - val_soft_acc: 0.5900\n",
      "Epoch 824/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3989 - mean_absolute_error: 0.3989 - soft_acc: 0.7228 - val_loss: 0.4903 - val_mean_absolute_error: 0.4903 - val_soft_acc: 0.5571\n",
      "Epoch 825/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3462 - mean_absolute_error: 0.3462 - soft_acc: 0.7578 - val_loss: 0.4582 - val_mean_absolute_error: 0.4582 - val_soft_acc: 0.6264\n",
      "Epoch 826/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3495 - mean_absolute_error: 0.3495 - soft_acc: 0.7739 - val_loss: 0.4980 - val_mean_absolute_error: 0.4980 - val_soft_acc: 0.5707\n",
      "Epoch 827/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3264 - mean_absolute_error: 0.3264 - soft_acc: 0.7461 - val_loss: 0.5121 - val_mean_absolute_error: 0.5121 - val_soft_acc: 0.6193\n",
      "Epoch 828/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3399 - mean_absolute_error: 0.3399 - soft_acc: 0.7961 - val_loss: 0.5456 - val_mean_absolute_error: 0.5456 - val_soft_acc: 0.5329\n",
      "Epoch 829/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3659 - mean_absolute_error: 0.3659 - soft_acc: 0.7350 - val_loss: 0.4800 - val_mean_absolute_error: 0.4800 - val_soft_acc: 0.6136\n",
      "Epoch 830/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3509 - mean_absolute_error: 0.3509 - soft_acc: 0.7756 - val_loss: 0.4782 - val_mean_absolute_error: 0.4782 - val_soft_acc: 0.5907\n",
      "Epoch 831/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.4080 - mean_absolute_error: 0.4080 - soft_acc: 0.7244 - val_loss: 0.4436 - val_mean_absolute_error: 0.4436 - val_soft_acc: 0.6564\n",
      "Epoch 832/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3400 - mean_absolute_error: 0.3400 - soft_acc: 0.7633 - val_loss: 0.4486 - val_mean_absolute_error: 0.4486 - val_soft_acc: 0.6793\n",
      "Epoch 833/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3807 - mean_absolute_error: 0.3807 - soft_acc: 0.7350 - val_loss: 0.4708 - val_mean_absolute_error: 0.4708 - val_soft_acc: 0.6343\n",
      "Epoch 834/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4170 - mean_absolute_error: 0.4170 - soft_acc: 0.6672 - val_loss: 0.4933 - val_mean_absolute_error: 0.4933 - val_soft_acc: 0.6650\n",
      "Epoch 835/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3977 - mean_absolute_error: 0.3977 - soft_acc: 0.7006 - val_loss: 0.5073 - val_mean_absolute_error: 0.5073 - val_soft_acc: 0.6243\n",
      "Epoch 836/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4005 - mean_absolute_error: 0.4005 - soft_acc: 0.6911 - val_loss: 0.5177 - val_mean_absolute_error: 0.5177 - val_soft_acc: 0.6014\n",
      "Epoch 837/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3989 - mean_absolute_error: 0.3989 - soft_acc: 0.7061 - val_loss: 0.5006 - val_mean_absolute_error: 0.5006 - val_soft_acc: 0.6807\n",
      "Epoch 838/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3458 - mean_absolute_error: 0.3458 - soft_acc: 0.7722 - val_loss: 0.4921 - val_mean_absolute_error: 0.4921 - val_soft_acc: 0.5986\n",
      "Epoch 839/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3347 - mean_absolute_error: 0.3347 - soft_acc: 0.7994 - val_loss: 0.5562 - val_mean_absolute_error: 0.5562 - val_soft_acc: 0.5500\n",
      "Epoch 840/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3709 - mean_absolute_error: 0.3709 - soft_acc: 0.7728 - val_loss: 0.5340 - val_mean_absolute_error: 0.5340 - val_soft_acc: 0.5829\n",
      "Epoch 841/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3228 - mean_absolute_error: 0.3228 - soft_acc: 0.8089 - val_loss: 0.4905 - val_mean_absolute_error: 0.4905 - val_soft_acc: 0.5679\n",
      "Epoch 842/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3054 - mean_absolute_error: 0.3054 - soft_acc: 0.8289 - val_loss: 0.5047 - val_mean_absolute_error: 0.5047 - val_soft_acc: 0.6371\n",
      "Epoch 843/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3113 - mean_absolute_error: 0.3113 - soft_acc: 0.7972 - val_loss: 0.5008 - val_mean_absolute_error: 0.5008 - val_soft_acc: 0.5957\n",
      "Epoch 844/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3086 - mean_absolute_error: 0.3086 - soft_acc: 0.8028 - val_loss: 0.4777 - val_mean_absolute_error: 0.4777 - val_soft_acc: 0.6214\n",
      "Epoch 845/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3448 - mean_absolute_error: 0.3448 - soft_acc: 0.7556 - val_loss: 0.4689 - val_mean_absolute_error: 0.4689 - val_soft_acc: 0.5600\n",
      "Epoch 846/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3154 - mean_absolute_error: 0.3154 - soft_acc: 0.7917 - val_loss: 0.4582 - val_mean_absolute_error: 0.4582 - val_soft_acc: 0.5750\n",
      "Epoch 847/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3165 - mean_absolute_error: 0.3165 - soft_acc: 0.7933 - val_loss: 0.4866 - val_mean_absolute_error: 0.4866 - val_soft_acc: 0.6321\n",
      "Epoch 848/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3319 - mean_absolute_error: 0.3319 - soft_acc: 0.7839 - val_loss: 0.4845 - val_mean_absolute_error: 0.4845 - val_soft_acc: 0.6729\n",
      "Epoch 849/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3463 - mean_absolute_error: 0.3463 - soft_acc: 0.7578 - val_loss: 0.5014 - val_mean_absolute_error: 0.5014 - val_soft_acc: 0.5629\n",
      "Epoch 850/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3282 - mean_absolute_error: 0.3282 - soft_acc: 0.7339 - val_loss: 0.5115 - val_mean_absolute_error: 0.5115 - val_soft_acc: 0.5629\n",
      "Epoch 851/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3649 - mean_absolute_error: 0.3649 - soft_acc: 0.7456 - val_loss: 0.4771 - val_mean_absolute_error: 0.4771 - val_soft_acc: 0.5879\n",
      "Epoch 852/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3289 - mean_absolute_error: 0.3289 - soft_acc: 0.7978 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118 - val_soft_acc: 0.5986\n",
      "Epoch 853/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3877 - mean_absolute_error: 0.3877 - soft_acc: 0.7244 - val_loss: 0.5266 - val_mean_absolute_error: 0.5266 - val_soft_acc: 0.5521\n",
      "Epoch 854/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4479 - mean_absolute_error: 0.4479 - soft_acc: 0.6467 - val_loss: 0.4860 - val_mean_absolute_error: 0.4860 - val_soft_acc: 0.5786\n",
      "Epoch 855/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3641 - mean_absolute_error: 0.3641 - soft_acc: 0.7450 - val_loss: 0.4725 - val_mean_absolute_error: 0.4725 - val_soft_acc: 0.6464\n",
      "Epoch 856/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3427 - mean_absolute_error: 0.3427 - soft_acc: 0.7856 - val_loss: 0.4624 - val_mean_absolute_error: 0.4624 - val_soft_acc: 0.6571\n",
      "Epoch 857/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3422 - mean_absolute_error: 0.3422 - soft_acc: 0.7839 - val_loss: 0.4633 - val_mean_absolute_error: 0.4633 - val_soft_acc: 0.6236\n",
      "Epoch 858/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3316 - mean_absolute_error: 0.3316 - soft_acc: 0.7922 - val_loss: 0.4821 - val_mean_absolute_error: 0.4821 - val_soft_acc: 0.6236\n",
      "Epoch 859/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3474 - mean_absolute_error: 0.3474 - soft_acc: 0.7050 - val_loss: 0.5031 - val_mean_absolute_error: 0.5031 - val_soft_acc: 0.5579\n",
      "Epoch 860/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3342 - mean_absolute_error: 0.3342 - soft_acc: 0.8006 - val_loss: 0.4942 - val_mean_absolute_error: 0.4942 - val_soft_acc: 0.5114\n",
      "Epoch 861/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3278 - mean_absolute_error: 0.3278 - soft_acc: 0.7889 - val_loss: 0.4584 - val_mean_absolute_error: 0.4584 - val_soft_acc: 0.6107\n",
      "Epoch 862/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3134 - mean_absolute_error: 0.3134 - soft_acc: 0.7961 - val_loss: 0.4920 - val_mean_absolute_error: 0.4920 - val_soft_acc: 0.6879\n",
      "Epoch 863/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3094 - mean_absolute_error: 0.3094 - soft_acc: 0.7900 - val_loss: 0.5199 - val_mean_absolute_error: 0.5199 - val_soft_acc: 0.5964\n",
      "Epoch 864/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3766 - mean_absolute_error: 0.3766 - soft_acc: 0.7050 - val_loss: 0.4589 - val_mean_absolute_error: 0.4589 - val_soft_acc: 0.6486\n",
      "Epoch 865/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3215 - mean_absolute_error: 0.3215 - soft_acc: 0.7989 - val_loss: 0.4465 - val_mean_absolute_error: 0.4465 - val_soft_acc: 0.6543\n",
      "Epoch 866/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2942 - mean_absolute_error: 0.2942 - soft_acc: 0.8189 - val_loss: 0.4640 - val_mean_absolute_error: 0.4640 - val_soft_acc: 0.6436\n",
      "Epoch 867/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3023 - mean_absolute_error: 0.3023 - soft_acc: 0.7917 - val_loss: 0.4920 - val_mean_absolute_error: 0.4920 - val_soft_acc: 0.5521\n",
      "Epoch 868/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3191 - mean_absolute_error: 0.3191 - soft_acc: 0.7717 - val_loss: 0.5319 - val_mean_absolute_error: 0.5319 - val_soft_acc: 0.5607\n",
      "Epoch 869/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3712 - mean_absolute_error: 0.3712 - soft_acc: 0.7172 - val_loss: 0.4853 - val_mean_absolute_error: 0.4853 - val_soft_acc: 0.6236\n",
      "Epoch 870/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3744 - mean_absolute_error: 0.3744 - soft_acc: 0.7561 - val_loss: 0.5052 - val_mean_absolute_error: 0.5052 - val_soft_acc: 0.5857\n",
      "Epoch 871/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3822 - mean_absolute_error: 0.3822 - soft_acc: 0.7472 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118 - val_soft_acc: 0.6371\n",
      "Epoch 872/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3498 - mean_absolute_error: 0.3498 - soft_acc: 0.7900 - val_loss: 0.5273 - val_mean_absolute_error: 0.5273 - val_soft_acc: 0.4657\n",
      "Epoch 873/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4103 - mean_absolute_error: 0.4103 - soft_acc: 0.7239 - val_loss: 0.5122 - val_mean_absolute_error: 0.5122 - val_soft_acc: 0.6400\n",
      "Epoch 874/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4233 - mean_absolute_error: 0.4233 - soft_acc: 0.6806 - val_loss: 0.4980 - val_mean_absolute_error: 0.4980 - val_soft_acc: 0.6850\n",
      "Epoch 875/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3579 - mean_absolute_error: 0.3579 - soft_acc: 0.7706 - val_loss: 0.5315 - val_mean_absolute_error: 0.5315 - val_soft_acc: 0.5986\n",
      "Epoch 876/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5470 - mean_absolute_error: 0.5470 - soft_acc: 0.5394 - val_loss: 0.5548 - val_mean_absolute_error: 0.5548 - val_soft_acc: 0.4686\n",
      "Epoch 877/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4516 - mean_absolute_error: 0.4516 - soft_acc: 0.6472 - val_loss: 0.5110 - val_mean_absolute_error: 0.5110 - val_soft_acc: 0.5786\n",
      "Epoch 878/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4372 - mean_absolute_error: 0.4372 - soft_acc: 0.6922 - val_loss: 0.5022 - val_mean_absolute_error: 0.5022 - val_soft_acc: 0.5779\n",
      "Epoch 879/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3933 - mean_absolute_error: 0.3933 - soft_acc: 0.6978 - val_loss: 0.5384 - val_mean_absolute_error: 0.5384 - val_soft_acc: 0.5557\n",
      "Epoch 880/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4402 - mean_absolute_error: 0.4402 - soft_acc: 0.6778 - val_loss: 0.5047 - val_mean_absolute_error: 0.5047 - val_soft_acc: 0.4943\n",
      "Epoch 881/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3960 - mean_absolute_error: 0.3960 - soft_acc: 0.6978 - val_loss: 0.4843 - val_mean_absolute_error: 0.4843 - val_soft_acc: 0.5443\n",
      "Epoch 882/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4803 - mean_absolute_error: 0.4803 - soft_acc: 0.6289 - val_loss: 0.5360 - val_mean_absolute_error: 0.5360 - val_soft_acc: 0.5607\n",
      "Epoch 883/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4773 - mean_absolute_error: 0.4773 - soft_acc: 0.6439 - val_loss: 0.5061 - val_mean_absolute_error: 0.5061 - val_soft_acc: 0.6450\n",
      "Epoch 884/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4630 - mean_absolute_error: 0.4630 - soft_acc: 0.6744 - val_loss: 0.4359 - val_mean_absolute_error: 0.4359 - val_soft_acc: 0.6893\n",
      "Epoch 885/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3870 - mean_absolute_error: 0.3870 - soft_acc: 0.6939 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.6414\n",
      "Epoch 886/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3613 - mean_absolute_error: 0.3613 - soft_acc: 0.7189 - val_loss: 0.4811 - val_mean_absolute_error: 0.4811 - val_soft_acc: 0.5629\n",
      "Epoch 887/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3492 - mean_absolute_error: 0.3492 - soft_acc: 0.7756 - val_loss: 0.4802 - val_mean_absolute_error: 0.4802 - val_soft_acc: 0.6036\n",
      "Epoch 888/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3658 - mean_absolute_error: 0.3658 - soft_acc: 0.7228 - val_loss: 0.4960 - val_mean_absolute_error: 0.4960 - val_soft_acc: 0.5707\n",
      "Epoch 889/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3375 - mean_absolute_error: 0.3375 - soft_acc: 0.8094 - val_loss: 0.4794 - val_mean_absolute_error: 0.4794 - val_soft_acc: 0.5757\n",
      "Epoch 890/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3145 - mean_absolute_error: 0.3145 - soft_acc: 0.8033 - val_loss: 0.4690 - val_mean_absolute_error: 0.4690 - val_soft_acc: 0.5957\n",
      "Epoch 891/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3190 - mean_absolute_error: 0.3190 - soft_acc: 0.7661 - val_loss: 0.5193 - val_mean_absolute_error: 0.5193 - val_soft_acc: 0.5679\n",
      "Epoch 892/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3919 - mean_absolute_error: 0.3919 - soft_acc: 0.7306 - val_loss: 0.5131 - val_mean_absolute_error: 0.5131 - val_soft_acc: 0.5557\n",
      "Epoch 893/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3686 - mean_absolute_error: 0.3686 - soft_acc: 0.7194 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045 - val_soft_acc: 0.6293\n",
      "Epoch 894/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3837 - mean_absolute_error: 0.3837 - soft_acc: 0.6983 - val_loss: 0.6166 - val_mean_absolute_error: 0.6166 - val_soft_acc: 0.4593\n",
      "Epoch 895/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.6808 - mean_absolute_error: 0.6808 - soft_acc: 0.4678 - val_loss: 0.6305 - val_mean_absolute_error: 0.6305 - val_soft_acc: 0.4771\n",
      "Epoch 896/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5709 - mean_absolute_error: 0.5709 - soft_acc: 0.6161 - val_loss: 0.4488 - val_mean_absolute_error: 0.4488 - val_soft_acc: 0.6493\n",
      "Epoch 897/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3481 - mean_absolute_error: 0.3481 - soft_acc: 0.7622 - val_loss: 0.4929 - val_mean_absolute_error: 0.4929 - val_soft_acc: 0.5300\n",
      "Epoch 898/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3750 - mean_absolute_error: 0.3750 - soft_acc: 0.7578 - val_loss: 0.4890 - val_mean_absolute_error: 0.4890 - val_soft_acc: 0.5779\n",
      "Epoch 899/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3607 - mean_absolute_error: 0.3607 - soft_acc: 0.7678 - val_loss: 0.4888 - val_mean_absolute_error: 0.4888 - val_soft_acc: 0.5700\n",
      "Epoch 900/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.4287 - mean_absolute_error: 0.4287 - soft_acc: 0.6711 - val_loss: 0.4903 - val_mean_absolute_error: 0.4903 - val_soft_acc: 0.6521\n",
      "Epoch 901/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4007 - mean_absolute_error: 0.4007 - soft_acc: 0.6733 - val_loss: 0.5163 - val_mean_absolute_error: 0.5163 - val_soft_acc: 0.5657\n",
      "Epoch 902/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4959 - mean_absolute_error: 0.4959 - soft_acc: 0.6383 - val_loss: 0.4744 - val_mean_absolute_error: 0.4744 - val_soft_acc: 0.6514\n",
      "Epoch 903/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.4145 - mean_absolute_error: 0.4145 - soft_acc: 0.7306 - val_loss: 0.4699 - val_mean_absolute_error: 0.4699 - val_soft_acc: 0.5907\n",
      "Epoch 904/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3563 - mean_absolute_error: 0.3563 - soft_acc: 0.7256 - val_loss: 0.4596 - val_mean_absolute_error: 0.4596 - val_soft_acc: 0.6314\n",
      "Epoch 905/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3824 - mean_absolute_error: 0.3824 - soft_acc: 0.7839 - val_loss: 0.4625 - val_mean_absolute_error: 0.4625 - val_soft_acc: 0.6571\n",
      "Epoch 906/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3170 - mean_absolute_error: 0.3170 - soft_acc: 0.8144 - val_loss: 0.4816 - val_mean_absolute_error: 0.4816 - val_soft_acc: 0.5829\n",
      "Epoch 907/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3600 - mean_absolute_error: 0.3600 - soft_acc: 0.7456 - val_loss: 0.4981 - val_mean_absolute_error: 0.4981 - val_soft_acc: 0.6064\n",
      "Epoch 908/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3234 - mean_absolute_error: 0.3234 - soft_acc: 0.7639 - val_loss: 0.4812 - val_mean_absolute_error: 0.4812 - val_soft_acc: 0.5550\n",
      "Epoch 909/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3377 - mean_absolute_error: 0.3377 - soft_acc: 0.7550 - val_loss: 0.4823 - val_mean_absolute_error: 0.4823 - val_soft_acc: 0.6493\n",
      "Epoch 910/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3294 - mean_absolute_error: 0.3294 - soft_acc: 0.8011 - val_loss: 0.4572 - val_mean_absolute_error: 0.4572 - val_soft_acc: 0.5957\n",
      "Epoch 911/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3209 - mean_absolute_error: 0.3209 - soft_acc: 0.7261 - val_loss: 0.5056 - val_mean_absolute_error: 0.5056 - val_soft_acc: 0.5650\n",
      "Epoch 912/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4363 - mean_absolute_error: 0.4363 - soft_acc: 0.6917 - val_loss: 0.4994 - val_mean_absolute_error: 0.4994 - val_soft_acc: 0.5807\n",
      "Epoch 913/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3162 - mean_absolute_error: 0.3162 - soft_acc: 0.7483 - val_loss: 0.5100 - val_mean_absolute_error: 0.5100 - val_soft_acc: 0.5529\n",
      "Epoch 914/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4230 - mean_absolute_error: 0.4230 - soft_acc: 0.7072 - val_loss: 0.4701 - val_mean_absolute_error: 0.4701 - val_soft_acc: 0.6671\n",
      "Epoch 915/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3888 - mean_absolute_error: 0.3888 - soft_acc: 0.6789 - val_loss: 0.4858 - val_mean_absolute_error: 0.4858 - val_soft_acc: 0.6086\n",
      "Epoch 916/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3235 - mean_absolute_error: 0.3235 - soft_acc: 0.8028 - val_loss: 0.5077 - val_mean_absolute_error: 0.5077 - val_soft_acc: 0.5314\n",
      "Epoch 917/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3209 - mean_absolute_error: 0.3209 - soft_acc: 0.7661 - val_loss: 0.4856 - val_mean_absolute_error: 0.4856 - val_soft_acc: 0.6057\n",
      "Epoch 918/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3053 - mean_absolute_error: 0.3053 - soft_acc: 0.7883 - val_loss: 0.4582 - val_mean_absolute_error: 0.4582 - val_soft_acc: 0.5879\n",
      "Epoch 919/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3324 - mean_absolute_error: 0.3324 - soft_acc: 0.7661 - val_loss: 0.4531 - val_mean_absolute_error: 0.4531 - val_soft_acc: 0.6364\n",
      "Epoch 920/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3419 - mean_absolute_error: 0.3419 - soft_acc: 0.7494 - val_loss: 0.5203 - val_mean_absolute_error: 0.5203 - val_soft_acc: 0.5500\n",
      "Epoch 921/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3985 - mean_absolute_error: 0.3985 - soft_acc: 0.7194 - val_loss: 0.5298 - val_mean_absolute_error: 0.5298 - val_soft_acc: 0.6550\n",
      "Epoch 922/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4186 - mean_absolute_error: 0.4186 - soft_acc: 0.7089 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.6550\n",
      "Epoch 923/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3689 - mean_absolute_error: 0.3689 - soft_acc: 0.7072 - val_loss: 0.4902 - val_mean_absolute_error: 0.4902 - val_soft_acc: 0.6729\n",
      "Epoch 924/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3476 - mean_absolute_error: 0.3476 - soft_acc: 0.7506 - val_loss: 0.4519 - val_mean_absolute_error: 0.4519 - val_soft_acc: 0.5771\n",
      "Epoch 925/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3497 - mean_absolute_error: 0.3497 - soft_acc: 0.7428 - val_loss: 0.4334 - val_mean_absolute_error: 0.4334 - val_soft_acc: 0.7029\n",
      "Epoch 926/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3254 - mean_absolute_error: 0.3254 - soft_acc: 0.7372 - val_loss: 0.5228 - val_mean_absolute_error: 0.5228 - val_soft_acc: 0.5071\n",
      "Epoch 927/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4558 - mean_absolute_error: 0.4558 - soft_acc: 0.6922 - val_loss: 0.5128 - val_mean_absolute_error: 0.5128 - val_soft_acc: 0.5907\n",
      "Epoch 928/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3255 - mean_absolute_error: 0.3255 - soft_acc: 0.7678 - val_loss: 0.4652 - val_mean_absolute_error: 0.4652 - val_soft_acc: 0.6850\n",
      "Epoch 929/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3193 - mean_absolute_error: 0.3193 - soft_acc: 0.7644 - val_loss: 0.4468 - val_mean_absolute_error: 0.4468 - val_soft_acc: 0.6186\n",
      "Epoch 930/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2977 - mean_absolute_error: 0.2977 - soft_acc: 0.7944 - val_loss: 0.4672 - val_mean_absolute_error: 0.4672 - val_soft_acc: 0.6257\n",
      "Epoch 931/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2908 - mean_absolute_error: 0.2908 - soft_acc: 0.8156 - val_loss: 0.4821 - val_mean_absolute_error: 0.4821 - val_soft_acc: 0.6057\n",
      "Epoch 932/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3472 - mean_absolute_error: 0.3472 - soft_acc: 0.7117 - val_loss: 0.5005 - val_mean_absolute_error: 0.5005 - val_soft_acc: 0.5736\n",
      "Epoch 933/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3930 - mean_absolute_error: 0.3930 - soft_acc: 0.7183 - val_loss: 0.4676 - val_mean_absolute_error: 0.4676 - val_soft_acc: 0.6600\n",
      "Epoch 934/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3443 - mean_absolute_error: 0.3443 - soft_acc: 0.7961 - val_loss: 0.4558 - val_mean_absolute_error: 0.4558 - val_soft_acc: 0.6821\n",
      "Epoch 935/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3125 - mean_absolute_error: 0.3125 - soft_acc: 0.8044 - val_loss: 0.4645 - val_mean_absolute_error: 0.4645 - val_soft_acc: 0.5621\n",
      "Epoch 936/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3456 - mean_absolute_error: 0.3456 - soft_acc: 0.7450 - val_loss: 0.4649 - val_mean_absolute_error: 0.4649 - val_soft_acc: 0.6464\n",
      "Epoch 937/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3526 - mean_absolute_error: 0.3526 - soft_acc: 0.7572 - val_loss: 0.5138 - val_mean_absolute_error: 0.5138 - val_soft_acc: 0.5679\n",
      "Epoch 938/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3604 - mean_absolute_error: 0.3604 - soft_acc: 0.7628 - val_loss: 0.5052 - val_mean_absolute_error: 0.5052 - val_soft_acc: 0.5857\n",
      "Epoch 939/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3315 - mean_absolute_error: 0.3315 - soft_acc: 0.7594 - val_loss: 0.5338 - val_mean_absolute_error: 0.5338 - val_soft_acc: 0.5371\n",
      "Epoch 940/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3806 - mean_absolute_error: 0.3806 - soft_acc: 0.7306 - val_loss: 0.5032 - val_mean_absolute_error: 0.5032 - val_soft_acc: 0.5886\n",
      "Epoch 941/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3634 - mean_absolute_error: 0.3634 - soft_acc: 0.7439 - val_loss: 0.4818 - val_mean_absolute_error: 0.4818 - val_soft_acc: 0.5729\n",
      "Epoch 942/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3098 - mean_absolute_error: 0.3098 - soft_acc: 0.8028 - val_loss: 0.4816 - val_mean_absolute_error: 0.4816 - val_soft_acc: 0.6136\n",
      "Epoch 943/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3152 - mean_absolute_error: 0.3152 - soft_acc: 0.7850 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634 - val_soft_acc: 0.5850\n",
      "Epoch 944/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3092 - mean_absolute_error: 0.3092 - soft_acc: 0.8061 - val_loss: 0.4795 - val_mean_absolute_error: 0.4795 - val_soft_acc: 0.6443\n",
      "Epoch 945/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2896 - mean_absolute_error: 0.2896 - soft_acc: 0.7944 - val_loss: 0.5067 - val_mean_absolute_error: 0.5067 - val_soft_acc: 0.5471\n",
      "Epoch 946/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4727 - mean_absolute_error: 0.4727 - soft_acc: 0.6139 - val_loss: 0.5011 - val_mean_absolute_error: 0.5011 - val_soft_acc: 0.5500\n",
      "Epoch 947/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4905 - mean_absolute_error: 0.4905 - soft_acc: 0.5972 - val_loss: 0.5011 - val_mean_absolute_error: 0.5011 - val_soft_acc: 0.6750\n",
      "Epoch 948/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4108 - mean_absolute_error: 0.4108 - soft_acc: 0.7133 - val_loss: 0.5924 - val_mean_absolute_error: 0.5924 - val_soft_acc: 0.5000\n",
      "Epoch 949/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4308 - mean_absolute_error: 0.4308 - soft_acc: 0.6850 - val_loss: 0.5280 - val_mean_absolute_error: 0.5280 - val_soft_acc: 0.5400\n",
      "Epoch 950/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3816 - mean_absolute_error: 0.3816 - soft_acc: 0.7289 - val_loss: 0.4716 - val_mean_absolute_error: 0.4716 - val_soft_acc: 0.6729\n",
      "Epoch 951/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3536 - mean_absolute_error: 0.3536 - soft_acc: 0.7706 - val_loss: 0.5089 - val_mean_absolute_error: 0.5089 - val_soft_acc: 0.5350\n",
      "Epoch 952/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4097 - mean_absolute_error: 0.4097 - soft_acc: 0.7344 - val_loss: 0.4467 - val_mean_absolute_error: 0.4467 - val_soft_acc: 0.6564\n",
      "Epoch 953/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3351 - mean_absolute_error: 0.3351 - soft_acc: 0.7561 - val_loss: 0.5024 - val_mean_absolute_error: 0.5024 - val_soft_acc: 0.5829\n",
      "Epoch 954/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4296 - mean_absolute_error: 0.4296 - soft_acc: 0.6928 - val_loss: 0.5747 - val_mean_absolute_error: 0.5747 - val_soft_acc: 0.4893\n",
      "Epoch 955/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.5429 - mean_absolute_error: 0.5429 - soft_acc: 0.6167 - val_loss: 0.6026 - val_mean_absolute_error: 0.6026 - val_soft_acc: 0.5050\n",
      "Epoch 956/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.6371 - mean_absolute_error: 0.6371 - soft_acc: 0.4883 - val_loss: 0.5136 - val_mean_absolute_error: 0.5136 - val_soft_acc: 0.5936\n",
      "Epoch 957/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.6159 - mean_absolute_error: 0.6159 - soft_acc: 0.5972 - val_loss: 0.5669 - val_mean_absolute_error: 0.5669 - val_soft_acc: 0.6143\n",
      "Epoch 958/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.6154 - mean_absolute_error: 0.6154 - soft_acc: 0.5478 - val_loss: 0.6520 - val_mean_absolute_error: 0.6520 - val_soft_acc: 0.4743\n",
      "Epoch 959/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.8073 - mean_absolute_error: 0.8073 - soft_acc: 0.6006 - val_loss: 0.9351 - val_mean_absolute_error: 0.9351 - val_soft_acc: 0.3386\n",
      "Epoch 960/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.9908 - mean_absolute_error: 0.9908 - soft_acc: 0.3644 - val_loss: 0.6407 - val_mean_absolute_error: 0.6407 - val_soft_acc: 0.5129\n",
      "Epoch 961/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.7963 - mean_absolute_error: 0.7963 - soft_acc: 0.4533 - val_loss: 1.1657 - val_mean_absolute_error: 1.1657 - val_soft_acc: 0.2393\n",
      "Epoch 962/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 1.7961 - mean_absolute_error: 1.7961 - soft_acc: 0.3522 - val_loss: 0.8975 - val_mean_absolute_error: 0.8975 - val_soft_acc: 0.3279\n",
      "Epoch 963/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.7482 - mean_absolute_error: 0.7482 - soft_acc: 0.4917 - val_loss: 0.7215 - val_mean_absolute_error: 0.7215 - val_soft_acc: 0.3707\n",
      "Epoch 964/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4995 - mean_absolute_error: 0.4995 - soft_acc: 0.6450 - val_loss: 0.5608 - val_mean_absolute_error: 0.5608 - val_soft_acc: 0.5071\n",
      "Epoch 965/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.4649 - mean_absolute_error: 0.4649 - soft_acc: 0.6811 - val_loss: 0.5030 - val_mean_absolute_error: 0.5030 - val_soft_acc: 0.5650\n",
      "Epoch 966/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4297 - mean_absolute_error: 0.4297 - soft_acc: 0.6500 - val_loss: 0.5728 - val_mean_absolute_error: 0.5728 - val_soft_acc: 0.5157\n",
      "Epoch 967/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4352 - mean_absolute_error: 0.4352 - soft_acc: 0.6639 - val_loss: 0.5556 - val_mean_absolute_error: 0.5556 - val_soft_acc: 0.5450\n",
      "Epoch 968/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4898 - mean_absolute_error: 0.4898 - soft_acc: 0.6594 - val_loss: 0.4922 - val_mean_absolute_error: 0.4922 - val_soft_acc: 0.5121\n",
      "Epoch 969/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.4629 - mean_absolute_error: 0.4629 - soft_acc: 0.6489 - val_loss: 0.5423 - val_mean_absolute_error: 0.5423 - val_soft_acc: 0.5200\n",
      "Epoch 970/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.5516 - mean_absolute_error: 0.5516 - soft_acc: 0.5450 - val_loss: 0.4814 - val_mean_absolute_error: 0.4814 - val_soft_acc: 0.5829\n",
      "Epoch 971/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4785 - mean_absolute_error: 0.4785 - soft_acc: 0.6339 - val_loss: 1.1833 - val_mean_absolute_error: 1.1833 - val_soft_acc: 0.4250\n",
      "Epoch 972/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.7703 - mean_absolute_error: 0.7703 - soft_acc: 0.6006 - val_loss: 0.5704 - val_mean_absolute_error: 0.5704 - val_soft_acc: 0.5229\n",
      "Epoch 973/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5129 - mean_absolute_error: 0.5129 - soft_acc: 0.6483 - val_loss: 0.5409 - val_mean_absolute_error: 0.5409 - val_soft_acc: 0.5707\n",
      "Epoch 974/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4703 - mean_absolute_error: 0.4703 - soft_acc: 0.6506 - val_loss: 0.6080 - val_mean_absolute_error: 0.6080 - val_soft_acc: 0.4843\n",
      "Epoch 975/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.6984 - mean_absolute_error: 0.6984 - soft_acc: 0.5333 - val_loss: 0.5359 - val_mean_absolute_error: 0.5359 - val_soft_acc: 0.5607\n",
      "Epoch 976/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5733 - mean_absolute_error: 0.5733 - soft_acc: 0.6133 - val_loss: 0.5170 - val_mean_absolute_error: 0.5170 - val_soft_acc: 0.6164\n",
      "Epoch 977/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3861 - mean_absolute_error: 0.3861 - soft_acc: 0.7144 - val_loss: 0.4303 - val_mean_absolute_error: 0.4303 - val_soft_acc: 0.6614\n",
      "Epoch 978/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3663 - mean_absolute_error: 0.3663 - soft_acc: 0.7483 - val_loss: 0.4944 - val_mean_absolute_error: 0.4944 - val_soft_acc: 0.6300\n",
      "Epoch 979/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3912 - mean_absolute_error: 0.3912 - soft_acc: 0.7233 - val_loss: 0.6678 - val_mean_absolute_error: 0.6678 - val_soft_acc: 0.4800\n",
      "Epoch 980/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.8211 - mean_absolute_error: 0.8211 - soft_acc: 0.4806 - val_loss: 0.6808 - val_mean_absolute_error: 0.6808 - val_soft_acc: 0.4693\n",
      "Epoch 981/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.8366 - mean_absolute_error: 0.8366 - soft_acc: 0.4639 - val_loss: 0.4930 - val_mean_absolute_error: 0.4930 - val_soft_acc: 0.6571\n",
      "Epoch 982/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.6242 - mean_absolute_error: 0.6242 - soft_acc: 0.5900 - val_loss: 0.6068 - val_mean_absolute_error: 0.6068 - val_soft_acc: 0.5250\n",
      "Epoch 983/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4385 - mean_absolute_error: 0.4385 - soft_acc: 0.7206 - val_loss: 0.5693 - val_mean_absolute_error: 0.5693 - val_soft_acc: 0.5629\n",
      "Epoch 984/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4536 - mean_absolute_error: 0.4536 - soft_acc: 0.6972 - val_loss: 0.5727 - val_mean_absolute_error: 0.5727 - val_soft_acc: 0.5557\n",
      "Epoch 985/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4497 - mean_absolute_error: 0.4497 - soft_acc: 0.6678 - val_loss: 0.5160 - val_mean_absolute_error: 0.5160 - val_soft_acc: 0.5736\n",
      "Epoch 986/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.4637 - mean_absolute_error: 0.4637 - soft_acc: 0.6789 - val_loss: 0.5268 - val_mean_absolute_error: 0.5268 - val_soft_acc: 0.5736\n",
      "Epoch 987/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4589 - mean_absolute_error: 0.4589 - soft_acc: 0.6756 - val_loss: 0.6790 - val_mean_absolute_error: 0.6790 - val_soft_acc: 0.5307\n",
      "Epoch 988/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.7128 - mean_absolute_error: 0.7128 - soft_acc: 0.5122 - val_loss: 0.5407 - val_mean_absolute_error: 0.5407 - val_soft_acc: 0.6536\n",
      "Epoch 989/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5418 - mean_absolute_error: 0.5418 - soft_acc: 0.5728 - val_loss: 0.5449 - val_mean_absolute_error: 0.5449 - val_soft_acc: 0.4407\n",
      "Epoch 990/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4730 - mean_absolute_error: 0.4730 - soft_acc: 0.6367 - val_loss: 0.5167 - val_mean_absolute_error: 0.5167 - val_soft_acc: 0.5321\n",
      "Epoch 991/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4183 - mean_absolute_error: 0.4183 - soft_acc: 0.7333 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095 - val_soft_acc: 0.5864\n",
      "Epoch 992/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.4259 - mean_absolute_error: 0.4259 - soft_acc: 0.6917 - val_loss: 0.5430 - val_mean_absolute_error: 0.5430 - val_soft_acc: 0.5429\n",
      "Epoch 993/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3896 - mean_absolute_error: 0.3896 - soft_acc: 0.6750 - val_loss: 0.5122 - val_mean_absolute_error: 0.5122 - val_soft_acc: 0.6136\n",
      "Epoch 994/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3670 - mean_absolute_error: 0.3670 - soft_acc: 0.7383 - val_loss: 0.4999 - val_mean_absolute_error: 0.4999 - val_soft_acc: 0.5300\n",
      "Epoch 995/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3650 - mean_absolute_error: 0.3650 - soft_acc: 0.7639 - val_loss: 0.5113 - val_mean_absolute_error: 0.5113 - val_soft_acc: 0.5571\n",
      "Epoch 996/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3412 - mean_absolute_error: 0.3412 - soft_acc: 0.7739 - val_loss: 0.5654 - val_mean_absolute_error: 0.5654 - val_soft_acc: 0.5507\n",
      "Epoch 997/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4073 - mean_absolute_error: 0.4073 - soft_acc: 0.6617 - val_loss: 0.5009 - val_mean_absolute_error: 0.5009 - val_soft_acc: 0.5629\n",
      "Epoch 998/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3286 - mean_absolute_error: 0.3286 - soft_acc: 0.7750 - val_loss: 0.5012 - val_mean_absolute_error: 0.5012 - val_soft_acc: 0.5964\n",
      "Epoch 999/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3289 - mean_absolute_error: 0.3289 - soft_acc: 0.7739 - val_loss: 0.4551 - val_mean_absolute_error: 0.4551 - val_soft_acc: 0.6929\n",
      "Epoch 1000/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3705 - mean_absolute_error: 0.3705 - soft_acc: 0.7344 - val_loss: 0.4910 - val_mean_absolute_error: 0.4910 - val_soft_acc: 0.5957\n",
      "Epoch 1001/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3666 - mean_absolute_error: 0.3666 - soft_acc: 0.7289 - val_loss: 0.4818 - val_mean_absolute_error: 0.4818 - val_soft_acc: 0.5550\n",
      "Epoch 1002/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3121 - mean_absolute_error: 0.3121 - soft_acc: 0.8267 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841 - val_soft_acc: 0.5729\n",
      "Epoch 1003/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2849 - mean_absolute_error: 0.2849 - soft_acc: 0.8278 - val_loss: 0.4824 - val_mean_absolute_error: 0.4824 - val_soft_acc: 0.5343\n",
      "Epoch 1004/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3132 - mean_absolute_error: 0.3132 - soft_acc: 0.80 - 0s 37us/sample - loss: 0.2825 - mean_absolute_error: 0.2825 - soft_acc: 0.8256 - val_loss: 0.4955 - val_mean_absolute_error: 0.4955 - val_soft_acc: 0.6193\n",
      "Epoch 1005/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3382 - mean_absolute_error: 0.3382 - soft_acc: 0.7794 - val_loss: 0.4942 - val_mean_absolute_error: 0.4942 - val_soft_acc: 0.6521\n",
      "Epoch 1006/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3610 - mean_absolute_error: 0.3610 - soft_acc: 0.7278 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.6493\n",
      "Epoch 1007/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3571 - mean_absolute_error: 0.3571 - soft_acc: 0.7522 - val_loss: 0.5171 - val_mean_absolute_error: 0.5171 - val_soft_acc: 0.5371\n",
      "Epoch 1008/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3923 - mean_absolute_error: 0.3923 - soft_acc: 0.7078 - val_loss: 0.4918 - val_mean_absolute_error: 0.4918 - val_soft_acc: 0.6114\n",
      "Epoch 1009/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3079 - mean_absolute_error: 0.3079 - soft_acc: 0.8344 - val_loss: 0.4876 - val_mean_absolute_error: 0.4876 - val_soft_acc: 0.6064\n",
      "Epoch 1010/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3047 - mean_absolute_error: 0.3047 - soft_acc: 0.7950 - val_loss: 0.4937 - val_mean_absolute_error: 0.4937 - val_soft_acc: 0.5350\n",
      "Epoch 1011/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2937 - mean_absolute_error: 0.2937 - soft_acc: 0.8233 - val_loss: 0.5040 - val_mean_absolute_error: 0.5040 - val_soft_acc: 0.5579\n",
      "Epoch 1012/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3036 - mean_absolute_error: 0.3036 - soft_acc: 0.7844 - val_loss: 0.4926 - val_mean_absolute_error: 0.4926 - val_soft_acc: 0.6014\n",
      "Epoch 1013/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3063 - mean_absolute_error: 0.3063 - soft_acc: 0.7828 - val_loss: 0.4848 - val_mean_absolute_error: 0.4848 - val_soft_acc: 0.5629\n",
      "Epoch 1014/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3180 - mean_absolute_error: 0.3180 - soft_acc: 0.8022 - val_loss: 0.4658 - val_mean_absolute_error: 0.4658 - val_soft_acc: 0.6114\n",
      "Epoch 1015/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3217 - mean_absolute_error: 0.3217 - soft_acc: 0.7628 - val_loss: 0.5131 - val_mean_absolute_error: 0.5131 - val_soft_acc: 0.6136\n",
      "Epoch 1016/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3306 - mean_absolute_error: 0.3306 - soft_acc: 0.7578 - val_loss: 0.5232 - val_mean_absolute_error: 0.5232 - val_soft_acc: 0.5064\n",
      "Epoch 1017/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3303 - mean_absolute_error: 0.3303 - soft_acc: 0.7806 - val_loss: 0.4830 - val_mean_absolute_error: 0.4830 - val_soft_acc: 0.6214\n",
      "Epoch 1018/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3253 - mean_absolute_error: 0.3253 - soft_acc: 0.7422 - val_loss: 0.4889 - val_mean_absolute_error: 0.4889 - val_soft_acc: 0.6007\n",
      "Epoch 1019/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3712 - mean_absolute_error: 0.3712 - soft_acc: 0.7528 - val_loss: 0.5165 - val_mean_absolute_error: 0.5165 - val_soft_acc: 0.5500\n",
      "Epoch 1020/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4133 - mean_absolute_error: 0.4133 - soft_acc: 0.7039 - val_loss: 0.5101 - val_mean_absolute_error: 0.5101 - val_soft_acc: 0.5936\n",
      "Epoch 1021/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3763 - mean_absolute_error: 0.3763 - soft_acc: 0.6850 - val_loss: 0.4973 - val_mean_absolute_error: 0.4973 - val_soft_acc: 0.6086\n",
      "Epoch 1022/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3397 - mean_absolute_error: 0.3397 - soft_acc: 0.7750 - val_loss: 0.4830 - val_mean_absolute_error: 0.4830 - val_soft_acc: 0.5343\n",
      "Epoch 1023/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3478 - mean_absolute_error: 0.3478 - soft_acc: 0.7394 - val_loss: 0.4713 - val_mean_absolute_error: 0.4713 - val_soft_acc: 0.6186\n",
      "Epoch 1024/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3278 - mean_absolute_error: 0.3278 - soft_acc: 0.7889 - val_loss: 0.5038 - val_mean_absolute_error: 0.5038 - val_soft_acc: 0.6193\n",
      "Epoch 1025/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3185 - mean_absolute_error: 0.3185 - soft_acc: 0.8094 - val_loss: 0.5023 - val_mean_absolute_error: 0.5023 - val_soft_acc: 0.6036\n",
      "Epoch 1026/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3255 - mean_absolute_error: 0.3255 - soft_acc: 0.7717 - val_loss: 0.5087 - val_mean_absolute_error: 0.5087 - val_soft_acc: 0.5371\n",
      "Epoch 1027/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3332 - mean_absolute_error: 0.3332 - soft_acc: 0.7806 - val_loss: 0.5548 - val_mean_absolute_error: 0.5548 - val_soft_acc: 0.5964\n",
      "Epoch 1028/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3914 - mean_absolute_error: 0.3914 - soft_acc: 0.7211 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045 - val_soft_acc: 0.5907\n",
      "Epoch 1029/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3642 - mean_absolute_error: 0.3642 - soft_acc: 0.7689 - val_loss: 0.7477 - val_mean_absolute_error: 0.7477 - val_soft_acc: 0.3979\n",
      "Epoch 1030/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4873 - mean_absolute_error: 0.4873 - soft_acc: 0.6856 - val_loss: 0.5961 - val_mean_absolute_error: 0.5961 - val_soft_acc: 0.5050\n",
      "Epoch 1031/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3965 - mean_absolute_error: 0.3965 - soft_acc: 0.7267 - val_loss: 0.5026 - val_mean_absolute_error: 0.5026 - val_soft_acc: 0.6371\n",
      "Epoch 1032/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3655 - mean_absolute_error: 0.3655 - soft_acc: 0.7183 - val_loss: 0.5441 - val_mean_absolute_error: 0.5441 - val_soft_acc: 0.6114\n",
      "Epoch 1033/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4811 - mean_absolute_error: 0.4811 - soft_acc: 0.6789 - val_loss: 0.5622 - val_mean_absolute_error: 0.5622 - val_soft_acc: 0.6143\n",
      "Epoch 1034/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4103 - mean_absolute_error: 0.4103 - soft_acc: 0.6778 - val_loss: 0.5031 - val_mean_absolute_error: 0.5031 - val_soft_acc: 0.5364\n",
      "Epoch 1035/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3592 - mean_absolute_error: 0.3592 - soft_acc: 0.7550 - val_loss: 0.4952 - val_mean_absolute_error: 0.4952 - val_soft_acc: 0.6243\n",
      "Epoch 1036/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3978 - mean_absolute_error: 0.3978 - soft_acc: 0.6756 - val_loss: 0.6911 - val_mean_absolute_error: 0.6911 - val_soft_acc: 0.4750\n",
      "Epoch 1037/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.6052 - mean_absolute_error: 0.6052 - soft_acc: 0.5561 - val_loss: 0.5947 - val_mean_absolute_error: 0.5947 - val_soft_acc: 0.4950\n",
      "Epoch 1038/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4614 - mean_absolute_error: 0.4614 - soft_acc: 0.6511 - val_loss: 0.5729 - val_mean_absolute_error: 0.5729 - val_soft_acc: 0.5429\n",
      "Epoch 1039/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3956 - mean_absolute_error: 0.3956 - soft_acc: 0.7078 - val_loss: 0.4807 - val_mean_absolute_error: 0.4807 - val_soft_acc: 0.5907\n",
      "Epoch 1040/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3414 - mean_absolute_error: 0.3414 - soft_acc: 0.7406 - val_loss: 0.5451 - val_mean_absolute_error: 0.5451 - val_soft_acc: 0.5557\n",
      "Epoch 1041/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3528 - mean_absolute_error: 0.3528 - soft_acc: 0.7622 - val_loss: 0.5206 - val_mean_absolute_error: 0.5206 - val_soft_acc: 0.5971\n",
      "Epoch 1042/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3226 - mean_absolute_error: 0.3226 - soft_acc: 0.7711 - val_loss: 0.4882 - val_mean_absolute_error: 0.4882 - val_soft_acc: 0.5957\n",
      "Epoch 1043/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3451 - mean_absolute_error: 0.3451 - soft_acc: 0.7622 - val_loss: 0.4775 - val_mean_absolute_error: 0.4775 - val_soft_acc: 0.6157\n",
      "Epoch 1044/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3904 - mean_absolute_error: 0.3904 - soft_acc: 0.7117 - val_loss: 0.4473 - val_mean_absolute_error: 0.4473 - val_soft_acc: 0.6593\n",
      "Epoch 1045/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3180 - mean_absolute_error: 0.3180 - soft_acc: 0.7561 - val_loss: 0.4918 - val_mean_absolute_error: 0.4918 - val_soft_acc: 0.6471\n",
      "Epoch 1046/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3373 - mean_absolute_error: 0.3373 - soft_acc: 0.7717 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.6029\n",
      "Epoch 1047/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3550 - mean_absolute_error: 0.3550 - soft_acc: 0.7417 - val_loss: 0.4523 - val_mean_absolute_error: 0.4523 - val_soft_acc: 0.6514\n",
      "Epoch 1048/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3688 - mean_absolute_error: 0.3688 - soft_acc: 0.7211 - val_loss: 0.5042 - val_mean_absolute_error: 0.5042 - val_soft_acc: 0.6036\n",
      "Epoch 1049/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3436 - mean_absolute_error: 0.3436 - soft_acc: 0.7861 - val_loss: 0.4951 - val_mean_absolute_error: 0.4951 - val_soft_acc: 0.5629\n",
      "Epoch 1050/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3291 - mean_absolute_error: 0.3291 - soft_acc: 0.8028 - val_loss: 0.5226 - val_mean_absolute_error: 0.5226 - val_soft_acc: 0.5814\n",
      "Epoch 1051/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3276 - mean_absolute_error: 0.3276 - soft_acc: 0.7594 - val_loss: 0.4712 - val_mean_absolute_error: 0.4712 - val_soft_acc: 0.6600\n",
      "Epoch 1052/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3046 - mean_absolute_error: 0.3046 - soft_acc: 0.7950 - val_loss: 0.4936 - val_mean_absolute_error: 0.4936 - val_soft_acc: 0.5729\n",
      "Epoch 1053/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2837 - mean_absolute_error: 0.2837 - soft_acc: 0.8633 - val_loss: 0.5031 - val_mean_absolute_error: 0.5031 - val_soft_acc: 0.5964\n",
      "Epoch 1054/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3422 - mean_absolute_error: 0.3422 - soft_acc: 0.7461 - val_loss: 0.4663 - val_mean_absolute_error: 0.4663 - val_soft_acc: 0.6079\n",
      "Epoch 1055/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3287 - mean_absolute_error: 0.3287 - soft_acc: 0.7828 - val_loss: 0.4552 - val_mean_absolute_error: 0.4552 - val_soft_acc: 0.6471\n",
      "Epoch 1056/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2957 - mean_absolute_error: 0.2957 - soft_acc: 0.8206 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.6443\n",
      "Epoch 1057/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3014 - mean_absolute_error: 0.3014 - soft_acc: 0.7744 - val_loss: 0.4788 - val_mean_absolute_error: 0.4788 - val_soft_acc: 0.5114\n",
      "Epoch 1058/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3141 - mean_absolute_error: 0.3141 - soft_acc: 0.8094 - val_loss: 0.4615 - val_mean_absolute_error: 0.4615 - val_soft_acc: 0.6207\n",
      "Epoch 1059/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3050 - mean_absolute_error: 0.3050 - soft_acc: 0.8317 - val_loss: 0.5148 - val_mean_absolute_error: 0.5148 - val_soft_acc: 0.5121\n",
      "Epoch 1060/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.7756 - val_loss: 0.4546 - val_mean_absolute_error: 0.4546 - val_soft_acc: 0.6514\n",
      "Epoch 1061/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3030 - mean_absolute_error: 0.3030 - soft_acc: 0.7956 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634 - val_soft_acc: 0.5600\n",
      "Epoch 1062/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3200 - mean_absolute_error: 0.3200 - soft_acc: 0.8222 - val_loss: 0.4926 - val_mean_absolute_error: 0.4926 - val_soft_acc: 0.5829\n",
      "Epoch 1063/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3058 - mean_absolute_error: 0.3058 - soft_acc: 0.8139 - val_loss: 0.5102 - val_mean_absolute_error: 0.5102 - val_soft_acc: 0.6164\n",
      "Epoch 1064/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3092 - mean_absolute_error: 0.3092 - soft_acc: 0.8228 - val_loss: 0.5258 - val_mean_absolute_error: 0.5258 - val_soft_acc: 0.5479\n",
      "Epoch 1065/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3433 - mean_absolute_error: 0.3433 - soft_acc: 0.7750 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.5629\n",
      "Epoch 1066/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2936 - mean_absolute_error: 0.2936 - soft_acc: 0.7978 - val_loss: 0.4788 - val_mean_absolute_error: 0.4788 - val_soft_acc: 0.5857\n",
      "Epoch 1067/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3072 - mean_absolute_error: 0.3072 - soft_acc: 0.7844 - val_loss: 0.5173 - val_mean_absolute_error: 0.5173 - val_soft_acc: 0.5043\n",
      "Epoch 1068/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3754 - mean_absolute_error: 0.3754 - soft_acc: 0.7567 - val_loss: 0.5237 - val_mean_absolute_error: 0.5237 - val_soft_acc: 0.5914\n",
      "Epoch 1069/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3605 - mean_absolute_error: 0.3605 - soft_acc: 0.7194 - val_loss: 0.4931 - val_mean_absolute_error: 0.4931 - val_soft_acc: 0.6064\n",
      "Epoch 1070/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3233 - mean_absolute_error: 0.3233 - soft_acc: 0.7528 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.5243\n",
      "Epoch 1071/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3186 - mean_absolute_error: 0.3186 - soft_acc: 0.8028 - val_loss: 0.5229 - val_mean_absolute_error: 0.5229 - val_soft_acc: 0.5150\n",
      "Epoch 1072/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3194 - mean_absolute_error: 0.3194 - soft_acc: 0.7839 - val_loss: 0.5653 - val_mean_absolute_error: 0.5653 - val_soft_acc: 0.5429\n",
      "Epoch 1073/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3921 - mean_absolute_error: 0.3921 - soft_acc: 0.7278 - val_loss: 0.5039 - val_mean_absolute_error: 0.5039 - val_soft_acc: 0.6093\n",
      "Epoch 1074/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3300 - mean_absolute_error: 0.3300 - soft_acc: 0.7567 - val_loss: 0.5056 - val_mean_absolute_error: 0.5056 - val_soft_acc: 0.6193\n",
      "Epoch 1075/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3227 - mean_absolute_error: 0.3227 - soft_acc: 0.7594 - val_loss: 0.4684 - val_mean_absolute_error: 0.4684 - val_soft_acc: 0.5907\n",
      "Epoch 1076/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3717 - mean_absolute_error: 0.3717 - soft_acc: 0.73 - 0s 37us/sample - loss: 0.3518 - mean_absolute_error: 0.3518 - soft_acc: 0.7656 - val_loss: 0.5208 - val_mean_absolute_error: 0.5208 - val_soft_acc: 0.5421\n",
      "Epoch 1077/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3060 - mean_absolute_error: 0.3060 - soft_acc: 0.8006 - val_loss: 0.5643 - val_mean_absolute_error: 0.5643 - val_soft_acc: 0.5250\n",
      "Epoch 1078/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3157 - mean_absolute_error: 0.3157 - soft_acc: 0.7694 - val_loss: 0.6199 - val_mean_absolute_error: 0.6199 - val_soft_acc: 0.5457\n",
      "Epoch 1079/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3442 - mean_absolute_error: 0.3442 - soft_acc: 0.7706 - val_loss: 0.5263 - val_mean_absolute_error: 0.5263 - val_soft_acc: 0.5757\n",
      "Epoch 1080/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3153 - mean_absolute_error: 0.3153 - soft_acc: 0.7794 - val_loss: 0.4958 - val_mean_absolute_error: 0.4958 - val_soft_acc: 0.5936\n",
      "Epoch 1081/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3408 - mean_absolute_error: 0.3408 - soft_acc: 0.7478 - val_loss: 0.4674 - val_mean_absolute_error: 0.4674 - val_soft_acc: 0.5779\n",
      "Epoch 1082/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3977 - mean_absolute_error: 0.3977 - soft_acc: 0.7372 - val_loss: 0.4588 - val_mean_absolute_error: 0.4588 - val_soft_acc: 0.6086\n",
      "Epoch 1083/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3915 - mean_absolute_error: 0.3915 - soft_acc: 0.7111 - val_loss: 0.5136 - val_mean_absolute_error: 0.5136 - val_soft_acc: 0.6143\n",
      "Epoch 1084/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3312 - mean_absolute_error: 0.3312 - soft_acc: 0.7944 - val_loss: 0.4733 - val_mean_absolute_error: 0.4733 - val_soft_acc: 0.6443\n",
      "Epoch 1085/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3109 - mean_absolute_error: 0.3109 - soft_acc: 0.8039 - val_loss: 0.4860 - val_mean_absolute_error: 0.4860 - val_soft_acc: 0.5214\n",
      "Epoch 1086/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3010 - mean_absolute_error: 0.3010 - soft_acc: 0.8050 - val_loss: 0.4644 - val_mean_absolute_error: 0.4644 - val_soft_acc: 0.6086\n",
      "Epoch 1087/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2898 - mean_absolute_error: 0.2898 - soft_acc: 0.7994 - val_loss: 0.4482 - val_mean_absolute_error: 0.4482 - val_soft_acc: 0.6286\n",
      "Epoch 1088/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3016 - mean_absolute_error: 0.3016 - soft_acc: 0.8144 - val_loss: 0.4834 - val_mean_absolute_error: 0.4834 - val_soft_acc: 0.5650\n",
      "Epoch 1089/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3123 - mean_absolute_error: 0.3123 - soft_acc: 0.82 - 0s 41us/sample - loss: 0.3141 - mean_absolute_error: 0.3141 - soft_acc: 0.8194 - val_loss: 0.5202 - val_mean_absolute_error: 0.5202 - val_soft_acc: 0.5836\n",
      "Epoch 1090/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3573 - mean_absolute_error: 0.3573 - soft_acc: 0.7539 - val_loss: 0.4910 - val_mean_absolute_error: 0.4910 - val_soft_acc: 0.6136\n",
      "Epoch 1091/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3556 - mean_absolute_error: 0.3556 - soft_acc: 0.7556 - val_loss: 0.4683 - val_mean_absolute_error: 0.4683 - val_soft_acc: 0.5829\n",
      "Epoch 1092/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4119 - mean_absolute_error: 0.4119 - soft_acc: 0.6933 - val_loss: 0.5203 - val_mean_absolute_error: 0.5203 - val_soft_acc: 0.5429\n",
      "Epoch 1093/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3107 - mean_absolute_error: 0.3107 - soft_acc: 0.8139 - val_loss: 0.4931 - val_mean_absolute_error: 0.4931 - val_soft_acc: 0.6114\n",
      "Epoch 1094/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3542 - mean_absolute_error: 0.3542 - soft_acc: 0.7750 - val_loss: 0.4843 - val_mean_absolute_error: 0.4843 - val_soft_acc: 0.5607\n",
      "Epoch 1095/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3111 - mean_absolute_error: 0.3111 - soft_acc: 0.8061 - val_loss: 0.4909 - val_mean_absolute_error: 0.4909 - val_soft_acc: 0.6057\n",
      "Epoch 1096/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3091 - mean_absolute_error: 0.3091 - soft_acc: 0.7761 - val_loss: 0.5021 - val_mean_absolute_error: 0.5021 - val_soft_acc: 0.5629\n",
      "Epoch 1097/3000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.2889 - mean_absolute_error: 0.2889 - soft_acc: 0.8239 - val_loss: 0.4973 - val_mean_absolute_error: 0.4973 - val_soft_acc: 0.6193\n",
      "Epoch 1098/3000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2758 - mean_absolute_error: 0.2758 - soft_acc: 0.7956 - val_loss: 0.4818 - val_mean_absolute_error: 0.4818 - val_soft_acc: 0.5886\n",
      "Epoch 1099/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3336 - mean_absolute_error: 0.3336 - soft_acc: 0.7817 - val_loss: 0.5068 - val_mean_absolute_error: 0.5068 - val_soft_acc: 0.6371\n",
      "Epoch 1100/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4561 - mean_absolute_error: 0.4561 - soft_acc: 0.6644 - val_loss: 0.4786 - val_mean_absolute_error: 0.4786 - val_soft_acc: 0.5550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1101/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3599 - mean_absolute_error: 0.3599 - soft_acc: 0.7400 - val_loss: 0.5144 - val_mean_absolute_error: 0.5144 - val_soft_acc: 0.6629\n",
      "Epoch 1102/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3003 - mean_absolute_error: 0.3003 - soft_acc: 0.8156 - val_loss: 0.4851 - val_mean_absolute_error: 0.4851 - val_soft_acc: 0.6679\n",
      "Epoch 1103/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3134 - mean_absolute_error: 0.3134 - soft_acc: 0.8128 - val_loss: 0.4900 - val_mean_absolute_error: 0.4900 - val_soft_acc: 0.5321\n",
      "Epoch 1104/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2814 - mean_absolute_error: 0.2814 - soft_acc: 0.8111 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827 - val_soft_acc: 0.6243\n",
      "Epoch 1105/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2772 - mean_absolute_error: 0.2772 - soft_acc: 0.8411 - val_loss: 0.5135 - val_mean_absolute_error: 0.5135 - val_soft_acc: 0.5371\n",
      "Epoch 1106/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4752 - mean_absolute_error: 0.4752 - soft_acc: 0.6144 - val_loss: 0.4945 - val_mean_absolute_error: 0.4945 - val_soft_acc: 0.5500\n",
      "Epoch 1107/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4454 - mean_absolute_error: 0.4454 - soft_acc: 0.6906 - val_loss: 0.5614 - val_mean_absolute_error: 0.5614 - val_soft_acc: 0.5043\n",
      "Epoch 1108/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3722 - mean_absolute_error: 0.3722 - soft_acc: 0.7467 - val_loss: 0.4618 - val_mean_absolute_error: 0.4618 - val_soft_acc: 0.6493\n",
      "Epoch 1109/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2901 - mean_absolute_error: 0.2901 - soft_acc: 0.8261 - val_loss: 0.4802 - val_mean_absolute_error: 0.4802 - val_soft_acc: 0.5907\n",
      "Epoch 1110/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3135 - mean_absolute_error: 0.3135 - soft_acc: 0.7850 - val_loss: 0.4865 - val_mean_absolute_error: 0.4865 - val_soft_acc: 0.5700\n",
      "Epoch 1111/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3057 - mean_absolute_error: 0.3057 - soft_acc: 0.8278 - val_loss: 0.5302 - val_mean_absolute_error: 0.5302 - val_soft_acc: 0.5836\n",
      "Epoch 1112/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3035 - mean_absolute_error: 0.3035 - soft_acc: 0.7917 - val_loss: 0.4728 - val_mean_absolute_error: 0.4728 - val_soft_acc: 0.5600\n",
      "Epoch 1113/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2842 - mean_absolute_error: 0.2842 - soft_acc: 0.8156 - val_loss: 0.5048 - val_mean_absolute_error: 0.5048 - val_soft_acc: 0.5986\n",
      "Epoch 1114/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3949 - mean_absolute_error: 0.3949 - soft_acc: 0.7056 - val_loss: 0.5220 - val_mean_absolute_error: 0.5220 - val_soft_acc: 0.5407\n",
      "Epoch 1115/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3461 - mean_absolute_error: 0.3461 - soft_acc: 0.7689 - val_loss: 0.4927 - val_mean_absolute_error: 0.4927 - val_soft_acc: 0.5986\n",
      "Epoch 1116/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3025 - mean_absolute_error: 0.3025 - soft_acc: 0.8144 - val_loss: 0.4640 - val_mean_absolute_error: 0.4640 - val_soft_acc: 0.5929\n",
      "Epoch 1117/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2843 - mean_absolute_error: 0.2843 - soft_acc: 0.8228 - val_loss: 0.4822 - val_mean_absolute_error: 0.4822 - val_soft_acc: 0.6264\n",
      "Epoch 1118/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3751 - mean_absolute_error: 0.3751 - soft_acc: 0.7317 - val_loss: 0.5055 - val_mean_absolute_error: 0.5055 - val_soft_acc: 0.5507\n",
      "Epoch 1119/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3104 - mean_absolute_error: 0.3104 - soft_acc: 0.8061 - val_loss: 0.4913 - val_mean_absolute_error: 0.4913 - val_soft_acc: 0.6064\n",
      "Epoch 1120/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3941 - mean_absolute_error: 0.3941 - soft_acc: 0.7239 - val_loss: 0.4971 - val_mean_absolute_error: 0.4971 - val_soft_acc: 0.5786\n",
      "Epoch 1121/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - soft_acc: 0.7744 - val_loss: 0.4646 - val_mean_absolute_error: 0.4646 - val_soft_acc: 0.6029\n",
      "Epoch 1122/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3159 - mean_absolute_error: 0.3159 - soft_acc: 0.7889 - val_loss: 0.4657 - val_mean_absolute_error: 0.4657 - val_soft_acc: 0.6343\n",
      "Epoch 1123/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2945 - mean_absolute_error: 0.2945 - soft_acc: 0.7739 - val_loss: 0.4861 - val_mean_absolute_error: 0.4861 - val_soft_acc: 0.5857\n",
      "Epoch 1124/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3112 - mean_absolute_error: 0.3112 - soft_acc: 0.7972 - val_loss: 0.4777 - val_mean_absolute_error: 0.4777 - val_soft_acc: 0.5471\n",
      "Epoch 1125/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3290 - mean_absolute_error: 0.3290 - soft_acc: 0.8283 - val_loss: 0.4802 - val_mean_absolute_error: 0.4802 - val_soft_acc: 0.5836\n",
      "Epoch 1126/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3058 - mean_absolute_error: 0.3058 - soft_acc: 0.8233 - val_loss: 0.4640 - val_mean_absolute_error: 0.4640 - val_soft_acc: 0.6264\n",
      "Epoch 1127/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3070 - mean_absolute_error: 0.3070 - soft_acc: 0.8000 - val_loss: 0.4748 - val_mean_absolute_error: 0.4748 - val_soft_acc: 0.6421\n",
      "Epoch 1128/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3235 - mean_absolute_error: 0.3235 - soft_acc: 0.7594 - val_loss: 0.5644 - val_mean_absolute_error: 0.5644 - val_soft_acc: 0.5229\n",
      "Epoch 1129/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5490 - mean_absolute_error: 0.5490 - soft_acc: 0.5733 - val_loss: 0.5297 - val_mean_absolute_error: 0.5297 - val_soft_acc: 0.5586\n",
      "Epoch 1130/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.5343 - mean_absolute_error: 0.5343 - soft_acc: 0.6483 - val_loss: 0.4557 - val_mean_absolute_error: 0.4557 - val_soft_acc: 0.6157\n",
      "Epoch 1131/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3582 - mean_absolute_error: 0.3582 - soft_acc: 0.7500 - val_loss: 0.4422 - val_mean_absolute_error: 0.4422 - val_soft_acc: 0.6950\n",
      "Epoch 1132/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3162 - mean_absolute_error: 0.3162 - soft_acc: 0.8078 - val_loss: 0.4747 - val_mean_absolute_error: 0.4747 - val_soft_acc: 0.6164\n",
      "Epoch 1133/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2997 - mean_absolute_error: 0.2997 - soft_acc: 0.8000 - val_loss: 0.4901 - val_mean_absolute_error: 0.4901 - val_soft_acc: 0.5243\n",
      "Epoch 1134/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2923 - mean_absolute_error: 0.2923 - soft_acc: 0.8283 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.5957\n",
      "Epoch 1135/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2846 - mean_absolute_error: 0.2846 - soft_acc: 0.8311 - val_loss: 0.5018 - val_mean_absolute_error: 0.5018 - val_soft_acc: 0.5550\n",
      "Epoch 1136/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3066 - mean_absolute_error: 0.3066 - soft_acc: 0.7500 - val_loss: 0.5444 - val_mean_absolute_error: 0.5444 - val_soft_acc: 0.5479\n",
      "Epoch 1137/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3182 - mean_absolute_error: 0.3182 - soft_acc: 0.7939 - val_loss: 0.4858 - val_mean_absolute_error: 0.4858 - val_soft_acc: 0.6064\n",
      "Epoch 1138/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2989 - mean_absolute_error: 0.2989 - soft_acc: 0.7861 - val_loss: 0.4959 - val_mean_absolute_error: 0.4959 - val_soft_acc: 0.5886\n",
      "Epoch 1139/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3725 - mean_absolute_error: 0.3725 - soft_acc: 0.7489 - val_loss: 0.4740 - val_mean_absolute_error: 0.4740 - val_soft_acc: 0.6114\n",
      "Epoch 1140/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3137 - mean_absolute_error: 0.3137 - soft_acc: 0.7956 - val_loss: 0.4736 - val_mean_absolute_error: 0.4736 - val_soft_acc: 0.6750\n",
      "Epoch 1141/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3000 - mean_absolute_error: 0.3000 - soft_acc: 0.8072 - val_loss: 0.4754 - val_mean_absolute_error: 0.4754 - val_soft_acc: 0.5886\n",
      "Epoch 1142/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3375 - mean_absolute_error: 0.3375 - soft_acc: 0.7572 - val_loss: 0.4801 - val_mean_absolute_error: 0.4801 - val_soft_acc: 0.6214\n",
      "Epoch 1143/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3923 - mean_absolute_error: 0.3923 - soft_acc: 0.6883 - val_loss: 0.4776 - val_mean_absolute_error: 0.4776 - val_soft_acc: 0.5821\n",
      "Epoch 1144/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3145 - mean_absolute_error: 0.3145 - soft_acc: 0.7644 - val_loss: 0.4712 - val_mean_absolute_error: 0.4712 - val_soft_acc: 0.6186\n",
      "Epoch 1145/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3245 - mean_absolute_error: 0.3245 - soft_acc: 0.7728 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.6057\n",
      "Epoch 1146/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2978 - mean_absolute_error: 0.2978 - soft_acc: 0.7994 - val_loss: 1.3750 - val_mean_absolute_error: 1.3750 - val_soft_acc: 0.2579\n",
      "Epoch 1147/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.8147 - mean_absolute_error: 0.8147 - soft_acc: 0.5983 - val_loss: 0.5301 - val_mean_absolute_error: 0.5301 - val_soft_acc: 0.5529\n",
      "Epoch 1148/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4695 - mean_absolute_error: 0.4695 - soft_acc: 0.6894 - val_loss: 1.3403 - val_mean_absolute_error: 1.3403 - val_soft_acc: 0.3457\n",
      "Epoch 1149/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 2.7016 - mean_absolute_error: 2.7016 - soft_acc: 0.3467 - val_loss: 0.7090 - val_mean_absolute_error: 0.7090 - val_soft_acc: 0.4293\n",
      "Epoch 1150/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.0119 - mean_absolute_error: 1.0119 - soft_acc: 0.4050 - val_loss: 0.5404 - val_mean_absolute_error: 0.5404 - val_soft_acc: 0.5736\n",
      "Epoch 1151/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 1.4685 - mean_absolute_error: 1.4685 - soft_acc: 0.3700 - val_loss: 1.5723 - val_mean_absolute_error: 1.5723 - val_soft_acc: 0.2093\n",
      "Epoch 1152/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 1.8767 - mean_absolute_error: 1.8767 - soft_acc: 0.2567 - val_loss: 0.5451 - val_mean_absolute_error: 0.5451 - val_soft_acc: 0.5171\n",
      "Epoch 1153/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.7662 - mean_absolute_error: 0.7662 - soft_acc: 0.5439 - val_loss: 0.4943 - val_mean_absolute_error: 0.4943 - val_soft_acc: 0.6143\n",
      "Epoch 1154/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.5387 - mean_absolute_error: 0.5387 - soft_acc: 0.6533 - val_loss: 0.5040 - val_mean_absolute_error: 0.5040 - val_soft_acc: 0.6450\n",
      "Epoch 1155/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3998 - mean_absolute_error: 0.3998 - soft_acc: 0.6783 - val_loss: 0.6195 - val_mean_absolute_error: 0.6195 - val_soft_acc: 0.4386\n",
      "Epoch 1156/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4598 - mean_absolute_error: 0.4598 - soft_acc: 0.6783 - val_loss: 0.6193 - val_mean_absolute_error: 0.6193 - val_soft_acc: 0.5436\n",
      "Epoch 1157/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.4633 - mean_absolute_error: 0.4633 - soft_acc: 0.6644 - val_loss: 0.4862 - val_mean_absolute_error: 0.4862 - val_soft_acc: 0.6029\n",
      "Epoch 1158/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4201 - mean_absolute_error: 0.4201 - soft_acc: 0.7450 - val_loss: 0.5011 - val_mean_absolute_error: 0.5011 - val_soft_acc: 0.5729\n",
      "Epoch 1159/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4374 - mean_absolute_error: 0.4374 - soft_acc: 0.7072 - val_loss: 0.6913 - val_mean_absolute_error: 0.6913 - val_soft_acc: 0.4721\n",
      "Epoch 1160/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.4916 - mean_absolute_error: 0.4916 - soft_acc: 0.6683 - val_loss: 0.5296 - val_mean_absolute_error: 0.5296 - val_soft_acc: 0.5943\n",
      "Epoch 1161/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3658 - mean_absolute_error: 0.3658 - soft_acc: 0.7317 - val_loss: 0.5708 - val_mean_absolute_error: 0.5708 - val_soft_acc: 0.5764\n",
      "Epoch 1162/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3281 - mean_absolute_error: 0.3281 - soft_acc: 0.7683 - val_loss: 0.4799 - val_mean_absolute_error: 0.4799 - val_soft_acc: 0.6293\n",
      "Epoch 1163/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3154 - mean_absolute_error: 0.3154 - soft_acc: 0.7817 - val_loss: 0.4569 - val_mean_absolute_error: 0.4569 - val_soft_acc: 0.5879\n",
      "Epoch 1164/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3088 - mean_absolute_error: 0.3088 - soft_acc: 0.8156 - val_loss: 0.4880 - val_mean_absolute_error: 0.4880 - val_soft_acc: 0.5471\n",
      "Epoch 1165/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3414 - mean_absolute_error: 0.3414 - soft_acc: 0.7961 - val_loss: 0.5083 - val_mean_absolute_error: 0.5083 - val_soft_acc: 0.5500\n",
      "Epoch 1166/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3564 - mean_absolute_error: 0.3564 - soft_acc: 0.6861 - val_loss: 0.6688 - val_mean_absolute_error: 0.6688 - val_soft_acc: 0.4907\n",
      "Epoch 1167/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.5272 - mean_absolute_error: 0.5272 - soft_acc: 0.6728 - val_loss: 0.4852 - val_mean_absolute_error: 0.4852 - val_soft_acc: 0.5757\n",
      "Epoch 1168/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3536 - mean_absolute_error: 0.3536 - soft_acc: 0.7639 - val_loss: 0.4948 - val_mean_absolute_error: 0.4948 - val_soft_acc: 0.6186\n",
      "Epoch 1169/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3156 - mean_absolute_error: 0.3156 - soft_acc: 0.7678 - val_loss: 0.4719 - val_mean_absolute_error: 0.4719 - val_soft_acc: 0.6036\n",
      "Epoch 1170/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2990 - mean_absolute_error: 0.2990 - soft_acc: 0.8089 - val_loss: 0.4913 - val_mean_absolute_error: 0.4913 - val_soft_acc: 0.5786\n",
      "Epoch 1171/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3106 - mean_absolute_error: 0.3106 - soft_acc: 0.7744 - val_loss: 0.4917 - val_mean_absolute_error: 0.4917 - val_soft_acc: 0.6014\n",
      "Epoch 1172/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3453 - mean_absolute_error: 0.3453 - soft_acc: 0.7100 - val_loss: 0.4869 - val_mean_absolute_error: 0.4869 - val_soft_acc: 0.6521\n",
      "Epoch 1173/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3086 - mean_absolute_error: 0.3086 - soft_acc: 0.7983 - val_loss: 0.4813 - val_mean_absolute_error: 0.4813 - val_soft_acc: 0.6214\n",
      "Epoch 1174/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3020 - mean_absolute_error: 0.3020 - soft_acc: 0.7789 - val_loss: 0.5287 - val_mean_absolute_error: 0.5287 - val_soft_acc: 0.5657\n",
      "Epoch 1175/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4887 - mean_absolute_error: 0.4887 - soft_acc: 0.6311 - val_loss: 0.4533 - val_mean_absolute_error: 0.4533 - val_soft_acc: 0.6421\n",
      "Epoch 1176/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3179 - mean_absolute_error: 0.3179 - soft_acc: 0.7606 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732 - val_soft_acc: 0.6214\n",
      "Epoch 1177/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3111 - mean_absolute_error: 0.3111 - soft_acc: 0.7694 - val_loss: 0.4573 - val_mean_absolute_error: 0.4573 - val_soft_acc: 0.6136\n",
      "Epoch 1178/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3043 - mean_absolute_error: 0.3043 - soft_acc: 0.7778 - val_loss: 0.5248 - val_mean_absolute_error: 0.5248 - val_soft_acc: 0.5450\n",
      "Epoch 1179/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3225 - mean_absolute_error: 0.3225 - soft_acc: 0.7789 - val_loss: 0.4825 - val_mean_absolute_error: 0.4825 - val_soft_acc: 0.6543\n",
      "Epoch 1180/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2853 - mean_absolute_error: 0.2853 - soft_acc: 0.8344 - val_loss: 0.4678 - val_mean_absolute_error: 0.4678 - val_soft_acc: 0.5450\n",
      "Epoch 1181/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2891 - mean_absolute_error: 0.2891 - soft_acc: 0.8417 - val_loss: 0.4691 - val_mean_absolute_error: 0.4691 - val_soft_acc: 0.5986\n",
      "Epoch 1182/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3018 - mean_absolute_error: 0.3018 - soft_acc: 0.8106 - val_loss: 0.4789 - val_mean_absolute_error: 0.4789 - val_soft_acc: 0.6443\n",
      "Epoch 1183/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3380 - mean_absolute_error: 0.3380 - soft_acc: 0.8067 - val_loss: 0.4533 - val_mean_absolute_error: 0.4533 - val_soft_acc: 0.6293\n",
      "Epoch 1184/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2866 - mean_absolute_error: 0.2866 - soft_acc: 0.8083 - val_loss: 0.5116 - val_mean_absolute_error: 0.5116 - val_soft_acc: 0.5964\n",
      "Epoch 1185/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3118 - mean_absolute_error: 0.3118 - soft_acc: 0.7722 - val_loss: 0.4960 - val_mean_absolute_error: 0.4960 - val_soft_acc: 0.5886\n",
      "Epoch 1186/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3132 - mean_absolute_error: 0.3132 - soft_acc: 0.7417 - val_loss: 0.4824 - val_mean_absolute_error: 0.4824 - val_soft_acc: 0.5986\n",
      "Epoch 1187/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2987 - mean_absolute_error: 0.2987 - soft_acc: 0.8067 - val_loss: 0.4920 - val_mean_absolute_error: 0.4920 - val_soft_acc: 0.5829\n",
      "Epoch 1188/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3451 - mean_absolute_error: 0.3451 - soft_acc: 0.7489 - val_loss: 0.4743 - val_mean_absolute_error: 0.4743 - val_soft_acc: 0.5929\n",
      "Epoch 1189/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3015 - mean_absolute_error: 0.3015 - soft_acc: 0.7672 - val_loss: 0.4623 - val_mean_absolute_error: 0.4623 - val_soft_acc: 0.6421\n",
      "Epoch 1190/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2719 - mean_absolute_error: 0.2719 - soft_acc: 0.8561 - val_loss: 0.4642 - val_mean_absolute_error: 0.4642 - val_soft_acc: 0.5929\n",
      "Epoch 1191/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2655 - mean_absolute_error: 0.2655 - soft_acc: 0.8356 - val_loss: 0.4900 - val_mean_absolute_error: 0.4900 - val_soft_acc: 0.5779\n",
      "Epoch 1192/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3279 - mean_absolute_error: 0.3279 - soft_acc: 0.8083 - val_loss: 0.5947 - val_mean_absolute_error: 0.5947 - val_soft_acc: 0.5557\n",
      "Epoch 1193/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5240 - mean_absolute_error: 0.5240 - soft_acc: 0.6100 - val_loss: 0.5666 - val_mean_absolute_error: 0.5666 - val_soft_acc: 0.5150\n",
      "Epoch 1194/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4868 - mean_absolute_error: 0.4868 - soft_acc: 0.6461 - val_loss: 0.5622 - val_mean_absolute_error: 0.5622 - val_soft_acc: 0.5329\n",
      "Epoch 1195/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4375 - mean_absolute_error: 0.4375 - soft_acc: 0.6444 - val_loss: 0.5728 - val_mean_absolute_error: 0.5728 - val_soft_acc: 0.4786\n",
      "Epoch 1196/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4163 - mean_absolute_error: 0.4163 - soft_acc: 0.6461 - val_loss: 0.4857 - val_mean_absolute_error: 0.4857 - val_soft_acc: 0.6443\n",
      "Epoch 1197/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4764 - mean_absolute_error: 0.4764 - soft_acc: 0.6578 - val_loss: 0.5108 - val_mean_absolute_error: 0.5108 - val_soft_acc: 0.5607\n",
      "Epoch 1198/3000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.3217 - mean_absolute_error: 0.3217 - soft_acc: 0.7939 - val_loss: 0.4845 - val_mean_absolute_error: 0.4845 - val_soft_acc: 0.6493\n",
      "Epoch 1199/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.4326 - mean_absolute_error: 0.4326 - soft_acc: 0.6967 - val_loss: 0.4519 - val_mean_absolute_error: 0.4519 - val_soft_acc: 0.6136\n",
      "Epoch 1200/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3014 - mean_absolute_error: 0.3014 - soft_acc: 0.7672 - val_loss: 0.5039 - val_mean_absolute_error: 0.5039 - val_soft_acc: 0.5836\n",
      "Epoch 1201/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3227 - mean_absolute_error: 0.3227 - soft_acc: 0.7611 - val_loss: 0.5337 - val_mean_absolute_error: 0.5337 - val_soft_acc: 0.5864\n",
      "Epoch 1202/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4232 - mean_absolute_error: 0.4232 - soft_acc: 0.6972 - val_loss: 0.4709 - val_mean_absolute_error: 0.4709 - val_soft_acc: 0.6214\n",
      "Epoch 1203/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3756 - mean_absolute_error: 0.3756 - soft_acc: 0.7194 - val_loss: 0.4953 - val_mean_absolute_error: 0.4953 - val_soft_acc: 0.5471\n",
      "Epoch 1204/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3579 - mean_absolute_error: 0.3579 - soft_acc: 0.7467 - val_loss: 0.5320 - val_mean_absolute_error: 0.5320 - val_soft_acc: 0.5807\n",
      "Epoch 1205/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3429 - mean_absolute_error: 0.3429 - soft_acc: 0.7911 - val_loss: 0.5501 - val_mean_absolute_error: 0.5501 - val_soft_acc: 0.6121\n",
      "Epoch 1206/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3620 - mean_absolute_error: 0.3620 - soft_acc: 0.7606 - val_loss: 0.4850 - val_mean_absolute_error: 0.4850 - val_soft_acc: 0.6143\n",
      "Epoch 1207/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3068 - mean_absolute_error: 0.3068 - soft_acc: 0.7828 - val_loss: 0.4440 - val_mean_absolute_error: 0.4440 - val_soft_acc: 0.6621\n",
      "Epoch 1208/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2911 - mean_absolute_error: 0.2911 - soft_acc: 0.8261 - val_loss: 0.4681 - val_mean_absolute_error: 0.4681 - val_soft_acc: 0.6007\n",
      "Epoch 1209/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2723 - mean_absolute_error: 0.2723 - soft_acc: 0.8506 - val_loss: 0.5091 - val_mean_absolute_error: 0.5091 - val_soft_acc: 0.5271\n",
      "Epoch 1210/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3303 - mean_absolute_error: 0.3303 - soft_acc: 0.7656 - val_loss: 0.5479 - val_mean_absolute_error: 0.5479 - val_soft_acc: 0.5479\n",
      "Epoch 1211/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4394 - mean_absolute_error: 0.4394 - soft_acc: 0.7028 - val_loss: 0.4550 - val_mean_absolute_error: 0.4550 - val_soft_acc: 0.6236\n",
      "Epoch 1212/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3516 - mean_absolute_error: 0.3516 - soft_acc: 0.7689 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095 - val_soft_acc: 0.5836\n",
      "Epoch 1213/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3060 - mean_absolute_error: 0.3060 - soft_acc: 0.8006 - val_loss: 0.4778 - val_mean_absolute_error: 0.4778 - val_soft_acc: 0.5429\n",
      "Epoch 1214/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2911 - mean_absolute_error: 0.2911 - soft_acc: 0.8067 - val_loss: 0.4670 - val_mean_absolute_error: 0.4670 - val_soft_acc: 0.5829\n",
      "Epoch 1215/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3078 - mean_absolute_error: 0.3078 - soft_acc: 0.8128 - val_loss: 0.4953 - val_mean_absolute_error: 0.4953 - val_soft_acc: 0.5957\n",
      "Epoch 1216/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3129 - mean_absolute_error: 0.3129 - soft_acc: 0.7978 - val_loss: 0.4890 - val_mean_absolute_error: 0.4890 - val_soft_acc: 0.6036\n",
      "Epoch 1217/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2763 - mean_absolute_error: 0.2763 - soft_acc: 0.8144 - val_loss: 0.4774 - val_mean_absolute_error: 0.4774 - val_soft_acc: 0.6393\n",
      "Epoch 1218/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2881 - mean_absolute_error: 0.2881 - soft_acc: 0.8428 - val_loss: 0.4803 - val_mean_absolute_error: 0.4803 - val_soft_acc: 0.6700\n",
      "Epoch 1219/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3064 - mean_absolute_error: 0.3064 - soft_acc: 0.7489 - val_loss: 0.4798 - val_mean_absolute_error: 0.4798 - val_soft_acc: 0.5936\n",
      "Epoch 1220/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3195 - mean_absolute_error: 0.3195 - soft_acc: 0.7478 - val_loss: 0.4717 - val_mean_absolute_error: 0.4717 - val_soft_acc: 0.6243\n",
      "Epoch 1221/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.3114 - mean_absolute_error: 0.3114 - soft_acc: 0.7767 - val_loss: 0.4694 - val_mean_absolute_error: 0.4694 - val_soft_acc: 0.6086\n",
      "Epoch 1222/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2982 - mean_absolute_error: 0.2982 - soft_acc: 0.7844 - val_loss: 0.4768 - val_mean_absolute_error: 0.4768 - val_soft_acc: 0.5957\n",
      "Epoch 1223/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3304 - mean_absolute_error: 0.3304 - soft_acc: 0.7683 - val_loss: 0.4836 - val_mean_absolute_error: 0.4836 - val_soft_acc: 0.6471\n",
      "Epoch 1224/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3880 - mean_absolute_error: 0.3880 - soft_acc: 0.6839 - val_loss: 0.4864 - val_mean_absolute_error: 0.4864 - val_soft_acc: 0.6243\n",
      "Epoch 1225/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3152 - mean_absolute_error: 0.3152 - soft_acc: 0.7783 - val_loss: 0.4998 - val_mean_absolute_error: 0.4998 - val_soft_acc: 0.5836\n",
      "Epoch 1226/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4139 - mean_absolute_error: 0.4139 - soft_acc: 0.6433 - val_loss: 0.4618 - val_mean_absolute_error: 0.4618 - val_soft_acc: 0.6571\n",
      "Epoch 1227/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3846 - mean_absolute_error: 0.3846 - soft_acc: 0.6633 - val_loss: 0.4850 - val_mean_absolute_error: 0.4850 - val_soft_acc: 0.5350\n",
      "Epoch 1228/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3149 - mean_absolute_error: 0.3149 - soft_acc: 0.8133 - val_loss: 0.4767 - val_mean_absolute_error: 0.4767 - val_soft_acc: 0.6214\n",
      "Epoch 1229/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2872 - mean_absolute_error: 0.2872 - soft_acc: 0.8083 - val_loss: 0.5093 - val_mean_absolute_error: 0.5093 - val_soft_acc: 0.5914\n",
      "Epoch 1230/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2849 - mean_absolute_error: 0.2849 - soft_acc: 0.8406 - val_loss: 0.4817 - val_mean_absolute_error: 0.4817 - val_soft_acc: 0.5371\n",
      "Epoch 1231/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2804 - mean_absolute_error: 0.2804 - soft_acc: 0.8272 - val_loss: 0.4636 - val_mean_absolute_error: 0.4636 - val_soft_acc: 0.5979\n",
      "Epoch 1232/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2832 - mean_absolute_error: 0.2832 - soft_acc: 0.8344 - val_loss: 0.5088 - val_mean_absolute_error: 0.5088 - val_soft_acc: 0.5479\n",
      "Epoch 1233/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2778 - mean_absolute_error: 0.2778 - soft_acc: 0.8206 - val_loss: 0.4678 - val_mean_absolute_error: 0.4678 - val_soft_acc: 0.5986\n",
      "Epoch 1234/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2795 - mean_absolute_error: 0.2795 - soft_acc: 0.8117 - val_loss: 0.4763 - val_mean_absolute_error: 0.4763 - val_soft_acc: 0.6779\n",
      "Epoch 1235/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2999 - mean_absolute_error: 0.2999 - soft_acc: 0.7939 - val_loss: 0.4817 - val_mean_absolute_error: 0.4817 - val_soft_acc: 0.6093\n",
      "Epoch 1236/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2771 - mean_absolute_error: 0.2771 - soft_acc: 0.8028 - val_loss: 0.4244 - val_mean_absolute_error: 0.4244 - val_soft_acc: 0.6643\n",
      "Epoch 1237/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2643 - mean_absolute_error: 0.2643 - soft_acc: 0.8528 - val_loss: 0.4574 - val_mean_absolute_error: 0.4574 - val_soft_acc: 0.5979\n",
      "Epoch 1238/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2884 - mean_absolute_error: 0.2884 - soft_acc: 0.7894 - val_loss: 0.5447 - val_mean_absolute_error: 0.5447 - val_soft_acc: 0.5329\n",
      "Epoch 1239/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3724 - mean_absolute_error: 0.3724 - soft_acc: 0.7461 - val_loss: 0.5460 - val_mean_absolute_error: 0.5460 - val_soft_acc: 0.5557\n",
      "Epoch 1240/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3287 - mean_absolute_error: 0.3287 - soft_acc: 0.7950 - val_loss: 0.5072 - val_mean_absolute_error: 0.5072 - val_soft_acc: 0.5857\n",
      "Epoch 1241/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2836 - mean_absolute_error: 0.2836 - soft_acc: 0.8294 - val_loss: 0.5276 - val_mean_absolute_error: 0.5276 - val_soft_acc: 0.5707\n",
      "Epoch 1242/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3023 - mean_absolute_error: 0.3023 - soft_acc: 0.8328 - val_loss: 0.4943 - val_mean_absolute_error: 0.4943 - val_soft_acc: 0.5700\n",
      "Epoch 1243/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2814 - mean_absolute_error: 0.2814 - soft_acc: 0.8378 - val_loss: 0.4972 - val_mean_absolute_error: 0.4972 - val_soft_acc: 0.5650\n",
      "Epoch 1244/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2704 - mean_absolute_error: 0.2704 - soft_acc: 0.8511 - val_loss: 0.5104 - val_mean_absolute_error: 0.5104 - val_soft_acc: 0.5757\n",
      "Epoch 1245/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2736 - mean_absolute_error: 0.2736 - soft_acc: 0.7850 - val_loss: 0.4785 - val_mean_absolute_error: 0.4785 - val_soft_acc: 0.5571\n",
      "Epoch 1246/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3696 - mean_absolute_error: 0.3696 - soft_acc: 0.7278 - val_loss: 0.5167 - val_mean_absolute_error: 0.5167 - val_soft_acc: 0.5964\n",
      "Epoch 1247/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4023 - mean_absolute_error: 0.4023 - soft_acc: 0.7222 - val_loss: 0.4809 - val_mean_absolute_error: 0.4809 - val_soft_acc: 0.5193\n",
      "Epoch 1248/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2720 - mean_absolute_error: 0.2720 - soft_acc: 0.8394 - val_loss: 0.4386 - val_mean_absolute_error: 0.4386 - val_soft_acc: 0.6514\n",
      "Epoch 1249/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2635 - mean_absolute_error: 0.2635 - soft_acc: 0.8522 - val_loss: 0.4620 - val_mean_absolute_error: 0.4620 - val_soft_acc: 0.6114\n",
      "Epoch 1250/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3010 - mean_absolute_error: 0.3010 - soft_acc: 0.7689 - val_loss: 0.4708 - val_mean_absolute_error: 0.4708 - val_soft_acc: 0.5750\n",
      "Epoch 1251/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3117 - mean_absolute_error: 0.3117 - soft_acc: 0.8167 - val_loss: 0.5870 - val_mean_absolute_error: 0.5870 - val_soft_acc: 0.4971\n",
      "Epoch 1252/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.5723 - mean_absolute_error: 0.5723 - soft_acc: 0.5678 - val_loss: 0.5120 - val_mean_absolute_error: 0.5120 - val_soft_acc: 0.5936\n",
      "Epoch 1253/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4520 - mean_absolute_error: 0.4520 - soft_acc: 0.7256 - val_loss: 0.5931 - val_mean_absolute_error: 0.5931 - val_soft_acc: 0.5357\n",
      "Epoch 1254/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4747 - mean_absolute_error: 0.4747 - soft_acc: 0.6639 - val_loss: 0.4570 - val_mean_absolute_error: 0.4570 - val_soft_acc: 0.6721\n",
      "Epoch 1255/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4126 - mean_absolute_error: 0.4126 - soft_acc: 0.6933 - val_loss: 0.4881 - val_mean_absolute_error: 0.4881 - val_soft_acc: 0.6571\n",
      "Epoch 1256/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3753 - mean_absolute_error: 0.3753 - soft_acc: 0.7711 - val_loss: 0.4734 - val_mean_absolute_error: 0.4734 - val_soft_acc: 0.6086\n",
      "Epoch 1257/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3276 - mean_absolute_error: 0.3276 - soft_acc: 0.7556 - val_loss: 0.5062 - val_mean_absolute_error: 0.5062 - val_soft_acc: 0.5736\n",
      "Epoch 1258/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3191 - mean_absolute_error: 0.3191 - soft_acc: 0.7417 - val_loss: 0.5168 - val_mean_absolute_error: 0.5168 - val_soft_acc: 0.5329\n",
      "Epoch 1259/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3630 - mean_absolute_error: 0.3630 - soft_acc: 0.7417 - val_loss: 0.5798 - val_mean_absolute_error: 0.5798 - val_soft_acc: 0.4736\n",
      "Epoch 1260/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.4491 - mean_absolute_error: 0.4491 - soft_acc: 0.6817 - val_loss: 0.6359 - val_mean_absolute_error: 0.6359 - val_soft_acc: 0.4621\n",
      "Epoch 1261/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3764 - mean_absolute_error: 0.3764 - soft_acc: 0.7267 - val_loss: 0.5308 - val_mean_absolute_error: 0.5308 - val_soft_acc: 0.5657\n",
      "Epoch 1262/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3410 - mean_absolute_error: 0.3410 - soft_acc: 0.7878 - val_loss: 0.5104 - val_mean_absolute_error: 0.5104 - val_soft_acc: 0.5657\n",
      "Epoch 1263/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3466 - mean_absolute_error: 0.3466 - soft_acc: 0.7478 - val_loss: 0.5192 - val_mean_absolute_error: 0.5192 - val_soft_acc: 0.5557\n",
      "Epoch 1264/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4537 - mean_absolute_error: 0.4537 - soft_acc: 0.7133 - val_loss: 0.5092 - val_mean_absolute_error: 0.5092 - val_soft_acc: 0.5657\n",
      "Epoch 1265/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3586 - mean_absolute_error: 0.3586 - soft_acc: 0.7467 - val_loss: 0.5491 - val_mean_absolute_error: 0.5491 - val_soft_acc: 0.5150\n",
      "Epoch 1266/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3460 - mean_absolute_error: 0.3460 - soft_acc: 0.7517 - val_loss: 0.5584 - val_mean_absolute_error: 0.5584 - val_soft_acc: 0.5150\n",
      "Epoch 1267/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2817 - mean_absolute_error: 0.2817 - soft_acc: 0.8500 - val_loss: 0.5501 - val_mean_absolute_error: 0.5501 - val_soft_acc: 0.5786\n",
      "Epoch 1268/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3138 - mean_absolute_error: 0.3138 - soft_acc: 0.7700 - val_loss: 0.5291 - val_mean_absolute_error: 0.5291 - val_soft_acc: 0.5964\n",
      "Epoch 1269/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3229 - mean_absolute_error: 0.3229 - soft_acc: 0.8117 - val_loss: 0.5157 - val_mean_absolute_error: 0.5157 - val_soft_acc: 0.5300\n",
      "Epoch 1270/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3779 - mean_absolute_error: 0.3779 - soft_acc: 0.7261 - val_loss: 0.5199 - val_mean_absolute_error: 0.5199 - val_soft_acc: 0.5250\n",
      "Epoch 1271/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3565 - mean_absolute_error: 0.3565 - soft_acc: 0.7622 - val_loss: 0.4751 - val_mean_absolute_error: 0.4751 - val_soft_acc: 0.5807\n",
      "Epoch 1272/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2833 - mean_absolute_error: 0.2833 - soft_acc: 0.7961 - val_loss: 0.4789 - val_mean_absolute_error: 0.4789 - val_soft_acc: 0.6521\n",
      "Epoch 1273/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2722 - mean_absolute_error: 0.2722 - soft_acc: 0.8494 - val_loss: 0.5080 - val_mean_absolute_error: 0.5080 - val_soft_acc: 0.5886\n",
      "Epoch 1274/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2893 - mean_absolute_error: 0.2893 - soft_acc: 0.7867 - val_loss: 0.5405 - val_mean_absolute_error: 0.5405 - val_soft_acc: 0.5557\n",
      "Epoch 1275/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3163 - mean_absolute_error: 0.3163 - soft_acc: 0.7833 - val_loss: 0.5238 - val_mean_absolute_error: 0.5238 - val_soft_acc: 0.6164\n",
      "Epoch 1276/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3095 - mean_absolute_error: 0.3095 - soft_acc: 0.7772 - val_loss: 0.5360 - val_mean_absolute_error: 0.5360 - val_soft_acc: 0.5357\n",
      "Epoch 1277/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.3843 - mean_absolute_error: 0.3843 - soft_acc: 0.7267 - val_loss: 0.4769 - val_mean_absolute_error: 0.4769 - val_soft_acc: 0.5679\n",
      "Epoch 1278/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3156 - mean_absolute_error: 0.3156 - soft_acc: 0.7800 - val_loss: 0.4716 - val_mean_absolute_error: 0.4716 - val_soft_acc: 0.5629\n",
      "Epoch 1279/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3444 - mean_absolute_error: 0.3444 - soft_acc: 0.7689 - val_loss: 0.5055 - val_mean_absolute_error: 0.5055 - val_soft_acc: 0.5807\n",
      "Epoch 1280/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4394 - mean_absolute_error: 0.4394 - soft_acc: 0.6872 - val_loss: 0.5144 - val_mean_absolute_error: 0.5144 - val_soft_acc: 0.5986\n",
      "Epoch 1281/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4226 - mean_absolute_error: 0.4226 - soft_acc: 0.6394 - val_loss: 0.4930 - val_mean_absolute_error: 0.4930 - val_soft_acc: 0.6443\n",
      "Epoch 1282/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4064 - mean_absolute_error: 0.4064 - soft_acc: 0.7078 - val_loss: 0.5457 - val_mean_absolute_error: 0.5457 - val_soft_acc: 0.5479\n",
      "Epoch 1283/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3783 - mean_absolute_error: 0.3783 - soft_acc: 0.6650 - val_loss: 0.5867 - val_mean_absolute_error: 0.5867 - val_soft_acc: 0.5386\n",
      "Epoch 1284/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.4266 - mean_absolute_error: 0.4266 - soft_acc: 0.7161 - val_loss: 0.5107 - val_mean_absolute_error: 0.5107 - val_soft_acc: 0.5043\n",
      "Epoch 1285/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3692 - mean_absolute_error: 0.3692 - soft_acc: 0.7106 - val_loss: 0.4907 - val_mean_absolute_error: 0.4907 - val_soft_acc: 0.5836\n",
      "Epoch 1286/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3193 - mean_absolute_error: 0.3193 - soft_acc: 0.7578 - val_loss: 0.5548 - val_mean_absolute_error: 0.5548 - val_soft_acc: 0.5429\n",
      "Epoch 1287/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4853 - mean_absolute_error: 0.4853 - soft_acc: 0.6511 - val_loss: 0.6636 - val_mean_absolute_error: 0.6636 - val_soft_acc: 0.4493\n",
      "Epoch 1288/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.5258 - mean_absolute_error: 0.5258 - soft_acc: 0.6039 - val_loss: 0.6212 - val_mean_absolute_error: 0.6212 - val_soft_acc: 0.4286\n",
      "Epoch 1289/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4611 - mean_absolute_error: 0.4611 - soft_acc: 0.6167 - val_loss: 0.4998 - val_mean_absolute_error: 0.4998 - val_soft_acc: 0.5936\n",
      "Epoch 1290/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.4747 - mean_absolute_error: 0.4747 - soft_acc: 0.6178 - val_loss: 0.4796 - val_mean_absolute_error: 0.4796 - val_soft_acc: 0.6750\n",
      "Epoch 1291/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4484 - mean_absolute_error: 0.4484 - soft_acc: 0.6817 - val_loss: 0.4763 - val_mean_absolute_error: 0.4763 - val_soft_acc: 0.5443\n",
      "Epoch 1292/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4282 - mean_absolute_error: 0.4282 - soft_acc: 0.6978 - val_loss: 0.5827 - val_mean_absolute_error: 0.5827 - val_soft_acc: 0.5486\n",
      "Epoch 1293/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.4612 - mean_absolute_error: 0.4612 - soft_acc: 0.6394 - val_loss: 0.5181 - val_mean_absolute_error: 0.5181 - val_soft_acc: 0.5657\n",
      "Epoch 1294/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3280 - mean_absolute_error: 0.3280 - soft_acc: 0.7739 - val_loss: 0.4552 - val_mean_absolute_error: 0.4552 - val_soft_acc: 0.6264\n",
      "Epoch 1295/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3217 - mean_absolute_error: 0.3217 - soft_acc: 0.8017 - val_loss: 0.4637 - val_mean_absolute_error: 0.4637 - val_soft_acc: 0.6600\n",
      "Epoch 1296/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3112 - mean_absolute_error: 0.3112 - soft_acc: 0.7678 - val_loss: 0.5640 - val_mean_absolute_error: 0.5640 - val_soft_acc: 0.4843\n",
      "Epoch 1297/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.5313 - mean_absolute_error: 0.5313 - soft_acc: 0.5878 - val_loss: 0.5141 - val_mean_absolute_error: 0.5141 - val_soft_acc: 0.6093\n",
      "Epoch 1298/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.4304 - mean_absolute_error: 0.4304 - soft_acc: 0.6656 - val_loss: 0.5578 - val_mean_absolute_error: 0.5578 - val_soft_acc: 0.5257\n",
      "Epoch 1299/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3657 - mean_absolute_error: 0.3657 - soft_acc: 0.7800 - val_loss: 0.4803 - val_mean_absolute_error: 0.4803 - val_soft_acc: 0.6114\n",
      "Epoch 1300/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3338 - mean_absolute_error: 0.3338 - soft_acc: 0.7750 - val_loss: 0.4398 - val_mean_absolute_error: 0.4398 - val_soft_acc: 0.6500\n",
      "Epoch 1301/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2990 - mean_absolute_error: 0.2990 - soft_acc: 0.8122 - val_loss: 0.4916 - val_mean_absolute_error: 0.4916 - val_soft_acc: 0.6071\n",
      "Epoch 1302/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.3342 - mean_absolute_error: 0.3342 - soft_acc: 0.7633 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.6236\n",
      "Epoch 1303/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3313 - mean_absolute_error: 0.3313 - soft_acc: 0.8050 - val_loss: 0.4862 - val_mean_absolute_error: 0.4862 - val_soft_acc: 0.5857\n",
      "Epoch 1304/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3100 - mean_absolute_error: 0.3100 - soft_acc: 0.8500 - val_loss: 0.4795 - val_mean_absolute_error: 0.4795 - val_soft_acc: 0.5479\n",
      "Epoch 1305/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2888 - mean_absolute_error: 0.2888 - soft_acc: 0.8106 - val_loss: 0.4963 - val_mean_absolute_error: 0.4963 - val_soft_acc: 0.5836\n",
      "Epoch 1306/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2777 - mean_absolute_error: 0.2777 - soft_acc: 0.8444 - val_loss: 0.5285 - val_mean_absolute_error: 0.5285 - val_soft_acc: 0.4686\n",
      "Epoch 1307/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2709 - mean_absolute_error: 0.2709 - soft_acc: 0.8528 - val_loss: 0.5714 - val_mean_absolute_error: 0.5714 - val_soft_acc: 0.5614\n",
      "Epoch 1308/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3702 - mean_absolute_error: 0.3702 - soft_acc: 0.7317 - val_loss: 0.5555 - val_mean_absolute_error: 0.5555 - val_soft_acc: 0.5586\n",
      "Epoch 1309/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3272 - mean_absolute_error: 0.3272 - soft_acc: 0.7922 - val_loss: 0.5151 - val_mean_absolute_error: 0.5151 - val_soft_acc: 0.5943\n",
      "Epoch 1310/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2781 - mean_absolute_error: 0.2781 - soft_acc: 0.8478 - val_loss: 0.4941 - val_mean_absolute_error: 0.4941 - val_soft_acc: 0.5807\n",
      "Epoch 1311/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2845 - mean_absolute_error: 0.2845 - soft_acc: 0.8206 - val_loss: 0.5440 - val_mean_absolute_error: 0.5440 - val_soft_acc: 0.5429\n",
      "Epoch 1312/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3863 - mean_absolute_error: 0.3863 - soft_acc: 0.6994 - val_loss: 0.5021 - val_mean_absolute_error: 0.5021 - val_soft_acc: 0.5271\n",
      "Epoch 1313/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3356 - mean_absolute_error: 0.3356 - soft_acc: 0.7911 - val_loss: 0.4900 - val_mean_absolute_error: 0.4900 - val_soft_acc: 0.6007\n",
      "Epoch 1314/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2802 - mean_absolute_error: 0.2802 - soft_acc: 0.8167 - val_loss: 0.5505 - val_mean_absolute_error: 0.5505 - val_soft_acc: 0.5171\n",
      "Epoch 1315/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2867 - mean_absolute_error: 0.2867 - soft_acc: 0.7861 - val_loss: 0.5447 - val_mean_absolute_error: 0.5447 - val_soft_acc: 0.4764\n",
      "Epoch 1316/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2690 - mean_absolute_error: 0.2690 - soft_acc: 0.8628 - val_loss: 0.4836 - val_mean_absolute_error: 0.4836 - val_soft_acc: 0.6036\n",
      "Epoch 1317/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2602 - mean_absolute_error: 0.2602 - soft_acc: 0.8506 - val_loss: 0.5053 - val_mean_absolute_error: 0.5053 - val_soft_acc: 0.5457\n",
      "Epoch 1318/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3081 - mean_absolute_error: 0.3081 - soft_acc: 0.7661 - val_loss: 0.6246 - val_mean_absolute_error: 0.6246 - val_soft_acc: 0.4593\n",
      "Epoch 1319/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.5288 - mean_absolute_error: 0.5288 - soft_acc: 0.6028 - val_loss: 0.6040 - val_mean_absolute_error: 0.6040 - val_soft_acc: 0.4386\n",
      "Epoch 1320/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.3974 - mean_absolute_error: 0.3974 - soft_acc: 0.7078 - val_loss: 0.5158 - val_mean_absolute_error: 0.5158 - val_soft_acc: 0.5650\n",
      "Epoch 1321/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3705 - mean_absolute_error: 0.3705 - soft_acc: 0.7367 - val_loss: 0.4377 - val_mean_absolute_error: 0.4377 - val_soft_acc: 0.6364\n",
      "Epoch 1322/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3281 - mean_absolute_error: 0.3281 - soft_acc: 0.7300 - val_loss: 0.4926 - val_mean_absolute_error: 0.4926 - val_soft_acc: 0.5986\n",
      "Epoch 1323/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3716 - mean_absolute_error: 0.3716 - soft_acc: 0.7478 - val_loss: 0.4526 - val_mean_absolute_error: 0.4526 - val_soft_acc: 0.5800\n",
      "Epoch 1324/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3320 - mean_absolute_error: 0.3320 - soft_acc: 0.7406 - val_loss: 0.4883 - val_mean_absolute_error: 0.4883 - val_soft_acc: 0.6650\n",
      "Epoch 1325/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3440 - mean_absolute_error: 0.3440 - soft_acc: 0.8011 - val_loss: 0.4755 - val_mean_absolute_error: 0.4755 - val_soft_acc: 0.5879\n",
      "Epoch 1326/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3138 - mean_absolute_error: 0.3138 - soft_acc: 0.7744 - val_loss: 0.5459 - val_mean_absolute_error: 0.5459 - val_soft_acc: 0.4564\n",
      "Epoch 1327/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3214 - mean_absolute_error: 0.3214 - soft_acc: 0.7728 - val_loss: 0.5035 - val_mean_absolute_error: 0.5035 - val_soft_acc: 0.5986\n",
      "Epoch 1328/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4121 - mean_absolute_error: 0.4121 - soft_acc: 0.7194 - val_loss: 0.5550 - val_mean_absolute_error: 0.5550 - val_soft_acc: 0.5914\n",
      "Epoch 1329/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3456 - mean_absolute_error: 0.3456 - soft_acc: 0.7711 - val_loss: 0.4748 - val_mean_absolute_error: 0.4748 - val_soft_acc: 0.6057\n",
      "Epoch 1330/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3412 - mean_absolute_error: 0.3412 - soft_acc: 0.7394 - val_loss: 0.4717 - val_mean_absolute_error: 0.4717 - val_soft_acc: 0.5914\n",
      "Epoch 1331/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3253 - mean_absolute_error: 0.3253 - soft_acc: 0.7628 - val_loss: 0.4687 - val_mean_absolute_error: 0.4687 - val_soft_acc: 0.5700\n",
      "Epoch 1332/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2937 - mean_absolute_error: 0.2937 - soft_acc: 0.8228 - val_loss: 0.4874 - val_mean_absolute_error: 0.4874 - val_soft_acc: 0.5293\n",
      "Epoch 1333/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2701 - mean_absolute_error: 0.2701 - soft_acc: 0.8628 - val_loss: 0.4872 - val_mean_absolute_error: 0.4872 - val_soft_acc: 0.5907\n",
      "Epoch 1334/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2689 - mean_absolute_error: 0.2689 - soft_acc: 0.8083 - val_loss: 0.5141 - val_mean_absolute_error: 0.5141 - val_soft_acc: 0.5121\n",
      "Epoch 1335/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2712 - mean_absolute_error: 0.2712 - soft_acc: 0.8578 - val_loss: 0.4805 - val_mean_absolute_error: 0.4805 - val_soft_acc: 0.5829\n",
      "Epoch 1336/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2753 - mean_absolute_error: 0.2753 - soft_acc: 0.8050 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.5886\n",
      "Epoch 1337/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2791 - mean_absolute_error: 0.2791 - soft_acc: 0.8122 - val_loss: 0.5080 - val_mean_absolute_error: 0.5080 - val_soft_acc: 0.5736\n",
      "Epoch 1338/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2541 - mean_absolute_error: 0.2541 - soft_acc: 0.8389 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150 - val_soft_acc: 0.5814\n",
      "Epoch 1339/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2372 - mean_absolute_error: 0.2372 - soft_acc: 0.8522 - val_loss: 0.5252 - val_mean_absolute_error: 0.5252 - val_soft_acc: 0.6221\n",
      "Epoch 1340/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3291 - mean_absolute_error: 0.3291 - soft_acc: 0.7822 - val_loss: 0.5406 - val_mean_absolute_error: 0.5406 - val_soft_acc: 0.5179\n",
      "Epoch 1341/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2795 - mean_absolute_error: 0.2795 - soft_acc: 0.8133 - val_loss: 0.4889 - val_mean_absolute_error: 0.4889 - val_soft_acc: 0.5371\n",
      "Epoch 1342/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3391 - mean_absolute_error: 0.3391 - soft_acc: 0.7744 - val_loss: 0.5315 - val_mean_absolute_error: 0.5315 - val_soft_acc: 0.5479\n",
      "Epoch 1343/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3566 - mean_absolute_error: 0.3566 - soft_acc: 0.7444 - val_loss: 0.5809 - val_mean_absolute_error: 0.5809 - val_soft_acc: 0.4793\n",
      "Epoch 1344/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3240 - mean_absolute_error: 0.3240 - soft_acc: 0.7756 - val_loss: 0.5348 - val_mean_absolute_error: 0.5348 - val_soft_acc: 0.5964\n",
      "Epoch 1345/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3495 - mean_absolute_error: 0.3495 - soft_acc: 0.7622 - val_loss: 0.5172 - val_mean_absolute_error: 0.5172 - val_soft_acc: 0.5400\n",
      "Epoch 1346/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3471 - mean_absolute_error: 0.3471 - soft_acc: 0.7256 - val_loss: 0.5162 - val_mean_absolute_error: 0.5162 - val_soft_acc: 0.5836\n",
      "Epoch 1347/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3684 - mean_absolute_error: 0.3684 - soft_acc: 0.7717 - val_loss: 0.5611 - val_mean_absolute_error: 0.5611 - val_soft_acc: 0.5579\n",
      "Epoch 1348/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3037 - mean_absolute_error: 0.3037 - soft_acc: 0.8072 - val_loss: 0.4498 - val_mean_absolute_error: 0.4498 - val_soft_acc: 0.6114\n",
      "Epoch 1349/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2741 - mean_absolute_error: 0.2741 - soft_acc: 0.8256 - val_loss: 0.4287 - val_mean_absolute_error: 0.4287 - val_soft_acc: 0.6386\n",
      "Epoch 1350/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2977 - mean_absolute_error: 0.2977 - soft_acc: 0.7878 - val_loss: 0.4547 - val_mean_absolute_error: 0.4547 - val_soft_acc: 0.6114\n",
      "Epoch 1351/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2881 - mean_absolute_error: 0.2881 - soft_acc: 0.8500 - val_loss: 0.4679 - val_mean_absolute_error: 0.4679 - val_soft_acc: 0.5807\n",
      "Epoch 1352/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2659 - mean_absolute_error: 0.2659 - soft_acc: 0.8644 - val_loss: 0.4358 - val_mean_absolute_error: 0.4358 - val_soft_acc: 0.5979\n",
      "Epoch 1353/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2606 - mean_absolute_error: 0.2606 - soft_acc: 0.8283 - val_loss: 0.4643 - val_mean_absolute_error: 0.4643 - val_soft_acc: 0.6571\n",
      "Epoch 1354/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2674 - mean_absolute_error: 0.2674 - soft_acc: 0.8511 - val_loss: 0.5059 - val_mean_absolute_error: 0.5059 - val_soft_acc: 0.6064\n",
      "Epoch 1355/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3101 - mean_absolute_error: 0.3101 - soft_acc: 0.7978 - val_loss: 0.4649 - val_mean_absolute_error: 0.4649 - val_soft_acc: 0.6750\n",
      "Epoch 1356/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2548 - mean_absolute_error: 0.2548 - soft_acc: 0.8372 - val_loss: 0.5285 - val_mean_absolute_error: 0.5285 - val_soft_acc: 0.6014\n",
      "Epoch 1357/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3306 - mean_absolute_error: 0.3306 - soft_acc: 0.8017 - val_loss: 0.5856 - val_mean_absolute_error: 0.5856 - val_soft_acc: 0.4900\n",
      "Epoch 1358/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4833 - mean_absolute_error: 0.4833 - soft_acc: 0.6083 - val_loss: 0.4822 - val_mean_absolute_error: 0.4822 - val_soft_acc: 0.5779\n",
      "Epoch 1359/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.4212 - mean_absolute_error: 0.4212 - soft_acc: 0.6950 - val_loss: 0.5450 - val_mean_absolute_error: 0.5450 - val_soft_acc: 0.5507\n",
      "Epoch 1360/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3897 - mean_absolute_error: 0.3897 - soft_acc: 0.7544 - val_loss: 0.4577 - val_mean_absolute_error: 0.4577 - val_soft_acc: 0.6543\n",
      "Epoch 1361/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2638 - mean_absolute_error: 0.2638 - soft_acc: 0.8594 - val_loss: 0.5134 - val_mean_absolute_error: 0.5134 - val_soft_acc: 0.5607\n",
      "Epoch 1362/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.7322 - mean_absolute_error: 0.7322 - soft_acc: 0.5078 - val_loss: 0.5166 - val_mean_absolute_error: 0.5166 - val_soft_acc: 0.5679\n",
      "Epoch 1363/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 1.7448 - mean_absolute_error: 1.7448 - soft_acc: 0.4300 - val_loss: 0.5268 - val_mean_absolute_error: 0.5268 - val_soft_acc: 0.5964\n",
      "Epoch 1364/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 1.4319 - mean_absolute_error: 1.4319 - soft_acc: 0.4578 - val_loss: 1.0374 - val_mean_absolute_error: 1.0374 - val_soft_acc: 0.3057\n",
      "Epoch 1365/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.0485 - mean_absolute_error: 1.0485 - soft_acc: 0.3989 - val_loss: 1.0662 - val_mean_absolute_error: 1.0662 - val_soft_acc: 0.2957\n",
      "Epoch 1366/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 1.6363 - mean_absolute_error: 1.6363 - soft_acc: 0.2328 - val_loss: 4.0563 - val_mean_absolute_error: 4.0563 - val_soft_acc: 0.2171\n",
      "Epoch 1367/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 2.8831 - mean_absolute_error: 2.8831 - soft_acc: 0.4017 - val_loss: 1.0950 - val_mean_absolute_error: 1.0950 - val_soft_acc: 0.2243\n",
      "Epoch 1368/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 1.0135 - mean_absolute_error: 1.0135 - soft_acc: 0.3972 - val_loss: 1.3297 - val_mean_absolute_error: 1.3297 - val_soft_acc: 0.2771\n",
      "Epoch 1369/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 1.1530 - mean_absolute_error: 1.1530 - soft_acc: 0.4300 - val_loss: 0.9502 - val_mean_absolute_error: 0.9502 - val_soft_acc: 0.4793\n",
      "Epoch 1370/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 1.1860 - mean_absolute_error: 1.1860 - soft_acc: 0.3639 - val_loss: 0.5782 - val_mean_absolute_error: 0.5782 - val_soft_acc: 0.4871\n",
      "Epoch 1371/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.7535 - mean_absolute_error: 0.7535 - soft_acc: 0.5122 - val_loss: 0.5244 - val_mean_absolute_error: 0.5244 - val_soft_acc: 0.5250\n",
      "Epoch 1372/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4672 - mean_absolute_error: 0.4672 - soft_acc: 0.6711 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.5807\n",
      "Epoch 1373/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4019 - mean_absolute_error: 0.4019 - soft_acc: 0.6928 - val_loss: 0.4603 - val_mean_absolute_error: 0.4603 - val_soft_acc: 0.6143\n",
      "Epoch 1374/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3873 - mean_absolute_error: 0.3873 - soft_acc: 0.7178 - val_loss: 0.5346 - val_mean_absolute_error: 0.5346 - val_soft_acc: 0.5729\n",
      "Epoch 1375/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3896 - mean_absolute_error: 0.3896 - soft_acc: 0.6850 - val_loss: 0.4966 - val_mean_absolute_error: 0.4966 - val_soft_acc: 0.6086\n",
      "Epoch 1376/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4611 - mean_absolute_error: 0.4611 - soft_acc: 0.6717 - val_loss: 0.4760 - val_mean_absolute_error: 0.4760 - val_soft_acc: 0.5986\n",
      "Epoch 1377/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.4687 - mean_absolute_error: 0.4687 - soft_acc: 0.6817 - val_loss: 0.5949 - val_mean_absolute_error: 0.5949 - val_soft_acc: 0.5079\n",
      "Epoch 1378/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5272 - mean_absolute_error: 0.5272 - soft_acc: 0.6261 - val_loss: 0.4727 - val_mean_absolute_error: 0.4727 - val_soft_acc: 0.5529\n",
      "Epoch 1379/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3576 - mean_absolute_error: 0.3576 - soft_acc: 0.7572 - val_loss: 0.5329 - val_mean_absolute_error: 0.5329 - val_soft_acc: 0.5171\n",
      "Epoch 1380/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3377 - mean_absolute_error: 0.3377 - soft_acc: 0.7667 - val_loss: 0.5891 - val_mean_absolute_error: 0.5891 - val_soft_acc: 0.5257\n",
      "Epoch 1381/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3881 - mean_absolute_error: 0.3881 - soft_acc: 0.7311 - val_loss: 0.5371 - val_mean_absolute_error: 0.5371 - val_soft_acc: 0.5786\n",
      "Epoch 1382/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4912 - mean_absolute_error: 0.4912 - soft_acc: 0.6617 - val_loss: 0.4576 - val_mean_absolute_error: 0.4576 - val_soft_acc: 0.6029\n",
      "Epoch 1383/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3467 - mean_absolute_error: 0.3467 - soft_acc: 0.7672 - val_loss: 0.4703 - val_mean_absolute_error: 0.4703 - val_soft_acc: 0.6671\n",
      "Epoch 1384/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3426 - mean_absolute_error: 0.3426 - soft_acc: 0.7222 - val_loss: 0.4583 - val_mean_absolute_error: 0.4583 - val_soft_acc: 0.6543\n",
      "Epoch 1385/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2991 - mean_absolute_error: 0.2991 - soft_acc: 0.8222 - val_loss: 0.4410 - val_mean_absolute_error: 0.4410 - val_soft_acc: 0.6207\n",
      "Epoch 1386/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3232 - mean_absolute_error: 0.3232 - soft_acc: 0.7694 - val_loss: 0.5362 - val_mean_absolute_error: 0.5362 - val_soft_acc: 0.5657\n",
      "Epoch 1387/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3885 - mean_absolute_error: 0.3885 - soft_acc: 0.7644 - val_loss: 0.4598 - val_mean_absolute_error: 0.4598 - val_soft_acc: 0.5707\n",
      "Epoch 1388/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3462 - mean_absolute_error: 0.3462 - soft_acc: 0.7933 - val_loss: 0.4556 - val_mean_absolute_error: 0.4556 - val_soft_acc: 0.6036\n",
      "Epoch 1389/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3332 - mean_absolute_error: 0.3332 - soft_acc: 0.7550 - val_loss: 0.4379 - val_mean_absolute_error: 0.4379 - val_soft_acc: 0.5879\n",
      "Epoch 1390/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3068 - mean_absolute_error: 0.3068 - soft_acc: 0.7889 - val_loss: 0.4308 - val_mean_absolute_error: 0.4308 - val_soft_acc: 0.6264\n",
      "Epoch 1391/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2910 - mean_absolute_error: 0.2910 - soft_acc: 0.8378 - val_loss: 0.4657 - val_mean_absolute_error: 0.4657 - val_soft_acc: 0.6193\n",
      "Epoch 1392/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3157 - mean_absolute_error: 0.3157 - soft_acc: 0.7778 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827 - val_soft_acc: 0.5807\n",
      "Epoch 1393/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2999 - mean_absolute_error: 0.2999 - soft_acc: 0.8267 - val_loss: 0.4660 - val_mean_absolute_error: 0.4660 - val_soft_acc: 0.4936\n",
      "Epoch 1394/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2937 - mean_absolute_error: 0.2937 - soft_acc: 0.8361 - val_loss: 0.4545 - val_mean_absolute_error: 0.4545 - val_soft_acc: 0.5629\n",
      "Epoch 1395/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2849 - mean_absolute_error: 0.2849 - soft_acc: 0.7978 - val_loss: 0.4791 - val_mean_absolute_error: 0.4791 - val_soft_acc: 0.5757\n",
      "Epoch 1396/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2902 - mean_absolute_error: 0.2902 - soft_acc: 0.8083 - val_loss: 0.4798 - val_mean_absolute_error: 0.4798 - val_soft_acc: 0.5071\n",
      "Epoch 1397/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2745 - mean_absolute_error: 0.2745 - soft_acc: 0.8289 - val_loss: 0.4538 - val_mean_absolute_error: 0.4538 - val_soft_acc: 0.5779\n",
      "Epoch 1398/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2770 - mean_absolute_error: 0.2770 - soft_acc: 0.8144 - val_loss: 0.4743 - val_mean_absolute_error: 0.4743 - val_soft_acc: 0.5886\n",
      "Epoch 1399/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3150 - mean_absolute_error: 0.3150 - soft_acc: 0.8006 - val_loss: 0.4816 - val_mean_absolute_error: 0.4816 - val_soft_acc: 0.4636\n",
      "Epoch 1400/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3065 - mean_absolute_error: 0.3065 - soft_acc: 0.8139 - val_loss: 0.4584 - val_mean_absolute_error: 0.4584 - val_soft_acc: 0.6264\n",
      "Epoch 1401/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3140 - mean_absolute_error: 0.3140 - soft_acc: 0.8039 - val_loss: 0.4683 - val_mean_absolute_error: 0.4683 - val_soft_acc: 0.6136\n",
      "Epoch 1402/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2893 - mean_absolute_error: 0.2893 - soft_acc: 0.8272 - val_loss: 0.5406 - val_mean_absolute_error: 0.5406 - val_soft_acc: 0.5814\n",
      "Epoch 1403/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3881 - mean_absolute_error: 0.3881 - soft_acc: 0.6444 - val_loss: 0.4700 - val_mean_absolute_error: 0.4700 - val_soft_acc: 0.5679\n",
      "Epoch 1404/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3643 - mean_absolute_error: 0.3643 - soft_acc: 0.7439 - val_loss: 0.5052 - val_mean_absolute_error: 0.5052 - val_soft_acc: 0.5229\n",
      "Epoch 1405/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 23us/sample - loss: 0.3494 - mean_absolute_error: 0.3494 - soft_acc: 0.7200 - val_loss: 0.4906 - val_mean_absolute_error: 0.4906 - val_soft_acc: 0.5886\n",
      "Epoch 1406/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3134 - mean_absolute_error: 0.3134 - soft_acc: 0.7906 - val_loss: 0.4836 - val_mean_absolute_error: 0.4836 - val_soft_acc: 0.5579\n",
      "Epoch 1407/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2890 - mean_absolute_error: 0.2890 - soft_acc: 0.8189 - val_loss: 0.4364 - val_mean_absolute_error: 0.4364 - val_soft_acc: 0.5957\n",
      "Epoch 1408/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2596 - mean_absolute_error: 0.2596 - soft_acc: 0.8400 - val_loss: 0.4332 - val_mean_absolute_error: 0.4332 - val_soft_acc: 0.5879\n",
      "Epoch 1409/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2655 - mean_absolute_error: 0.2655 - soft_acc: 0.8633 - val_loss: 0.4608 - val_mean_absolute_error: 0.4608 - val_soft_acc: 0.6293\n",
      "Epoch 1410/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3064 - mean_absolute_error: 0.3064 - soft_acc: 0.7728 - val_loss: 0.4586 - val_mean_absolute_error: 0.4586 - val_soft_acc: 0.5979\n",
      "Epoch 1411/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3212 - mean_absolute_error: 0.3212 - soft_acc: 0.7906 - val_loss: 0.5248 - val_mean_absolute_error: 0.5248 - val_soft_acc: 0.5714\n",
      "Epoch 1412/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3084 - mean_absolute_error: 0.3084 - soft_acc: 0.8017 - val_loss: 0.4668 - val_mean_absolute_error: 0.4668 - val_soft_acc: 0.6114\n",
      "Epoch 1413/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2657 - mean_absolute_error: 0.2657 - soft_acc: 0.8561 - val_loss: 0.4588 - val_mean_absolute_error: 0.4588 - val_soft_acc: 0.6036\n",
      "Epoch 1414/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2584 - mean_absolute_error: 0.2584 - soft_acc: 0.8333 - val_loss: 0.4623 - val_mean_absolute_error: 0.4623 - val_soft_acc: 0.5964\n",
      "Epoch 1415/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2543 - mean_absolute_error: 0.2543 - soft_acc: 0.8522 - val_loss: 0.4589 - val_mean_absolute_error: 0.4589 - val_soft_acc: 0.6193\n",
      "Epoch 1416/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2478 - mean_absolute_error: 0.2478 - soft_acc: 0.8683 - val_loss: 0.4646 - val_mean_absolute_error: 0.4646 - val_soft_acc: 0.5729\n",
      "Epoch 1417/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2739 - mean_absolute_error: 0.2739 - soft_acc: 0.8650 - val_loss: 0.4527 - val_mean_absolute_error: 0.4527 - val_soft_acc: 0.5600\n",
      "Epoch 1418/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2537 - mean_absolute_error: 0.2537 - soft_acc: 0.8489 - val_loss: 0.4825 - val_mean_absolute_error: 0.4825 - val_soft_acc: 0.5529\n",
      "Epoch 1419/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2835 - mean_absolute_error: 0.2835 - soft_acc: 0.8200 - val_loss: 0.5106 - val_mean_absolute_error: 0.5106 - val_soft_acc: 0.5064\n",
      "Epoch 1420/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3048 - mean_absolute_error: 0.3048 - soft_acc: 0.7883 - val_loss: 0.4955 - val_mean_absolute_error: 0.4955 - val_soft_acc: 0.5529\n",
      "Epoch 1421/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3319 - mean_absolute_error: 0.3319 - soft_acc: 0.8067 - val_loss: 0.4991 - val_mean_absolute_error: 0.4991 - val_soft_acc: 0.5914\n",
      "Epoch 1422/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.3519 - mean_absolute_error: 0.3519 - soft_acc: 0.7539 - val_loss: 0.4895 - val_mean_absolute_error: 0.4895 - val_soft_acc: 0.5271\n",
      "Epoch 1423/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3326 - mean_absolute_error: 0.3326 - soft_acc: 0.7528 - val_loss: 0.5077 - val_mean_absolute_error: 0.5077 - val_soft_acc: 0.5379\n",
      "Epoch 1424/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3600 - mean_absolute_error: 0.3600 - soft_acc: 0.7639 - val_loss: 0.4721 - val_mean_absolute_error: 0.4721 - val_soft_acc: 0.6014\n",
      "Epoch 1425/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3396 - mean_absolute_error: 0.3396 - soft_acc: 0.7600 - val_loss: 0.4754 - val_mean_absolute_error: 0.4754 - val_soft_acc: 0.6014\n",
      "Epoch 1426/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2976 - mean_absolute_error: 0.2976 - soft_acc: 0.7994 - val_loss: 0.4508 - val_mean_absolute_error: 0.4508 - val_soft_acc: 0.6386\n",
      "Epoch 1427/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3098 - mean_absolute_error: 0.3098 - soft_acc: 0.8050 - val_loss: 0.5157 - val_mean_absolute_error: 0.5157 - val_soft_acc: 0.5786\n",
      "Epoch 1428/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2961 - mean_absolute_error: 0.2961 - soft_acc: 0.7600 - val_loss: 0.4815 - val_mean_absolute_error: 0.4815 - val_soft_acc: 0.5914\n",
      "Epoch 1429/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2646 - mean_absolute_error: 0.2646 - soft_acc: 0.8383 - val_loss: 0.4964 - val_mean_absolute_error: 0.4964 - val_soft_acc: 0.5479\n",
      "Epoch 1430/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2851 - mean_absolute_error: 0.2851 - soft_acc: 0.8017 - val_loss: 0.4923 - val_mean_absolute_error: 0.4923 - val_soft_acc: 0.6629\n",
      "Epoch 1431/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3176 - mean_absolute_error: 0.3176 - soft_acc: 0.7856 - val_loss: 0.4572 - val_mean_absolute_error: 0.4572 - val_soft_acc: 0.6114\n",
      "Epoch 1432/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2805 - mean_absolute_error: 0.2805 - soft_acc: 0.7822 - val_loss: 0.4833 - val_mean_absolute_error: 0.4833 - val_soft_acc: 0.5607\n",
      "Epoch 1433/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2831 - mean_absolute_error: 0.2831 - soft_acc: 0.8067 - val_loss: 0.4833 - val_mean_absolute_error: 0.4833 - val_soft_acc: 0.5271\n",
      "Epoch 1434/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3176 - mean_absolute_error: 0.3176 - soft_acc: 0.7889 - val_loss: 0.4672 - val_mean_absolute_error: 0.4672 - val_soft_acc: 0.5500\n",
      "Epoch 1435/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2584 - mean_absolute_error: 0.2584 - soft_acc: 0.8306 - val_loss: 0.4830 - val_mean_absolute_error: 0.4830 - val_soft_acc: 0.5443\n",
      "Epoch 1436/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2599 - mean_absolute_error: 0.2599 - soft_acc: 0.8333 - val_loss: 0.4803 - val_mean_absolute_error: 0.4803 - val_soft_acc: 0.5657\n",
      "Epoch 1437/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2782 - mean_absolute_error: 0.2782 - soft_acc: 0.8117 - val_loss: 0.5025 - val_mean_absolute_error: 0.5025 - val_soft_acc: 0.5607\n",
      "Epoch 1438/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3237 - mean_absolute_error: 0.3237 - soft_acc: 0.7789 - val_loss: 0.4874 - val_mean_absolute_error: 0.4874 - val_soft_acc: 0.6064\n",
      "Epoch 1439/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2745 - mean_absolute_error: 0.2745 - soft_acc: 0.8372 - val_loss: 0.4674 - val_mean_absolute_error: 0.4674 - val_soft_acc: 0.5986\n",
      "Epoch 1440/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2611 - mean_absolute_error: 0.2611 - soft_acc: 0.8633 - val_loss: 0.4722 - val_mean_absolute_error: 0.4722 - val_soft_acc: 0.5571\n",
      "Epoch 1441/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2835 - mean_absolute_error: 0.2835 - soft_acc: 0.8411 - val_loss: 0.4745 - val_mean_absolute_error: 0.4745 - val_soft_acc: 0.5864\n",
      "Epoch 1442/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2922 - mean_absolute_error: 0.2922 - soft_acc: 0.8239 - val_loss: 0.4662 - val_mean_absolute_error: 0.4662 - val_soft_acc: 0.6164\n",
      "Epoch 1443/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2819 - mean_absolute_error: 0.2819 - soft_acc: 0.8117 - val_loss: 0.4797 - val_mean_absolute_error: 0.4797 - val_soft_acc: 0.5707\n",
      "Epoch 1444/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2617 - mean_absolute_error: 0.2617 - soft_acc: 0.8678 - val_loss: 0.4710 - val_mean_absolute_error: 0.4710 - val_soft_acc: 0.5557\n",
      "Epoch 1445/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2518 - mean_absolute_error: 0.2518 - soft_acc: 0.8800 - val_loss: 0.4955 - val_mean_absolute_error: 0.4955 - val_soft_acc: 0.5914\n",
      "Epoch 1446/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.3043 - mean_absolute_error: 0.3043 - soft_acc: 0.7939 - val_loss: 0.4688 - val_mean_absolute_error: 0.4688 - val_soft_acc: 0.6193\n",
      "Epoch 1447/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2632 - mean_absolute_error: 0.2632 - soft_acc: 0.8389 - val_loss: 0.4872 - val_mean_absolute_error: 0.4872 - val_soft_acc: 0.5557\n",
      "Epoch 1448/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2565 - mean_absolute_error: 0.2565 - soft_acc: 0.8800 - val_loss: 0.4677 - val_mean_absolute_error: 0.4677 - val_soft_acc: 0.6600\n",
      "Epoch 1449/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2650 - mean_absolute_error: 0.2650 - soft_acc: 0.8578 - val_loss: 0.4501 - val_mean_absolute_error: 0.4501 - val_soft_acc: 0.6386\n",
      "Epoch 1450/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2605 - mean_absolute_error: 0.2605 - soft_acc: 0.8539 - val_loss: 0.5024 - val_mean_absolute_error: 0.5024 - val_soft_acc: 0.5857\n",
      "Epoch 1451/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2593 - mean_absolute_error: 0.2593 - soft_acc: 0.8617 - val_loss: 0.5175 - val_mean_absolute_error: 0.5175 - val_soft_acc: 0.5707\n",
      "Epoch 1452/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2729 - mean_absolute_error: 0.2729 - soft_acc: 0.8283 - val_loss: 0.5131 - val_mean_absolute_error: 0.5131 - val_soft_acc: 0.5964\n",
      "Epoch 1453/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2618 - mean_absolute_error: 0.2618 - soft_acc: 0.8406 - val_loss: 0.4759 - val_mean_absolute_error: 0.4759 - val_soft_acc: 0.6521\n",
      "Epoch 1454/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3298 - mean_absolute_error: 0.3298 - soft_acc: 0.7789 - val_loss: 0.5075 - val_mean_absolute_error: 0.5075 - val_soft_acc: 0.5586\n",
      "Epoch 1455/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2591 - mean_absolute_error: 0.2591 - soft_acc: 0.8561 - val_loss: 0.4620 - val_mean_absolute_error: 0.4620 - val_soft_acc: 0.5671\n",
      "Epoch 1456/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2513 - mean_absolute_error: 0.2513 - soft_acc: 0.8400 - val_loss: 0.4940 - val_mean_absolute_error: 0.4940 - val_soft_acc: 0.5450\n",
      "Epoch 1457/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2629 - mean_absolute_error: 0.2629 - soft_acc: 0.8544 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732 - val_soft_acc: 0.5936\n",
      "Epoch 1458/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2995 - mean_absolute_error: 0.2995 - soft_acc: 0.8067 - val_loss: 0.4855 - val_mean_absolute_error: 0.4855 - val_soft_acc: 0.5193\n",
      "Epoch 1459/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2504 - mean_absolute_error: 0.2504 - soft_acc: 0.8417 - val_loss: 0.4985 - val_mean_absolute_error: 0.4985 - val_soft_acc: 0.6143\n",
      "Epoch 1460/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2576 - mean_absolute_error: 0.2576 - soft_acc: 0.8489 - val_loss: 0.5204 - val_mean_absolute_error: 0.5204 - val_soft_acc: 0.5886\n",
      "Epoch 1461/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3193 - mean_absolute_error: 0.3193 - soft_acc: 0.7989 - val_loss: 0.4882 - val_mean_absolute_error: 0.4882 - val_soft_acc: 0.6086\n",
      "Epoch 1462/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2876 - mean_absolute_error: 0.2876 - soft_acc: 0.7894 - val_loss: 0.4956 - val_mean_absolute_error: 0.4956 - val_soft_acc: 0.5450\n",
      "Epoch 1463/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3240 - mean_absolute_error: 0.3240 - soft_acc: 0.7522 - val_loss: 0.4600 - val_mean_absolute_error: 0.4600 - val_soft_acc: 0.5986\n",
      "Epoch 1464/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3868 - mean_absolute_error: 0.3868 - soft_acc: 0.7039 - val_loss: 0.4695 - val_mean_absolute_error: 0.4695 - val_soft_acc: 0.5986\n",
      "Epoch 1465/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3657 - mean_absolute_error: 0.3657 - soft_acc: 0.7028 - val_loss: 0.5019 - val_mean_absolute_error: 0.5019 - val_soft_acc: 0.5221\n",
      "Epoch 1466/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3020 - mean_absolute_error: 0.3020 - soft_acc: 0.7917 - val_loss: 0.5374 - val_mean_absolute_error: 0.5374 - val_soft_acc: 0.5121\n",
      "Epoch 1467/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3222 - mean_absolute_error: 0.3222 - soft_acc: 0.7972 - val_loss: 0.4747 - val_mean_absolute_error: 0.4747 - val_soft_acc: 0.6321\n",
      "Epoch 1468/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3183 - mean_absolute_error: 0.3183 - soft_acc: 0.7856 - val_loss: 0.4555 - val_mean_absolute_error: 0.4555 - val_soft_acc: 0.6471\n",
      "Epoch 1469/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2976 - mean_absolute_error: 0.2976 - soft_acc: 0.7756 - val_loss: 0.5230 - val_mean_absolute_error: 0.5230 - val_soft_acc: 0.5150\n",
      "Epoch 1470/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2875 - mean_absolute_error: 0.2875 - soft_acc: 0.8256 - val_loss: 0.5008 - val_mean_absolute_error: 0.5008 - val_soft_acc: 0.6371\n",
      "Epoch 1471/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2762 - mean_absolute_error: 0.2762 - soft_acc: 0.8372 - val_loss: 0.5157 - val_mean_absolute_error: 0.5157 - val_soft_acc: 0.6214\n",
      "Epoch 1472/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2807 - mean_absolute_error: 0.2807 - soft_acc: 0.8222 - val_loss: 0.4855 - val_mean_absolute_error: 0.4855 - val_soft_acc: 0.5879\n",
      "Epoch 1473/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2586 - mean_absolute_error: 0.2586 - soft_acc: 0.8628 - val_loss: 0.5376 - val_mean_absolute_error: 0.5376 - val_soft_acc: 0.5557\n",
      "Epoch 1474/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3248 - mean_absolute_error: 0.3248 - soft_acc: 0.8128 - val_loss: 0.4877 - val_mean_absolute_error: 0.4877 - val_soft_acc: 0.5807\n",
      "Epoch 1475/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2604 - mean_absolute_error: 0.2604 - soft_acc: 0.8267 - val_loss: 0.5116 - val_mean_absolute_error: 0.5116 - val_soft_acc: 0.5864\n",
      "Epoch 1476/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.3063 - mean_absolute_error: 0.3063 - soft_acc: 0.8078 - val_loss: 0.4647 - val_mean_absolute_error: 0.4647 - val_soft_acc: 0.7000\n",
      "Epoch 1477/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2493 - mean_absolute_error: 0.2493 - soft_acc: 0.8661 - val_loss: 0.4576 - val_mean_absolute_error: 0.4576 - val_soft_acc: 0.6314\n",
      "Epoch 1478/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2610 - mean_absolute_error: 0.2610 - soft_acc: 0.8544 - val_loss: 0.4825 - val_mean_absolute_error: 0.4825 - val_soft_acc: 0.6471\n",
      "Epoch 1479/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3126 - mean_absolute_error: 0.3126 - soft_acc: 0.8056 - val_loss: 0.4586 - val_mean_absolute_error: 0.4586 - val_soft_acc: 0.6236\n",
      "Epoch 1480/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3358 - mean_absolute_error: 0.3358 - soft_acc: 0.7633 - val_loss: 0.5042 - val_mean_absolute_error: 0.5042 - val_soft_acc: 0.5757\n",
      "Epoch 1481/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3025 - mean_absolute_error: 0.3025 - soft_acc: 0.7883 - val_loss: 0.4780 - val_mean_absolute_error: 0.4780 - val_soft_acc: 0.5836\n",
      "Epoch 1482/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2752 - mean_absolute_error: 0.2752 - soft_acc: 0.8294 - val_loss: 0.4922 - val_mean_absolute_error: 0.4922 - val_soft_acc: 0.5736\n",
      "Epoch 1483/3000\n",
      "512/512 [==============================] - 0s 46us/sample - loss: 0.2547 - mean_absolute_error: 0.2547 - soft_acc: 0.8539 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095 - val_soft_acc: 0.5500\n",
      "Epoch 1484/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3257 - mean_absolute_error: 0.3257 - soft_acc: 0.7978 - val_loss: 0.5144 - val_mean_absolute_error: 0.5144 - val_soft_acc: 0.5071\n",
      "Epoch 1485/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2971 - mean_absolute_error: 0.2971 - soft_acc: 0.8083 - val_loss: 0.4675 - val_mean_absolute_error: 0.4675 - val_soft_acc: 0.6143\n",
      "Epoch 1486/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2486 - mean_absolute_error: 0.2486 - soft_acc: 0.8578 - val_loss: 0.4765 - val_mean_absolute_error: 0.4765 - val_soft_acc: 0.5857\n",
      "Epoch 1487/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3173 - mean_absolute_error: 0.3173 - soft_acc: 0.7683 - val_loss: 0.4907 - val_mean_absolute_error: 0.4907 - val_soft_acc: 0.6293\n",
      "Epoch 1488/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3464 - mean_absolute_error: 0.3464 - soft_acc: 0.7861 - val_loss: 0.5010 - val_mean_absolute_error: 0.5010 - val_soft_acc: 0.5250\n",
      "Epoch 1489/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2907 - mean_absolute_error: 0.2907 - soft_acc: 0.7944 - val_loss: 0.4701 - val_mean_absolute_error: 0.4701 - val_soft_acc: 0.6164\n",
      "Epoch 1490/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3022 - mean_absolute_error: 0.3022 - soft_acc: 0.7933 - val_loss: 0.4747 - val_mean_absolute_error: 0.4747 - val_soft_acc: 0.5571\n",
      "Epoch 1491/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3773 - mean_absolute_error: 0.3773 - soft_acc: 0.7489 - val_loss: 0.4872 - val_mean_absolute_error: 0.4872 - val_soft_acc: 0.5936\n",
      "Epoch 1492/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3051 - mean_absolute_error: 0.3051 - soft_acc: 0.8017 - val_loss: 0.4610 - val_mean_absolute_error: 0.4610 - val_soft_acc: 0.6364\n",
      "Epoch 1493/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3177 - mean_absolute_error: 0.3177 - soft_acc: 0.7811 - val_loss: 0.6004 - val_mean_absolute_error: 0.6004 - val_soft_acc: 0.4236\n",
      "Epoch 1494/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.6081 - mean_absolute_error: 0.6081 - soft_acc: 0.5283 - val_loss: 0.5380 - val_mean_absolute_error: 0.5380 - val_soft_acc: 0.5407\n",
      "Epoch 1495/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3671 - mean_absolute_error: 0.3671 - soft_acc: 0.7350 - val_loss: 0.4868 - val_mean_absolute_error: 0.4868 - val_soft_acc: 0.5629\n",
      "Epoch 1496/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3750 - mean_absolute_error: 0.3750 - soft_acc: 0.7200 - val_loss: 0.4720 - val_mean_absolute_error: 0.4720 - val_soft_acc: 0.6114\n",
      "Epoch 1497/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3172 - mean_absolute_error: 0.3172 - soft_acc: 0.8122 - val_loss: 0.7470 - val_mean_absolute_error: 0.7470 - val_soft_acc: 0.3457\n",
      "Epoch 1498/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.5053 - mean_absolute_error: 0.5053 - soft_acc: 0.6422 - val_loss: 0.4924 - val_mean_absolute_error: 0.4924 - val_soft_acc: 0.6193\n",
      "Epoch 1499/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4281 - mean_absolute_error: 0.4281 - soft_acc: 0.7022 - val_loss: 0.4757 - val_mean_absolute_error: 0.4757 - val_soft_acc: 0.5729\n",
      "Epoch 1500/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3306 - mean_absolute_error: 0.3306 - soft_acc: 0.7906 - val_loss: 0.4596 - val_mean_absolute_error: 0.4596 - val_soft_acc: 0.6086\n",
      "Epoch 1501/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3159 - mean_absolute_error: 0.3159 - soft_acc: 0.8094 - val_loss: 0.5027 - val_mean_absolute_error: 0.5027 - val_soft_acc: 0.5936\n",
      "Epoch 1502/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3033 - mean_absolute_error: 0.3033 - soft_acc: 0.7950 - val_loss: 0.4534 - val_mean_absolute_error: 0.4534 - val_soft_acc: 0.6779\n",
      "Epoch 1503/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2664 - mean_absolute_error: 0.2664 - soft_acc: 0.8422 - val_loss: 0.4648 - val_mean_absolute_error: 0.4648 - val_soft_acc: 0.5729\n",
      "Epoch 1504/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2882 - mean_absolute_error: 0.2882 - soft_acc: 0.8294 - val_loss: 0.4727 - val_mean_absolute_error: 0.4727 - val_soft_acc: 0.6243\n",
      "Epoch 1505/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2735 - mean_absolute_error: 0.2735 - soft_acc: 0.8117 - val_loss: 0.4696 - val_mean_absolute_error: 0.4696 - val_soft_acc: 0.5736\n",
      "Epoch 1506/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2702 - mean_absolute_error: 0.2702 - soft_acc: 0.8078 - val_loss: 0.4698 - val_mean_absolute_error: 0.4698 - val_soft_acc: 0.6136\n",
      "Epoch 1507/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2742 - mean_absolute_error: 0.2742 - soft_acc: 0.8322 - val_loss: 0.5104 - val_mean_absolute_error: 0.5104 - val_soft_acc: 0.5221\n",
      "Epoch 1508/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2839 - mean_absolute_error: 0.2839 - soft_acc: 0.8261 - val_loss: 0.4917 - val_mean_absolute_error: 0.4917 - val_soft_acc: 0.6243\n",
      "Epoch 1509/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3297 - mean_absolute_error: 0.3297 - soft_acc: 0.7833 - val_loss: 0.4869 - val_mean_absolute_error: 0.4869 - val_soft_acc: 0.5071\n",
      "Epoch 1510/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2999 - mean_absolute_error: 0.2999 - soft_acc: 0.8039 - val_loss: 0.4461 - val_mean_absolute_error: 0.4461 - val_soft_acc: 0.5550\n",
      "Epoch 1511/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2633 - mean_absolute_error: 0.2633 - soft_acc: 0.8522 - val_loss: 0.4871 - val_mean_absolute_error: 0.4871 - val_soft_acc: 0.5886\n",
      "Epoch 1512/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2585 - mean_absolute_error: 0.2585 - soft_acc: 0.8572 - val_loss: 0.4752 - val_mean_absolute_error: 0.4752 - val_soft_acc: 0.5886\n",
      "Epoch 1513/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2612 - mean_absolute_error: 0.2612 - soft_acc: 0.8422 - val_loss: 0.5044 - val_mean_absolute_error: 0.5044 - val_soft_acc: 0.4764\n",
      "Epoch 1514/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2928 - mean_absolute_error: 0.2928 - soft_acc: 0.8306 - val_loss: 0.4694 - val_mean_absolute_error: 0.4694 - val_soft_acc: 0.6271\n",
      "Epoch 1515/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2952 - mean_absolute_error: 0.2952 - soft_acc: 0.8244 - val_loss: 0.4674 - val_mean_absolute_error: 0.4674 - val_soft_acc: 0.5986\n",
      "Epoch 1516/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2900 - mean_absolute_error: 0.2900 - soft_acc: 0.8361 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.5736\n",
      "Epoch 1517/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3012 - mean_absolute_error: 0.3012 - soft_acc: 0.8311 - val_loss: 0.4911 - val_mean_absolute_error: 0.4911 - val_soft_acc: 0.5193\n",
      "Epoch 1518/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2851 - mean_absolute_error: 0.2851 - soft_acc: 0.8394 - val_loss: 0.5028 - val_mean_absolute_error: 0.5028 - val_soft_acc: 0.5814\n",
      "Epoch 1519/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2826 - mean_absolute_error: 0.2826 - soft_acc: 0.8172 - val_loss: 0.5242 - val_mean_absolute_error: 0.5242 - val_soft_acc: 0.6093\n",
      "Epoch 1520/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3285 - mean_absolute_error: 0.3285 - soft_acc: 0.7544 - val_loss: 0.5130 - val_mean_absolute_error: 0.5130 - val_soft_acc: 0.5071\n",
      "Epoch 1521/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3117 - mean_absolute_error: 0.3117 - soft_acc: 0.7667 - val_loss: 0.5002 - val_mean_absolute_error: 0.5002 - val_soft_acc: 0.5650\n",
      "Epoch 1522/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3297 - mean_absolute_error: 0.3297 - soft_acc: 0.8067 - val_loss: 0.5031 - val_mean_absolute_error: 0.5031 - val_soft_acc: 0.5529\n",
      "Epoch 1523/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2937 - mean_absolute_error: 0.2937 - soft_acc: 0.8222 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827 - val_soft_acc: 0.6093\n",
      "Epoch 1524/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3279 - mean_absolute_error: 0.3279 - soft_acc: 0.7689 - val_loss: 0.4445 - val_mean_absolute_error: 0.4445 - val_soft_acc: 0.5879\n",
      "Epoch 1525/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2632 - mean_absolute_error: 0.2632 - soft_acc: 0.8472 - val_loss: 0.5134 - val_mean_absolute_error: 0.5134 - val_soft_acc: 0.5893\n",
      "Epoch 1526/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2693 - mean_absolute_error: 0.2693 - soft_acc: 0.8478 - val_loss: 0.4899 - val_mean_absolute_error: 0.4899 - val_soft_acc: 0.5829\n",
      "Epoch 1527/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2801 - mean_absolute_error: 0.2801 - soft_acc: 0.8461 - val_loss: 0.4773 - val_mean_absolute_error: 0.4773 - val_soft_acc: 0.5550\n",
      "Epoch 1528/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2654 - mean_absolute_error: 0.2654 - soft_acc: 0.8650 - val_loss: 0.5452 - val_mean_absolute_error: 0.5452 - val_soft_acc: 0.4921\n",
      "Epoch 1529/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3720 - mean_absolute_error: 0.3720 - soft_acc: 0.7317 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.5343\n",
      "Epoch 1530/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3309 - mean_absolute_error: 0.3309 - soft_acc: 0.7772 - val_loss: 0.5291 - val_mean_absolute_error: 0.5291 - val_soft_acc: 0.5307\n",
      "Epoch 1531/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.3255 - mean_absolute_error: 0.3255 - soft_acc: 0.7767 - val_loss: 0.5329 - val_mean_absolute_error: 0.5329 - val_soft_acc: 0.5171\n",
      "Epoch 1532/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3779 - mean_absolute_error: 0.3779 - soft_acc: 0.6867 - val_loss: 0.4950 - val_mean_absolute_error: 0.4950 - val_soft_acc: 0.5757\n",
      "Epoch 1533/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.4258 - mean_absolute_error: 0.4258 - soft_acc: 0.6689 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118 - val_soft_acc: 0.5636\n",
      "Epoch 1534/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3578 - mean_absolute_error: 0.3578 - soft_acc: 0.7661 - val_loss: 0.4684 - val_mean_absolute_error: 0.4684 - val_soft_acc: 0.5679\n",
      "Epoch 1535/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3612 - mean_absolute_error: 0.3612 - soft_acc: 0.7817 - val_loss: 0.5356 - val_mean_absolute_error: 0.5356 - val_soft_acc: 0.4971\n",
      "Epoch 1536/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3308 - mean_absolute_error: 0.3308 - soft_acc: 0.8111 - val_loss: 0.5066 - val_mean_absolute_error: 0.5066 - val_soft_acc: 0.5757\n",
      "Epoch 1537/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3311 - mean_absolute_error: 0.3311 - soft_acc: 0.7578 - val_loss: 0.4552 - val_mean_absolute_error: 0.4552 - val_soft_acc: 0.5500\n",
      "Epoch 1538/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2997 - mean_absolute_error: 0.2997 - soft_acc: 0.8150 - val_loss: 0.4687 - val_mean_absolute_error: 0.4687 - val_soft_acc: 0.6293\n",
      "Epoch 1539/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2854 - mean_absolute_error: 0.2854 - soft_acc: 0.8083 - val_loss: 0.4810 - val_mean_absolute_error: 0.4810 - val_soft_acc: 0.5829\n",
      "Epoch 1540/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2894 - mean_absolute_error: 0.2894 - soft_acc: 0.8344 - val_loss: 0.4541 - val_mean_absolute_error: 0.4541 - val_soft_acc: 0.6521\n",
      "Epoch 1541/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2725 - mean_absolute_error: 0.2725 - soft_acc: 0.8167 - val_loss: 0.4231 - val_mean_absolute_error: 0.4231 - val_soft_acc: 0.6714\n",
      "Epoch 1542/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.3067 - mean_absolute_error: 0.3067 - soft_acc: 0.7694 - val_loss: 0.4940 - val_mean_absolute_error: 0.4940 - val_soft_acc: 0.6493\n",
      "Epoch 1543/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3935 - mean_absolute_error: 0.3935 - soft_acc: 0.7133 - val_loss: 0.4868 - val_mean_absolute_error: 0.4868 - val_soft_acc: 0.5857\n",
      "Epoch 1544/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3673 - mean_absolute_error: 0.3673 - soft_acc: 0.7572 - val_loss: 0.5364 - val_mean_absolute_error: 0.5364 - val_soft_acc: 0.5864\n",
      "Epoch 1545/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3842 - mean_absolute_error: 0.3842 - soft_acc: 0.7056 - val_loss: 0.4879 - val_mean_absolute_error: 0.4879 - val_soft_acc: 0.5786\n",
      "Epoch 1546/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3437 - mean_absolute_error: 0.3437 - soft_acc: 0.7656 - val_loss: 0.4819 - val_mean_absolute_error: 0.4819 - val_soft_acc: 0.6086\n",
      "Epoch 1547/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3795 - mean_absolute_error: 0.3795 - soft_acc: 0.7056 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045 - val_soft_acc: 0.5557\n",
      "Epoch 1548/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3061 - mean_absolute_error: 0.3061 - soft_acc: 0.7872 - val_loss: 0.5103 - val_mean_absolute_error: 0.5103 - val_soft_acc: 0.5936\n",
      "Epoch 1549/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2983 - mean_absolute_error: 0.2983 - soft_acc: 0.8383 - val_loss: 0.4522 - val_mean_absolute_error: 0.4522 - val_soft_acc: 0.5907\n",
      "Epoch 1550/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2593 - mean_absolute_error: 0.2593 - soft_acc: 0.8561 - val_loss: 0.4836 - val_mean_absolute_error: 0.4836 - val_soft_acc: 0.5807\n",
      "Epoch 1551/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2573 - mean_absolute_error: 0.2573 - soft_acc: 0.8300 - val_loss: 0.4951 - val_mean_absolute_error: 0.4951 - val_soft_acc: 0.5886\n",
      "Epoch 1552/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2593 - mean_absolute_error: 0.2593 - soft_acc: 0.8528 - val_loss: 0.4687 - val_mean_absolute_error: 0.4687 - val_soft_acc: 0.5350\n",
      "Epoch 1553/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2441 - mean_absolute_error: 0.2441 - soft_acc: 0.8500 - val_loss: 0.4792 - val_mean_absolute_error: 0.4792 - val_soft_acc: 0.5321\n",
      "Epoch 1554/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2446 - mean_absolute_error: 0.2446 - soft_acc: 0.8589 - val_loss: 0.4595 - val_mean_absolute_error: 0.4595 - val_soft_acc: 0.6136\n",
      "Epoch 1555/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2358 - mean_absolute_error: 0.2358 - soft_acc: 0.8728 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841 - val_soft_acc: 0.5043\n",
      "Epoch 1556/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2433 - mean_absolute_error: 0.2433 - soft_acc: 0.8800 - val_loss: 0.4794 - val_mean_absolute_error: 0.4794 - val_soft_acc: 0.6400\n",
      "Epoch 1557/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2657 - mean_absolute_error: 0.2657 - soft_acc: 0.8544 - val_loss: 0.5080 - val_mean_absolute_error: 0.5080 - val_soft_acc: 0.5429\n",
      "Epoch 1558/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2953 - mean_absolute_error: 0.2953 - soft_acc: 0.8067 - val_loss: 0.4704 - val_mean_absolute_error: 0.4704 - val_soft_acc: 0.5450\n",
      "Epoch 1559/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3017 - mean_absolute_error: 0.3017 - soft_acc: 0.7928 - val_loss: 0.4813 - val_mean_absolute_error: 0.4813 - val_soft_acc: 0.5629\n",
      "Epoch 1560/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2605 - mean_absolute_error: 0.2605 - soft_acc: 0.8628 - val_loss: 0.4523 - val_mean_absolute_error: 0.4523 - val_soft_acc: 0.6057\n",
      "Epoch 1561/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2583 - mean_absolute_error: 0.2583 - soft_acc: 0.8594 - val_loss: 0.4732 - val_mean_absolute_error: 0.4732 - val_soft_acc: 0.5807\n",
      "Epoch 1562/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2401 - mean_absolute_error: 0.2401 - soft_acc: 0.8817 - val_loss: 0.4760 - val_mean_absolute_error: 0.4760 - val_soft_acc: 0.6293\n",
      "Epoch 1563/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2692 - mean_absolute_error: 0.2692 - soft_acc: 0.8444 - val_loss: 0.4806 - val_mean_absolute_error: 0.4806 - val_soft_acc: 0.5686\n",
      "Epoch 1564/3000\n",
      "512/512 [==============================] - 0s 54us/sample - loss: 0.2368 - mean_absolute_error: 0.2368 - soft_acc: 0.8861 - val_loss: 0.4715 - val_mean_absolute_error: 0.4715 - val_soft_acc: 0.6007\n",
      "Epoch 1565/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2800 - mean_absolute_error: 0.2800 - soft_acc: 0.8444 - val_loss: 0.4905 - val_mean_absolute_error: 0.4905 - val_soft_acc: 0.5886\n",
      "Epoch 1566/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2456 - mean_absolute_error: 0.2456 - soft_acc: 0.8311 - val_loss: 0.4705 - val_mean_absolute_error: 0.4705 - val_soft_acc: 0.6064\n",
      "Epoch 1567/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2697 - mean_absolute_error: 0.2697 - soft_acc: 0.8200 - val_loss: 0.4864 - val_mean_absolute_error: 0.4864 - val_soft_acc: 0.5500\n",
      "Epoch 1568/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2584 - mean_absolute_error: 0.2584 - soft_acc: 0.8300 - val_loss: 0.4622 - val_mean_absolute_error: 0.4622 - val_soft_acc: 0.5107\n",
      "Epoch 1569/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2422 - mean_absolute_error: 0.2422 - soft_acc: 0.8761 - val_loss: 0.4551 - val_mean_absolute_error: 0.4551 - val_soft_acc: 0.6114\n",
      "Epoch 1570/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2468 - mean_absolute_error: 0.2468 - soft_acc: 0.8433 - val_loss: 0.4505 - val_mean_absolute_error: 0.4505 - val_soft_acc: 0.5679\n",
      "Epoch 1571/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2363 - mean_absolute_error: 0.2363 - soft_acc: 0.8917 - val_loss: 0.4779 - val_mean_absolute_error: 0.4779 - val_soft_acc: 0.5600\n",
      "Epoch 1572/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2428 - mean_absolute_error: 0.2428 - soft_acc: 0.8794 - val_loss: 0.4656 - val_mean_absolute_error: 0.4656 - val_soft_acc: 0.6171\n",
      "Epoch 1573/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2316 - mean_absolute_error: 0.2316 - soft_acc: 0.8794 - val_loss: 0.4744 - val_mean_absolute_error: 0.4744 - val_soft_acc: 0.5371\n",
      "Epoch 1574/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2222 - mean_absolute_error: 0.2222 - soft_acc: 0.8933 - val_loss: 0.4892 - val_mean_absolute_error: 0.4892 - val_soft_acc: 0.5986\n",
      "Epoch 1575/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2563 - mean_absolute_error: 0.2563 - soft_acc: 0.8611 - val_loss: 0.4779 - val_mean_absolute_error: 0.4779 - val_soft_acc: 0.5757\n",
      "Epoch 1576/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2532 - mean_absolute_error: 0.2532 - soft_acc: 0.8511 - val_loss: 0.4574 - val_mean_absolute_error: 0.4574 - val_soft_acc: 0.5650\n",
      "Epoch 1577/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2603 - mean_absolute_error: 0.2603 - soft_acc: 0.8333 - val_loss: 0.4942 - val_mean_absolute_error: 0.4942 - val_soft_acc: 0.6043\n",
      "Epoch 1578/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2542 - mean_absolute_error: 0.2542 - soft_acc: 0.8456 - val_loss: 0.4716 - val_mean_absolute_error: 0.4716 - val_soft_acc: 0.5864\n",
      "Epoch 1579/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2190 - mean_absolute_error: 0.2190 - soft_acc: 0.8828 - val_loss: 0.4907 - val_mean_absolute_error: 0.4907 - val_soft_acc: 0.5479\n",
      "Epoch 1580/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2801 - mean_absolute_error: 0.2801 - soft_acc: 0.8600 - val_loss: 0.4765 - val_mean_absolute_error: 0.4765 - val_soft_acc: 0.5886\n",
      "Epoch 1581/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2442 - mean_absolute_error: 0.2442 - soft_acc: 0.8622 - val_loss: 0.4610 - val_mean_absolute_error: 0.4610 - val_soft_acc: 0.5936\n",
      "Epoch 1582/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2340 - mean_absolute_error: 0.2340 - soft_acc: 0.8656 - val_loss: 0.4898 - val_mean_absolute_error: 0.4898 - val_soft_acc: 0.5164\n",
      "Epoch 1583/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2774 - mean_absolute_error: 0.2774 - soft_acc: 0.8178 - val_loss: 0.5221 - val_mean_absolute_error: 0.5221 - val_soft_acc: 0.5786\n",
      "Epoch 1584/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3767 - mean_absolute_error: 0.3767 - soft_acc: 0.6867 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150 - val_soft_acc: 0.6321\n",
      "Epoch 1585/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.3348 - mean_absolute_error: 0.3348 - soft_acc: 0.7672 - val_loss: 0.4687 - val_mean_absolute_error: 0.4687 - val_soft_acc: 0.5779\n",
      "Epoch 1586/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2665 - mean_absolute_error: 0.2665 - soft_acc: 0.8389 - val_loss: 0.4561 - val_mean_absolute_error: 0.4561 - val_soft_acc: 0.5857\n",
      "Epoch 1587/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2599 - mean_absolute_error: 0.2599 - soft_acc: 0.8683 - val_loss: 0.4621 - val_mean_absolute_error: 0.4621 - val_soft_acc: 0.5500\n",
      "Epoch 1588/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2287 - mean_absolute_error: 0.2287 - soft_acc: 0.8839 - val_loss: 0.4552 - val_mean_absolute_error: 0.4552 - val_soft_acc: 0.6014\n",
      "Epoch 1589/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2391 - mean_absolute_error: 0.2391 - soft_acc: 0.8883 - val_loss: 0.4618 - val_mean_absolute_error: 0.4618 - val_soft_acc: 0.5879\n",
      "Epoch 1590/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2480 - mean_absolute_error: 0.2480 - soft_acc: 0.8456 - val_loss: 0.5122 - val_mean_absolute_error: 0.5122 - val_soft_acc: 0.5221\n",
      "Epoch 1591/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2558 - mean_absolute_error: 0.2558 - soft_acc: 0.8494 - val_loss: 0.4931 - val_mean_absolute_error: 0.4931 - val_soft_acc: 0.5500\n",
      "Epoch 1592/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.2664 - mean_absolute_error: 0.2664 - soft_acc: 0.86 - 0s 41us/sample - loss: 0.2572 - mean_absolute_error: 0.2572 - soft_acc: 0.8389 - val_loss: 0.4616 - val_mean_absolute_error: 0.4616 - val_soft_acc: 0.6007\n",
      "Epoch 1593/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2520 - mean_absolute_error: 0.2520 - soft_acc: 0.8372 - val_loss: 0.5031 - val_mean_absolute_error: 0.5031 - val_soft_acc: 0.5786\n",
      "Epoch 1594/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2421 - mean_absolute_error: 0.2421 - soft_acc: 0.8917 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.5471\n",
      "Epoch 1595/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2374 - mean_absolute_error: 0.2374 - soft_acc: 0.8778 - val_loss: 0.4876 - val_mean_absolute_error: 0.4876 - val_soft_acc: 0.6014\n",
      "Epoch 1596/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2269 - mean_absolute_error: 0.2269 - soft_acc: 0.8911 - val_loss: 0.4938 - val_mean_absolute_error: 0.4938 - val_soft_acc: 0.5707\n",
      "Epoch 1597/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2294 - mean_absolute_error: 0.2294 - soft_acc: 0.8411 - val_loss: 0.4974 - val_mean_absolute_error: 0.4974 - val_soft_acc: 0.6036\n",
      "Epoch 1598/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3020 - mean_absolute_error: 0.3020 - soft_acc: 0.8072 - val_loss: 0.4877 - val_mean_absolute_error: 0.4877 - val_soft_acc: 0.5757\n",
      "Epoch 1599/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3110 - mean_absolute_error: 0.3110 - soft_acc: 0.8167 - val_loss: 0.4703 - val_mean_absolute_error: 0.4703 - val_soft_acc: 0.5707\n",
      "Epoch 1600/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2456 - mean_absolute_error: 0.2456 - soft_acc: 0.8672 - val_loss: 0.4609 - val_mean_absolute_error: 0.4609 - val_soft_acc: 0.5629\n",
      "Epoch 1601/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2616 - mean_absolute_error: 0.2616 - soft_acc: 0.8333 - val_loss: 0.5353 - val_mean_absolute_error: 0.5353 - val_soft_acc: 0.4843\n",
      "Epoch 1602/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2323 - mean_absolute_error: 0.2323 - soft_acc: 0.8828 - val_loss: 0.4634 - val_mean_absolute_error: 0.4634 - val_soft_acc: 0.5829\n",
      "Epoch 1603/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2447 - mean_absolute_error: 0.2447 - soft_acc: 0.8506 - val_loss: 0.4550 - val_mean_absolute_error: 0.4550 - val_soft_acc: 0.6214\n",
      "Epoch 1604/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2437 - mean_absolute_error: 0.2437 - soft_acc: 0.8706 - val_loss: 0.4737 - val_mean_absolute_error: 0.4737 - val_soft_acc: 0.5879\n",
      "Epoch 1605/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2871 - mean_absolute_error: 0.2871 - soft_acc: 0.8033 - val_loss: 0.4851 - val_mean_absolute_error: 0.4851 - val_soft_acc: 0.5779\n",
      "Epoch 1606/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2693 - mean_absolute_error: 0.2693 - soft_acc: 0.8322 - val_loss: 0.5099 - val_mean_absolute_error: 0.5099 - val_soft_acc: 0.5121\n",
      "Epoch 1607/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2884 - mean_absolute_error: 0.2884 - soft_acc: 0.8444 - val_loss: 0.4538 - val_mean_absolute_error: 0.4538 - val_soft_acc: 0.6214\n",
      "Epoch 1608/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2385 - mean_absolute_error: 0.2385 - soft_acc: 0.8694 - val_loss: 0.4892 - val_mean_absolute_error: 0.4892 - val_soft_acc: 0.5886\n",
      "Epoch 1609/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2442 - mean_absolute_error: 0.2442 - soft_acc: 0.8472 - val_loss: 0.4618 - val_mean_absolute_error: 0.4618 - val_soft_acc: 0.6136\n",
      "Epoch 1610/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2775 - mean_absolute_error: 0.2775 - soft_acc: 0.8322 - val_loss: 0.4603 - val_mean_absolute_error: 0.4603 - val_soft_acc: 0.5957\n",
      "Epoch 1611/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3276 - mean_absolute_error: 0.3276 - soft_acc: 0.7789 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150 - val_soft_acc: 0.6014\n",
      "Epoch 1612/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.4629 - mean_absolute_error: 0.4629 - soft_acc: 0.6083 - val_loss: 0.4900 - val_mean_absolute_error: 0.4900 - val_soft_acc: 0.6164\n",
      "Epoch 1613/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.4540 - mean_absolute_error: 0.4540 - soft_acc: 0.6506 - val_loss: 0.5353 - val_mean_absolute_error: 0.5353 - val_soft_acc: 0.5636\n",
      "Epoch 1614/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3768 - mean_absolute_error: 0.3768 - soft_acc: 0.7294 - val_loss: 0.5524 - val_mean_absolute_error: 0.5524 - val_soft_acc: 0.5250\n",
      "Epoch 1615/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.4225 - mean_absolute_error: 0.4225 - soft_acc: 0.6711 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.5786\n",
      "Epoch 1616/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3521 - mean_absolute_error: 0.3521 - soft_acc: 0.7383 - val_loss: 0.5120 - val_mean_absolute_error: 0.5120 - val_soft_acc: 0.5293\n",
      "Epoch 1617/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3029 - mean_absolute_error: 0.3029 - soft_acc: 0.7989 - val_loss: 0.5068 - val_mean_absolute_error: 0.5068 - val_soft_acc: 0.5914\n",
      "Epoch 1618/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2789 - mean_absolute_error: 0.2789 - soft_acc: 0.8511 - val_loss: 0.5166 - val_mean_absolute_error: 0.5166 - val_soft_acc: 0.5300\n",
      "Epoch 1619/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2934 - mean_absolute_error: 0.2934 - soft_acc: 0.8339 - val_loss: 0.5317 - val_mean_absolute_error: 0.5317 - val_soft_acc: 0.5707\n",
      "Epoch 1620/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3767 - mean_absolute_error: 0.3767 - soft_acc: 0.7400 - val_loss: 0.4712 - val_mean_absolute_error: 0.4712 - val_soft_acc: 0.5936\n",
      "Epoch 1621/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3510 - mean_absolute_error: 0.3510 - soft_acc: 0.7722 - val_loss: 0.4947 - val_mean_absolute_error: 0.4947 - val_soft_acc: 0.5729\n",
      "Epoch 1622/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.3177 - mean_absolute_error: 0.3177 - soft_acc: 0.7739 - val_loss: 0.5130 - val_mean_absolute_error: 0.5130 - val_soft_acc: 0.6243\n",
      "Epoch 1623/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.4073 - mean_absolute_error: 0.4073 - soft_acc: 0.7978 - val_loss: 0.5107 - val_mean_absolute_error: 0.5107 - val_soft_acc: 0.4814\n",
      "Epoch 1624/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3064 - mean_absolute_error: 0.3064 - soft_acc: 0.7750 - val_loss: 0.5227 - val_mean_absolute_error: 0.5227 - val_soft_acc: 0.5607\n",
      "Epoch 1625/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3957 - mean_absolute_error: 0.3957 - soft_acc: 0.7078 - val_loss: 0.5189 - val_mean_absolute_error: 0.5189 - val_soft_acc: 0.5000\n",
      "Epoch 1626/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3519 - mean_absolute_error: 0.3519 - soft_acc: 0.7400 - val_loss: 0.4936 - val_mean_absolute_error: 0.4936 - val_soft_acc: 0.6064\n",
      "Epoch 1627/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2954 - mean_absolute_error: 0.2954 - soft_acc: 0.8072 - val_loss: 0.4860 - val_mean_absolute_error: 0.4860 - val_soft_acc: 0.5886\n",
      "Epoch 1628/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2701 - mean_absolute_error: 0.2701 - soft_acc: 0.8322 - val_loss: 0.5109 - val_mean_absolute_error: 0.5109 - val_soft_acc: 0.5629\n",
      "Epoch 1629/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3074 - mean_absolute_error: 0.3074 - soft_acc: 0.7889 - val_loss: 0.4833 - val_mean_absolute_error: 0.4833 - val_soft_acc: 0.5936\n",
      "Epoch 1630/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2907 - mean_absolute_error: 0.2907 - soft_acc: 0.8467 - val_loss: 0.4548 - val_mean_absolute_error: 0.4548 - val_soft_acc: 0.5700\n",
      "Epoch 1631/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2537 - mean_absolute_error: 0.2537 - soft_acc: 0.8561 - val_loss: 0.4892 - val_mean_absolute_error: 0.4892 - val_soft_acc: 0.6193\n",
      "Epoch 1632/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3118 - mean_absolute_error: 0.3118 - soft_acc: 0.8128 - val_loss: 0.5426 - val_mean_absolute_error: 0.5426 - val_soft_acc: 0.6071\n",
      "Epoch 1633/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.4544 - mean_absolute_error: 0.4544 - soft_acc: 0.6644 - val_loss: 0.5522 - val_mean_absolute_error: 0.5522 - val_soft_acc: 0.5143\n",
      "Epoch 1634/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.3034 - mean_absolute_error: 0.3034 - soft_acc: 0.8394 - val_loss: 0.5500 - val_mean_absolute_error: 0.5500 - val_soft_acc: 0.5536\n",
      "Epoch 1635/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3427 - mean_absolute_error: 0.3427 - soft_acc: 0.7711 - val_loss: 0.5018 - val_mean_absolute_error: 0.5018 - val_soft_acc: 0.5936\n",
      "Epoch 1636/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2755 - mean_absolute_error: 0.2755 - soft_acc: 0.8206 - val_loss: 0.5632 - val_mean_absolute_error: 0.5632 - val_soft_acc: 0.5021\n",
      "Epoch 1637/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.3046 - mean_absolute_error: 0.3046 - soft_acc: 0.8283 - val_loss: 0.5007 - val_mean_absolute_error: 0.5007 - val_soft_acc: 0.5479\n",
      "Epoch 1638/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2788 - mean_absolute_error: 0.2788 - soft_acc: 0.8267 - val_loss: 0.4613 - val_mean_absolute_error: 0.4613 - val_soft_acc: 0.7136\n",
      "Epoch 1639/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3431 - mean_absolute_error: 0.3431 - soft_acc: 0.7961 - val_loss: 0.4896 - val_mean_absolute_error: 0.4896 - val_soft_acc: 0.5557\n",
      "Epoch 1640/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2920 - mean_absolute_error: 0.2920 - soft_acc: 0.8428 - val_loss: 0.4748 - val_mean_absolute_error: 0.4748 - val_soft_acc: 0.6064\n",
      "Epoch 1641/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2652 - mean_absolute_error: 0.2652 - soft_acc: 0.8339 - val_loss: 0.4845 - val_mean_absolute_error: 0.4845 - val_soft_acc: 0.5221\n",
      "Epoch 1642/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2753 - mean_absolute_error: 0.2753 - soft_acc: 0.8150 - val_loss: 0.4835 - val_mean_absolute_error: 0.4835 - val_soft_acc: 0.6114\n",
      "Epoch 1643/3000\n",
      "512/512 [==============================] - 0s 11us/sample - loss: 0.2555 - mean_absolute_error: 0.2555 - soft_acc: 0.8644 - val_loss: 0.4860 - val_mean_absolute_error: 0.4860 - val_soft_acc: 0.5864\n",
      "Epoch 1644/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2680 - mean_absolute_error: 0.2680 - soft_acc: 0.8483 - val_loss: 0.4990 - val_mean_absolute_error: 0.4990 - val_soft_acc: 0.5907\n",
      "Epoch 1645/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3564 - mean_absolute_error: 0.3564 - soft_acc: 0.7367 - val_loss: 0.5416 - val_mean_absolute_error: 0.5416 - val_soft_acc: 0.4407\n",
      "Epoch 1646/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3053 - mean_absolute_error: 0.3053 - soft_acc: 0.7872 - val_loss: 0.5347 - val_mean_absolute_error: 0.5347 - val_soft_acc: 0.5221\n",
      "Epoch 1647/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2778 - mean_absolute_error: 0.2778 - soft_acc: 0.8028 - val_loss: 0.5581 - val_mean_absolute_error: 0.5581 - val_soft_acc: 0.5357\n",
      "Epoch 1648/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3004 - mean_absolute_error: 0.3004 - soft_acc: 0.7983 - val_loss: 0.5749 - val_mean_absolute_error: 0.5749 - val_soft_acc: 0.5357\n",
      "Epoch 1649/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2786 - mean_absolute_error: 0.2786 - soft_acc: 0.8306 - val_loss: 0.4834 - val_mean_absolute_error: 0.4834 - val_soft_acc: 0.5550\n",
      "Epoch 1650/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2726 - mean_absolute_error: 0.2726 - soft_acc: 0.8011 - val_loss: 0.4690 - val_mean_absolute_error: 0.4690 - val_soft_acc: 0.5600\n",
      "Epoch 1651/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2559 - mean_absolute_error: 0.2559 - soft_acc: 0.8322 - val_loss: 0.4746 - val_mean_absolute_error: 0.4746 - val_soft_acc: 0.5350\n",
      "Epoch 1652/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2521 - mean_absolute_error: 0.2521 - soft_acc: 0.8611 - val_loss: 0.4756 - val_mean_absolute_error: 0.4756 - val_soft_acc: 0.5421\n",
      "Epoch 1653/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2462 - mean_absolute_error: 0.2462 - soft_acc: 0.8711 - val_loss: 0.4778 - val_mean_absolute_error: 0.4778 - val_soft_acc: 0.5679\n",
      "Epoch 1654/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2369 - mean_absolute_error: 0.2369 - soft_acc: 0.8778 - val_loss: 0.4754 - val_mean_absolute_error: 0.4754 - val_soft_acc: 0.6093\n",
      "Epoch 1655/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2319 - mean_absolute_error: 0.2319 - soft_acc: 0.8572 - val_loss: 0.4744 - val_mean_absolute_error: 0.4744 - val_soft_acc: 0.6343\n",
      "Epoch 1656/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2596 - mean_absolute_error: 0.2596 - soft_acc: 0.8406 - val_loss: 0.4859 - val_mean_absolute_error: 0.4859 - val_soft_acc: 0.5214\n",
      "Epoch 1657/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2380 - mean_absolute_error: 0.2380 - soft_acc: 0.8489 - val_loss: 0.4702 - val_mean_absolute_error: 0.4702 - val_soft_acc: 0.5700\n",
      "Epoch 1658/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2271 - mean_absolute_error: 0.2271 - soft_acc: 0.8744 - val_loss: 0.5011 - val_mean_absolute_error: 0.5011 - val_soft_acc: 0.5686\n",
      "Epoch 1659/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2551 - mean_absolute_error: 0.2551 - soft_acc: 0.8239 - val_loss: 0.5056 - val_mean_absolute_error: 0.5056 - val_soft_acc: 0.5579\n",
      "Epoch 1660/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2853 - mean_absolute_error: 0.2853 - soft_acc: 0.8483 - val_loss: 0.5037 - val_mean_absolute_error: 0.5037 - val_soft_acc: 0.5986\n",
      "Epoch 1661/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2723 - mean_absolute_error: 0.2723 - soft_acc: 0.8483 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150 - val_soft_acc: 0.5229\n",
      "Epoch 1662/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2471 - mean_absolute_error: 0.2471 - soft_acc: 0.8333 - val_loss: 0.4609 - val_mean_absolute_error: 0.4609 - val_soft_acc: 0.5679\n",
      "Epoch 1663/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2396 - mean_absolute_error: 0.2396 - soft_acc: 0.8744 - val_loss: 0.4802 - val_mean_absolute_error: 0.4802 - val_soft_acc: 0.5757\n",
      "Epoch 1664/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2496 - mean_absolute_error: 0.2496 - soft_acc: 0.8611 - val_loss: 0.5329 - val_mean_absolute_error: 0.5329 - val_soft_acc: 0.4821\n",
      "Epoch 1665/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2597 - mean_absolute_error: 0.2597 - soft_acc: 0.8628 - val_loss: 0.5151 - val_mean_absolute_error: 0.5151 - val_soft_acc: 0.5421\n",
      "Epoch 1666/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3275 - mean_absolute_error: 0.3275 - soft_acc: 0.7733 - val_loss: 0.5039 - val_mean_absolute_error: 0.5039 - val_soft_acc: 0.5786\n",
      "Epoch 1667/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3107 - mean_absolute_error: 0.3107 - soft_acc: 0.7711 - val_loss: 0.4851 - val_mean_absolute_error: 0.4851 - val_soft_acc: 0.6171\n",
      "Epoch 1668/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2399 - mean_absolute_error: 0.2399 - soft_acc: 0.8811 - val_loss: 0.5089 - val_mean_absolute_error: 0.5089 - val_soft_acc: 0.4964\n",
      "Epoch 1669/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2410 - mean_absolute_error: 0.2410 - soft_acc: 0.8694 - val_loss: 0.5044 - val_mean_absolute_error: 0.5044 - val_soft_acc: 0.5664\n",
      "Epoch 1670/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2408 - mean_absolute_error: 0.2408 - soft_acc: 0.8689 - val_loss: 0.4741 - val_mean_absolute_error: 0.4741 - val_soft_acc: 0.6471\n",
      "Epoch 1671/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 18us/sample - loss: 0.3062 - mean_absolute_error: 0.3062 - soft_acc: 0.7694 - val_loss: 0.5203 - val_mean_absolute_error: 0.5203 - val_soft_acc: 0.5329\n",
      "Epoch 1672/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3006 - mean_absolute_error: 0.3006 - soft_acc: 0.8133 - val_loss: 0.4825 - val_mean_absolute_error: 0.4825 - val_soft_acc: 0.6214\n",
      "Epoch 1673/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2858 - mean_absolute_error: 0.2858 - soft_acc: 0.8156 - val_loss: 0.5471 - val_mean_absolute_error: 0.5471 - val_soft_acc: 0.5457\n",
      "Epoch 1674/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3124 - mean_absolute_error: 0.3124 - soft_acc: 0.7939 - val_loss: 0.5076 - val_mean_absolute_error: 0.5076 - val_soft_acc: 0.5579\n",
      "Epoch 1675/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2862 - mean_absolute_error: 0.2862 - soft_acc: 0.7933 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841 - val_soft_acc: 0.5550\n",
      "Epoch 1676/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.3426 - mean_absolute_error: 0.3426 - soft_acc: 0.7128 - val_loss: 0.4889 - val_mean_absolute_error: 0.4889 - val_soft_acc: 0.5836\n",
      "Epoch 1677/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3302 - mean_absolute_error: 0.3302 - soft_acc: 0.7772 - val_loss: 0.5009 - val_mean_absolute_error: 0.5009 - val_soft_acc: 0.5579\n",
      "Epoch 1678/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3352 - mean_absolute_error: 0.3352 - soft_acc: 0.7872 - val_loss: 0.4998 - val_mean_absolute_error: 0.4998 - val_soft_acc: 0.5914\n",
      "Epoch 1679/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3660 - mean_absolute_error: 0.3660 - soft_acc: 0.7267 - val_loss: 0.5310 - val_mean_absolute_error: 0.5310 - val_soft_acc: 0.6400\n",
      "Epoch 1680/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.3215 - mean_absolute_error: 0.3215 - soft_acc: 0.8061 - val_loss: 0.4981 - val_mean_absolute_error: 0.4981 - val_soft_acc: 0.5500\n",
      "Epoch 1681/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2544 - mean_absolute_error: 0.2544 - soft_acc: 0.8194 - val_loss: 0.5068 - val_mean_absolute_error: 0.5068 - val_soft_acc: 0.5193\n",
      "Epoch 1682/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2649 - mean_absolute_error: 0.2649 - soft_acc: 0.8817 - val_loss: 0.4674 - val_mean_absolute_error: 0.4674 - val_soft_acc: 0.5857\n",
      "Epoch 1683/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2401 - mean_absolute_error: 0.2401 - soft_acc: 0.8661 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827 - val_soft_acc: 0.5964\n",
      "Epoch 1684/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2349 - mean_absolute_error: 0.2349 - soft_acc: 0.8639 - val_loss: 0.4660 - val_mean_absolute_error: 0.4660 - val_soft_acc: 0.6043\n",
      "Epoch 1685/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2366 - mean_absolute_error: 0.2366 - soft_acc: 0.8656 - val_loss: 0.4819 - val_mean_absolute_error: 0.4819 - val_soft_acc: 0.5836\n",
      "Epoch 1686/3000\n",
      "512/512 [==============================] - 0s 53us/sample - loss: 0.2255 - mean_absolute_error: 0.2255 - soft_acc: 0.8794 - val_loss: 0.4582 - val_mean_absolute_error: 0.4582 - val_soft_acc: 0.6393\n",
      "Epoch 1687/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2613 - mean_absolute_error: 0.2613 - soft_acc: 0.8578 - val_loss: 0.4870 - val_mean_absolute_error: 0.4870 - val_soft_acc: 0.5886\n",
      "Epoch 1688/3000\n",
      "512/512 [==============================] - 0s 50us/sample - loss: 0.2535 - mean_absolute_error: 0.2535 - soft_acc: 0.8572 - val_loss: 0.5515 - val_mean_absolute_error: 0.5515 - val_soft_acc: 0.5479\n",
      "Epoch 1689/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.5178 - mean_absolute_error: 0.5178 - soft_acc: 0.5856 - val_loss: 0.6229 - val_mean_absolute_error: 0.6229 - val_soft_acc: 0.5079\n",
      "Epoch 1690/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3762 - mean_absolute_error: 0.3762 - soft_acc: 0.7517 - val_loss: 0.5324 - val_mean_absolute_error: 0.5324 - val_soft_acc: 0.5221\n",
      "Epoch 1691/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3222 - mean_absolute_error: 0.3222 - soft_acc: 0.7944 - val_loss: 0.4934 - val_mean_absolute_error: 0.4934 - val_soft_acc: 0.6321\n",
      "Epoch 1692/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2814 - mean_absolute_error: 0.2814 - soft_acc: 0.8328 - val_loss: 0.5013 - val_mean_absolute_error: 0.5013 - val_soft_acc: 0.5350\n",
      "Epoch 1693/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2758 - mean_absolute_error: 0.2758 - soft_acc: 0.8283 - val_loss: 0.5004 - val_mean_absolute_error: 0.5004 - val_soft_acc: 0.5250\n",
      "Epoch 1694/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2496 - mean_absolute_error: 0.2496 - soft_acc: 0.8606 - val_loss: 0.4919 - val_mean_absolute_error: 0.4919 - val_soft_acc: 0.5279\n",
      "Epoch 1695/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2820 - mean_absolute_error: 0.2820 - soft_acc: 0.8433 - val_loss: 0.5122 - val_mean_absolute_error: 0.5122 - val_soft_acc: 0.5707\n",
      "Epoch 1696/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3572 - mean_absolute_error: 0.3572 - soft_acc: 0.7494 - val_loss: 0.5418 - val_mean_absolute_error: 0.5418 - val_soft_acc: 0.5171\n",
      "Epoch 1697/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.4083 - mean_absolute_error: 0.4083 - soft_acc: 0.6483 - val_loss: 0.5253 - val_mean_absolute_error: 0.5253 - val_soft_acc: 0.5021\n",
      "Epoch 1698/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3204 - mean_absolute_error: 0.3204 - soft_acc: 0.7633 - val_loss: 0.5088 - val_mean_absolute_error: 0.5088 - val_soft_acc: 0.5836\n",
      "Epoch 1699/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2797 - mean_absolute_error: 0.2797 - soft_acc: 0.8083 - val_loss: 0.5457 - val_mean_absolute_error: 0.5457 - val_soft_acc: 0.5121\n",
      "Epoch 1700/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2506 - mean_absolute_error: 0.2506 - soft_acc: 0.8717 - val_loss: 0.4797 - val_mean_absolute_error: 0.4797 - val_soft_acc: 0.5957\n",
      "Epoch 1701/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2391 - mean_absolute_error: 0.2391 - soft_acc: 0.8950 - val_loss: 0.5053 - val_mean_absolute_error: 0.5053 - val_soft_acc: 0.5429\n",
      "Epoch 1702/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2271 - mean_absolute_error: 0.2271 - soft_acc: 0.8911 - val_loss: 0.4679 - val_mean_absolute_error: 0.4679 - val_soft_acc: 0.6343\n",
      "Epoch 1703/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2375 - mean_absolute_error: 0.2375 - soft_acc: 0.8661 - val_loss: 0.4966 - val_mean_absolute_error: 0.4966 - val_soft_acc: 0.5936\n",
      "Epoch 1704/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2587 - mean_absolute_error: 0.2587 - soft_acc: 0.8389 - val_loss: 0.5796 - val_mean_absolute_error: 0.5796 - val_soft_acc: 0.5050\n",
      "Epoch 1705/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2659 - mean_absolute_error: 0.2659 - soft_acc: 0.8700 - val_loss: 0.4998 - val_mean_absolute_error: 0.4998 - val_soft_acc: 0.5471\n",
      "Epoch 1706/3000\n",
      "512/512 [==============================] - 0s 9us/sample - loss: 0.2278 - mean_absolute_error: 0.2278 - soft_acc: 0.8861 - val_loss: 0.4894 - val_mean_absolute_error: 0.4894 - val_soft_acc: 0.5450\n",
      "Epoch 1707/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2603 - mean_absolute_error: 0.2603 - soft_acc: 0.8339 - val_loss: 0.4883 - val_mean_absolute_error: 0.4883 - val_soft_acc: 0.5479\n",
      "Epoch 1708/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2238 - mean_absolute_error: 0.2238 - soft_acc: 0.8633 - val_loss: 0.4847 - val_mean_absolute_error: 0.4847 - val_soft_acc: 0.6014\n",
      "Epoch 1709/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2501 - mean_absolute_error: 0.2501 - soft_acc: 0.8506 - val_loss: 0.4871 - val_mean_absolute_error: 0.4871 - val_soft_acc: 0.6571\n",
      "Epoch 1710/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2769 - mean_absolute_error: 0.2769 - soft_acc: 0.8339 - val_loss: 0.5262 - val_mean_absolute_error: 0.5262 - val_soft_acc: 0.5557\n",
      "Epoch 1711/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2416 - mean_absolute_error: 0.2416 - soft_acc: 0.8761 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841 - val_soft_acc: 0.6114\n",
      "Epoch 1712/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2573 - mean_absolute_error: 0.2573 - soft_acc: 0.8433 - val_loss: 0.4709 - val_mean_absolute_error: 0.4709 - val_soft_acc: 0.5471\n",
      "Epoch 1713/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2317 - mean_absolute_error: 0.2317 - soft_acc: 0.8483 - val_loss: 0.4880 - val_mean_absolute_error: 0.4880 - val_soft_acc: 0.6014\n",
      "Epoch 1714/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2384 - mean_absolute_error: 0.2384 - soft_acc: 0.8828 - val_loss: 0.5019 - val_mean_absolute_error: 0.5019 - val_soft_acc: 0.5857\n",
      "Epoch 1715/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2727 - mean_absolute_error: 0.2727 - soft_acc: 0.8500 - val_loss: 0.5328 - val_mean_absolute_error: 0.5328 - val_soft_acc: 0.5536\n",
      "Epoch 1716/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.3164 - mean_absolute_error: 0.3164 - soft_acc: 0.8183 - val_loss: 0.4705 - val_mean_absolute_error: 0.4705 - val_soft_acc: 0.6136\n",
      "Epoch 1717/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2886 - mean_absolute_error: 0.2886 - soft_acc: 0.8089 - val_loss: 0.5217 - val_mean_absolute_error: 0.5217 - val_soft_acc: 0.5350\n",
      "Epoch 1718/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2827 - mean_absolute_error: 0.2827 - soft_acc: 0.8233 - val_loss: 0.5336 - val_mean_absolute_error: 0.5336 - val_soft_acc: 0.5250\n",
      "Epoch 1719/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2902 - mean_absolute_error: 0.2902 - soft_acc: 0.8106 - val_loss: 0.4963 - val_mean_absolute_error: 0.4963 - val_soft_acc: 0.6164\n",
      "Epoch 1720/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2657 - mean_absolute_error: 0.2657 - soft_acc: 0.8567 - val_loss: 0.5371 - val_mean_absolute_error: 0.5371 - val_soft_acc: 0.5793\n",
      "Epoch 1721/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2409 - mean_absolute_error: 0.2409 - soft_acc: 0.8606 - val_loss: 0.5160 - val_mean_absolute_error: 0.5160 - val_soft_acc: 0.5600\n",
      "Epoch 1722/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3045 - mean_absolute_error: 0.3045 - soft_acc: 0.7989 - val_loss: 0.5171 - val_mean_absolute_error: 0.5171 - val_soft_acc: 0.5529\n",
      "Epoch 1723/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3490 - mean_absolute_error: 0.3490 - soft_acc: 0.7728 - val_loss: 0.4951 - val_mean_absolute_error: 0.4951 - val_soft_acc: 0.5864\n",
      "Epoch 1724/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2756 - mean_absolute_error: 0.2756 - soft_acc: 0.8356 - val_loss: 0.5296 - val_mean_absolute_error: 0.5296 - val_soft_acc: 0.5607\n",
      "Epoch 1725/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2870 - mean_absolute_error: 0.2870 - soft_acc: 0.8483 - val_loss: 0.4974 - val_mean_absolute_error: 0.4974 - val_soft_acc: 0.5200\n",
      "Epoch 1726/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2518 - mean_absolute_error: 0.2518 - soft_acc: 0.8661 - val_loss: 0.4673 - val_mean_absolute_error: 0.4673 - val_soft_acc: 0.5629\n",
      "Epoch 1727/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2458 - mean_absolute_error: 0.2458 - soft_acc: 0.8683 - val_loss: 0.4903 - val_mean_absolute_error: 0.4903 - val_soft_acc: 0.5629\n",
      "Epoch 1728/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2350 - mean_absolute_error: 0.2350 - soft_acc: 0.8933 - val_loss: 0.5256 - val_mean_absolute_error: 0.5256 - val_soft_acc: 0.5350\n",
      "Epoch 1729/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2249 - mean_absolute_error: 0.2249 - soft_acc: 0.8928 - val_loss: 0.5076 - val_mean_absolute_error: 0.5076 - val_soft_acc: 0.5321\n",
      "Epoch 1730/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2136 - mean_absolute_error: 0.2136 - soft_acc: 0.9033 - val_loss: 0.4905 - val_mean_absolute_error: 0.4905 - val_soft_acc: 0.5714\n",
      "Epoch 1731/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1991 - mean_absolute_error: 0.1991 - soft_acc: 0.9150 - val_loss: 0.4667 - val_mean_absolute_error: 0.4667 - val_soft_acc: 0.5629\n",
      "Epoch 1732/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2050 - mean_absolute_error: 0.2050 - soft_acc: 0.8872 - val_loss: 0.4970 - val_mean_absolute_error: 0.4970 - val_soft_acc: 0.5943\n",
      "Epoch 1733/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2141 - mean_absolute_error: 0.2141 - soft_acc: 0.8856 - val_loss: 0.4978 - val_mean_absolute_error: 0.4978 - val_soft_acc: 0.5964\n",
      "Epoch 1734/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2219 - mean_absolute_error: 0.2219 - soft_acc: 0.8928 - val_loss: 0.4728 - val_mean_absolute_error: 0.4728 - val_soft_acc: 0.6036\n",
      "Epoch 1735/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2319 - mean_absolute_error: 0.2319 - soft_acc: 0.8206 - val_loss: 0.4993 - val_mean_absolute_error: 0.4993 - val_soft_acc: 0.6143\n",
      "Epoch 1736/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2409 - mean_absolute_error: 0.2409 - soft_acc: 0.8417 - val_loss: 0.5200 - val_mean_absolute_error: 0.5200 - val_soft_acc: 0.5429\n",
      "Epoch 1737/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2302 - mean_absolute_error: 0.2302 - soft_acc: 0.8589 - val_loss: 0.5340 - val_mean_absolute_error: 0.5340 - val_soft_acc: 0.5579\n",
      "Epoch 1738/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3203 - mean_absolute_error: 0.3203 - soft_acc: 0.7750 - val_loss: 0.4829 - val_mean_absolute_error: 0.4829 - val_soft_acc: 0.5707\n",
      "Epoch 1739/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3016 - mean_absolute_error: 0.3016 - soft_acc: 0.8161 - val_loss: 0.4707 - val_mean_absolute_error: 0.4707 - val_soft_acc: 0.6193\n",
      "Epoch 1740/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2987 - mean_absolute_error: 0.2987 - soft_acc: 0.7761 - val_loss: 0.5061 - val_mean_absolute_error: 0.5061 - val_soft_acc: 0.6014\n",
      "Epoch 1741/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2525 - mean_absolute_error: 0.2525 - soft_acc: 0.8433 - val_loss: 0.5212 - val_mean_absolute_error: 0.5212 - val_soft_acc: 0.5171\n",
      "Epoch 1742/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2718 - mean_absolute_error: 0.2718 - soft_acc: 0.8306 - val_loss: 0.5097 - val_mean_absolute_error: 0.5097 - val_soft_acc: 0.5121\n",
      "Epoch 1743/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2445 - mean_absolute_error: 0.2445 - soft_acc: 0.8300 - val_loss: 0.4716 - val_mean_absolute_error: 0.4716 - val_soft_acc: 0.6600\n",
      "Epoch 1744/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2216 - mean_absolute_error: 0.2216 - soft_acc: 0.8983 - val_loss: 0.5202 - val_mean_absolute_error: 0.5202 - val_soft_acc: 0.4586\n",
      "Epoch 1745/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2541 - mean_absolute_error: 0.2541 - soft_acc: 0.8211 - val_loss: 0.4646 - val_mean_absolute_error: 0.4646 - val_soft_acc: 0.6136\n",
      "Epoch 1746/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2384 - mean_absolute_error: 0.2384 - soft_acc: 0.8267 - val_loss: 0.4951 - val_mean_absolute_error: 0.4951 - val_soft_acc: 0.5529\n",
      "Epoch 1747/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2129 - mean_absolute_error: 0.2129 - soft_acc: 0.8894 - val_loss: 0.5013 - val_mean_absolute_error: 0.5013 - val_soft_acc: 0.5629\n",
      "Epoch 1748/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2159 - mean_absolute_error: 0.2159 - soft_acc: 0.8961 - val_loss: 0.4837 - val_mean_absolute_error: 0.4837 - val_soft_acc: 0.5864\n",
      "Epoch 1749/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2373 - mean_absolute_error: 0.2373 - soft_acc: 0.8744 - val_loss: 0.5114 - val_mean_absolute_error: 0.5114 - val_soft_acc: 0.5471\n",
      "Epoch 1750/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2446 - mean_absolute_error: 0.2446 - soft_acc: 0.8517 - val_loss: 0.4962 - val_mean_absolute_error: 0.4962 - val_soft_acc: 0.5707\n",
      "Epoch 1751/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2411 - mean_absolute_error: 0.2411 - soft_acc: 0.8917 - val_loss: 0.4778 - val_mean_absolute_error: 0.4778 - val_soft_acc: 0.6264\n",
      "Epoch 1752/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2140 - mean_absolute_error: 0.2140 - soft_acc: 0.8722 - val_loss: 0.5244 - val_mean_absolute_error: 0.5244 - val_soft_acc: 0.5436\n",
      "Epoch 1753/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2270 - mean_absolute_error: 0.2270 - soft_acc: 0.8739 - val_loss: 0.4960 - val_mean_absolute_error: 0.4960 - val_soft_acc: 0.5836\n",
      "Epoch 1754/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2494 - mean_absolute_error: 0.2494 - soft_acc: 0.8711 - val_loss: 0.5356 - val_mean_absolute_error: 0.5356 - val_soft_acc: 0.5707\n",
      "Epoch 1755/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2557 - mean_absolute_error: 0.2557 - soft_acc: 0.8322 - val_loss: 0.4992 - val_mean_absolute_error: 0.4992 - val_soft_acc: 0.5550\n",
      "Epoch 1756/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2380 - mean_absolute_error: 0.2380 - soft_acc: 0.8733 - val_loss: 0.5154 - val_mean_absolute_error: 0.5154 - val_soft_acc: 0.5629\n",
      "Epoch 1757/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2483 - mean_absolute_error: 0.2483 - soft_acc: 0.8611 - val_loss: 0.4969 - val_mean_absolute_error: 0.4969 - val_soft_acc: 0.5914\n",
      "Epoch 1758/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2315 - mean_absolute_error: 0.2315 - soft_acc: 0.8639 - val_loss: 0.5816 - val_mean_absolute_error: 0.5816 - val_soft_acc: 0.5536\n",
      "Epoch 1759/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.2480 - mean_absolute_error: 0.2480 - soft_acc: 0.8817 - val_loss: 0.5650 - val_mean_absolute_error: 0.5650 - val_soft_acc: 0.5379\n",
      "Epoch 1760/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2390 - mean_absolute_error: 0.2390 - soft_acc: 0.8572 - val_loss: 0.5318 - val_mean_absolute_error: 0.5318 - val_soft_acc: 0.5914\n",
      "Epoch 1761/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.3630 - mean_absolute_error: 0.3630 - soft_acc: 0.69 - 0s 41us/sample - loss: 0.3472 - mean_absolute_error: 0.3472 - soft_acc: 0.7567 - val_loss: 0.4883 - val_mean_absolute_error: 0.4883 - val_soft_acc: 0.6471\n",
      "Epoch 1762/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2694 - mean_absolute_error: 0.2694 - soft_acc: 0.8667 - val_loss: 0.5195 - val_mean_absolute_error: 0.5195 - val_soft_acc: 0.5479\n",
      "Epoch 1763/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2777 - mean_absolute_error: 0.2777 - soft_acc: 0.7961 - val_loss: 0.4702 - val_mean_absolute_error: 0.4702 - val_soft_acc: 0.6036\n",
      "Epoch 1764/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2361 - mean_absolute_error: 0.2361 - soft_acc: 0.8900 - val_loss: 0.4760 - val_mean_absolute_error: 0.4760 - val_soft_acc: 0.5550\n",
      "Epoch 1765/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2183 - mean_absolute_error: 0.2183 - soft_acc: 0.8722 - val_loss: 0.5168 - val_mean_absolute_error: 0.5168 - val_soft_acc: 0.5736\n",
      "Epoch 1766/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2447 - mean_absolute_error: 0.2447 - soft_acc: 0.8800 - val_loss: 0.4865 - val_mean_absolute_error: 0.4865 - val_soft_acc: 0.5786\n",
      "Epoch 1767/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2423 - mean_absolute_error: 0.2423 - soft_acc: 0.8744 - val_loss: 0.4936 - val_mean_absolute_error: 0.4936 - val_soft_acc: 0.5729\n",
      "Epoch 1768/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2817 - mean_absolute_error: 0.2817 - soft_acc: 0.8189 - val_loss: 0.5205 - val_mean_absolute_error: 0.5205 - val_soft_acc: 0.5429\n",
      "Epoch 1769/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2450 - mean_absolute_error: 0.2450 - soft_acc: 0.8750 - val_loss: 0.4589 - val_mean_absolute_error: 0.4589 - val_soft_acc: 0.6393\n",
      "Epoch 1770/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2306 - mean_absolute_error: 0.2306 - soft_acc: 0.8606 - val_loss: 0.5145 - val_mean_absolute_error: 0.5145 - val_soft_acc: 0.5100\n",
      "Epoch 1771/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2471 - mean_absolute_error: 0.2471 - soft_acc: 0.8356 - val_loss: 0.4980 - val_mean_absolute_error: 0.4980 - val_soft_acc: 0.6036\n",
      "Epoch 1772/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2440 - mean_absolute_error: 0.2440 - soft_acc: 0.8383 - val_loss: 0.5333 - val_mean_absolute_error: 0.5333 - val_soft_acc: 0.5886\n",
      "Epoch 1773/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2667 - mean_absolute_error: 0.2667 - soft_acc: 0.8450 - val_loss: 0.4914 - val_mean_absolute_error: 0.4914 - val_soft_acc: 0.6186\n",
      "Epoch 1774/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2569 - mean_absolute_error: 0.2569 - soft_acc: 0.8094 - val_loss: 0.5148 - val_mean_absolute_error: 0.5148 - val_soft_acc: 0.5529\n",
      "Epoch 1775/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2523 - mean_absolute_error: 0.2523 - soft_acc: 0.8583 - val_loss: 0.5293 - val_mean_absolute_error: 0.5293 - val_soft_acc: 0.5550\n",
      "Epoch 1776/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2247 - mean_absolute_error: 0.2247 - soft_acc: 0.8950 - val_loss: 0.4929 - val_mean_absolute_error: 0.4929 - val_soft_acc: 0.5857\n",
      "Epoch 1777/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2414 - mean_absolute_error: 0.2414 - soft_acc: 0.8706 - val_loss: 0.5095 - val_mean_absolute_error: 0.5095 - val_soft_acc: 0.5600\n",
      "Epoch 1778/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2311 - mean_absolute_error: 0.2311 - soft_acc: 0.8617 - val_loss: 0.5268 - val_mean_absolute_error: 0.5268 - val_soft_acc: 0.5271\n",
      "Epoch 1779/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2141 - mean_absolute_error: 0.2141 - soft_acc: 0.9050 - val_loss: 0.5330 - val_mean_absolute_error: 0.5330 - val_soft_acc: 0.5636\n",
      "Epoch 1780/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2076 - mean_absolute_error: 0.2076 - soft_acc: 0.8961 - val_loss: 0.5150 - val_mean_absolute_error: 0.5150 - val_soft_acc: 0.5707\n",
      "Epoch 1781/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2210 - mean_absolute_error: 0.2210 - soft_acc: 0.8822 - val_loss: 0.4931 - val_mean_absolute_error: 0.4931 - val_soft_acc: 0.5600\n",
      "Epoch 1782/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2110 - mean_absolute_error: 0.2110 - soft_acc: 0.8878 - val_loss: 0.5267 - val_mean_absolute_error: 0.5267 - val_soft_acc: 0.5936\n",
      "Epoch 1783/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2175 - mean_absolute_error: 0.2175 - soft_acc: 0.8461 - val_loss: 0.4844 - val_mean_absolute_error: 0.4844 - val_soft_acc: 0.6236\n",
      "Epoch 1784/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2109 - mean_absolute_error: 0.2109 - soft_acc: 0.9078 - val_loss: 0.5045 - val_mean_absolute_error: 0.5045 - val_soft_acc: 0.5807\n",
      "Epoch 1785/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2351 - mean_absolute_error: 0.2351 - soft_acc: 0.8828 - val_loss: 0.4929 - val_mean_absolute_error: 0.4929 - val_soft_acc: 0.5500\n",
      "Epoch 1786/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2392 - mean_absolute_error: 0.2392 - soft_acc: 0.8761 - val_loss: 0.5558 - val_mean_absolute_error: 0.5558 - val_soft_acc: 0.5607\n",
      "Epoch 1787/3000\n",
      "512/512 [==============================] - 0s 47us/sample - loss: 0.3179 - mean_absolute_error: 0.3179 - soft_acc: 0.7411 - val_loss: 0.4868 - val_mean_absolute_error: 0.4868 - val_soft_acc: 0.6164\n",
      "Epoch 1788/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.2991 - mean_absolute_error: 0.2991 - soft_acc: 0.7900 - val_loss: 0.4966 - val_mean_absolute_error: 0.4966 - val_soft_acc: 0.5507\n",
      "Epoch 1789/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.3047 - mean_absolute_error: 0.3047 - soft_acc: 0.8228 - val_loss: 0.5313 - val_mean_absolute_error: 0.5313 - val_soft_acc: 0.5714\n",
      "Epoch 1790/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3083 - mean_absolute_error: 0.3083 - soft_acc: 0.7833 - val_loss: 0.4987 - val_mean_absolute_error: 0.4987 - val_soft_acc: 0.5914\n",
      "Epoch 1791/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2880 - mean_absolute_error: 0.2880 - soft_acc: 0.8022 - val_loss: 0.5087 - val_mean_absolute_error: 0.5087 - val_soft_acc: 0.5221\n",
      "Epoch 1792/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2247 - mean_absolute_error: 0.2247 - soft_acc: 0.8606 - val_loss: 0.4828 - val_mean_absolute_error: 0.4828 - val_soft_acc: 0.6143\n",
      "Epoch 1793/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2117 - mean_absolute_error: 0.2117 - soft_acc: 0.8978 - val_loss: 0.4891 - val_mean_absolute_error: 0.4891 - val_soft_acc: 0.6629\n",
      "Epoch 1794/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2195 - mean_absolute_error: 0.2195 - soft_acc: 0.9000 - val_loss: 0.5200 - val_mean_absolute_error: 0.5200 - val_soft_acc: 0.5686\n",
      "Epoch 1795/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2109 - mean_absolute_error: 0.2109 - soft_acc: 0.9100 - val_loss: 0.4887 - val_mean_absolute_error: 0.4887 - val_soft_acc: 0.5629\n",
      "Epoch 1796/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2272 - mean_absolute_error: 0.2272 - soft_acc: 0.8706 - val_loss: 0.4967 - val_mean_absolute_error: 0.4967 - val_soft_acc: 0.4914\n",
      "Epoch 1797/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2119 - mean_absolute_error: 0.2119 - soft_acc: 0.8872 - val_loss: 0.5061 - val_mean_absolute_error: 0.5061 - val_soft_acc: 0.6200\n",
      "Epoch 1798/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2201 - mean_absolute_error: 0.2201 - soft_acc: 0.8572 - val_loss: 0.5297 - val_mean_absolute_error: 0.5297 - val_soft_acc: 0.5914\n",
      "Epoch 1799/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2096 - mean_absolute_error: 0.2096 - soft_acc: 0.8717 - val_loss: 0.5487 - val_mean_absolute_error: 0.5487 - val_soft_acc: 0.5300\n",
      "Epoch 1800/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2198 - mean_absolute_error: 0.2198 - soft_acc: 0.8950 - val_loss: 0.5183 - val_mean_absolute_error: 0.5183 - val_soft_acc: 0.5479\n",
      "Epoch 1801/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2162 - mean_absolute_error: 0.2162 - soft_acc: 0.9033 - val_loss: 0.5174 - val_mean_absolute_error: 0.5174 - val_soft_acc: 0.6143\n",
      "Epoch 1802/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2136 - mean_absolute_error: 0.2136 - soft_acc: 0.9117 - val_loss: 0.4940 - val_mean_absolute_error: 0.4940 - val_soft_acc: 0.5986\n",
      "Epoch 1803/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2038 - mean_absolute_error: 0.2038 - soft_acc: 0.9044 - val_loss: 0.4983 - val_mean_absolute_error: 0.4983 - val_soft_acc: 0.5679\n",
      "Epoch 1804/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2257 - mean_absolute_error: 0.2257 - soft_acc: 0.8611 - val_loss: 0.5281 - val_mean_absolute_error: 0.5281 - val_soft_acc: 0.5607\n",
      "Epoch 1805/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2587 - mean_absolute_error: 0.2587 - soft_acc: 0.8428 - val_loss: 0.5280 - val_mean_absolute_error: 0.5280 - val_soft_acc: 0.6014\n",
      "Epoch 1806/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.2237 - mean_absolute_error: 0.2237 - soft_acc: 0.90 - 0s 39us/sample - loss: 0.2342 - mean_absolute_error: 0.2342 - soft_acc: 0.8689 - val_loss: 0.5205 - val_mean_absolute_error: 0.5205 - val_soft_acc: 0.5836\n",
      "Epoch 1807/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2236 - mean_absolute_error: 0.2236 - soft_acc: 0.8622 - val_loss: 0.4766 - val_mean_absolute_error: 0.4766 - val_soft_acc: 0.6314\n",
      "Epoch 1808/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2228 - mean_absolute_error: 0.2228 - soft_acc: 0.8928 - val_loss: 0.5078 - val_mean_absolute_error: 0.5078 - val_soft_acc: 0.5371\n",
      "Epoch 1809/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.3440 - mean_absolute_error: 0.3440 - soft_acc: 0.7794 - val_loss: 0.5044 - val_mean_absolute_error: 0.5044 - val_soft_acc: 0.6114\n",
      "Epoch 1810/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2878 - mean_absolute_error: 0.2878 - soft_acc: 0.8211 - val_loss: 0.4862 - val_mean_absolute_error: 0.4862 - val_soft_acc: 0.6136\n",
      "Epoch 1811/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2410 - mean_absolute_error: 0.2410 - soft_acc: 0.8606 - val_loss: 0.4928 - val_mean_absolute_error: 0.4928 - val_soft_acc: 0.5936\n",
      "Epoch 1812/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2246 - mean_absolute_error: 0.2246 - soft_acc: 0.8983 - val_loss: 0.4842 - val_mean_absolute_error: 0.4842 - val_soft_acc: 0.5986\n",
      "Epoch 1813/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2368 - mean_absolute_error: 0.2368 - soft_acc: 0.8783 - val_loss: 0.5233 - val_mean_absolute_error: 0.5233 - val_soft_acc: 0.5557\n",
      "Epoch 1814/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2534 - mean_absolute_error: 0.2534 - soft_acc: 0.8383 - val_loss: 0.4950 - val_mean_absolute_error: 0.4950 - val_soft_acc: 0.5729\n",
      "Epoch 1815/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2362 - mean_absolute_error: 0.2362 - soft_acc: 0.8778 - val_loss: 0.5348 - val_mean_absolute_error: 0.5348 - val_soft_acc: 0.5071\n",
      "Epoch 1816/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2196 - mean_absolute_error: 0.2196 - soft_acc: 0.8822 - val_loss: 0.5070 - val_mean_absolute_error: 0.5070 - val_soft_acc: 0.5757\n",
      "Epoch 1817/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2427 - mean_absolute_error: 0.2427 - soft_acc: 0.8539 - val_loss: 0.4422 - val_mean_absolute_error: 0.4422 - val_soft_acc: 0.6593\n",
      "Epoch 1818/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2395 - mean_absolute_error: 0.2395 - soft_acc: 0.8450 - val_loss: 0.4500 - val_mean_absolute_error: 0.4500 - val_soft_acc: 0.6264\n",
      "Epoch 1819/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2195 - mean_absolute_error: 0.2195 - soft_acc: 0.8778 - val_loss: 0.4698 - val_mean_absolute_error: 0.4698 - val_soft_acc: 0.6493\n",
      "Epoch 1820/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2225 - mean_absolute_error: 0.2225 - soft_acc: 0.8950 - val_loss: 0.5125 - val_mean_absolute_error: 0.5125 - val_soft_acc: 0.5943\n",
      "Epoch 1821/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2581 - mean_absolute_error: 0.2581 - soft_acc: 0.8356 - val_loss: 0.4845 - val_mean_absolute_error: 0.4845 - val_soft_acc: 0.6064\n",
      "Epoch 1822/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2236 - mean_absolute_error: 0.2236 - soft_acc: 0.8483 - val_loss: 0.4724 - val_mean_absolute_error: 0.4724 - val_soft_acc: 0.6243\n",
      "Epoch 1823/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2608 - mean_absolute_error: 0.2608 - soft_acc: 0.8317 - val_loss: 0.4747 - val_mean_absolute_error: 0.4747 - val_soft_acc: 0.6779\n",
      "Epoch 1824/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3333 - mean_absolute_error: 0.3333 - soft_acc: 0.7722 - val_loss: 0.4864 - val_mean_absolute_error: 0.4864 - val_soft_acc: 0.4857\n",
      "Epoch 1825/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2630 - mean_absolute_error: 0.2630 - soft_acc: 0.8378 - val_loss: 0.5550 - val_mean_absolute_error: 0.5550 - val_soft_acc: 0.5657\n",
      "Epoch 1826/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2850 - mean_absolute_error: 0.2850 - soft_acc: 0.8194 - val_loss: 0.4858 - val_mean_absolute_error: 0.4858 - val_soft_acc: 0.5857\n",
      "Epoch 1827/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2316 - mean_absolute_error: 0.2316 - soft_acc: 0.8489 - val_loss: 0.4849 - val_mean_absolute_error: 0.4849 - val_soft_acc: 0.6164\n",
      "Epoch 1828/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2613 - mean_absolute_error: 0.2613 - soft_acc: 0.8389 - val_loss: 0.4680 - val_mean_absolute_error: 0.4680 - val_soft_acc: 0.7079\n",
      "Epoch 1829/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.4680 - mean_absolute_error: 0.4680 - soft_acc: 0.7756 - val_loss: 0.4975 - val_mean_absolute_error: 0.4975 - val_soft_acc: 0.5579\n",
      "Epoch 1830/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2758 - mean_absolute_error: 0.2758 - soft_acc: 0.8250 - val_loss: 0.5548 - val_mean_absolute_error: 0.5548 - val_soft_acc: 0.5357\n",
      "Epoch 1831/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.4164 - mean_absolute_error: 0.4164 - soft_acc: 0.7733 - val_loss: 0.5271 - val_mean_absolute_error: 0.5271 - val_soft_acc: 0.4943\n",
      "Epoch 1832/3000\n",
      "512/512 [==============================] - 0s 21us/sample - loss: 0.3157 - mean_absolute_error: 0.3157 - soft_acc: 0.7783 - val_loss: 0.5111 - val_mean_absolute_error: 0.5111 - val_soft_acc: 0.5429\n",
      "Epoch 1833/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2960 - mean_absolute_error: 0.2960 - soft_acc: 0.8000 - val_loss: 0.4668 - val_mean_absolute_error: 0.4668 - val_soft_acc: 0.6593\n",
      "Epoch 1834/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2983 - mean_absolute_error: 0.2983 - soft_acc: 0.7500 - val_loss: 0.4838 - val_mean_absolute_error: 0.4838 - val_soft_acc: 0.6271\n",
      "Epoch 1835/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2718 - mean_absolute_error: 0.2718 - soft_acc: 0.8228 - val_loss: 0.4960 - val_mean_absolute_error: 0.4960 - val_soft_acc: 0.5500\n",
      "Epoch 1836/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.2583 - mean_absolute_error: 0.2583 - soft_acc: 0.8311 - val_loss: 0.4961 - val_mean_absolute_error: 0.4961 - val_soft_acc: 0.5321\n",
      "Epoch 1837/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2668 - mean_absolute_error: 0.2668 - soft_acc: 0.8211 - val_loss: 0.4977 - val_mean_absolute_error: 0.4977 - val_soft_acc: 0.6093\n",
      "Epoch 1838/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2702 - mean_absolute_error: 0.2702 - soft_acc: 0.8328 - val_loss: 0.5044 - val_mean_absolute_error: 0.5044 - val_soft_acc: 0.6371\n",
      "Epoch 1839/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2857 - mean_absolute_error: 0.2857 - soft_acc: 0.8339 - val_loss: 0.5074 - val_mean_absolute_error: 0.5074 - val_soft_acc: 0.5500\n",
      "Epoch 1840/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.3012 - mean_absolute_error: 0.3012 - soft_acc: 0.8144 - val_loss: 0.5197 - val_mean_absolute_error: 0.5197 - val_soft_acc: 0.5379\n",
      "Epoch 1841/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3307 - mean_absolute_error: 0.3307 - soft_acc: 0.7589 - val_loss: 0.5368 - val_mean_absolute_error: 0.5368 - val_soft_acc: 0.5121\n",
      "Epoch 1842/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2511 - mean_absolute_error: 0.2511 - soft_acc: 0.8489 - val_loss: 0.5232 - val_mean_absolute_error: 0.5232 - val_soft_acc: 0.5371\n",
      "Epoch 1843/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.3179 - mean_absolute_error: 0.3179 - soft_acc: 0.8144 - val_loss: 0.5020 - val_mean_absolute_error: 0.5020 - val_soft_acc: 0.5836\n",
      "Epoch 1844/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.3043 - mean_absolute_error: 0.3043 - soft_acc: 0.7711 - val_loss: 0.4805 - val_mean_absolute_error: 0.4805 - val_soft_acc: 0.6057\n",
      "Epoch 1845/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.5170 - mean_absolute_error: 0.5170 - soft_acc: 0.6589 - val_loss: 0.5400 - val_mean_absolute_error: 0.5400 - val_soft_acc: 0.5507\n",
      "Epoch 1846/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.3777 - mean_absolute_error: 0.3777 - soft_acc: 0.7028 - val_loss: 0.5391 - val_mean_absolute_error: 0.5391 - val_soft_acc: 0.5307\n",
      "Epoch 1847/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.3551 - mean_absolute_error: 0.3551 - soft_acc: 0.7594 - val_loss: 0.4863 - val_mean_absolute_error: 0.4863 - val_soft_acc: 0.6114\n",
      "Epoch 1848/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2838 - mean_absolute_error: 0.2838 - soft_acc: 0.8083 - val_loss: 0.5105 - val_mean_absolute_error: 0.5105 - val_soft_acc: 0.5050\n",
      "Epoch 1849/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2948 - mean_absolute_error: 0.2948 - soft_acc: 0.8106 - val_loss: 0.5157 - val_mean_absolute_error: 0.5157 - val_soft_acc: 0.5943\n",
      "Epoch 1850/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2677 - mean_absolute_error: 0.2677 - soft_acc: 0.8494 - val_loss: 0.5116 - val_mean_absolute_error: 0.5116 - val_soft_acc: 0.5043\n",
      "Epoch 1851/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2736 - mean_absolute_error: 0.2736 - soft_acc: 0.8528 - val_loss: 0.5024 - val_mean_absolute_error: 0.5024 - val_soft_acc: 0.4786\n",
      "Epoch 1852/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2210 - mean_absolute_error: 0.2210 - soft_acc: 0.8722 - val_loss: 0.4888 - val_mean_absolute_error: 0.4888 - val_soft_acc: 0.5629\n",
      "Epoch 1853/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2167 - mean_absolute_error: 0.2167 - soft_acc: 0.9033 - val_loss: 0.4731 - val_mean_absolute_error: 0.4731 - val_soft_acc: 0.5243\n",
      "Epoch 1854/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2256 - mean_absolute_error: 0.2256 - soft_acc: 0.8672 - val_loss: 0.4895 - val_mean_absolute_error: 0.4895 - val_soft_acc: 0.5879\n",
      "Epoch 1855/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2540 - mean_absolute_error: 0.2540 - soft_acc: 0.8678 - val_loss: 0.5137 - val_mean_absolute_error: 0.5137 - val_soft_acc: 0.5043\n",
      "Epoch 1856/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2052 - mean_absolute_error: 0.2052 - soft_acc: 0.8767 - val_loss: 0.4664 - val_mean_absolute_error: 0.4664 - val_soft_acc: 0.5421\n",
      "Epoch 1857/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2151 - mean_absolute_error: 0.2151 - soft_acc: 0.8633 - val_loss: 0.4849 - val_mean_absolute_error: 0.4849 - val_soft_acc: 0.5757\n",
      "Epoch 1858/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2105 - mean_absolute_error: 0.2105 - soft_acc: 0.8839 - val_loss: 0.4770 - val_mean_absolute_error: 0.4770 - val_soft_acc: 0.5650\n",
      "Epoch 1859/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2123 - mean_absolute_error: 0.2123 - soft_acc: 0.8683 - val_loss: 0.4811 - val_mean_absolute_error: 0.4811 - val_soft_acc: 0.5550\n",
      "Epoch 1860/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2405 - mean_absolute_error: 0.2405 - soft_acc: 0.8411 - val_loss: 0.5643 - val_mean_absolute_error: 0.5643 - val_soft_acc: 0.5357\n",
      "Epoch 1861/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.3156 - mean_absolute_error: 0.3156 - soft_acc: 0.7856 - val_loss: 0.5135 - val_mean_absolute_error: 0.5135 - val_soft_acc: 0.6143\n",
      "Epoch 1862/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2232 - mean_absolute_error: 0.2232 - soft_acc: 0.8794 - val_loss: 0.5357 - val_mean_absolute_error: 0.5357 - val_soft_acc: 0.5121\n",
      "Epoch 1863/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2098 - mean_absolute_error: 0.2098 - soft_acc: 0.9061 - val_loss: 0.5139 - val_mean_absolute_error: 0.5139 - val_soft_acc: 0.6250\n",
      "Epoch 1864/3000\n",
      "512/512 [==============================] - 0s 28us/sample - loss: 0.2378 - mean_absolute_error: 0.2378 - soft_acc: 0.8778 - val_loss: 0.5046 - val_mean_absolute_error: 0.5046 - val_soft_acc: 0.6014\n",
      "Epoch 1865/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2194 - mean_absolute_error: 0.2194 - soft_acc: 0.8911 - val_loss: 0.4840 - val_mean_absolute_error: 0.4840 - val_soft_acc: 0.5907\n",
      "Epoch 1866/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2385 - mean_absolute_error: 0.2385 - soft_acc: 0.8833 - val_loss: 0.5094 - val_mean_absolute_error: 0.5094 - val_soft_acc: 0.5400\n",
      "Epoch 1867/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2122 - mean_absolute_error: 0.2122 - soft_acc: 0.8922 - val_loss: 0.4904 - val_mean_absolute_error: 0.4904 - val_soft_acc: 0.5936\n",
      "Epoch 1868/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2234 - mean_absolute_error: 0.2234 - soft_acc: 0.8744 - val_loss: 0.4967 - val_mean_absolute_error: 0.4967 - val_soft_acc: 0.5757\n",
      "Epoch 1869/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2050 - mean_absolute_error: 0.2050 - soft_acc: 0.8978 - val_loss: 0.5338 - val_mean_absolute_error: 0.5338 - val_soft_acc: 0.6143\n",
      "Epoch 1870/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2573 - mean_absolute_error: 0.2573 - soft_acc: 0.8561 - val_loss: 0.5034 - val_mean_absolute_error: 0.5034 - val_soft_acc: 0.6014\n",
      "Epoch 1871/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3110 - mean_absolute_error: 0.3110 - soft_acc: 0.7922 - val_loss: 0.4751 - val_mean_absolute_error: 0.4751 - val_soft_acc: 0.5857\n",
      "Epoch 1872/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2474 - mean_absolute_error: 0.2474 - soft_acc: 0.8439 - val_loss: 0.5392 - val_mean_absolute_error: 0.5392 - val_soft_acc: 0.4943\n",
      "Epoch 1873/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2435 - mean_absolute_error: 0.2435 - soft_acc: 0.8661 - val_loss: 0.5311 - val_mean_absolute_error: 0.5311 - val_soft_acc: 0.5557\n",
      "Epoch 1874/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2689 - mean_absolute_error: 0.2689 - soft_acc: 0.8300 - val_loss: 0.4723 - val_mean_absolute_error: 0.4723 - val_soft_acc: 0.5929\n",
      "Epoch 1875/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2619 - mean_absolute_error: 0.2619 - soft_acc: 0.8594 - val_loss: 0.4792 - val_mean_absolute_error: 0.4792 - val_soft_acc: 0.5507\n",
      "Epoch 1876/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2376 - mean_absolute_error: 0.2376 - soft_acc: 0.8511 - val_loss: 0.5142 - val_mean_absolute_error: 0.5142 - val_soft_acc: 0.5586\n",
      "Epoch 1877/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2669 - mean_absolute_error: 0.2669 - soft_acc: 0.8461 - val_loss: 0.5262 - val_mean_absolute_error: 0.5262 - val_soft_acc: 0.5836\n",
      "Epoch 1878/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2141 - mean_absolute_error: 0.2141 - soft_acc: 0.8983 - val_loss: 0.5703 - val_mean_absolute_error: 0.5703 - val_soft_acc: 0.5300\n",
      "Epoch 1879/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.3103 - mean_absolute_error: 0.3103 - soft_acc: 0.7939 - val_loss: 0.4870 - val_mean_absolute_error: 0.4870 - val_soft_acc: 0.5014\n",
      "Epoch 1880/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2498 - mean_absolute_error: 0.2498 - soft_acc: 0.8578 - val_loss: 0.5244 - val_mean_absolute_error: 0.5244 - val_soft_acc: 0.5707\n",
      "Epoch 1881/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2170 - mean_absolute_error: 0.2170 - soft_acc: 0.8594 - val_loss: 0.5081 - val_mean_absolute_error: 0.5081 - val_soft_acc: 0.6064\n",
      "Epoch 1882/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2444 - mean_absolute_error: 0.2444 - soft_acc: 0.8294 - val_loss: 0.5085 - val_mean_absolute_error: 0.5085 - val_soft_acc: 0.5529\n",
      "Epoch 1883/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2098 - mean_absolute_error: 0.2098 - soft_acc: 0.8683 - val_loss: 0.5012 - val_mean_absolute_error: 0.5012 - val_soft_acc: 0.5857\n",
      "Epoch 1884/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2301 - mean_absolute_error: 0.2301 - soft_acc: 0.8539 - val_loss: 0.5325 - val_mean_absolute_error: 0.5325 - val_soft_acc: 0.5914\n",
      "Epoch 1885/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2348 - mean_absolute_error: 0.2348 - soft_acc: 0.8517 - val_loss: 0.5265 - val_mean_absolute_error: 0.5265 - val_soft_acc: 0.5736\n",
      "Epoch 1886/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2194 - mean_absolute_error: 0.2194 - soft_acc: 0.8706 - val_loss: 0.4836 - val_mean_absolute_error: 0.4836 - val_soft_acc: 0.5650\n",
      "Epoch 1887/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2124 - mean_absolute_error: 0.2124 - soft_acc: 0.9100 - val_loss: 0.5602 - val_mean_absolute_error: 0.5602 - val_soft_acc: 0.5071\n",
      "Epoch 1888/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2489 - mean_absolute_error: 0.2489 - soft_acc: 0.8472 - val_loss: 0.5499 - val_mean_absolute_error: 0.5499 - val_soft_acc: 0.5429\n",
      "Epoch 1889/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.3303 - mean_absolute_error: 0.3303 - soft_acc: 0.7928 - val_loss: 0.5142 - val_mean_absolute_error: 0.5142 - val_soft_acc: 0.5221\n",
      "Epoch 1890/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2411 - mean_absolute_error: 0.2411 - soft_acc: 0.8483 - val_loss: 0.4857 - val_mean_absolute_error: 0.4857 - val_soft_acc: 0.5907\n",
      "Epoch 1891/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2580 - mean_absolute_error: 0.2580 - soft_acc: 0.8511 - val_loss: 0.4936 - val_mean_absolute_error: 0.4936 - val_soft_acc: 0.6343\n",
      "Epoch 1892/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2948 - mean_absolute_error: 0.2948 - soft_acc: 0.7989 - val_loss: 0.5245 - val_mean_absolute_error: 0.5245 - val_soft_acc: 0.5486\n",
      "Epoch 1893/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2346 - mean_absolute_error: 0.2346 - soft_acc: 0.8661 - val_loss: 0.4868 - val_mean_absolute_error: 0.4868 - val_soft_acc: 0.5421\n",
      "Epoch 1894/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2138 - mean_absolute_error: 0.2138 - soft_acc: 0.9028 - val_loss: 0.4996 - val_mean_absolute_error: 0.4996 - val_soft_acc: 0.6171\n",
      "Epoch 1895/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1889 - mean_absolute_error: 0.1889 - soft_acc: 0.9111 - val_loss: 0.5222 - val_mean_absolute_error: 0.5222 - val_soft_acc: 0.5300\n",
      "Epoch 1896/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2075 - mean_absolute_error: 0.2075 - soft_acc: 0.8783 - val_loss: 0.5343 - val_mean_absolute_error: 0.5343 - val_soft_acc: 0.5500\n",
      "Epoch 1897/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2174 - mean_absolute_error: 0.2174 - soft_acc: 0.8756 - val_loss: 0.5080 - val_mean_absolute_error: 0.5080 - val_soft_acc: 0.5579\n",
      "Epoch 1898/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2017 - mean_absolute_error: 0.2017 - soft_acc: 0.9011 - val_loss: 0.5081 - val_mean_absolute_error: 0.5081 - val_soft_acc: 0.6143\n",
      "Epoch 1899/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2263 - mean_absolute_error: 0.2263 - soft_acc: 0.8606 - val_loss: 0.4892 - val_mean_absolute_error: 0.4892 - val_soft_acc: 0.5936\n",
      "Epoch 1900/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2324 - mean_absolute_error: 0.2324 - soft_acc: 0.8950 - val_loss: 0.5227 - val_mean_absolute_error: 0.5227 - val_soft_acc: 0.5350\n",
      "Epoch 1901/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1941 - mean_absolute_error: 0.1941 - soft_acc: 0.9028 - val_loss: 0.4701 - val_mean_absolute_error: 0.4701 - val_soft_acc: 0.6393\n",
      "Epoch 1902/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1922 - mean_absolute_error: 0.1922 - soft_acc: 0.9150 - val_loss: 0.5051 - val_mean_absolute_error: 0.5051 - val_soft_acc: 0.5707\n",
      "Epoch 1903/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1985 - mean_absolute_error: 0.1985 - soft_acc: 0.9150 - val_loss: 0.4983 - val_mean_absolute_error: 0.4983 - val_soft_acc: 0.5121\n",
      "Epoch 1904/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2122 - mean_absolute_error: 0.2122 - soft_acc: 0.9083 - val_loss: 0.4821 - val_mean_absolute_error: 0.4821 - val_soft_acc: 0.6036\n",
      "Epoch 1905/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2174 - mean_absolute_error: 0.2174 - soft_acc: 0.8706 - val_loss: 0.5745 - val_mean_absolute_error: 0.5745 - val_soft_acc: 0.4893\n",
      "Epoch 1906/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1972 - mean_absolute_error: 0.1972 - soft_acc: 0.9094 - val_loss: 0.5061 - val_mean_absolute_error: 0.5061 - val_soft_acc: 0.5529\n",
      "Epoch 1907/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1880 - mean_absolute_error: 0.1880 - soft_acc: 0.9028 - val_loss: 0.5136 - val_mean_absolute_error: 0.5136 - val_soft_acc: 0.6064\n",
      "Epoch 1908/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2027 - mean_absolute_error: 0.2027 - soft_acc: 0.9078 - val_loss: 0.4904 - val_mean_absolute_error: 0.4904 - val_soft_acc: 0.6143\n",
      "Epoch 1909/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2089 - mean_absolute_error: 0.2089 - soft_acc: 0.8683 - val_loss: 0.5052 - val_mean_absolute_error: 0.5052 - val_soft_acc: 0.6500\n",
      "Epoch 1910/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1924 - mean_absolute_error: 0.1924 - soft_acc: 0.8972 - val_loss: 0.5181 - val_mean_absolute_error: 0.5181 - val_soft_acc: 0.5964\n",
      "Epoch 1911/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2042 - mean_absolute_error: 0.2042 - soft_acc: 0.9044 - val_loss: 0.5001 - val_mean_absolute_error: 0.5001 - val_soft_acc: 0.5550\n",
      "Epoch 1912/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2011 - mean_absolute_error: 0.2011 - soft_acc: 0.8661 - val_loss: 0.4984 - val_mean_absolute_error: 0.4984 - val_soft_acc: 0.5836\n",
      "Epoch 1913/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.1982 - mean_absolute_error: 0.1982 - soft_acc: 0.8867 - val_loss: 0.5726 - val_mean_absolute_error: 0.5726 - val_soft_acc: 0.5100\n",
      "Epoch 1914/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2500 - mean_absolute_error: 0.2500 - soft_acc: 0.8433 - val_loss: 0.5321 - val_mean_absolute_error: 0.5321 - val_soft_acc: 0.5550\n",
      "Epoch 1915/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2355 - mean_absolute_error: 0.2355 - soft_acc: 0.8833 - val_loss: 0.4847 - val_mean_absolute_error: 0.4847 - val_soft_acc: 0.5757\n",
      "Epoch 1916/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2314 - mean_absolute_error: 0.2314 - soft_acc: 0.8694 - val_loss: 0.5464 - val_mean_absolute_error: 0.5464 - val_soft_acc: 0.5964\n",
      "Epoch 1917/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2773 - mean_absolute_error: 0.2773 - soft_acc: 0.8361 - val_loss: 0.5235 - val_mean_absolute_error: 0.5235 - val_soft_acc: 0.5786\n",
      "Epoch 1918/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1982 - mean_absolute_error: 0.1982 - soft_acc: 0.9061 - val_loss: 0.5210 - val_mean_absolute_error: 0.5210 - val_soft_acc: 0.5557\n",
      "Epoch 1919/3000\n",
      "512/512 [==============================] - 0s 13us/sample - loss: 0.1968 - mean_absolute_error: 0.1968 - soft_acc: 0.9200 - val_loss: 0.5112 - val_mean_absolute_error: 0.5112 - val_soft_acc: 0.5329\n",
      "Epoch 1920/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1888 - mean_absolute_error: 0.1888 - soft_acc: 0.8867 - val_loss: 0.5118 - val_mean_absolute_error: 0.5118 - val_soft_acc: 0.5450\n",
      "Epoch 1921/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1844 - mean_absolute_error: 0.1844 - soft_acc: 0.9178 - val_loss: 0.5148 - val_mean_absolute_error: 0.5148 - val_soft_acc: 0.6114\n",
      "Epoch 1922/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2003 - mean_absolute_error: 0.2003 - soft_acc: 0.8944 - val_loss: 0.5322 - val_mean_absolute_error: 0.5322 - val_soft_acc: 0.5757\n",
      "Epoch 1923/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.1956 - mean_absolute_error: 0.1956 - soft_acc: 0.8850 - val_loss: 0.5026 - val_mean_absolute_error: 0.5026 - val_soft_acc: 0.5521\n",
      "Epoch 1924/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2419 - mean_absolute_error: 0.2419 - soft_acc: 0.8644 - val_loss: 0.5434 - val_mean_absolute_error: 0.5434 - val_soft_acc: 0.5357\n",
      "Epoch 1925/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.2635 - mean_absolute_error: 0.2635 - soft_acc: 0.8283 - val_loss: 0.5427 - val_mean_absolute_error: 0.5427 - val_soft_acc: 0.6093\n",
      "Epoch 1926/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.3446 - mean_absolute_error: 0.3446 - soft_acc: 0.7689 - val_loss: 0.5323 - val_mean_absolute_error: 0.5323 - val_soft_acc: 0.5321\n",
      "Epoch 1927/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2906 - mean_absolute_error: 0.2906 - soft_acc: 0.7528 - val_loss: 0.5485 - val_mean_absolute_error: 0.5485 - val_soft_acc: 0.5857\n",
      "Epoch 1928/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.3105 - mean_absolute_error: 0.3105 - soft_acc: 0.8044 - val_loss: 0.5741 - val_mean_absolute_error: 0.5741 - val_soft_acc: 0.5350\n",
      "Epoch 1929/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2541 - mean_absolute_error: 0.2541 - soft_acc: 0.8667 - val_loss: 0.5256 - val_mean_absolute_error: 0.5256 - val_soft_acc: 0.5679\n",
      "Epoch 1930/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2263 - mean_absolute_error: 0.2263 - soft_acc: 0.8728 - val_loss: 0.5367 - val_mean_absolute_error: 0.5367 - val_soft_acc: 0.5786\n",
      "Epoch 1931/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2308 - mean_absolute_error: 0.2308 - soft_acc: 0.8572 - val_loss: 0.5289 - val_mean_absolute_error: 0.5289 - val_soft_acc: 0.5450\n",
      "Epoch 1932/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2064 - mean_absolute_error: 0.2064 - soft_acc: 0.8956 - val_loss: 0.5258 - val_mean_absolute_error: 0.5258 - val_soft_acc: 0.5557\n",
      "Epoch 1933/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2163 - mean_absolute_error: 0.2163 - soft_acc: 0.8794 - val_loss: 0.5089 - val_mean_absolute_error: 0.5089 - val_soft_acc: 0.5171\n",
      "Epoch 1934/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2177 - mean_absolute_error: 0.2177 - soft_acc: 0.8872 - val_loss: 0.5156 - val_mean_absolute_error: 0.5156 - val_soft_acc: 0.5993\n",
      "Epoch 1935/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2310 - mean_absolute_error: 0.2310 - soft_acc: 0.8606 - val_loss: 0.5954 - val_mean_absolute_error: 0.5954 - val_soft_acc: 0.5000\n",
      "Epoch 1936/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2332 - mean_absolute_error: 0.2332 - soft_acc: 0.8606 - val_loss: 0.5629 - val_mean_absolute_error: 0.5629 - val_soft_acc: 0.5507\n",
      "Epoch 1937/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.2627 - mean_absolute_error: 0.2627 - soft_acc: 0.8667 - val_loss: 0.5486 - val_mean_absolute_error: 0.5486 - val_soft_acc: 0.5886\n",
      "Epoch 1938/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2137 - mean_absolute_error: 0.2137 - soft_acc: 0.8961 - val_loss: 0.5505 - val_mean_absolute_error: 0.5505 - val_soft_acc: 0.5636\n",
      "Epoch 1939/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.2269 - mean_absolute_error: 0.2269 - soft_acc: 0.88 - 0s 41us/sample - loss: 0.2180 - mean_absolute_error: 0.2180 - soft_acc: 0.8806 - val_loss: 0.4911 - val_mean_absolute_error: 0.4911 - val_soft_acc: 0.5529\n",
      "Epoch 1940/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2048 - mean_absolute_error: 0.2048 - soft_acc: 0.8783 - val_loss: 0.4637 - val_mean_absolute_error: 0.4637 - val_soft_acc: 0.5936\n",
      "Epoch 1941/3000\n",
      "512/512 [==============================] - 0s 19us/sample - loss: 0.2116 - mean_absolute_error: 0.2116 - soft_acc: 0.8928 - val_loss: 0.5163 - val_mean_absolute_error: 0.5163 - val_soft_acc: 0.5171\n",
      "Epoch 1942/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2072 - mean_absolute_error: 0.2072 - soft_acc: 0.9217 - val_loss: 0.5145 - val_mean_absolute_error: 0.5145 - val_soft_acc: 0.5886\n",
      "Epoch 1943/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2168 - mean_absolute_error: 0.2168 - soft_acc: 0.8978 - val_loss: 0.4838 - val_mean_absolute_error: 0.4838 - val_soft_acc: 0.5986\n",
      "Epoch 1944/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2318 - mean_absolute_error: 0.2318 - soft_acc: 0.8311 - val_loss: 0.5198 - val_mean_absolute_error: 0.5198 - val_soft_acc: 0.5764\n",
      "Epoch 1945/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2272 - mean_absolute_error: 0.2272 - soft_acc: 0.8811 - val_loss: 0.4850 - val_mean_absolute_error: 0.4850 - val_soft_acc: 0.5629\n",
      "Epoch 1946/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2324 - mean_absolute_error: 0.2324 - soft_acc: 0.8894 - val_loss: 0.5341 - val_mean_absolute_error: 0.5341 - val_soft_acc: 0.5150\n",
      "Epoch 1947/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.2170 - mean_absolute_error: 0.2170 - soft_acc: 0.8839 - val_loss: 0.5183 - val_mean_absolute_error: 0.5183 - val_soft_acc: 0.6243\n",
      "Epoch 1948/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2268 - mean_absolute_error: 0.2268 - soft_acc: 0.8967 - val_loss: 0.5191 - val_mean_absolute_error: 0.5191 - val_soft_acc: 0.5993\n",
      "Epoch 1949/3000\n",
      "512/512 [==============================] - 0s 14us/sample - loss: 0.2108 - mean_absolute_error: 0.2108 - soft_acc: 0.8961 - val_loss: 0.5321 - val_mean_absolute_error: 0.5321 - val_soft_acc: 0.5836\n",
      "Epoch 1950/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2079 - mean_absolute_error: 0.2079 - soft_acc: 0.8789 - val_loss: 0.5234 - val_mean_absolute_error: 0.5234 - val_soft_acc: 0.5164\n",
      "Epoch 1951/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.3084 - mean_absolute_error: 0.3084 - soft_acc: 0.7850 - val_loss: 0.5571 - val_mean_absolute_error: 0.5571 - val_soft_acc: 0.5507\n",
      "Epoch 1952/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.3096 - mean_absolute_error: 0.3096 - soft_acc: 0.7711 - val_loss: 0.5293 - val_mean_absolute_error: 0.5293 - val_soft_acc: 0.5093\n",
      "Epoch 1953/3000\n",
      "512/512 [==============================] - 0s 16us/sample - loss: 0.3227 - mean_absolute_error: 0.3227 - soft_acc: 0.7789 - val_loss: 0.5302 - val_mean_absolute_error: 0.5302 - val_soft_acc: 0.5886\n",
      "Epoch 1954/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2972 - mean_absolute_error: 0.2972 - soft_acc: 0.7878 - val_loss: 0.5083 - val_mean_absolute_error: 0.5083 - val_soft_acc: 0.5471\n",
      "Epoch 1955/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2321 - mean_absolute_error: 0.2321 - soft_acc: 0.8317 - val_loss: 0.5372 - val_mean_absolute_error: 0.5372 - val_soft_acc: 0.5729\n",
      "Epoch 1956/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2221 - mean_absolute_error: 0.2221 - soft_acc: 0.8967 - val_loss: 0.5609 - val_mean_absolute_error: 0.5609 - val_soft_acc: 0.5814\n",
      "Epoch 1957/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2119 - mean_absolute_error: 0.2119 - soft_acc: 0.8961 - val_loss: 0.5007 - val_mean_absolute_error: 0.5007 - val_soft_acc: 0.5450\n",
      "Epoch 1958/3000\n",
      "512/512 [==============================] - 0s 32us/sample - loss: 0.1961 - mean_absolute_error: 0.1961 - soft_acc: 0.9178 - val_loss: 0.4992 - val_mean_absolute_error: 0.4992 - val_soft_acc: 0.5757\n",
      "Epoch 1959/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2178 - mean_absolute_error: 0.2178 - soft_acc: 0.8967 - val_loss: 0.5209 - val_mean_absolute_error: 0.5209 - val_soft_acc: 0.5786\n",
      "Epoch 1960/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.2060 - mean_absolute_error: 0.2060 - soft_acc: 0.8972 - val_loss: 0.5539 - val_mean_absolute_error: 0.5539 - val_soft_acc: 0.5279\n",
      "Epoch 1961/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2535 - mean_absolute_error: 0.2535 - soft_acc: 0.8250 - val_loss: 0.5259 - val_mean_absolute_error: 0.5259 - val_soft_acc: 0.5457\n",
      "Epoch 1962/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2068 - mean_absolute_error: 0.2068 - soft_acc: 0.8789 - val_loss: 0.4649 - val_mean_absolute_error: 0.4649 - val_soft_acc: 0.5886\n",
      "Epoch 1963/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2049 - mean_absolute_error: 0.2049 - soft_acc: 0.9028 - val_loss: 0.4811 - val_mean_absolute_error: 0.4811 - val_soft_acc: 0.5686\n",
      "Epoch 1964/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2141 - mean_absolute_error: 0.2141 - soft_acc: 0.9033 - val_loss: 0.4571 - val_mean_absolute_error: 0.4571 - val_soft_acc: 0.6600\n",
      "Epoch 1965/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2572 - mean_absolute_error: 0.2572 - soft_acc: 0.8583 - val_loss: 0.4702 - val_mean_absolute_error: 0.4702 - val_soft_acc: 0.5707\n",
      "Epoch 1966/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2280 - mean_absolute_error: 0.2280 - soft_acc: 0.8622 - val_loss: 0.5223 - val_mean_absolute_error: 0.5223 - val_soft_acc: 0.5229\n",
      "Epoch 1967/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2402 - mean_absolute_error: 0.2402 - soft_acc: 0.8522 - val_loss: 0.4770 - val_mean_absolute_error: 0.4770 - val_soft_acc: 0.5400\n",
      "Epoch 1968/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2520 - mean_absolute_error: 0.2520 - soft_acc: 0.8650 - val_loss: 0.4951 - val_mean_absolute_error: 0.4951 - val_soft_acc: 0.5786\n",
      "Epoch 1969/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.2185 - mean_absolute_error: 0.2185 - soft_acc: 0.8717 - val_loss: 0.4805 - val_mean_absolute_error: 0.4805 - val_soft_acc: 0.5429\n",
      "Epoch 1970/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.1944 - mean_absolute_error: 0.1944 - soft_acc: 0.9100 - val_loss: 0.4556 - val_mean_absolute_error: 0.4556 - val_soft_acc: 0.5786\n",
      "Epoch 1971/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2015 - mean_absolute_error: 0.2015 - soft_acc: 0.9028 - val_loss: 0.4623 - val_mean_absolute_error: 0.4623 - val_soft_acc: 0.5471\n",
      "Epoch 1972/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2057 - mean_absolute_error: 0.2057 - soft_acc: 0.8772 - val_loss: 0.4892 - val_mean_absolute_error: 0.4892 - val_soft_acc: 0.6014\n",
      "Epoch 1973/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2184 - mean_absolute_error: 0.2184 - soft_acc: 0.8911 - val_loss: 0.5081 - val_mean_absolute_error: 0.5081 - val_soft_acc: 0.5836\n",
      "Epoch 1974/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1895 - mean_absolute_error: 0.1895 - soft_acc: 0.9250 - val_loss: 0.5121 - val_mean_absolute_error: 0.5121 - val_soft_acc: 0.5814\n",
      "Epoch 1975/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2101 - mean_absolute_error: 0.2101 - soft_acc: 0.9133 - val_loss: 0.5155 - val_mean_absolute_error: 0.5155 - val_soft_acc: 0.5629\n",
      "Epoch 1976/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1860 - mean_absolute_error: 0.1860 - soft_acc: 0.9211 - val_loss: 0.5018 - val_mean_absolute_error: 0.5018 - val_soft_acc: 0.6043\n",
      "Epoch 1977/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2259 - mean_absolute_error: 0.2259 - soft_acc: 0.8828 - val_loss: 0.4720 - val_mean_absolute_error: 0.4720 - val_soft_acc: 0.5936\n",
      "Epoch 1978/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2478 - mean_absolute_error: 0.2478 - soft_acc: 0.8578 - val_loss: 0.5208 - val_mean_absolute_error: 0.5208 - val_soft_acc: 0.5686\n",
      "Epoch 1979/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.3066 - mean_absolute_error: 0.3066 - soft_acc: 0.7800 - val_loss: 0.5246 - val_mean_absolute_error: 0.5246 - val_soft_acc: 0.5271\n",
      "Epoch 1980/3000\n",
      "512/512 [==============================] - 0s 40us/sample - loss: 0.2557 - mean_absolute_error: 0.2557 - soft_acc: 0.8633 - val_loss: 0.5214 - val_mean_absolute_error: 0.5214 - val_soft_acc: 0.6121\n",
      "Epoch 1981/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.2344 - mean_absolute_error: 0.2344 - soft_acc: 0.8544 - val_loss: 0.5761 - val_mean_absolute_error: 0.5761 - val_soft_acc: 0.5171\n",
      "Epoch 1982/3000\n",
      "512/512 [==============================] - 0s 44us/sample - loss: 0.2275 - mean_absolute_error: 0.2275 - soft_acc: 0.8967 - val_loss: 0.5337 - val_mean_absolute_error: 0.5337 - val_soft_acc: 0.5557\n",
      "Epoch 1983/3000\n",
      "512/512 [==============================] - 0s 45us/sample - loss: 0.2598 - mean_absolute_error: 0.2598 - soft_acc: 0.8578 - val_loss: 0.5529 - val_mean_absolute_error: 0.5529 - val_soft_acc: 0.5586\n",
      "Epoch 1984/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2743 - mean_absolute_error: 0.2743 - soft_acc: 0.8100 - val_loss: 0.5233 - val_mean_absolute_error: 0.5233 - val_soft_acc: 0.5400\n",
      "Epoch 1985/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2027 - mean_absolute_error: 0.2027 - soft_acc: 0.8917 - val_loss: 0.4987 - val_mean_absolute_error: 0.4987 - val_soft_acc: 0.5964\n",
      "Epoch 1986/3000\n",
      "512/512 [==============================] - 0s 25us/sample - loss: 0.2080 - mean_absolute_error: 0.2080 - soft_acc: 0.9133 - val_loss: 0.4815 - val_mean_absolute_error: 0.4815 - val_soft_acc: 0.6064\n",
      "Epoch 1987/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2044 - mean_absolute_error: 0.2044 - soft_acc: 0.9183 - val_loss: 0.4843 - val_mean_absolute_error: 0.4843 - val_soft_acc: 0.5936\n",
      "Epoch 1988/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2065 - mean_absolute_error: 0.2065 - soft_acc: 0.9133 - val_loss: 0.4974 - val_mean_absolute_error: 0.4974 - val_soft_acc: 0.5250\n",
      "Epoch 1989/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2232 - mean_absolute_error: 0.2232 - soft_acc: 0.8789 - val_loss: 0.5112 - val_mean_absolute_error: 0.5112 - val_soft_acc: 0.5679\n",
      "Epoch 1990/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.2893 - mean_absolute_error: 0.2893 - soft_acc: 0.8467 - val_loss: 0.5131 - val_mean_absolute_error: 0.5131 - val_soft_acc: 0.5664\n",
      "Epoch 1991/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.2479 - mean_absolute_error: 0.2479 - soft_acc: 0.8506 - val_loss: 0.5012 - val_mean_absolute_error: 0.5012 - val_soft_acc: 0.5371\n",
      "Epoch 1992/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1985 - mean_absolute_error: 0.1985 - soft_acc: 0.9111 - val_loss: 0.4857 - val_mean_absolute_error: 0.4857 - val_soft_acc: 0.5579\n",
      "Epoch 1993/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1993 - mean_absolute_error: 0.1993 - soft_acc: 0.9233 - val_loss: 0.4841 - val_mean_absolute_error: 0.4841 - val_soft_acc: 0.6064\n",
      "Epoch 1994/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1897 - mean_absolute_error: 0.1897 - soft_acc: 0.9022 - val_loss: 0.5341 - val_mean_absolute_error: 0.5341 - val_soft_acc: 0.5607\n",
      "Epoch 1995/3000\n",
      "512/512 [==============================] - 0s 27us/sample - loss: 0.1902 - mean_absolute_error: 0.1902 - soft_acc: 0.8989 - val_loss: 0.5296 - val_mean_absolute_error: 0.5296 - val_soft_acc: 0.5450\n",
      "Epoch 1996/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1848 - mean_absolute_error: 0.1848 - soft_acc: 0.8817 - val_loss: 0.5203 - val_mean_absolute_error: 0.5203 - val_soft_acc: 0.5936\n",
      "Epoch 1997/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2122 - mean_absolute_error: 0.2122 - soft_acc: 0.8844 - val_loss: 0.5158 - val_mean_absolute_error: 0.5158 - val_soft_acc: 0.5450\n",
      "Epoch 1998/3000\n",
      "512/512 [==============================] - 0s 15us/sample - loss: 0.2205 - mean_absolute_error: 0.2205 - soft_acc: 0.8822 - val_loss: 0.5315 - val_mean_absolute_error: 0.5315 - val_soft_acc: 0.5400\n",
      "Epoch 1999/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1972 - mean_absolute_error: 0.1972 - soft_acc: 0.9167 - val_loss: 0.4908 - val_mean_absolute_error: 0.4908 - val_soft_acc: 0.5450\n",
      "Epoch 2000/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.1876 - mean_absolute_error: 0.1876 - soft_acc: 0.9283 - val_loss: 0.5285 - val_mean_absolute_error: 0.5285 - val_soft_acc: 0.5121\n",
      "Epoch 2001/3000\n",
      "512/512 [==============================] - 0s 22us/sample - loss: 0.1798 - mean_absolute_error: 0.1798 - soft_acc: 0.9211 - val_loss: 0.4957 - val_mean_absolute_error: 0.4957 - val_soft_acc: 0.6243\n",
      "Epoch 2002/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2010 - mean_absolute_error: 0.2010 - soft_acc: 0.9217 - val_loss: 0.5092 - val_mean_absolute_error: 0.5092 - val_soft_acc: 0.6350\n",
      "Epoch 2003/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.2034 - mean_absolute_error: 0.2034 - soft_acc: 0.9100 - val_loss: 0.5477 - val_mean_absolute_error: 0.5477 - val_soft_acc: 0.5121\n",
      "Epoch 2004/3000\n",
      "512/512 [==============================] - 0s 43us/sample - loss: 0.2191 - mean_absolute_error: 0.2191 - soft_acc: 0.9133 - val_loss: 0.5112 - val_mean_absolute_error: 0.5112 - val_soft_acc: 0.5679\n",
      "Epoch 2005/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2153 - mean_absolute_error: 0.2153 - soft_acc: 0.8656 - val_loss: 0.5027 - val_mean_absolute_error: 0.5027 - val_soft_acc: 0.5757\n",
      "Epoch 2006/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.1940 - mean_absolute_error: 0.1940 - soft_acc: 0.9039 - val_loss: 0.4820 - val_mean_absolute_error: 0.4820 - val_soft_acc: 0.5907\n",
      "Epoch 2007/3000\n",
      "512/512 [==============================] - 0s 24us/sample - loss: 0.1952 - mean_absolute_error: 0.1952 - soft_acc: 0.8678 - val_loss: 0.5008 - val_mean_absolute_error: 0.5008 - val_soft_acc: 0.5636\n",
      "Epoch 2008/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2112 - mean_absolute_error: 0.2112 - soft_acc: 0.9133 - val_loss: 0.4959 - val_mean_absolute_error: 0.4959 - val_soft_acc: 0.5550\n",
      "Epoch 2009/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.1862 - mean_absolute_error: 0.1862 - soft_acc: 0.9044 - val_loss: 0.5007 - val_mean_absolute_error: 0.5007 - val_soft_acc: 0.5736\n",
      "Epoch 2010/3000\n",
      "512/512 [==============================] - 0s 18us/sample - loss: 0.1824 - mean_absolute_error: 0.1824 - soft_acc: 0.9078 - val_loss: 0.5190 - val_mean_absolute_error: 0.5190 - val_soft_acc: 0.5914\n",
      "Epoch 2011/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1833 - mean_absolute_error: 0.1833 - soft_acc: 0.9267 - val_loss: 0.5019 - val_mean_absolute_error: 0.5019 - val_soft_acc: 0.6064\n",
      "Epoch 2012/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2188 - mean_absolute_error: 0.2188 - soft_acc: 0.8494 - val_loss: 0.5179 - val_mean_absolute_error: 0.5179 - val_soft_acc: 0.5736\n",
      "Epoch 2013/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2122 - mean_absolute_error: 0.2122 - soft_acc: 0.8994 - val_loss: 0.5087 - val_mean_absolute_error: 0.5087 - val_soft_acc: 0.5786\n",
      "Epoch 2014/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.1846 - mean_absolute_error: 0.1846 - soft_acc: 0.8989 - val_loss: 0.5211 - val_mean_absolute_error: 0.5211 - val_soft_acc: 0.6064\n",
      "Epoch 2015/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1812 - mean_absolute_error: 0.1812 - soft_acc: 0.9111 - val_loss: 0.5219 - val_mean_absolute_error: 0.5219 - val_soft_acc: 0.5150\n",
      "Epoch 2016/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2015 - mean_absolute_error: 0.2015 - soft_acc: 0.9150 - val_loss: 0.5041 - val_mean_absolute_error: 0.5041 - val_soft_acc: 0.5936\n",
      "Epoch 2017/3000\n",
      "512/512 [==============================] - 0s 30us/sample - loss: 0.1965 - mean_absolute_error: 0.1965 - soft_acc: 0.9061 - val_loss: 0.5413 - val_mean_absolute_error: 0.5413 - val_soft_acc: 0.5429\n",
      "Epoch 2018/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.1809 - mean_absolute_error: 0.1809 - soft_acc: 0.9161 - val_loss: 0.5014 - val_mean_absolute_error: 0.5014 - val_soft_acc: 0.5529\n",
      "Epoch 2019/3000\n",
      "512/512 [==============================] - 0s 33us/sample - loss: 0.2179 - mean_absolute_error: 0.2179 - soft_acc: 0.8722 - val_loss: 0.5157 - val_mean_absolute_error: 0.5157 - val_soft_acc: 0.5579\n",
      "Epoch 2020/3000\n",
      "512/512 [==============================] - 0s 35us/sample - loss: 0.1990 - mean_absolute_error: 0.1990 - soft_acc: 0.9094 - val_loss: 0.4627 - val_mean_absolute_error: 0.4627 - val_soft_acc: 0.6086\n",
      "Epoch 2021/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2287 - mean_absolute_error: 0.2287 - soft_acc: 0.8844 - val_loss: 0.5057 - val_mean_absolute_error: 0.5057 - val_soft_acc: 0.5357\n",
      "Epoch 2022/3000\n",
      "512/512 [==============================] - 0s 34us/sample - loss: 0.1831 - mean_absolute_error: 0.1831 - soft_acc: 0.9178 - val_loss: 0.5032 - val_mean_absolute_error: 0.5032 - val_soft_acc: 0.5679\n",
      "Epoch 2023/3000\n",
      "512/512 [==============================] - 0s 39us/sample - loss: 0.2336 - mean_absolute_error: 0.2336 - soft_acc: 0.8822 - val_loss: 0.5023 - val_mean_absolute_error: 0.5023 - val_soft_acc: 0.6550\n",
      "Epoch 2024/3000\n",
      "512/512 [==============================] - 0s 42us/sample - loss: 0.2083 - mean_absolute_error: 0.2083 - soft_acc: 0.9011 - val_loss: 0.5185 - val_mean_absolute_error: 0.5185 - val_soft_acc: 0.6014\n",
      "Epoch 2025/3000\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.2325 - mean_absolute_error: 0.2325 - soft_acc: 0.90 - 0s 13us/sample - loss: 0.2222 - mean_absolute_error: 0.2222 - soft_acc: 0.8717 - val_loss: 0.5277 - val_mean_absolute_error: 0.5277 - val_soft_acc: 0.5786\n",
      "Epoch 2026/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.1850 - mean_absolute_error: 0.1850 - soft_acc: 0.9211 - val_loss: 0.5133 - val_mean_absolute_error: 0.5133 - val_soft_acc: 0.5757\n",
      "Epoch 2027/3000\n",
      "512/512 [==============================] - 0s 41us/sample - loss: 0.2360 - mean_absolute_error: 0.2360 - soft_acc: 0.8883 - val_loss: 0.5119 - val_mean_absolute_error: 0.5119 - val_soft_acc: 0.6014\n",
      "Epoch 2028/3000\n",
      "512/512 [==============================] - 0s 17us/sample - loss: 0.2134 - mean_absolute_error: 0.2134 - soft_acc: 0.8878 - val_loss: 0.4988 - val_mean_absolute_error: 0.4988 - val_soft_acc: 0.5807\n",
      "Epoch 2029/3000\n",
      "512/512 [==============================] - 0s 36us/sample - loss: 0.2093 - mean_absolute_error: 0.2093 - soft_acc: 0.8856 - val_loss: 0.4935 - val_mean_absolute_error: 0.4935 - val_soft_acc: 0.5679\n",
      "Epoch 2030/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2059 - mean_absolute_error: 0.2059 - soft_acc: 0.8756 - val_loss: 0.5457 - val_mean_absolute_error: 0.5457 - val_soft_acc: 0.4864\n",
      "Epoch 2031/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2449 - mean_absolute_error: 0.2449 - soft_acc: 0.8244 - val_loss: 0.5159 - val_mean_absolute_error: 0.5159 - val_soft_acc: 0.5986\n",
      "Epoch 2032/3000\n",
      "512/512 [==============================] - 0s 23us/sample - loss: 0.2192 - mean_absolute_error: 0.2192 - soft_acc: 0.8583 - val_loss: 0.4561 - val_mean_absolute_error: 0.4561 - val_soft_acc: 0.6264\n",
      "Epoch 2033/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2323 - mean_absolute_error: 0.2323 - soft_acc: 0.8694 - val_loss: 0.4807 - val_mean_absolute_error: 0.4807 - val_soft_acc: 0.5500\n",
      "Epoch 2034/3000\n",
      "512/512 [==============================] - 0s 20us/sample - loss: 0.2076 - mean_absolute_error: 0.2076 - soft_acc: 0.8839 - val_loss: 0.4930 - val_mean_absolute_error: 0.4930 - val_soft_acc: 0.5914\n",
      "Epoch 2035/3000\n",
      "512/512 [==============================] - 0s 29us/sample - loss: 0.1901 - mean_absolute_error: 0.1901 - soft_acc: 0.9039 - val_loss: 0.4765 - val_mean_absolute_error: 0.4765 - val_soft_acc: 0.5579\n",
      "Epoch 2036/3000\n",
      "512/512 [==============================] - 0s 37us/sample - loss: 0.2174 - mean_absolute_error: 0.2174 - soft_acc: 0.8600 - val_loss: 0.4941 - val_mean_absolute_error: 0.4941 - val_soft_acc: 0.5500\n",
      "Epoch 2037/3000\n",
      "512/512 [==============================] - 0s 12us/sample - loss: 0.2606 - mean_absolute_error: 0.2606 - soft_acc: 0.8233 - val_loss: 0.5247 - val_mean_absolute_error: 0.5247 - val_soft_acc: 0.5814\n",
      "Epoch 2038/3000\n",
      "512/512 [==============================] - 0s 31us/sample - loss: 0.2487 - mean_absolute_error: 0.2487 - soft_acc: 0.8717 - val_loss: 0.5719 - val_mean_absolute_error: 0.5719 - val_soft_acc: 0.5300\n",
      "Epoch 2039/3000\n",
      "512/512 [==============================] - 0s 38us/sample - loss: 0.2759 - mean_absolute_error: 0.2759 - soft_acc: 0.8239 - val_loss: 0.5141 - val_mean_absolute_error: 0.5141 - val_soft_acc: 0.5607\n",
      "Epoch 2040/3000\n",
      "512/512 [==============================] - 0s 26us/sample - loss: 0.2150 - mean_absolute_error: 0.2150 - soft_acc: 0.8928 - val_loss: 0.5028 - val_mean_absolute_error: 0.5028 - val_soft_acc: 0.5093\n",
      "Epoch 2041/3000\n",
      "512/512 [==============================] - 0s 696us/sample - loss: 0.2247 - mean_absolute_error: 0.2247 - soft_acc: 0.8600 - val_loss: 0.5410 - val_mean_absolute_error: 0.5410 - val_soft_acc: 0.4843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as KB\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "adam = Adam(lr=0.001)\n",
    "# def linear_custom(x):\n",
    "#     tmp = KB.tanh(x) + 1\n",
    "#     return tmp*4.5\n",
    "# get_custom_objects().update({'linear_custom': Activation(linear_custom)})\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return KB.mean(KB.equal(KB.round(y_true),KB.round(y_pred)))\n",
    "# This returns a tensor\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512,input_shape=(72,),activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(units=512,activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1024,activation='relu',kernel_initializer='normal'))\n",
    "# model.add(Dense(units=512,activation='relu',kernel_initializer='normal'))\n",
    "#model.add(Dense(units=512,activation='relu'))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "es = EarlyStopping(monitor='val_loss',patience=500,restore_best_weights=True)\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mae',soft_acc])\n",
    "train_history = model.fit(X, Y,validation_split=0.2, epochs=3000, batch_size=100,callbacks=[es])  # starts training\n",
    "ploting(train_history,model,'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def ploting(train_history,model,modeldir):\n",
    "    now = datetime.datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    os.mkdir('./static/'+modeldir)\n",
    "    plot_model(model, to_file='./static/'+modeldir+'model'+now+'.png',show_shapes=True)\n",
    "    plt.plot(train_history.history['loss']) \n",
    "    plt.plot(train_history.history['val_loss']) \n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.savefig('./static/'+modeldir+'model_loss_'+now+'.png')\n",
    "    plt.show()\n",
    "    plt.plot(train_history.history['soft_acc'])\n",
    "    plt.plot(train_history.history['val_soft_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.savefig('./static/'+modeldir+'model_acurracy_'+now+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "plot_model(model, to_file='./static/model'+now+'.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(train_history.history['soft_acc'])\n",
    "plt.plot(train_history.history['val_soft_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./static/model_acurracy_'+now+'.png')\n",
    "plt.show()\n",
    "# summarize history for loss \n",
    "plt.plot(train_history.history['loss']) \n",
    "plt.plot(train_history.history['val_loss']) \n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.savefig('./static/model_loss_'+now+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.234375"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_func(transfer_label(np.reshape(model.predict(X_test),(Y_test.shape[0],))),Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = transfer_label(np.reshape(model.predict(test_X),(test_X.shape[0],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 3., 1., 3., 2., 1., 4., 5., 2., 1., 2., 4., 3., 4., 3., 2.,\n",
       "       1., 1., 2., 3., 4., 3., 2., 1., 3., 2., 4., 5., 3., 4., 2., 3., 5.,\n",
       "       4., 5., 3., 4., 3., 2., 3., 2., 3., 4., 6., 2., 3., 3., 5., 5., 4.,\n",
       "       4., 2., 5., 6., 3., 3., 5., 3., 4., 3., 4., 5., 5., 3., 4., 2., 2.,\n",
       "       6., 4., 3., 6., 4., 2., 3., 4., 4., 6., 4., 4., 3., 3., 3., 4., 4.,\n",
       "       5., 4., 3., 4., 3., 4., 5., 4., 4., 4., 3., 4., 4., 3., 5., 4., 4.,\n",
       "       4., 5., 3., 6., 4., 5., 3., 2., 3., 3., 5., 4., 5., 3., 4., 3., 4.,\n",
       "       6., 4., 5., 4., 4., 4., 3., 4., 5., 5., 3., 3., 3., 3., 5., 5., 4.,\n",
       "       3., 4., 5., 4., 5., 5., 4., 2., 3., 3., 4., 5., 5., 6., 2., 2., 3.])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  label\n",
       "0     2017-04-01      2\n",
       "1     2017-04-02      1\n",
       "2     2017-04-03      3\n",
       "3     2017-04-04      1\n",
       "4     2017-04-05      3\n",
       "..           ...    ...\n",
       "148   2017-08-27      5\n",
       "149   2017-08-28      6\n",
       "150   2017-08-29      2\n",
       "151   2017-08-30      2\n",
       "152   2017-08-31      3\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nolabel = pd.read_csv('./test_nolabel.csv')\n",
    "test_label = pd.DataFrame()\n",
    "test_label['arrival_date'] = test_nolabel['arrival_date']\n",
    "test_label['label'] = test_Y.astype('int64')\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label.to_csv('./test_label_dnn_mae_metric'+now+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(train_history.history['val_soft_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6528571"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history.history['val_soft_acc'][575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76055557"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history.history['soft_acc'][575]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (np.array(train_history.history['val_soft_acc'])+np.array(train_history.history['soft_acc']))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27859, 72)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of bag score: 0.6889236846429683\n"
     ]
    }
   ],
   "source": [
    "# 全拿來 train\n",
    "clf = RandomForestRegressor(oob_score=True).fit(X,Y)\n",
    "Y_test_predict = clf.predict(test)\n",
    "print('out of bag score:',clf.oob_score_)\n",
    "# ******* predict adr、no agent ***********\n",
    "# out of bag score: 0.6998593881224198\n",
    "# ******* predict adr、with agent ***********\n",
    "# out of bag score: 0.7148486662759064\n",
    "# ******* predict adr、with agent，cut half features ***********\n",
    "# out of bag score: 0.6889236846429683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27859,)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再預測 revenue rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./test.csv')\n",
    "test_data['booking_total_revenue'] = Y_test_predict*(test_data['stays_in_week_nights']+test_data['stays_in_weekend_nights']+1)\n",
    "# test_data['booking_total_revenue'] = Y_test_predict\n",
    "test_data = combine_arrival_date(test_data)\n",
    "test_data = test_data.groupby('arrival_date').sum()\n",
    "test_data = test_data['booking_total_revenue']\n",
    "test_data = test_data.values\n",
    "test_data = np.reshape(test_data,(test_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nolabel = pd.read_csv('./test_nolabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train_data,not_use = preprocess_x(train)\n",
    "train_label = pd.read_csv('./train_label.csv').set_index('arrival_date').values\n",
    "train_label = np.reshape(train_label,(train_label.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 1)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 1)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date\n",
       "0     2017-04-01\n",
       "1     2017-04-02\n",
       "2     2017-04-03\n",
       "3     2017-04-04\n",
       "4     2017-04-05\n",
       "..           ...\n",
       "148   2017-08-27\n",
       "149   2017-08-28\n",
       "150   2017-08-29\n",
       "151   2017-08-30\n",
       "152   2017-08-31\n",
       "\n",
       "[153 rows x 1 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1171875"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = LinearRegression().fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "err_func(transfer_label(Y_val_predict),Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression with norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1171875"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = LinearRegression(normalize=True).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "err_func(transfer_label(Y_val_predict),Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1953125"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = OneVsRestClassifier(svm.SVC()).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "err_func(Y_val_predict,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[15  1  0  0  0  0  0]\n",
      " [ 1 23  2  0  0  0  0]\n",
      " [ 1  6 36  4  0  0  0]\n",
      " [ 0  0  1 20  2  0  0]\n",
      " [ 0  0  0  0  7  5  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(Y_val_predict,Y_test)\n",
    "plot_confusion_matrix(cm,classes=clf.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1484375"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = OneVsOneClassifier(svm.SVC()).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "err_func(Y_val_predict,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[15  1  0  0  0  0  0]\n",
      " [ 1 23  2  0  0  0  0]\n",
      " [ 1  6 36  3  0  0  0]\n",
      " [ 0  0  1 21  2  0  0]\n",
      " [ 0  0  0  0  7  1  0]\n",
      " [ 0  0  0  0  0  5  0]\n",
      " [ 0  0  0  0  0  0  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(Y_val_predict,Y_test)\n",
    "plot_confusion_matrix(cm,classes=clf.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO with SVC with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "#linear和 rbf : 0.1484375\n",
    "#poly : 0.140625\n",
    "#sigmoid : 1.78125\n",
    "#C=1000 : 0.125\n",
    "#C=10000 : 0.1328125\n",
    "#degree high performance bad with large C\n",
    "clf = OneVsOneClassifier(svm.SVC(kernel='poly',C=1000,degree=3)).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "err_func(Y_val_predict,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error: 0.186678125\n",
      "mean absolute error: 0.2265625\n",
      "r2 score: 0.9079198458574181\n",
      "adjusted r2 score: 0.9071890509832706\n",
      "out of bag score: 0.9233861177974241\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = RandomForestRegressor(oob_score=True).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "mse = np.mean((Y_val_predict - Y_test) ** 2)\n",
    "r_squared = clf.score(X_test, Y_test)\n",
    "adj_r_squared = r_squared - (1 - r_squared) * (X_test.shape[1] / (X_test.shape[0] - X_test.shape[1] - 1))\n",
    "mae = err_func(transfer_label(Y_val_predict),Y_test)\n",
    "print('mean square error:',mse)\n",
    "print('mean absolute error:',mae)\n",
    "print('r2 score:',r_squared)\n",
    "print('adjusted r2 score:',adj_r_squared)\n",
    "print('out of bag score:',clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.186678125\n",
      "out of bag score: 0.783203125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_data,train_label,test_size=0.2,random_state=0)\n",
    "clf = RandomForestClassifier(oob_score=True).fit(X_train,Y_train)\n",
    "Y_val_predict = clf.predict(X_test)\n",
    "mae = err_func(Y_val_predict,Y_test)\n",
    "print('mean absolute error:',mse)\n",
    "print('out of bag score:',clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsOneClassifier(svm.SVC(kernel='poly',C=1000,degree=3)).fit(train_data,train_label)\n",
    "test_predict = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression才需要\n",
    "clf = LinearRegression().fit(train_data,train_label)\n",
    "test_predict = clf.predict(test_data)\n",
    "test_predict = transfer_label(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 5, 2, 5, 3, 2, 6, 8, 4, 2, 3, 6, 5, 7, 5, 4, 2, 3, 3, 4, 6,\n",
       "       4, 2, 1, 5, 4, 6, 8, 4, 5, 3, 4, 5, 6, 5, 3, 5, 3, 3, 4, 3, 4, 4,\n",
       "       7, 3, 2, 4, 6, 6, 4, 4, 2, 4, 6, 3, 3, 6, 3, 4, 3, 4, 5, 6, 4, 5,\n",
       "       3, 2, 7, 5, 3, 6, 5, 2, 3, 4, 4, 6, 4, 5, 3, 3, 4, 4, 4, 5, 5, 4,\n",
       "       4, 3, 5, 5, 4, 5, 4, 2, 4, 3, 3, 5, 5, 4, 4, 3, 4, 6, 4, 5, 3, 2,\n",
       "       3, 3, 5, 5, 5, 3, 4, 4, 4, 6, 3, 5, 4, 4, 4, 4, 5, 5, 6, 3, 3, 4,\n",
       "       4, 6, 5, 4, 4, 5, 6, 5, 6, 5, 5, 2, 3, 4, 4, 6, 5, 7, 2, 2, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date  label\n",
       "0     2017-04-01      3\n",
       "1     2017-04-02      2\n",
       "2     2017-04-03      5\n",
       "3     2017-04-04      2\n",
       "4     2017-04-05      5\n",
       "..           ...    ...\n",
       "148   2017-08-27      5\n",
       "149   2017-08-28      7\n",
       "150   2017-08-29      2\n",
       "151   2017-08-30      2\n",
       "152   2017-08-31      4\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = pd.DataFrame()\n",
    "test_label['arrival_date'] = test_nolabel['arrival_date']\n",
    "test_label['label'] = test_predict.astype('int64')\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label.to_csv('./test_label_adr_dnn_linearRegression.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "?test_label.to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "dnn_1 = (0.960526,0.909091)\n",
    "dnn_2 = (0.618421,0.779221)\n",
    "dnn_3 = (0.894737,0.779221)\n",
    "dnn_4 = (0.644737,0.727273)\n",
    "dnn_5 = (0.802632,0.935065)\n",
    "dnn_adr_linear_rank = (0.881579,1.025974)\n",
    "ovo_agent=(1.907895,1.831169)\n",
    "linerar_agent = (1.697368,1.649351)\n",
    "linear = (1.618421,1.662338)\n",
    "linear_cut = (1.881579,1.857143)\n",
    "x = [dnn_1[0],dnn_2[0],dnn_3[0],dnn_4[0],dnn_5[0],dnn_adr_linear_rank[0],ovo_agent[0],linerar_agent[0],linear[0],linear_cut[0]]\n",
    "y = [dnn_1[1],dnn_2[1],dnn_3[1],dnn_4[1],dnn_5[1],dnn_adr_linear_rank[1],ovo_agent[1],linerar_agent[1],linear[1],linear_cut[1]]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xlim(0,2.5)\n",
    "plt.xlabel('Public score')\n",
    "plt.ylabel('Private score')\n",
    "plt.ylim(0,2.5)\n",
    "colors = cm.rainbow(np.linspace(0, 1, 5))\n",
    "plt.scatter(x[0:6], y[0:6], s=80,alpha=0.8,color=colors[0],label='Different approach DNN')\n",
    "plt.scatter(x[6:7], y[6:7], s=80,alpha=0.8,color=colors[1],label='Randomforest + OVO SVC')\n",
    "plt.scatter(x[7:8], y[7:8], s=80,alpha=0.8,color=colors[2],label='Randomforest with agent feature + linear regression')\n",
    "plt.scatter(x[8:9], y[8:9], s=80,alpha=0.8,color=colors[3],label='Randomforest + linear regression')\n",
    "plt.scatter(x[9:], y[9:], s=80,alpha=0.8,color=colors[4],label='Randomforest with half features + linear regression')\n",
    "plt.plot([0,2.5],[0,2.5],alpha=0.6,linestyle='dashed')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
